#!/usr/bin/env node
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));

// src/utils/logger.ts
function getCurrentLogLevel() {
  const shouldLog = process.argv.includes("--trace-logger") && !isInitializing;
  if (shouldLog) {
    console.error(`Debug: getCurrentLogLevel called, AI_CODE_REVIEW_LOG_LEVEL=${process.env.AI_CODE_REVIEW_LOG_LEVEL}`);
  }
  if (process.argv.includes("--debug")) {
    if (shouldLog) {
      console.error("Debug: Debug flag found in process.argv, forcing DEBUG level");
    }
    return 0 /* DEBUG */;
  }
  const envLogLevel = process.env.AI_CODE_REVIEW_LOG_LEVEL?.toLowerCase();
  if (envLogLevel) {
    if (shouldLog) {
      console.error(`Debug: Found AI_CODE_REVIEW_LOG_LEVEL environment variable: ${envLogLevel}`);
    }
    if (envLogLevel in LOG_LEVEL_MAP) {
      if (shouldLog) {
        console.error(`Debug: Mapped log level ${envLogLevel} -> ${LOG_LEVEL_MAP[envLogLevel]}`);
      }
      return LOG_LEVEL_MAP[envLogLevel];
    } else if (shouldLog) {
      console.error(`Debug: Invalid log level: ${envLogLevel}, valid options are: ${Object.keys(LOG_LEVEL_MAP).join(", ")}`);
    }
  } else if (shouldLog) {
    console.error("Debug: AI_CODE_REVIEW_LOG_LEVEL environment variable not found");
  }
  if (shouldLog) {
    console.error("Debug: No valid log level found, defaulting to INFO");
  }
  return 1 /* INFO */;
}
function setLogLevel(level) {
  const shouldLog = process.argv.includes("--trace-logger");
  if (shouldLog) {
    console.error(`Debug: setLogLevel called with ${level}`);
  }
  if (typeof level === "string") {
    const levelLower = level.toLowerCase();
    if (levelLower in LOG_LEVEL_MAP) {
      currentLogLevel = LOG_LEVEL_MAP[levelLower];
      if (shouldLog) {
        console.error(`Debug: Log level set to ${levelLower} -> ${currentLogLevel}`);
      }
    } else {
      console.warn(`Invalid log level: ${level}. Using default.`);
    }
  } else {
    currentLogLevel = level;
    if (shouldLog) {
      console.error(`Debug: Log level set to numeric value ${level}`);
    }
  }
}
function getLogLevel() {
  return currentLogLevel;
}
function formatLogMessage(level, message) {
  const timestamp = (/* @__PURE__ */ new Date()).toISOString();
  const levelUpper = level.toUpperCase().padEnd(5);
  return `${COLORS.time}[${timestamp}]${COLORS.reset} ${COLORS[level]}${levelUpper}${COLORS.reset} ${message}`;
}
function log(level, levelName, message, ...args) {
  if (level >= currentLogLevel) {
    const formattedMessage = formatLogMessage(levelName, message);
    switch (level) {
      case 0 /* DEBUG */:
        console.debug(formattedMessage, ...args);
        break;
      case 1 /* INFO */:
        console.log(formattedMessage, ...args);
        break;
      case 2 /* WARN */:
        console.warn(formattedMessage, ...args);
        break;
      case 3 /* ERROR */:
        console.error(formattedMessage, ...args);
        break;
    }
  } else if (level === 0 /* DEBUG */ && process.argv.includes("--trace-logger")) {
    console.error(`Suppressing DEBUG log because currentLogLevel=${currentLogLevel}, message was: ${message}`);
  }
}
function debug(message, ...args) {
  log(0 /* DEBUG */, "debug", message, ...args);
}
function info(message, ...args) {
  log(1 /* INFO */, "info", message, ...args);
}
function warn(message, ...args) {
  log(2 /* WARN */, "warn", message, ...args);
}
function error(message, ...args) {
  log(3 /* ERROR */, "error", message, ...args);
}
function createLogger(prefix) {
  return {
    debug: (message, ...args) => debug(`[${prefix}] ${message}`, ...args),
    info: (message, ...args) => info(`[${prefix}] ${message}`, ...args),
    warn: (message, ...args) => warn(`[${prefix}] ${message}`, ...args),
    error: (message, ...args) => error(`[${prefix}] ${message}`, ...args)
  };
}
var LogLevel, LOG_LEVEL_MAP, COLORS, isInitializing, currentLogLevel, logger_default;
var init_logger = __esm({
  "src/utils/logger.ts"() {
    "use strict";
    LogLevel = /* @__PURE__ */ ((LogLevel3) => {
      LogLevel3[LogLevel3["DEBUG"] = 0] = "DEBUG";
      LogLevel3[LogLevel3["INFO"] = 1] = "INFO";
      LogLevel3[LogLevel3["WARN"] = 2] = "WARN";
      LogLevel3[LogLevel3["ERROR"] = 3] = "ERROR";
      LogLevel3[LogLevel3["NONE"] = 4] = "NONE";
      return LogLevel3;
    })(LogLevel || {});
    LOG_LEVEL_MAP = {
      debug: 0 /* DEBUG */,
      info: 1 /* INFO */,
      warn: 2 /* WARN */,
      error: 3 /* ERROR */,
      none: 4 /* NONE */
    };
    COLORS = {
      reset: "\x1B[0m",
      dim: "\x1B[2m",
      bright: "\x1B[1m",
      debug: "\x1B[36m",
      // Cyan
      info: "\x1B[32m",
      // Green
      warn: "\x1B[33m",
      // Yellow
      error: "\x1B[31m",
      // Red
      time: "\x1B[90m"
      // Gray
    };
    isInitializing = false;
    currentLogLevel = getCurrentLogLevel();
    logger_default = {
      debug,
      info,
      warn,
      error,
      setLogLevel,
      getLogLevel,
      createLogger,
      LogLevel
    };
  }
});

// src/utils/envLoader.ts
var envLoader_exports = {};
__export(envLoader_exports, {
  getAnthropicApiKey: () => getAnthropicApiKey,
  getGoogleApiKey: () => getGoogleApiKey,
  getOpenAIApiKey: () => getOpenAIApiKey,
  getOpenRouterApiKey: () => getOpenRouterApiKey,
  loadEnvVariables: () => loadEnvVariables,
  validateRequiredEnvVars: () => validateRequiredEnvVars
});
function debugLog(message) {
  if (process.argv.includes("--debug") || process.env.AI_CODE_REVIEW_LOG_LEVEL?.toLowerCase() === "debug") {
    console.log(`\x1B[36m[DEBUG:ENV]\x1B[0m ${message}`);
  }
}
function traceEnvVarLoading(message) {
  console.log(`\x1B[35m[ENV-TRACE]\x1B[0m ${message}`);
}
async function loadEnvVariables(envFilePath) {
  try {
    let envLocalPath;
    if (envFilePath) {
      envLocalPath = envFilePath;
    } else {
      const projectEnvLocal = path.resolve(process.cwd(), ".env.local");
      const projectEnv = path.resolve(process.cwd(), ".env");
      try {
        await import_promises.default.access(projectEnvLocal);
        envLocalPath = projectEnvLocal;
        debugLog(`Found project-level .env.local: ${projectEnvLocal}`);
      } catch {
        try {
          await import_promises.default.access(projectEnv);
          envLocalPath = projectEnv;
          debugLog(`Found project-level .env: ${projectEnv}`);
        } catch {
          const possibleToolDirectories2 = [
            path.resolve(__dirname, "..", ".."),
            // Local development or npm link
            path.resolve(__dirname, "..", "..", ".."),
            // Global npm installation
            "/opt/homebrew/lib/node_modules/@bobmatnyc/ai-code-review"
            // Homebrew global installation
          ];
          if (process.env.AI_CODE_REVIEW_DIR) {
            possibleToolDirectories2.unshift(process.env.AI_CODE_REVIEW_DIR);
            debugLog(`Using tool directory from AI_CODE_REVIEW_DIR: ${process.env.AI_CODE_REVIEW_DIR}`);
          }
          envLocalPath = projectEnvLocal;
          for (const dir of possibleToolDirectories2) {
            const potentialEnvPath = path.resolve(dir, ".env.local");
            debugLog(`Checking for tool .env.local in: ${potentialEnvPath}`);
            try {
              await import_promises.default.access(potentialEnvPath);
              envLocalPath = potentialEnvPath;
              debugLog(`Found .env.local in tool directory: ${potentialEnvPath}`);
              break;
            } catch (statError) {
              debugLog(`No .env.local in ${potentialEnvPath}`);
            }
          }
        }
      }
    }
    try {
      await import_promises.default.access(envLocalPath);
    } catch (error2) {
      const errorMessage = error2 instanceof Error ? error2.message : "Unknown error";
      traceEnvVarLoading(`Environment file not found: ${envLocalPath} (${errorMessage}). Continuing without it.`);
      return {
        success: true,
        message: `No .env.local file found. You may need to set API keys via environment variables or command line options.`,
        envFile: envLocalPath
      };
    }
    traceEnvVarLoading(`Attempting to load environment variables from: ${envLocalPath}`);
    const beforeModel = process.env.AI_CODE_REVIEW_MODEL;
    const result = dotenv.config({ path: envLocalPath, override: true });
    if (beforeModel !== process.env.AI_CODE_REVIEW_MODEL) {
      traceEnvVarLoading(`AI_CODE_REVIEW_MODEL changed from '${beforeModel}' to '${process.env.AI_CODE_REVIEW_MODEL}'`);
    }
    if (result.error) {
      traceEnvVarLoading(`Error loading environment variables: ${result.error.message}`);
      return {
        success: false,
        message: `Error loading environment variables: ${result.error.message}`,
        envFile: envLocalPath
      };
    }
    traceEnvVarLoading(`Successfully loaded environment variables from ${envLocalPath}`);
    const envVarNames = Object.keys(result.parsed || {});
    if (envVarNames.length > 0) {
      traceEnvVarLoading("Variables found in .env.local (names only):");
      if (envVarNames.includes("AI_CODE_REVIEW_LOG_LEVEL")) {
        traceEnvVarLoading(`AI_CODE_REVIEW_LOG_LEVEL is set to: ${process.env.AI_CODE_REVIEW_LOG_LEVEL}`);
      } else {
        traceEnvVarLoading("AI_CODE_REVIEW_LOG_LEVEL is NOT present in .env.local");
      }
      debugLog(envVarNames.join(", "));
    } else {
      traceEnvVarLoading("No variables found in .env.local");
    }
    return {
      success: true,
      message: `Successfully loaded environment variables from ${envLocalPath}`,
      envFile: envLocalPath
    };
  } catch (error2) {
    const errorMessage = error2 instanceof Error ? error2.message : String(error2);
    console.error(`Error loading environment variables: ${errorMessage}`);
    return {
      success: false,
      message: `Unexpected error loading environment variables: ${errorMessage}`,
      envFile: envFilePath
    };
  }
}
function getGoogleApiKey() {
  const apiKeyNew = process.env.AI_CODE_REVIEW_GOOGLE_API_KEY;
  const apiKeyLegacy = process.env.CODE_REVIEW_GOOGLE_API_KEY;
  const apiKeyGenAI = process.env.GOOGLE_GENERATIVE_AI_KEY;
  const apiKeyStudio = process.env.GOOGLE_AI_STUDIO_KEY;
  if (apiKeyNew) {
    debugLog("Google API key found: AI_CODE_REVIEW_GOOGLE_API_KEY");
    return {
      apiKey: apiKeyNew,
      source: "AI_CODE_REVIEW_GOOGLE_API_KEY",
      message: "Using AI_CODE_REVIEW_GOOGLE_API_KEY"
    };
  }
  if (apiKeyLegacy) {
    console.warn(
      "Warning: Using deprecated environment variable CODE_REVIEW_GOOGLE_API_KEY. Please switch to AI_CODE_REVIEW_GOOGLE_API_KEY."
    );
    debugLog("Google API key found: CODE_REVIEW_GOOGLE_API_KEY (deprecated)");
    return {
      apiKey: apiKeyLegacy,
      source: "CODE_REVIEW_GOOGLE_API_KEY",
      message: "Using deprecated CODE_REVIEW_GOOGLE_API_KEY"
    };
  }
  if (apiKeyGenAI) {
    console.warn(
      "Warning: Using generic environment variable GOOGLE_GENERATIVE_AI_KEY. Consider using AI_CODE_REVIEW_GOOGLE_API_KEY for better isolation."
    );
    debugLog("Google API key found: GOOGLE_GENERATIVE_AI_KEY");
    return {
      apiKey: apiKeyGenAI,
      source: "GOOGLE_GENERATIVE_AI_KEY",
      message: "Using GOOGLE_GENERATIVE_AI_KEY"
    };
  }
  if (apiKeyStudio) {
    console.warn(
      "Warning: Using deprecated environment variable GOOGLE_AI_STUDIO_KEY. Please switch to AI_CODE_REVIEW_GOOGLE_API_KEY."
    );
    debugLog("Google API key found: GOOGLE_AI_STUDIO_KEY (deprecated)");
    return {
      apiKey: apiKeyStudio,
      source: "GOOGLE_AI_STUDIO_KEY",
      message: "Using deprecated GOOGLE_AI_STUDIO_KEY"
    };
  }
  return {
    apiKey: void 0,
    source: "none",
    message: "No Google API key found. Please set AI_CODE_REVIEW_GOOGLE_API_KEY in your .env.local file."
  };
}
function getOpenRouterApiKey() {
  const apiKeyNew = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY;
  const apiKeyLegacy = process.env.CODE_REVIEW_OPENROUTER_API_KEY;
  const apiKeyGeneric = process.env.OPENROUTER_API_KEY;
  if (apiKeyNew) {
    debugLog("OpenRouter API key found: AI_CODE_REVIEW_OPENROUTER_API_KEY");
    return {
      apiKey: apiKeyNew,
      source: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
      message: "Using AI_CODE_REVIEW_OPENROUTER_API_KEY"
    };
  }
  if (apiKeyLegacy) {
    console.warn(
      "Warning: Using deprecated environment variable CODE_REVIEW_OPENROUTER_API_KEY. Please switch to AI_CODE_REVIEW_OPENROUTER_API_KEY."
    );
    debugLog(
      "OpenRouter API key found: CODE_REVIEW_OPENROUTER_API_KEY (deprecated)"
    );
    return {
      apiKey: apiKeyLegacy,
      source: "CODE_REVIEW_OPENROUTER_API_KEY",
      message: "Using deprecated CODE_REVIEW_OPENROUTER_API_KEY"
    };
  }
  if (apiKeyGeneric) {
    console.warn(
      "Warning: Using generic environment variable OPENROUTER_API_KEY. Consider using AI_CODE_REVIEW_OPENROUTER_API_KEY for better isolation."
    );
    debugLog("OpenRouter API key found: OPENROUTER_API_KEY");
    return {
      apiKey: apiKeyGeneric,
      source: "OPENROUTER_API_KEY",
      message: "Using OPENROUTER_API_KEY"
    };
  }
  return {
    apiKey: void 0,
    source: "none",
    message: "No OpenRouter API key found. Please set AI_CODE_REVIEW_OPENROUTER_API_KEY in your .env.local file."
  };
}
function getAnthropicApiKey() {
  const apiKeyNew = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY;
  const apiKeyLegacy = process.env.CODE_REVIEW_ANTHROPIC_API_KEY;
  const apiKeyGeneric = process.env.ANTHROPIC_API_KEY;
  if (apiKeyNew) {
    debugLog("Anthropic API key found: AI_CODE_REVIEW_ANTHROPIC_API_KEY");
    return {
      apiKey: apiKeyNew,
      source: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
      message: "Using AI_CODE_REVIEW_ANTHROPIC_API_KEY"
    };
  }
  if (apiKeyLegacy) {
    console.warn(
      "Warning: Using deprecated environment variable CODE_REVIEW_ANTHROPIC_API_KEY. Please switch to AI_CODE_REVIEW_ANTHROPIC_API_KEY."
    );
    debugLog(
      "Anthropic API key found: CODE_REVIEW_ANTHROPIC_API_KEY (deprecated)"
    );
    return {
      apiKey: apiKeyLegacy,
      source: "CODE_REVIEW_ANTHROPIC_API_KEY",
      message: "Using deprecated CODE_REVIEW_ANTHROPIC_API_KEY"
    };
  }
  if (apiKeyGeneric) {
    console.warn(
      "Warning: Using generic environment variable ANTHROPIC_API_KEY. Consider using AI_CODE_REVIEW_ANTHROPIC_API_KEY for better isolation."
    );
    debugLog("Anthropic API key found: ANTHROPIC_API_KEY");
    return {
      apiKey: apiKeyGeneric,
      source: "ANTHROPIC_API_KEY",
      message: "Using ANTHROPIC_API_KEY"
    };
  }
  return {
    apiKey: void 0,
    source: "none",
    message: "No Anthropic API key found. Please set AI_CODE_REVIEW_ANTHROPIC_API_KEY in your .env.local file."
  };
}
function getOpenAIApiKey() {
  const apiKeyNew = process.env.AI_CODE_REVIEW_OPENAI_API_KEY;
  const apiKeyLegacy = process.env.CODE_REVIEW_OPENAI_API_KEY;
  const apiKeyGeneric = process.env.OPENAI_API_KEY;
  if (apiKeyNew) {
    debugLog("OpenAI API key found: AI_CODE_REVIEW_OPENAI_API_KEY");
    return {
      apiKey: apiKeyNew,
      source: "AI_CODE_REVIEW_OPENAI_API_KEY",
      message: "Using AI_CODE_REVIEW_OPENAI_API_KEY"
    };
  }
  if (apiKeyLegacy) {
    console.warn(
      "Warning: Using deprecated environment variable CODE_REVIEW_OPENAI_API_KEY. Please switch to AI_CODE_REVIEW_OPENAI_API_KEY."
    );
    debugLog("OpenAI API key found: CODE_REVIEW_OPENAI_API_KEY (deprecated)");
    return {
      apiKey: apiKeyLegacy,
      source: "CODE_REVIEW_OPENAI_API_KEY",
      message: "Using deprecated CODE_REVIEW_OPENAI_API_KEY"
    };
  }
  if (apiKeyGeneric) {
    console.warn(
      "Warning: Using generic environment variable OPENAI_API_KEY. Consider using AI_CODE_REVIEW_OPENAI_API_KEY for better isolation."
    );
    debugLog("OpenAI API key found: OPENAI_API_KEY");
    return {
      apiKey: apiKeyGeneric,
      source: "OPENAI_API_KEY",
      message: "Using OPENAI_API_KEY"
    };
  }
  return {
    apiKey: void 0,
    source: "none",
    message: "No OpenAI API key found. Please set AI_CODE_REVIEW_OPENAI_API_KEY in your .env.local file."
  };
}
function validateRequiredEnvVars() {
  const googleApiKey = getGoogleApiKey();
  const openRouterApiKey = getOpenRouterApiKey();
  const anthropicApiKey = getAnthropicApiKey();
  const openaiApiKey = getOpenAIApiKey();
  if (googleApiKey.apiKey || openRouterApiKey.apiKey || anthropicApiKey.apiKey || openaiApiKey.apiKey) {
    return {
      valid: true,
      message: "At least one API key is available"
    };
  }
  return {
    valid: false,
    message: "No API keys found. Please set either AI_CODE_REVIEW_GOOGLE_API_KEY or AI_CODE_REVIEW_OPENROUTER_API_KEY in your .env.local file."
  };
}
var path, dotenv, import_promises;
var init_envLoader = __esm({
  "src/utils/envLoader.ts"() {
    "use strict";
    path = __toESM(require("path"));
    dotenv = __toESM(require("dotenv"));
    import_promises = __toESM(require("fs/promises"));
  }
});

// src/utils/configFileManager.ts
var configFileManager_exports = {};
__export(configFileManager_exports, {
  applyConfigToOptions: () => applyConfigToOptions,
  default: () => configFileManager_default,
  generateSampleConfig: () => generateSampleConfig,
  generateSampleConfigJSON: () => generateSampleConfigJSON,
  loadConfigFile: () => loadConfigFile,
  saveSampleConfig: () => saveSampleConfig
});
function loadConfigFile(configFilePath) {
  let filePath;
  if (configFilePath) {
    filePath = path2.resolve(process.cwd(), configFilePath);
  } else {
    filePath = "";
    for (const defaultFile of DEFAULT_CONFIG_FILES) {
      const testPath = path2.resolve(process.cwd(), defaultFile);
      if (fs2.existsSync(testPath)) {
        filePath = testPath;
        break;
      }
    }
    if (!filePath) {
      filePath = path2.resolve(process.cwd(), DEFAULT_CONFIG_FILES[0]);
    }
  }
  try {
    if (!fs2.existsSync(filePath)) {
      if (configFilePath) {
        logger_default.error(`Configuration file not found: ${filePath}`);
      } else {
        logger_default.debug(`No configuration file found at ${filePath}`);
      }
      return null;
    }
    const content = fs2.readFileSync(filePath, "utf-8");
    const fileExtension = path2.extname(filePath).toLowerCase();
    try {
      let config4;
      if (fileExtension === ".yaml" || fileExtension === ".yml") {
        config4 = YAML.parse(content);
        logger_default.info(`Loaded YAML configuration from ${filePath}`);
      } else if (fileExtension === ".json") {
        config4 = JSON.parse(content);
        logger_default.info(`Loaded JSON configuration from ${filePath}`);
      } else {
        try {
          config4 = YAML.parse(content);
          logger_default.info(`Loaded configuration from ${filePath} (detected as YAML)`);
        } catch (yamlError) {
          config4 = JSON.parse(content);
          logger_default.info(`Loaded configuration from ${filePath} (detected as JSON)`);
        }
      }
      return config4;
    } catch (parseError) {
      logger_default.error(`Error parsing configuration file: ${parseError instanceof Error ? parseError.message : String(parseError)}`);
      logger_default.error(`Please check the syntax in ${filePath}`);
      return null;
    }
  } catch (error2) {
    logger_default.error(`Error reading configuration file: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
function applyConfigToOptions(config4, options) {
  const newOptions = { ...options };
  if (config4.output) {
    if (config4.output.format && !newOptions.output) {
      newOptions.output = config4.output.format;
    }
    if (config4.output.dir && !newOptions.outputDir) {
      newOptions.outputDir = config4.output.dir;
    }
  }
  if (config4.review) {
    if (config4.review.type) {
      newOptions.type = config4.review.type;
    }
    if (config4.review.interactive !== void 0 && newOptions.interactive === void 0) {
      newOptions.interactive = config4.review.interactive;
    }
    if (config4.review.include_tests !== void 0 && newOptions.includeTests === void 0) {
      newOptions.includeTests = config4.review.include_tests;
    }
    if (config4.review.include_project_docs !== void 0 && newOptions.includeProjectDocs === void 0) {
      newOptions.includeProjectDocs = config4.review.include_project_docs;
    }
    if (config4.review.include_dependency_analysis !== void 0 && newOptions.includeDependencyAnalysis === void 0) {
      newOptions.includeDependencyAnalysis = config4.review.include_dependency_analysis;
    }
    if (config4.review.consolidated !== void 0 && newOptions.consolidated === void 0) {
      newOptions.consolidated = config4.review.consolidated;
    }
    if (config4.review.trace_code !== void 0 && newOptions.traceCode === void 0) {
      newOptions.traceCode = config4.review.trace_code;
    }
    if (config4.review.use_ts_prune !== void 0 && newOptions.useTsPrune === void 0) {
      newOptions.useTsPrune = config4.review.use_ts_prune;
    }
    if (config4.review.use_eslint !== void 0 && newOptions.useEslint === void 0) {
      newOptions.useEslint = config4.review.use_eslint;
    }
    if (config4.review.auto_fix !== void 0 && newOptions.autoFix === void 0) {
      newOptions.autoFix = config4.review.auto_fix;
    }
    if (config4.review.prompt_all !== void 0 && newOptions.promptAll === void 0) {
      newOptions.promptAll = config4.review.prompt_all;
    }
    if (config4.review.confirm !== void 0 && newOptions.noConfirm === void 0) {
      newOptions.noConfirm = !config4.review.confirm;
    }
  }
  if (config4.api) {
    if (config4.api.model && !newOptions.model) {
      newOptions.model = config4.api.model;
    }
    if (config4.api.writer_model && !newOptions.writerModel) {
      newOptions.writerModel = config4.api.writer_model;
    }
    if (config4.api.test_api !== void 0 && newOptions.testApi === void 0) {
      newOptions.testApi = config4.api.test_api;
    }
    if (config4.api.keys) {
      const cliOptions = newOptions;
      if (!cliOptions.apiKey) {
        cliOptions.apiKey = {};
      }
      if (config4.api.keys.google && !cliOptions.apiKey.google) {
        cliOptions.apiKey.google = config4.api.keys.google;
      }
      if (config4.api.keys.openrouter && !cliOptions.apiKey.openrouter) {
        cliOptions.apiKey.openrouter = config4.api.keys.openrouter;
      }
      if (config4.api.keys.anthropic && !cliOptions.apiKey.anthropic) {
        cliOptions.apiKey.anthropic = config4.api.keys.anthropic;
      }
      if (config4.api.keys.openai && !cliOptions.apiKey.openai) {
        cliOptions.apiKey.openai = config4.api.keys.openai;
      }
    }
  }
  if (config4.prompts) {
    if (config4.prompts.prompt_file && !newOptions.promptFile) {
      newOptions.promptFile = config4.prompts.prompt_file;
    }
    if (config4.prompts.prompt_fragment && !newOptions.promptFragments) {
      newOptions.promptFragments = [{
        content: config4.prompts.prompt_fragment,
        position: config4.prompts.prompt_fragment_position || "middle",
        priority: 5
      }];
    }
    if (config4.prompts.prompt_strategy && !newOptions.promptStrategy) {
      newOptions.promptStrategy = config4.prompts.prompt_strategy;
    }
    if (config4.prompts.use_cache !== void 0 && newOptions.useCache === void 0) {
      newOptions.useCache = config4.prompts.use_cache;
    }
  }
  if (config4.system) {
    if (config4.system.debug !== void 0 && newOptions.debug === void 0) {
      newOptions.debug = config4.system.debug;
    }
    if (config4.system.log_level && !newOptions.logLevel) {
      newOptions.logLevel = config4.system.log_level;
    }
  }
  return newOptions;
}
function generateSampleConfig() {
  const sampleConfig = {
    output: {
      format: "markdown",
      dir: "./ai-code-review-docs"
    },
    review: {
      type: "quick-fixes",
      interactive: false,
      include_tests: false,
      include_project_docs: true,
      include_dependency_analysis: true,
      trace_code: false,
      use_ts_prune: false,
      use_eslint: false,
      auto_fix: false,
      prompt_all: false,
      confirm: true
    },
    api: {
      model: "gemini:gemini-1.5-pro",
      keys: {
        google: "YOUR_GOOGLE_API_KEY_HERE",
        openrouter: "YOUR_OPENROUTER_API_KEY_HERE",
        anthropic: "YOUR_ANTHROPIC_API_KEY_HERE",
        openai: "YOUR_OPENAI_API_KEY_HERE"
      },
      test_api: false
    },
    system: {
      debug: false,
      log_level: "info"
    }
  };
  const yamlString = YAML.stringify(sampleConfig);
  const header = `# AI Code Review Configuration File
# This file contains configuration options for the AI Code Review tool.
#
# Configuration priority order:
# 1. Command-line arguments (highest priority)
# 2. Configuration file (this file)
# 3. Environment variables (AI_CODE_REVIEW_*)
# 4. Default values (lowest priority)
#
# Usage: ai-code-review --config .ai-code-review.yaml
#
# For security, consider using environment variables for API keys instead of
# storing them in this file. Environment variable names:
# - AI_CODE_REVIEW_GOOGLE_API_KEY
# - AI_CODE_REVIEW_OPENROUTER_API_KEY
# - AI_CODE_REVIEW_ANTHROPIC_API_KEY
# - AI_CODE_REVIEW_OPENAI_API_KEY

`;
  return header + yamlString;
}
function generateSampleConfigJSON() {
  const sampleConfig = {
    output: {
      format: "markdown",
      dir: "./ai-code-review-docs"
    },
    review: {
      type: "quick-fixes",
      interactive: false,
      include_tests: false,
      include_project_docs: true,
      include_dependency_analysis: true,
      trace_code: false,
      use_ts_prune: false,
      use_eslint: false,
      auto_fix: false,
      prompt_all: false,
      confirm: true
    },
    api: {
      model: "gemini:gemini-1.5-pro",
      keys: {
        google: "YOUR_GOOGLE_API_KEY_HERE",
        openrouter: "YOUR_OPENROUTER_API_KEY_HERE",
        anthropic: "YOUR_ANTHROPIC_API_KEY_HERE",
        openai: "YOUR_OPENAI_API_KEY_HERE"
      },
      test_api: false
    },
    system: {
      debug: false,
      log_level: "info"
    }
  };
  return JSON.stringify(sampleConfig, null, 2);
}
function saveSampleConfig(outputPath, format = "yaml") {
  try {
    const sampleConfig = format === "json" ? generateSampleConfigJSON() : generateSampleConfig();
    fs2.writeFileSync(outputPath, sampleConfig);
    return true;
  } catch (error2) {
    logger_default.error(`Error saving sample configuration: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return false;
  }
}
var fs2, path2, YAML, DEFAULT_CONFIG_FILES, configFileManager_default;
var init_configFileManager = __esm({
  "src/utils/configFileManager.ts"() {
    "use strict";
    fs2 = __toESM(require("fs"));
    path2 = __toESM(require("path"));
    YAML = __toESM(require("yaml"));
    init_logger();
    DEFAULT_CONFIG_FILES = [
      ".ai-code-review.yaml",
      ".ai-code-review.yml",
      ".ai-code-review.json"
    ];
    configFileManager_default = {
      loadConfigFile,
      applyConfigToOptions,
      generateSampleConfig,
      generateSampleConfigJSON,
      saveSampleConfig
    };
  }
});

// src/utils/unifiedConfig.ts
function loadEnvironmentFile() {
  const envPaths = [
    import_path.default.resolve(process.cwd(), ".env.local"),
    import_path.default.resolve(process.cwd(), ".env")
  ];
  for (const envPath of envPaths) {
    if (import_fs.default.existsSync(envPath)) {
      import_dotenv.default.config({ path: envPath, override: true });
      logger_default.debug(`Loaded environment variables from ${envPath}`);
      break;
    }
  }
}
function loadConfigurationFile(configPath) {
  const configPaths = configPath ? [configPath] : [
    ".ai-code-review.yaml",
    ".ai-code-review.yml",
    ".ai-code-review.json"
  ];
  for (const filePath of configPaths) {
    const fullPath = import_path.default.resolve(process.cwd(), filePath);
    if (import_fs.default.existsSync(fullPath)) {
      try {
        const content = import_fs.default.readFileSync(fullPath, "utf8");
        const config4 = filePath.endsWith(".json") ? JSON.parse(content) : import_yaml.default.parse(content);
        logger_default.debug(`Loaded configuration from ${fullPath}`);
        return config4;
      } catch (error2) {
        logger_default.warn(`Failed to parse configuration file ${fullPath}: ${error2}`);
      }
    }
  }
  return null;
}
function getApiKey(provider) {
  const envMappings = {
    google: {
      new: "AI_CODE_REVIEW_GOOGLE_API_KEY",
      legacy: "CODE_REVIEW_GOOGLE_API_KEY",
      generic: ["GOOGLE_GENERATIVE_AI_KEY", "GOOGLE_AI_STUDIO_KEY"]
    },
    openrouter: {
      new: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
      legacy: "CODE_REVIEW_OPENROUTER_API_KEY",
      generic: ["OPENROUTER_API_KEY"]
    },
    anthropic: {
      new: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
      legacy: "CODE_REVIEW_ANTHROPIC_API_KEY",
      generic: ["ANTHROPIC_API_KEY"]
    },
    openai: {
      new: "AI_CODE_REVIEW_OPENAI_API_KEY",
      legacy: "CODE_REVIEW_OPENAI_API_KEY",
      generic: ["OPENAI_API_KEY"]
    }
  };
  const mapping = envMappings[provider];
  const newKey = process.env[mapping.new];
  if (newKey) return newKey;
  const legacyKey = process.env[mapping.legacy];
  if (legacyKey) {
    logger_default.warn(`\u26A0\uFE0F  DEPRECATION WARNING: ${mapping.legacy} is deprecated. Please use ${mapping.new} instead.`);
    return legacyKey;
  }
  for (const genericVar of mapping.generic) {
    const genericKey = process.env[genericVar];
    if (genericKey) return genericKey;
  }
  return void 0;
}
function buildConfiguration(cliOptions) {
  loadEnvironmentFile();
  const configFile = loadConfigurationFile(cliOptions?.config);
  const rawConfig = {
    // API Keys (environment only, not exposed via CLI for security)
    googleApiKey: getApiKey("google"),
    openRouterApiKey: getApiKey("openrouter"),
    anthropicApiKey: getApiKey("anthropic"),
    openAIApiKey: getApiKey("openai"),
    // Model configuration
    model: cliOptions?.model || process.env.AI_CODE_REVIEW_MODEL || configFile?.model?.default || "gemini:gemini-1.5-pro",
    writerModel: cliOptions?.writerModel || process.env.AI_CODE_REVIEW_WRITER_MODEL || configFile?.model?.writer,
    // Output configuration
    outputDir: cliOptions?.outputDir || process.env.AI_CODE_REVIEW_OUTPUT_DIR || configFile?.output?.directory || "ai-code-review-docs",
    outputFormat: cliOptions?.outputFormat || configFile?.output?.format || "markdown",
    // Behavior configuration
    debug: cliOptions?.debug ?? process.env.AI_CODE_REVIEW_DEBUG === "true" ?? configFile?.behavior?.debug ?? false,
    logLevel: cliOptions?.logLevel || process.env.AI_CODE_REVIEW_LOG_LEVEL || configFile?.behavior?.log_level || "info",
    interactive: cliOptions?.interactive ?? configFile?.behavior?.interactive ?? false,
    // Feature flags
    includeTests: cliOptions?.includeTests ?? configFile?.features?.include_tests ?? false,
    includeProjectDocs: cliOptions?.includeProjectDocs ?? configFile?.features?.include_project_docs ?? false,
    includeDependencyAnalysis: cliOptions?.includeDependencyAnalysis ?? configFile?.features?.include_dependency_analysis ?? false,
    enableSemanticChunking: cliOptions?.enableSemanticChunking ?? process.env.AI_CODE_REVIEW_ENABLE_SEMANTIC_CHUNKING === "true" ?? configFile?.features?.enable_semantic_chunking ?? true,
    // Advanced configuration
    contextPaths: process.env.AI_CODE_REVIEW_CONTEXT?.split(",").map((p) => p.trim())
  };
  try {
    return ConfigSchema.parse(rawConfig);
  } catch (error2) {
    if (error2 instanceof import_zod.z.ZodError) {
      const issues = error2.issues.map((issue) => `${issue.path.join(".")}: ${issue.message}`).join(", ");
      throw new Error(`Configuration validation failed: ${issues}`);
    }
    throw error2;
  }
}
function getUnifiedConfig(cliOptions) {
  if (!configInstance || cliOptions) {
    configInstance = buildConfiguration(cliOptions);
  }
  return configInstance;
}
var import_path, import_fs, import_zod, import_dotenv, import_yaml, ConfigSchema, configInstance;
var init_unifiedConfig = __esm({
  "src/utils/unifiedConfig.ts"() {
    "use strict";
    import_path = __toESM(require("path"));
    import_fs = __toESM(require("fs"));
    import_zod = require("zod");
    import_dotenv = __toESM(require("dotenv"));
    import_yaml = __toESM(require("yaml"));
    init_logger();
    ConfigSchema = import_zod.z.object({
      // API Keys
      googleApiKey: import_zod.z.string().optional(),
      openRouterApiKey: import_zod.z.string().optional(),
      anthropicApiKey: import_zod.z.string().optional(),
      openAIApiKey: import_zod.z.string().optional(),
      // Model configuration
      model: import_zod.z.string().default("gemini:gemini-1.5-pro"),
      writerModel: import_zod.z.string().optional(),
      // Output configuration
      outputDir: import_zod.z.string().default("ai-code-review-docs"),
      outputFormat: import_zod.z.enum(["markdown", "json"]).default("markdown"),
      // Behavior configuration
      debug: import_zod.z.boolean().default(false),
      logLevel: import_zod.z.enum(["debug", "info", "warn", "error", "none"]).default("info"),
      interactive: import_zod.z.boolean().default(false),
      // Feature flags
      includeTests: import_zod.z.boolean().default(false),
      includeProjectDocs: import_zod.z.boolean().default(false),
      includeDependencyAnalysis: import_zod.z.boolean().default(false),
      enableSemanticChunking: import_zod.z.boolean().default(true),
      // Advanced configuration
      contextPaths: import_zod.z.array(import_zod.z.string()).optional(),
      maxTokens: import_zod.z.number().optional(),
      temperature: import_zod.z.number().min(0).max(2).optional()
    });
    configInstance = null;
  }
});

// src/utils/config.ts
var config_exports = {};
__export(config_exports, {
  appConfigSchema: () => appConfigSchema,
  displayConfigError: () => displayConfigError,
  getApiKeyForProvider: () => getApiKeyForProvider,
  getConfig: () => getConfig,
  getPromptsPath: () => getPromptsPath,
  hasAnyApiKey: () => hasAnyApiKey,
  loadConfigSafe: () => loadConfigSafe,
  resetConfig: () => resetConfig,
  validateConfigForSelectedModel: () => validateConfigForSelectedModel
});
function displayConfigError(result) {
  console.log("\n\u{1F6A8} Configuration Error");
  console.log("\u2550".repeat(50));
  console.log(`
\u274C ${result.error}`);
  if (result.details) {
    console.log(`
\u{1F4CB} Details: ${result.details}`);
  }
  console.log("\n\u{1F4A1} How to fix this:");
  result.suggestions.forEach((suggestion) => {
    console.log(`   ${suggestion}`);
  });
  console.log("\n\u{1F4DA} Additional help:");
  console.log("   \u2022 Run with --debug for detailed error information");
  console.log("   \u2022 Check the documentation for configuration examples");
  console.log("   \u2022 Use ai-code-review generate-config to create a sample config file");
  console.log("");
}
function buildConfigObject(cliOptions) {
  let jsonConfig = null;
  if (cliOptions?.config) {
    jsonConfig = loadConfigFile(cliOptions.config);
    if (!jsonConfig) {
      throw new Error(`Configuration file not found or invalid: ${cliOptions.config}`);
    }
  } else {
    jsonConfig = loadConfigFile();
  }
  let mergedOptions = cliOptions;
  if (jsonConfig && cliOptions) {
    const baseOptions = { ...cliOptions };
    const appliedOptions = applyConfigToOptions(jsonConfig, baseOptions);
    mergedOptions = { ...cliOptions, ...appliedOptions };
  } else if (jsonConfig && !cliOptions) {
    const baseOptions = { type: "quick-fixes" };
    const appliedOptions = applyConfigToOptions(jsonConfig, baseOptions);
    mergedOptions = appliedOptions;
  }
  const googleApiKeyResult = getGoogleApiKey();
  const openRouterApiKeyResult = getOpenRouterApiKey();
  const anthropicApiKeyResult = getAnthropicApiKey();
  const openAIApiKeyResult = getOpenAIApiKey();
  const googleApiKey = mergedOptions?.apiKey?.google || mergedOptions?.apiKeys?.google || googleApiKeyResult.apiKey;
  const openRouterApiKey = mergedOptions?.apiKey?.openrouter || mergedOptions?.apiKeys?.openrouter || openRouterApiKeyResult.apiKey;
  const anthropicApiKey = mergedOptions?.apiKey?.anthropic || mergedOptions?.apiKeys?.anthropic || anthropicApiKeyResult.apiKey;
  const openAIApiKey = mergedOptions?.apiKey?.openai || mergedOptions?.apiKeys?.openai || openAIApiKeyResult.apiKey;
  const selectedModel = mergedOptions?.model || process.env.AI_CODE_REVIEW_MODEL || "gemini:gemini-2.5-pro-preview";
  const writerModel = mergedOptions?.writerModel || process.env.AI_CODE_REVIEW_WRITER_MODEL || void 0;
  const debug2 = mergedOptions?.debug || process.env.AI_CODE_REVIEW_DEBUG === "true" || process.argv.includes("--debug");
  const logLevel = mergedOptions?.logLevel || process.env.AI_CODE_REVIEW_LOG_LEVEL?.toLowerCase() || "info";
  const contextPathsStr = process.env.AI_CODE_REVIEW_CONTEXT;
  const contextPaths = contextPathsStr ? contextPathsStr.split(",").map((p) => p.trim()) : void 0;
  const outputDir = mergedOptions?.outputDir || process.env.AI_CODE_REVIEW_OUTPUT_DIR || "ai-code-review-docs";
  return {
    googleApiKey,
    openRouterApiKey,
    anthropicApiKey,
    openAIApiKey,
    selectedModel,
    writerModel,
    debug: debug2,
    logLevel,
    contextPaths,
    outputDir
  };
}
function loadConfig(cliOptions) {
  const configObj = buildConfigObject(cliOptions);
  try {
    return appConfigSchema.parse(configObj);
  } catch (error2) {
    if (error2 instanceof import_zod2.z.ZodError) {
      logger_default.error("Configuration validation failed:", error2.errors);
      throw new Error(
        `Configuration validation failed: ${error2.errors.map((e) => e.message).join(", ")}`
      );
    }
    throw error2;
  }
}
function getConfig(cliOptions) {
  if (!config2 || cliOptions) {
    try {
      config2 = loadConfig(cliOptions);
    } catch (error2) {
      logger_default.error("Failed to load configuration:", error2);
      throw error2;
    }
  }
  return config2;
}
function hasAnyApiKey() {
  const { googleApiKey, openRouterApiKey, anthropicApiKey, openAIApiKey } = getConfig();
  return !!(googleApiKey || openRouterApiKey || anthropicApiKey || openAIApiKey);
}
function loadConfigSafe(cliOptions) {
  try {
    const unifiedCliOptions = cliOptions ? {
      model: cliOptions.model,
      writerModel: cliOptions.writerModel,
      outputDir: cliOptions.outputDir,
      outputFormat: cliOptions.output,
      debug: cliOptions.debug,
      logLevel: cliOptions.logLevel,
      interactive: cliOptions.interactive,
      includeTests: cliOptions.includeTests,
      includeProjectDocs: cliOptions.includeProjectDocs,
      includeDependencyAnalysis: cliOptions.includeDependencyAnalysis,
      enableSemanticChunking: cliOptions.enableSemanticChunking,
      config: cliOptions.config
    } : void 0;
    const unifiedConfig = getUnifiedConfig(unifiedCliOptions);
    const legacyConfig = {
      googleApiKey: unifiedConfig.googleApiKey,
      openRouterApiKey: unifiedConfig.openRouterApiKey,
      anthropicApiKey: unifiedConfig.anthropicApiKey,
      openAIApiKey: unifiedConfig.openAIApiKey,
      selectedModel: unifiedConfig.model,
      writerModel: unifiedConfig.writerModel,
      debug: unifiedConfig.debug,
      logLevel: unifiedConfig.logLevel,
      contextPaths: unifiedConfig.contextPaths,
      outputDir: unifiedConfig.outputDir
    };
    return {
      success: true,
      config: legacyConfig
    };
  } catch (error2) {
    const errorMessage = error2 instanceof Error ? error2.message : String(error2);
    const suggestions = [];
    if (errorMessage.includes("API key")) {
      suggestions.push("Set at least one API key using AI_CODE_REVIEW_*_API_KEY environment variables");
      suggestions.push("Check your .env.local file for correct API key format");
    }
    if (errorMessage.includes("model")) {
      suggestions.push('Set AI_CODE_REVIEW_MODEL environment variable (e.g., "gemini:gemini-1.5-pro")');
      suggestions.push('Ensure the model format is "provider:model-name"');
    }
    if (errorMessage.includes("validation")) {
      suggestions.push("Check your configuration file syntax (.ai-code-review.yaml)");
      suggestions.push("Verify all required fields are present and correctly formatted");
    }
    return {
      success: false,
      error: errorMessage,
      suggestions,
      details: error2 instanceof Error ? error2.stack : void 0
    };
  }
}
function getApiKeyForProvider(provider) {
  const config4 = getConfig();
  switch (provider.toLowerCase()) {
    case "gemini":
      return config4.googleApiKey;
    case "openrouter":
      return config4.openRouterApiKey;
    case "anthropic":
      return config4.anthropicApiKey;
    case "openai":
      return config4.openAIApiKey;
    default:
      return void 0;
  }
}
function resetConfig() {
  config2 = null;
}
function validateConfigForSelectedModel() {
  const config4 = getConfig();
  const [provider] = config4.selectedModel.split(":");
  if (!provider) {
    return {
      valid: false,
      message: `Invalid model format: ${config4.selectedModel}. Expected format: provider:model-name`
    };
  }
  switch (provider.toLowerCase()) {
    case "gemini":
      if (!config4.googleApiKey) {
        return {
          valid: false,
          message: `Missing Google API key for model ${config4.selectedModel}. Set AI_CODE_REVIEW_GOOGLE_API_KEY in your .env.local file.`
        };
      }
      break;
    case "openrouter":
      if (!config4.openRouterApiKey) {
        return {
          valid: false,
          message: `Missing OpenRouter API key for model ${config4.selectedModel}. Set AI_CODE_REVIEW_OPENROUTER_API_KEY in your .env.local file.`
        };
      }
      break;
    case "anthropic":
      if (!config4.anthropicApiKey) {
        return {
          valid: false,
          message: `Missing Anthropic API key for model ${config4.selectedModel}. Set AI_CODE_REVIEW_ANTHROPIC_API_KEY in your .env.local file.`
        };
      }
      break;
    case "openai":
      if (!config4.openAIApiKey) {
        return {
          valid: false,
          message: `Missing OpenAI API key for model ${config4.selectedModel}. Set AI_CODE_REVIEW_OPENAI_API_KEY in your .env.local file.`
        };
      }
      break;
    default:
      return {
        valid: false,
        message: `Unknown provider: ${provider}. Supported providers are: gemini, openrouter, anthropic, openai`
      };
  }
  return {
    valid: true,
    message: "Configuration is valid for the selected model"
  };
}
function getPromptsPath() {
  const possiblePaths = [
    // For local development
    import_path2.default.resolve("prompts"),
    // For npm package
    import_path2.default.resolve(__dirname, "..", "..", "prompts"),
    // For global installation
    import_path2.default.resolve(__dirname, "..", "..", "..", "prompts")
  ];
  for (const p of possiblePaths) {
    if (import_fs2.default.existsSync(p)) {
      return p;
    }
  }
  return possiblePaths[0];
}
var import_path2, import_fs2, import_zod2, appConfigSchema, config2;
var init_config = __esm({
  "src/utils/config.ts"() {
    "use strict";
    init_envLoader();
    init_logger();
    import_path2 = __toESM(require("path"));
    import_fs2 = __toESM(require("fs"));
    import_zod2 = require("zod");
    init_configFileManager();
    init_unifiedConfig();
    appConfigSchema = import_zod2.z.object({
      // API Keys
      googleApiKey: import_zod2.z.string().optional(),
      openRouterApiKey: import_zod2.z.string().optional(),
      anthropicApiKey: import_zod2.z.string().optional(),
      openAIApiKey: import_zod2.z.string().optional(),
      // Model configuration
      selectedModel: import_zod2.z.string(),
      writerModel: import_zod2.z.string().optional(),
      // Other configuration
      debug: import_zod2.z.boolean(),
      logLevel: import_zod2.z.enum(["debug", "info", "warn", "error", "none"]).default("info"),
      contextPaths: import_zod2.z.array(import_zod2.z.string()).optional(),
      outputDir: import_zod2.z.string().default("ai-code-review-docs")
    });
    config2 = null;
  }
});

// src/utils/pathValidator.ts
function isPathWithinCwd(targetPath) {
  const resolvedPath = import_path3.default.resolve(targetPath);
  const resolvedCwd = import_path3.default.resolve(process.cwd());
  return resolvedPath.startsWith(resolvedCwd);
}
function pathExists(targetPath) {
  try {
    import_fs3.default.accessSync(targetPath);
    return true;
  } catch (error2) {
    return false;
  }
}
function isDirectory(targetPath) {
  try {
    return import_fs3.default.statSync(targetPath).isDirectory();
  } catch (error2) {
    return false;
  }
}
var import_fs3, import_path3;
var init_pathValidator = __esm({
  "src/utils/pathValidator.ts"() {
    "use strict";
    import_fs3 = __toESM(require("fs"));
    import_path3 = __toESM(require("path"));
  }
});

// src/utils/FileReader.ts
var import_promises2, import_path4;
var init_FileReader = __esm({
  "src/utils/FileReader.ts"() {
    "use strict";
    import_promises2 = __toESM(require("fs/promises"));
    import_path4 = __toESM(require("path"));
    init_logger();
  }
});

// src/utils/FileWriter.ts
async function ensureDirectoryExists(dirPath) {
  try {
    if (!pathExists(dirPath)) {
      await import_promises3.default.mkdir(dirPath, { recursive: true });
      logger_default.debug(`Created directory: ${dirPath}`);
    }
  } catch (error2) {
    logger_default.error(
      `Error creating directory ${dirPath}: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}
var import_promises3, import_path5;
var init_FileWriter = __esm({
  "src/utils/FileWriter.ts"() {
    "use strict";
    import_promises3 = __toESM(require("fs/promises"));
    import_path5 = __toESM(require("path"));
    init_pathValidator();
    init_logger();
  }
});

// src/utils/PathGenerator.ts
async function generateVersionedOutputPath(baseDir, prefix, extension, modelName, targetName) {
  await ensureDirectoryExists(baseDir);
  const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
  const cleanModelName = modelName.replace(/[^a-zA-Z0-9-]/g, "-");
  let cleanTargetName = targetName.replace(/[^a-zA-Z0-9-]/g, "-");
  if (targetName === "." || cleanTargetName === "-" || cleanTargetName === "") {
    cleanTargetName = "current-dir";
  }
  cleanTargetName = cleanTargetName.replace(/-+/g, "-").replace(/^-|-$/g, "");
  const filename = `${prefix}-${cleanTargetName}-${cleanModelName}-${timestamp}${extension}`;
  return import_path6.default.join(baseDir, filename);
}
async function generateUniqueOutputPath(baseDir, filename) {
  await ensureDirectoryExists(baseDir);
  let outputPath = import_path6.default.join(baseDir, filename);
  if (await pathExists(outputPath)) {
    const extension = import_path6.default.extname(filename);
    const nameWithoutExtension = import_path6.default.basename(filename, extension);
    let counter = 1;
    while (await pathExists(outputPath)) {
      outputPath = import_path6.default.join(
        baseDir,
        `${nameWithoutExtension}-${counter}${extension}`
      );
      counter++;
    }
  }
  return outputPath;
}
var import_path6;
var init_PathGenerator = __esm({
  "src/utils/PathGenerator.ts"() {
    "use strict";
    import_path6 = __toESM(require("path"));
    init_pathValidator();
    init_FileWriter();
  }
});

// src/utils/fileSystem.ts
var fileExists, createDirectory;
var init_fileSystem = __esm({
  "src/utils/fileSystem.ts"() {
    "use strict";
    init_pathValidator();
    init_FileReader();
    init_FileWriter();
    init_PathGenerator();
    fileExists = pathExists;
    createDirectory = ensureDirectoryExists;
  }
});

// src/types/configuration.ts
var import_zod3, applicationConfigSchema;
var init_configuration = __esm({
  "src/types/configuration.ts"() {
    "use strict";
    import_zod3 = require("zod");
    applicationConfigSchema = import_zod3.z.object({
      apiKeys: import_zod3.z.object({
        google: import_zod3.z.object({ value: import_zod3.z.string().optional(), source: import_zod3.z.string() }).optional(),
        openRouter: import_zod3.z.object({ value: import_zod3.z.string().optional(), source: import_zod3.z.string() }).optional(),
        anthropic: import_zod3.z.object({ value: import_zod3.z.string().optional(), source: import_zod3.z.string() }).optional(),
        openai: import_zod3.z.object({ value: import_zod3.z.string().optional(), source: import_zod3.z.string() }).optional()
      }),
      apiEndpoints: import_zod3.z.object({
        gemini: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        openRouter: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        anthropic: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        openai: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() })
      }),
      apiVersions: import_zod3.z.object({
        gemini: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        openRouter: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        anthropic: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        openai: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() })
      }),
      selectedModel: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
      writerModel: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }).optional(),
      modelProvider: import_zod3.z.object({
        value: import_zod3.z.enum(["gemini", "openrouter", "anthropic", "openai"]),
        source: import_zod3.z.string()
      }),
      debug: import_zod3.z.object({ value: import_zod3.z.boolean(), source: import_zod3.z.string() }),
      logLevel: import_zod3.z.object({
        value: import_zod3.z.enum(["debug", "info", "warn", "error", "none"]),
        source: import_zod3.z.string()
      }),
      paths: import_zod3.z.object({
        outputDir: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        promptsDir: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        templatesDir: import_zod3.z.object({ value: import_zod3.z.string(), source: import_zod3.z.string() }),
        contextPaths: import_zod3.z.object({
          value: import_zod3.z.array(import_zod3.z.string()),
          source: import_zod3.z.string()
        }).optional()
      }),
      rateLimit: import_zod3.z.object({
        tokensPerSecond: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
        maxConcurrentRequests: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
        retryDelayMs: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
        maxRetries: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() })
      }),
      tokens: import_zod3.z.object({
        maxTokensPerRequest: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
        contextWindowSize: import_zod3.z.object({
          gemini: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openrouter: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          anthropic: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openai: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() })
        }),
        costPerInputToken: import_zod3.z.object({
          gemini: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openrouter: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          anthropic: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openai: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() })
        }),
        costPerOutputToken: import_zod3.z.object({
          gemini: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openrouter: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          anthropic: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() }),
          openai: import_zod3.z.object({ value: import_zod3.z.number(), source: import_zod3.z.string() })
        })
      })
    });
  }
});

// src/utils/configManager.ts
function createConfigValue(value, source) {
  return { value, source };
}
function resolveConfigValue(envValue, envSource, cliValue, defaultValue) {
  if (cliValue !== void 0) {
    return createConfigValue(cliValue, "cli_option");
  }
  if (envValue !== void 0) {
    return createConfigValue(envValue, envSource);
  }
  return createConfigValue(defaultValue, "default_value");
}
function getProviderFromModel(modelString) {
  const modelParts = modelString.split(":");
  if (modelParts.length === 2) {
    const provider = modelParts[0].toLowerCase();
    if (provider === "gemini" || provider === "openrouter" || provider === "anthropic" || provider === "openai") {
      return provider;
    }
  }
  logger_default.warn(`Invalid model string format: ${modelString}. Using gemini as default provider.`);
  return "gemini";
}
function initializeConfig(cliOptions) {
  loadEnvVariables().catch((error2) => {
    logger_default.warn(`Error loading environment variables: ${error2.message}`);
  });
  const googleApiKeyResult = getGoogleApiKey();
  const openRouterApiKeyResult = getOpenRouterApiKey();
  const anthropicApiKeyResult = getAnthropicApiKey();
  const openAIApiKeyResult = getOpenAIApiKey();
  const apiKeys = {
    google: googleApiKeyResult.apiKey ? createConfigValue(googleApiKeyResult.apiKey, googleApiKeyResult.source) : void 0,
    openRouter: openRouterApiKeyResult.apiKey ? createConfigValue(openRouterApiKeyResult.apiKey, openRouterApiKeyResult.source) : void 0,
    anthropic: anthropicApiKeyResult.apiKey ? createConfigValue(anthropicApiKeyResult.apiKey, anthropicApiKeyResult.source) : void 0,
    openai: openAIApiKeyResult.apiKey ? createConfigValue(openAIApiKeyResult.apiKey, openAIApiKeyResult.source) : void 0
  };
  const selectedModelEnvVar = process.env.AI_CODE_REVIEW_MODEL;
  const selectedModelValue = resolveConfigValue(
    selectedModelEnvVar,
    "AI_CODE_REVIEW_MODEL",
    cliOptions?.model,
    "gemini:gemini-1.5-pro-latest"
  );
  const modelProvider = createConfigValue(
    getProviderFromModel(selectedModelValue.value),
    "default_value"
  );
  const debugEnvVar2 = process.env.AI_CODE_REVIEW_DEBUG === "true";
  const debugValue = resolveConfigValue(
    debugEnvVar2,
    "AI_CODE_REVIEW_DEBUG",
    cliOptions?.debug,
    false
  );
  const logLevelEnvVar = process.env.AI_CODE_REVIEW_LOG_LEVEL;
  const logLevelValue = resolveConfigValue(
    logLevelEnvVar,
    "AI_CODE_REVIEW_LOG_LEVEL",
    cliOptions?.logLevel,
    "info"
  );
  const outputDirEnvVar = process.env.AI_CODE_REVIEW_OUTPUT_DIR;
  const outputDirValue = resolveConfigValue(
    outputDirEnvVar,
    "AI_CODE_REVIEW_OUTPUT_DIR",
    cliOptions?.outputDir,
    "ai-code-review-docs"
  );
  const promptsDirValue = createConfigValue(findPromptsDirectory(), "default_value");
  const templatesDirValue = createConfigValue(path10.join(promptsDirValue.value, "templates"), "default_value");
  const contextPathsEnvVar = process.env.AI_CODE_REVIEW_CONTEXT?.split(",").map((p) => p.trim());
  const contextPathsValue = contextPathsEnvVar ? createConfigValue(contextPathsEnvVar, "AI_CODE_REVIEW_CONTEXT") : void 0;
  const apiEndpoints = {
    gemini: createConfigValue("https://generativelanguage.googleapis.com/v1", "default_value"),
    openRouter: createConfigValue("https://openrouter.ai/api/v1", "default_value"),
    anthropic: createConfigValue("https://api.anthropic.com/v1/messages", "default_value"),
    openai: createConfigValue("https://api.openai.com/v1", "default_value")
  };
  const apiVersions = {
    gemini: createConfigValue("v1beta", "default_value"),
    openRouter: createConfigValue("v1", "default_value"),
    anthropic: createConfigValue("2023-06-01", "default_value"),
    openai: createConfigValue("v1", "default_value")
  };
  const rateLimit = {
    tokensPerSecond: createConfigValue(5, "default_value"),
    maxConcurrentRequests: createConfigValue(3, "default_value"),
    retryDelayMs: createConfigValue(1e3, "default_value"),
    maxRetries: createConfigValue(3, "default_value")
  };
  const tokens = {
    maxTokensPerRequest: createConfigValue(4096, "default_value"),
    contextWindowSize: {
      gemini: createConfigValue(1e6, "default_value"),
      // 1M tokens for Gemini models
      openrouter: createConfigValue(128e3, "default_value"),
      // Depends on model, using Claude Opus
      anthropic: createConfigValue(2e5, "default_value"),
      // 200K for Claude 3 Opus
      openai: createConfigValue(128e3, "default_value")
      // GPT-4 Turbo (128K)
    },
    costPerInputToken: {
      gemini: createConfigValue(7e-6, "default_value"),
      // $0.000007 per input token
      openrouter: createConfigValue(1e-5, "default_value"),
      // Average depends on model
      anthropic: createConfigValue(1e-5, "default_value"),
      // $0.00001 per input token for Opus
      openai: createConfigValue(1e-5, "default_value")
      // $0.00001 per input token for GPT-4 Turbo
    },
    costPerOutputToken: {
      gemini: createConfigValue(21e-6, "default_value"),
      // $0.000021 per output token
      openrouter: createConfigValue(3e-5, "default_value"),
      // Average depends on model
      anthropic: createConfigValue(3e-5, "default_value"),
      // $0.00003 per output token for Opus
      openai: createConfigValue(3e-5, "default_value")
      // $0.00003 per output token for GPT-4 Turbo
    }
  };
  const config4 = {
    apiKeys,
    apiEndpoints,
    apiVersions,
    selectedModel: selectedModelValue,
    modelProvider,
    debug: debugValue,
    logLevel: logLevelValue,
    paths: {
      outputDir: outputDirValue,
      promptsDir: promptsDirValue,
      templatesDir: templatesDirValue,
      contextPaths: contextPathsValue
    },
    rateLimit,
    tokens
  };
  try {
    applicationConfigSchema.parse(config4);
  } catch (error2) {
    logger_default.error("Configuration validation failed:", error2);
    logger_default.warn("Using potentially invalid configuration - some features may not work correctly");
  }
  return config4;
}
function findPromptsDirectory() {
  const possiblePaths = [
    // For local development
    path10.resolve("promptText"),
    // For npm package
    path10.resolve(__dirname, "..", "..", "promptText"),
    // For global installation
    path10.resolve(__dirname, "..", "..", "..", "promptText")
  ];
  for (const p of possiblePaths) {
    if (fs8.existsSync(p)) {
      return p;
    }
  }
  return possiblePaths[0];
}
function getApplicationConfig(cliOptions) {
  if (!configInstance2 || cliOptions) {
    try {
      configInstance2 = initializeConfig(cliOptions);
      if (configInstance2.debug.value) {
        logger_default.debug("Configuration initialized. Selected values:");
        logger_default.debug(`- Model: ${configInstance2.selectedModel.value} (source: ${configInstance2.selectedModel.source})`);
        logger_default.debug(`- Log Level: ${configInstance2.logLevel.value} (source: ${configInstance2.logLevel.source})`);
        logger_default.debug(`- Output Dir: ${configInstance2.paths.outputDir.value} (source: ${configInstance2.paths.outputDir.source})`);
      }
    } catch (error2) {
      logger_default.error(`Failed to load configuration: ${error2 instanceof Error ? error2.message : String(error2)}`);
      throw error2;
    }
  }
  return configInstance2;
}
function resetConfig2() {
  configInstance2 = null;
}
function getApiKey2(provider) {
  const config4 = getApplicationConfig();
  switch (provider) {
    case "gemini":
      return config4.apiKeys.google?.value;
    case "openrouter":
      return config4.apiKeys.openRouter?.value;
    case "anthropic":
      return config4.apiKeys.anthropic?.value;
    case "openai":
      return config4.apiKeys.openai?.value;
    default:
      return void 0;
  }
}
function getApiEndpoint(provider) {
  const config4 = getApplicationConfig();
  switch (provider) {
    case "gemini":
      return config4.apiEndpoints.gemini.value;
    case "openrouter":
      return config4.apiEndpoints.openRouter.value;
    case "anthropic":
      return config4.apiEndpoints.anthropic.value;
    case "openai":
      return config4.apiEndpoints.openai.value;
    default:
      return config4.apiEndpoints.gemini.value;
  }
}
function getApiVersion(provider) {
  const config4 = getApplicationConfig();
  switch (provider) {
    case "gemini":
      return config4.apiVersions.gemini.value;
    case "openrouter":
      return config4.apiVersions.openRouter.value;
    case "anthropic":
      return config4.apiVersions.anthropic.value;
    case "openai":
      return config4.apiVersions.openai.value;
    default:
      return config4.apiVersions.gemini.value;
  }
}
function getRateLimitConfig() {
  const config4 = getApplicationConfig();
  return {
    tokensPerSecond: config4.rateLimit.tokensPerSecond.value,
    maxConcurrentRequests: config4.rateLimit.maxConcurrentRequests.value,
    retryDelayMs: config4.rateLimit.retryDelayMs.value,
    maxRetries: config4.rateLimit.maxRetries.value
  };
}
function getTokenConfig(provider) {
  const config4 = getApplicationConfig();
  let contextWindowSize;
  let costPerInputToken;
  let costPerOutputToken;
  const tokens = config4.tokens;
  switch (provider) {
    case "gemini":
      contextWindowSize = tokens.contextWindowSize.gemini.value;
      costPerInputToken = tokens.costPerInputToken.gemini.value;
      costPerOutputToken = tokens.costPerOutputToken.gemini.value;
      break;
    case "openrouter":
      contextWindowSize = tokens.contextWindowSize.openrouter.value;
      costPerInputToken = tokens.costPerInputToken.openrouter.value;
      costPerOutputToken = tokens.costPerOutputToken.openrouter.value;
      break;
    case "anthropic":
      contextWindowSize = tokens.contextWindowSize.anthropic.value;
      costPerInputToken = tokens.costPerInputToken.anthropic.value;
      costPerOutputToken = tokens.costPerOutputToken.anthropic.value;
      break;
    case "openai":
      contextWindowSize = tokens.contextWindowSize.openai.value;
      costPerInputToken = tokens.costPerInputToken.openai.value;
      costPerOutputToken = tokens.costPerOutputToken.openai.value;
      break;
    default:
      contextWindowSize = tokens.contextWindowSize.gemini.value;
      costPerInputToken = tokens.costPerInputToken.gemini.value;
      costPerOutputToken = tokens.costPerOutputToken.gemini.value;
  }
  return {
    maxTokensPerRequest: config4.tokens.maxTokensPerRequest.value,
    contextWindowSize,
    costPerInputToken,
    costPerOutputToken
  };
}
function getPathsConfig() {
  const config4 = getApplicationConfig();
  return {
    outputDir: config4.paths.outputDir.value,
    promptsDir: config4.paths.promptsDir.value,
    templatesDir: config4.paths.templatesDir.value,
    contextPaths: config4.paths.contextPaths?.value
  };
}
function validateConfigForSelectedModel2() {
  const config4 = getApplicationConfig();
  const provider = config4.modelProvider.value;
  switch (provider) {
    case "gemini":
      if (!config4.apiKeys.google?.value) {
        return {
          valid: false,
          message: `Missing Google API key for model ${config4.selectedModel.value}. Set AI_CODE_REVIEW_GOOGLE_API_KEY in your .env.local file.`
        };
      }
      break;
    case "openrouter":
      if (!config4.apiKeys.openRouter?.value) {
        return {
          valid: false,
          message: `Missing OpenRouter API key for model ${config4.selectedModel.value}. Set AI_CODE_REVIEW_OPENROUTER_API_KEY in your .env.local file.`
        };
      }
      break;
    case "anthropic":
      if (!config4.apiKeys.anthropic?.value) {
        return {
          valid: false,
          message: `Missing Anthropic API key for model ${config4.selectedModel.value}. Set AI_CODE_REVIEW_ANTHROPIC_API_KEY in your .env.local file.`
        };
      }
      break;
    case "openai":
      if (!config4.apiKeys.openai?.value) {
        return {
          valid: false,
          message: `Missing OpenAI API key for model ${config4.selectedModel.value}. Set AI_CODE_REVIEW_OPENAI_API_KEY in your .env.local file.`
        };
      }
      break;
  }
  return {
    valid: true,
    message: "Configuration is valid for the selected model"
  };
}
function hasAnyApiKey2() {
  const config4 = getApplicationConfig();
  return !!(config4.apiKeys.google?.value || config4.apiKeys.openRouter?.value || config4.apiKeys.anthropic?.value || config4.apiKeys.openai?.value);
}
var path10, fs8, configInstance2, configManager_default;
var init_configManager = __esm({
  "src/utils/configManager.ts"() {
    "use strict";
    path10 = __toESM(require("path"));
    fs8 = __toESM(require("fs"));
    init_logger();
    init_envLoader();
    init_configuration();
    configInstance2 = null;
    configManager_default = {
      getApplicationConfig,
      resetConfig: resetConfig2,
      getApiKey: getApiKey2,
      getApiEndpoint,
      getApiVersion,
      getRateLimitConfig,
      getTokenConfig,
      getPathsConfig,
      validateConfigForSelectedModel: validateConfigForSelectedModel2,
      hasAnyApiKey: hasAnyApiKey2
    };
  }
});

// src/clients/utils/modelMaps/types.ts
var ModelCategory;
var init_types = __esm({
  "src/clients/utils/modelMaps/types.ts"() {
    "use strict";
    ModelCategory = /* @__PURE__ */ ((ModelCategory2) => {
      ModelCategory2["REASONING"] = "reasoning";
      ModelCategory2["FAST_INFERENCE"] = "fast-inference";
      ModelCategory2["COST_OPTIMIZED"] = "cost-optimized";
      ModelCategory2["LONG_CONTEXT"] = "long-context";
      ModelCategory2["MULTIMODAL"] = "multimodal";
      ModelCategory2["CODING"] = "coding";
      return ModelCategory2;
    })(ModelCategory || {});
  }
});

// src/clients/utils/modelMaps/gemini.ts
var GEMINI_MODELS;
var init_gemini = __esm({
  "src/clients/utils/modelMaps/gemini.ts"() {
    "use strict";
    init_types();
    GEMINI_MODELS = {
      "gemini:gemini-2.5-pro-preview": {
        apiIdentifier: "gemini-2.5-pro-preview-05-06",
        displayName: "Gemini 2.5 Pro Preview",
        provider: "gemini",
        useV1Beta: true,
        contextWindow: 1e6,
        description: "Most advanced reasoning and multimodal capabilities",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "preview",
        categories: ["reasoning" /* REASONING */, "long-context" /* LONG_CONTEXT */, "multimodal" /* MULTIMODAL */],
        capabilities: ["advanced-reasoning", "multimodal", "code-generation", "long-context"],
        tieredPricing: [
          { tokenThreshold: 0, inputPricePerMillion: 1.25, outputPricePerMillion: 5 },
          { tokenThreshold: 2e5, inputPricePerMillion: 2.5, outputPricePerMillion: 10 }
        ],
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "partial"
        }
      },
      "gemini:gemini-2.5-pro": {
        apiIdentifier: "gemini-2.5-pro-preview-05-06",
        displayName: "Gemini 2.5 Pro",
        provider: "gemini",
        useV1Beta: true,
        contextWindow: 1e6,
        description: "Production-ready advanced reasoning model",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["reasoning" /* REASONING */, "long-context" /* LONG_CONTEXT */, "multimodal" /* MULTIMODAL */],
        capabilities: ["advanced-reasoning", "multimodal", "code-generation", "long-context"],
        tieredPricing: [
          { tokenThreshold: 0, inputPricePerMillion: 1.25, outputPricePerMillion: 5 },
          { tokenThreshold: 2e5, inputPricePerMillion: 2.5, outputPricePerMillion: 10 }
        ],
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "partial"
        }
      },
      "gemini:gemini-2.0-flash-lite": {
        apiIdentifier: "gemini-2.0-flash-lite",
        displayName: "Gemini 2.0 Flash Lite",
        provider: "gemini",
        useV1Beta: true,
        contextWindow: 1e6,
        description: "Ultra-fast, cost-efficient model for simple tasks",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["fast-inference" /* FAST_INFERENCE */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["fast-inference", "basic-reasoning"],
        inputPricePerMillion: 0.05,
        outputPricePerMillion: 0.15,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "none"
        }
      },
      "gemini:gemini-2.0-flash": {
        apiIdentifier: "gemini-2.0-flash-preview-05-07",
        displayName: "Gemini 2.0 Flash",
        provider: "gemini",
        useV1Beta: true,
        contextWindow: 1e6,
        description: "Fast, efficient model with strong performance",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "preview",
        categories: ["fast-inference" /* FAST_INFERENCE */, "long-context" /* LONG_CONTEXT */],
        capabilities: ["fast-inference", "good-reasoning", "long-context"],
        inputPricePerMillion: 0.3,
        outputPricePerMillion: 1.2,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "partial"
        }
      },
      "gemini:gemini-1.5-pro": {
        apiIdentifier: "gemini-1.5-pro",
        displayName: "Gemini 1.5 Pro",
        provider: "gemini",
        useV1Beta: false,
        contextWindow: 1e6,
        description: "Previous generation large context model",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["long-context" /* LONG_CONTEXT */],
        capabilities: ["long-context", "good-reasoning"],
        tieredPricing: [
          { tokenThreshold: 0, inputPricePerMillion: 1.25, outputPricePerMillion: 5 },
          { tokenThreshold: 128e3, inputPricePerMillion: 2.5, outputPricePerMillion: 10 }
        ],
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "partial"
        }
      },
      "gemini:gemini-1.5-flash": {
        apiIdentifier: "gemini-1.5-flash",
        displayName: "Gemini 1.5 Flash",
        provider: "gemini",
        useV1Beta: false,
        contextWindow: 1e6,
        description: "Previous generation fast model",
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["fast-inference" /* FAST_INFERENCE */, "long-context" /* LONG_CONTEXT */],
        capabilities: ["fast-inference", "long-context"],
        tieredPricing: [
          { tokenThreshold: 0, inputPricePerMillion: 0.075, outputPricePerMillion: 0.3 },
          { tokenThreshold: 128e3, inputPricePerMillion: 0.15, outputPricePerMillion: 0.6 }
        ],
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "partial"
        }
      }
    };
  }
});

// src/clients/utils/modelMaps/anthropic.ts
var ANTHROPIC_MODELS;
var init_anthropic = __esm({
  "src/clients/utils/modelMaps/anthropic.ts"() {
    "use strict";
    init_types();
    ANTHROPIC_MODELS = {
      "anthropic:claude-4-opus": {
        apiIdentifier: "claude-4-opus-20241022",
        displayName: "Claude 4 Opus",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Most capable Claude model with superior reasoning",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["advanced-reasoning", "code-generation", "code-review", "analysis"],
        inputPricePerMillion: 15,
        outputPricePerMillion: 75,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          supportsPromptCaching: true,
          toolCallingSupport: "full"
        }
      },
      "anthropic:claude-4-sonnet": {
        apiIdentifier: "claude-4-sonnet-20241022",
        displayName: "Claude 4 Sonnet",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Balanced performance and cost for code review",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["good-reasoning", "code-generation", "code-review"],
        inputPricePerMillion: 3,
        outputPricePerMillion: 15,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          supportsPromptCaching: true,
          toolCallingSupport: "full"
        },
        notes: "Recommended model for code review tasks"
      },
      "anthropic:claude-3.5-sonnet": {
        apiIdentifier: "claude-3-5-sonnet-20241022",
        displayName: "Claude 3.5 Sonnet",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Enhanced Claude 3 with improved capabilities",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["good-reasoning", "code-generation", "code-review"],
        inputPricePerMillion: 3,
        outputPricePerMillion: 15,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          supportsPromptCaching: true,
          toolCallingSupport: "full"
        }
      },
      "anthropic:claude-3-opus": {
        apiIdentifier: "claude-3-opus-20240229",
        displayName: "Claude 3 Opus",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Previous generation powerful model",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "deprecated",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["advanced-reasoning", "code-generation"],
        inputPricePerMillion: 15,
        outputPricePerMillion: 75,
        deprecation: {
          deprecated: true,
          deprecationDate: "2024-01-21",
          removalDate: "2025-07-21",
          migrationGuide: "Migrate to Claude 4 Opus for improved performance and features",
          alternativeModel: "anthropic:claude-4-opus"
        },
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: false,
          supportsPromptCaching: false,
          toolCallingSupport: "full"
        }
      },
      "anthropic:claude-3-sonnet": {
        apiIdentifier: "claude-3-sonnet-20240229",
        displayName: "Claude 3 Sonnet",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Previous generation balanced model",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["coding" /* CODING */],
        capabilities: ["good-reasoning", "code-generation"],
        inputPricePerMillion: 3,
        outputPricePerMillion: 15,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: false,
          supportsPromptCaching: false,
          toolCallingSupport: "full"
        }
      },
      "anthropic:claude-3.5-haiku": {
        apiIdentifier: "claude-3-5-haiku-20241022",
        displayName: "Claude 3.5 Haiku",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Fast, cost-effective model for simple tasks",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["fast-inference" /* FAST_INFERENCE */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["fast-inference", "basic-reasoning"],
        inputPricePerMillion: 1,
        outputPricePerMillion: 5,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          supportsPromptCaching: true,
          toolCallingSupport: "full"
        }
      },
      "anthropic:claude-3-haiku": {
        apiIdentifier: "claude-3-haiku-20240307",
        displayName: "Claude 3 Haiku",
        provider: "anthropic",
        contextWindow: 2e5,
        description: "Previous generation fast model",
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY",
        supportsToolCalling: true,
        status: "deprecated",
        categories: ["fast-inference" /* FAST_INFERENCE */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["fast-inference", "basic-reasoning"],
        inputPricePerMillion: 0.25,
        outputPricePerMillion: 1.25,
        deprecation: {
          deprecated: true,
          deprecationDate: "2024-01-21",
          removalDate: "2025-07-21",
          migrationGuide: "Migrate to Claude 3.5 Haiku for better performance at similar cost",
          alternativeModel: "anthropic:claude-3.5-haiku"
        },
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: false,
          supportsPromptCaching: false,
          toolCallingSupport: "full"
        }
      }
    };
  }
});

// src/clients/utils/modelMaps/openai.ts
var OPENAI_MODELS;
var init_openai = __esm({
  "src/clients/utils/modelMaps/openai.ts"() {
    "use strict";
    init_types();
    OPENAI_MODELS = {
      "openai:gpt-4o": {
        apiIdentifier: "gpt-4o",
        displayName: "GPT-4o",
        provider: "openai",
        contextWindow: 128e3,
        description: "Multimodal model with vision capabilities",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["reasoning" /* REASONING */, "multimodal" /* MULTIMODAL */, "coding" /* CODING */],
        capabilities: ["advanced-reasoning", "multimodal", "code-generation", "vision"],
        inputPricePerMillion: 2.5,
        outputPricePerMillion: 10,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "full",
          rateLimit: 1e4
        }
      },
      "openai:gpt-4.1": {
        apiIdentifier: "gpt-4-0125-preview",
        displayName: "GPT-4.1 Preview",
        provider: "openai",
        contextWindow: 128e3,
        description: "Latest GPT-4 with improved reasoning",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: true,
        status: "preview",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["advanced-reasoning", "code-generation", "analysis"],
        inputPricePerMillion: 10,
        outputPricePerMillion: 30,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "full",
          rateLimit: 1e4
        }
      },
      "openai:gpt-4.5": {
        apiIdentifier: "gpt-4-turbo-2024-04-09",
        displayName: "GPT-4.5 Turbo",
        provider: "openai",
        contextWindow: 128e3,
        description: "Experimental model being phased out",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: true,
        status: "deprecated",
        categories: ["reasoning" /* REASONING */],
        capabilities: ["advanced-reasoning", "code-generation"],
        inputPricePerMillion: 10,
        outputPricePerMillion: 30,
        deprecation: {
          deprecated: true,
          deprecationDate: "2024-04-09",
          removalDate: "2025-07-14",
          migrationGuide: "This experimental model is being removed. Please migrate to GPT-4.1 for similar capabilities.",
          alternativeModel: "openai:gpt-4.1"
        },
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "full",
          rateLimit: 1e4
        }
      },
      "openai:gpt-4-turbo": {
        apiIdentifier: "gpt-4-turbo",
        displayName: "GPT-4 Turbo",
        provider: "openai",
        contextWindow: 128e3,
        description: "Fast GPT-4 variant with good performance",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["good-reasoning", "code-generation"],
        inputPricePerMillion: 10,
        outputPricePerMillion: 30,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "full",
          rateLimit: 1e4
        }
      },
      "openai:gpt-3.5-turbo": {
        apiIdentifier: "gpt-3.5-turbo",
        displayName: "GPT-3.5 Turbo",
        provider: "openai",
        contextWindow: 16384,
        description: "Fast, cost-effective model for simple tasks",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: true,
        status: "available",
        categories: ["fast-inference" /* FAST_INFERENCE */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["fast-inference", "basic-reasoning", "code-generation"],
        inputPricePerMillion: 0.5,
        outputPricePerMillion: 1.5,
        providerFeatures: {
          supportsStreaming: true,
          supportsBatch: true,
          toolCallingSupport: "full",
          rateLimit: 1e4
        }
      },
      "openai:o3": {
        apiIdentifier: "o3",
        displayName: "O3 Reasoning Model",
        provider: "openai",
        contextWindow: 1e5,
        description: "Advanced reasoning model for complex problems",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: false,
        status: "preview",
        categories: ["reasoning" /* REASONING */],
        capabilities: ["advanced-reasoning", "problem-solving"],
        inputPricePerMillion: 40,
        outputPricePerMillion: 120,
        providerFeatures: {
          supportsStreaming: false,
          supportsBatch: false,
          toolCallingSupport: "none",
          rateLimit: 1e3
        },
        notes: "Specialized for complex reasoning tasks, not optimized for code review"
      },
      "openai:o3-mini": {
        apiIdentifier: "o3-mini",
        displayName: "O3 Mini Reasoning Model",
        provider: "openai",
        contextWindow: 6e4,
        description: "Efficient reasoning model for moderate complexity",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY",
        supportsToolCalling: false,
        status: "preview",
        categories: ["reasoning" /* REASONING */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["good-reasoning", "problem-solving"],
        inputPricePerMillion: 10,
        outputPricePerMillion: 30,
        providerFeatures: {
          supportsStreaming: false,
          supportsBatch: false,
          toolCallingSupport: "none",
          rateLimit: 2e3
        }
      }
    };
  }
});

// src/clients/utils/modelMaps/openrouter.ts
var OPENROUTER_MODELS;
var init_openrouter = __esm({
  "src/clients/utils/modelMaps/openrouter.ts"() {
    "use strict";
    init_types();
    OPENROUTER_MODELS = {
      "openrouter:anthropic/claude-4-opus": {
        apiIdentifier: "anthropic/claude-4-opus",
        displayName: "Claude 4 Opus (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 2e5,
        description: "Access Claude 4 Opus through OpenRouter",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */],
        capabilities: ["advanced-reasoning", "code-generation", "code-review"],
        inputPricePerMillion: 15,
        outputPricePerMillion: 75,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      },
      "openrouter:anthropic/claude-4-sonnet": {
        apiIdentifier: "anthropic/claude-4-sonnet",
        displayName: "Claude 4 Sonnet (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 2e5,
        description: "Access Claude 4 Sonnet through OpenRouter",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["reasoning" /* REASONING */, "coding" /* CODING */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["good-reasoning", "code-generation", "code-review"],
        inputPricePerMillion: 3,
        outputPricePerMillion: 15,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      },
      "openrouter:openai/gpt-4o": {
        apiIdentifier: "openai/gpt-4o",
        displayName: "GPT-4o (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 128e3,
        description: "Access GPT-4o through OpenRouter",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["reasoning" /* REASONING */, "multimodal" /* MULTIMODAL */],
        capabilities: ["advanced-reasoning", "multimodal", "code-generation"],
        inputPricePerMillion: 2.5,
        outputPricePerMillion: 10,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      },
      "openrouter:google/gemini-2.5-pro": {
        apiIdentifier: "google/gemini-pro-1.5",
        displayName: "Gemini 2.5 Pro (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 1e6,
        description: "Access Gemini 2.5 Pro through OpenRouter",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["reasoning" /* REASONING */, "long-context" /* LONG_CONTEXT */],
        capabilities: ["advanced-reasoning", "long-context"],
        inputPricePerMillion: 1.25,
        outputPricePerMillion: 5,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      },
      "openrouter:meta-llama/llama-3.3-70b": {
        apiIdentifier: "meta-llama/llama-3.3-70b",
        displayName: "Llama 3.3 70B (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 131072,
        description: "Open source alternative with good performance",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["cost-optimized" /* COST_OPTIMIZED */, "coding" /* CODING */],
        capabilities: ["good-reasoning", "code-generation"],
        inputPricePerMillion: 0.59,
        outputPricePerMillion: 0.79,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      },
      "openrouter:anthropic/claude-3-haiku": {
        apiIdentifier: "anthropic/claude-3-haiku",
        displayName: "Claude 3 Haiku (via OpenRouter)",
        provider: "openrouter",
        contextWindow: 2e5,
        description: "Fast, affordable model through OpenRouter",
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY",
        supportsToolCalling: false,
        status: "available",
        categories: ["fast-inference" /* FAST_INFERENCE */, "cost-optimized" /* COST_OPTIMIZED */],
        capabilities: ["fast-inference", "basic-reasoning"],
        inputPricePerMillion: 0.25,
        outputPricePerMillion: 1.25,
        providerFeatures: {
          supportsStreaming: true,
          customHeaders: {
            "HTTP-Referer": "https://github.com/your-repo",
            "X-Title": "AI Code Review"
          }
        }
      }
    };
  }
});

// src/clients/utils/modelMaps/modelData.ts
var ENHANCED_MODEL_MAP;
var init_modelData = __esm({
  "src/clients/utils/modelMaps/modelData.ts"() {
    "use strict";
    init_gemini();
    init_anthropic();
    init_openai();
    init_openrouter();
    ENHANCED_MODEL_MAP = {
      ...GEMINI_MODELS,
      ...ANTHROPIC_MODELS,
      ...OPENAI_MODELS,
      ...OPENROUTER_MODELS
    };
  }
});

// src/clients/utils/modelMaps/legacy.ts
var MODEL_MAP, MODELS;
var init_legacy = __esm({
  "src/clients/utils/modelMaps/legacy.ts"() {
    "use strict";
    init_modelData();
    MODEL_MAP = Object.entries(ENHANCED_MODEL_MAP).reduce(
      (acc, [key, enhanced]) => {
        const legacy = {
          apiIdentifier: enhanced.apiIdentifier,
          displayName: enhanced.displayName,
          provider: enhanced.provider,
          useV1Beta: enhanced.useV1Beta,
          contextWindow: enhanced.contextWindow,
          description: enhanced.description,
          apiKeyEnvVar: enhanced.apiKeyEnvVar,
          supportsToolCalling: enhanced.supportsToolCalling
        };
        if (enhanced.deprecation?.deprecated) {
          legacy.displayName = `${legacy.displayName} (DEPRECATED)`;
          legacy.description = `DEPRECATED: ${enhanced.deprecation.migrationGuide || "Please migrate to an alternative model"}`;
        }
        acc[key] = legacy;
        return acc;
      },
      {}
    );
    MODELS = {
      gemini: Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === "gemini" && mapping.status !== "deprecated").map(([key, _]) => key),
      anthropic: Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === "anthropic" && mapping.status !== "deprecated").map(([key, _]) => key),
      openai: Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === "openai" && mapping.status !== "deprecated").map(([key, _]) => key),
      openrouter: Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === "openrouter" && mapping.status !== "deprecated").map(([key, _]) => key)
    };
  }
});

// src/clients/utils/modelMaps/functions.ts
function getApiNameFromKey(modelKey) {
  const mapping = ENHANCED_MODEL_MAP[modelKey];
  return mapping ? mapping.apiIdentifier : modelKey;
}
function getModelMapping(modelKey) {
  const enhanced = ENHANCED_MODEL_MAP[modelKey];
  if (!enhanced) return void 0;
  const legacy = {
    apiIdentifier: enhanced.apiIdentifier,
    displayName: enhanced.displayName,
    provider: enhanced.provider,
    useV1Beta: enhanced.useV1Beta,
    contextWindow: enhanced.contextWindow,
    description: enhanced.description,
    apiKeyEnvVar: enhanced.apiKeyEnvVar,
    supportsToolCalling: enhanced.supportsToolCalling
  };
  if (enhanced.deprecation?.deprecated) {
    legacy.displayName = `${legacy.displayName} (DEPRECATED)`;
    legacy.description = `DEPRECATED: ${enhanced.deprecation.migrationGuide || "Please migrate to an alternative model"}`;
  }
  return legacy;
}
function getModelsByProvider(provider) {
  return Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === provider).map(([key, _]) => key);
}
function getModels(provider) {
  return Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => mapping.provider === provider && mapping.status !== "deprecated").map(([key, _]) => key);
}
function parseModelString(modelString) {
  if (!modelString || modelString.trim() === "") {
    throw new Error("Model string cannot be empty");
  }
  const parts = modelString.split(":");
  if (parts.length === 2) {
    return {
      provider: parts[0],
      modelName: parts[1]
    };
  }
  return {
    provider: "gemini",
    modelName: modelString
  };
}
function getFullModelKey(provider, modelName) {
  return `${provider}:${modelName}`;
}
function supportsToolCalling(modelKey) {
  const mapping = ENHANCED_MODEL_MAP[modelKey];
  return mapping?.supportsToolCalling || false;
}
function getEnhancedModelMapping(modelKey) {
  return ENHANCED_MODEL_MAP[modelKey];
}
function validateModelKey(modelKey) {
  const enhanced = ENHANCED_MODEL_MAP[modelKey];
  if (!enhanced) {
    return {
      isValid: false,
      error: `Model '${modelKey}' not found in configuration`
    };
  }
  if (enhanced.deprecation?.deprecated) {
    return {
      isValid: false,
      error: `Model '${modelKey}' is deprecated`,
      warning: enhanced.deprecation.migrationGuide,
      suggestion: enhanced.deprecation.alternativeModel
    };
  }
  if (enhanced.status === "retiring") {
    return {
      isValid: true,
      warning: `Model '${modelKey}' is being retired. Consider migrating soon.`,
      suggestion: enhanced.deprecation?.alternativeModel
    };
  }
  return { isValid: true };
}
function calculateCost(modelKey, inputTokens, outputTokens) {
  const enhanced = ENHANCED_MODEL_MAP[modelKey];
  if (!enhanced) return void 0;
  if (enhanced.tieredPricing && enhanced.tieredPricing.length > 0) {
    let inputCost = 0;
    let outputCost = 0;
    let remainingInput = inputTokens;
    let remainingOutput = outputTokens;
    const sortedTiers = [...enhanced.tieredPricing].sort((a, b) => b.tokenThreshold - a.tokenThreshold);
    for (const tier of sortedTiers) {
      if (remainingInput > tier.tokenThreshold) {
        const tokensInTier = remainingInput - tier.tokenThreshold;
        inputCost += tokensInTier / 1e6 * tier.inputPricePerMillion;
        remainingInput = tier.tokenThreshold;
      }
      if (remainingOutput > tier.tokenThreshold) {
        const tokensInTier = remainingOutput - tier.tokenThreshold;
        outputCost += tokensInTier / 1e6 * tier.outputPricePerMillion;
        remainingOutput = tier.tokenThreshold;
      }
    }
    return inputCost + outputCost;
  }
  if (enhanced.inputPricePerMillion !== void 0 && enhanced.outputPricePerMillion !== void 0) {
    const inputCost = inputTokens / 1e6 * enhanced.inputPricePerMillion;
    const outputCost = outputTokens / 1e6 * enhanced.outputPricePerMillion;
    return inputCost + outputCost;
  }
  return void 0;
}
function getModelsByCategory(category, excludeDeprecated = true) {
  return Object.entries(ENHANCED_MODEL_MAP).filter(([_, mapping]) => {
    if (excludeDeprecated && mapping.deprecation?.deprecated) return false;
    return mapping.categories?.includes(category);
  }).map(([key, _]) => key);
}
function getRecommendedModelForCodeReview(preferCostOptimized = false) {
  if (preferCostOptimized) {
    const costOptimized = Object.entries(ENHANCED_MODEL_MAP).filter(
      ([_, m]) => m.categories?.includes("cost-optimized" /* COST_OPTIMIZED */) && m.categories?.includes("coding" /* CODING */) && !m.deprecation?.deprecated
    ).sort((a, b) => {
      const aCost = (a[1].inputPricePerMillion || 0) + (a[1].outputPricePerMillion || 0);
      const bCost = (b[1].inputPricePerMillion || 0) + (b[1].outputPricePerMillion || 0);
      return aCost - bCost;
    });
    if (costOptimized.length > 0) {
      return costOptimized[0][0];
    }
  }
  const recommended = Object.entries(ENHANCED_MODEL_MAP).find(([_, m]) => m.notes?.includes("Recommended model for code review"));
  return recommended ? recommended[0] : "anthropic:claude-4-sonnet";
}
function getProviderFeatures(modelKey) {
  return ENHANCED_MODEL_MAP[modelKey]?.providerFeatures;
}
function formatCost(cost) {
  if (cost < 0.01) {
    return `$${cost.toFixed(6)} USD`;
  } else if (cost < 1) {
    return `$${cost.toFixed(4)} USD`;
  } else {
    return `$${cost.toFixed(2)} USD`;
  }
}
var init_functions = __esm({
  "src/clients/utils/modelMaps/functions.ts"() {
    "use strict";
    init_modelData();
    init_types();
  }
});

// src/clients/utils/modelMaps/index.ts
var init_modelMaps = __esm({
  "src/clients/utils/modelMaps/index.ts"() {
    "use strict";
    init_types();
    init_modelData();
    init_legacy();
    init_functions();
  }
});

// src/clients/utils/modelMaps.ts
var modelMaps_exports = {};
__export(modelMaps_exports, {
  ENHANCED_MODEL_MAP: () => ENHANCED_MODEL_MAP,
  MODELS: () => MODELS,
  MODEL_MAP: () => MODEL_MAP,
  ModelCategory: () => ModelCategory,
  calculateCost: () => calculateCost,
  formatCost: () => formatCost,
  getApiNameFromKey: () => getApiNameFromKey,
  getEnhancedModelMapping: () => getEnhancedModelMapping,
  getFullModelKey: () => getFullModelKey,
  getModelMapping: () => getModelMapping,
  getModels: () => getModels,
  getModelsByCategory: () => getModelsByCategory,
  getModelsByProvider: () => getModelsByProvider,
  getProviderFeatures: () => getProviderFeatures,
  getRecommendedModelForCodeReview: () => getRecommendedModelForCodeReview,
  parseModelString: () => parseModelString,
  supportsToolCalling: () => supportsToolCalling,
  validateModelKey: () => validateModelKey
});
var init_modelMaps2 = __esm({
  "src/clients/utils/modelMaps.ts"() {
    "use strict";
    init_modelMaps();
  }
});

// src/clients/utils/modelLister.ts
function getModelsForProvider(providerKey) {
  const config4 = PROVIDER_CONFIG[providerKey];
  if (!config4) {
    logger_default.warn(`Unknown provider: ${providerKey}`);
    return [];
  }
  const apiKey = config4.apiKeyGetter();
  const apiKeyStatus = apiKey.apiKey ? "available" : "missing";
  return getModelsByProvider(providerKey).map((modelKey) => {
    const modelData = MODEL_MAP[modelKey];
    return {
      name: modelKey,
      displayName: modelData.displayName,
      provider: config4.displayName,
      description: modelData.description || config4.defaultDescription,
      contextWindow: modelData.contextWindow || config4.defaultContextWindow,
      apiKeyRequired: config4.apiKeyEnvVar,
      apiKeyStatus
    };
  });
}
function getAllModels() {
  return Object.keys(PROVIDER_CONFIG).flatMap(
    (provider) => getModelsForProvider(provider)
  );
}
function getAvailableModels() {
  return getAllModels().filter((model) => model.apiKeyStatus === "available");
}
function listModels(showOnlyAvailable = false) {
  const models = showOnlyAvailable ? getAvailableModels() : getAllModels();
  const modelsByProvider = {};
  models.forEach((model) => {
    if (!modelsByProvider[model.provider]) {
      modelsByProvider[model.provider] = [];
    }
    modelsByProvider[model.provider].push(model);
  });
  console.log(import_chalk.default.bold("\nAvailable AI Models for Code Review:"));
  console.log(import_chalk.default.dim("-----------------------------------"));
  Object.entries(modelsByProvider).forEach(([provider, providerModels]) => {
    console.log(import_chalk.default.bold(`
${provider} Models:`));
    providerModels.forEach((model) => {
      const statusColor = model.apiKeyStatus === "available" ? import_chalk.default.green : import_chalk.default.red;
      const statusText = model.apiKeyStatus === "available" ? "AVAILABLE" : "MISSING API KEY";
      console.log(
        `  ${import_chalk.default.cyan(model.displayName)} (${import_chalk.default.yellow(model.name)})`
      );
      console.log(`    ${import_chalk.default.dim("Description:")} ${model.description}`);
      if (model.contextWindow) {
        console.log(
          `    ${import_chalk.default.dim("Context Window:")} ${model.contextWindow.toLocaleString()} tokens`
        );
      }
      console.log(
        `    ${import_chalk.default.dim("API Key Required:")} ${model.apiKeyRequired}`
      );
      console.log(`    ${import_chalk.default.dim("Status:")} ${statusColor(statusText)}`);
      console.log();
    });
  });
  const availableCount = models.filter(
    (model) => model.apiKeyStatus === "available"
  ).length;
  const totalCount = models.length;
  console.log(import_chalk.default.dim("-----------------------------------"));
  console.log(
    `${import_chalk.default.bold("Summary:")} ${availableCount} of ${totalCount} models available`
  );
  if (availableCount === 0) {
    console.log(
      import_chalk.default.yellow(
        "\nNo API keys configured. Please set at least one of the following environment variables:"
      )
    );
    console.log(
      `  - ${import_chalk.default.cyan("AI_CODE_REVIEW_GOOGLE_API_KEY")} for Gemini models`
    );
    console.log(
      `  - ${import_chalk.default.cyan("AI_CODE_REVIEW_ANTHROPIC_API_KEY")} for Claude models`
    );
    console.log(
      `  - ${import_chalk.default.cyan("AI_CODE_REVIEW_OPENAI_API_KEY")} for OpenAI models`
    );
    console.log(
      `  - ${import_chalk.default.cyan("AI_CODE_REVIEW_OPENROUTER_API_KEY")} for OpenRouter models`
    );
  }
}
function listModelConfigs() {
  console.log(import_chalk.default.bold("\nSupported Models and Configuration Names:"));
  console.log(import_chalk.default.dim("-----------------------------------"));
  const modelsByProvider = {};
  Object.entries(MODEL_MAP).forEach(([key, model]) => {
    if (!modelsByProvider[model.provider]) {
      modelsByProvider[model.provider] = [];
    }
    modelsByProvider[model.provider].push({
      ...model,
      name: key
      // Add the key as the name
    });
  });
  Object.entries(modelsByProvider).forEach(([provider, providerModels]) => {
    console.log(
      import_chalk.default.bold(
        `
${provider.charAt(0).toUpperCase() + provider.slice(1)} Models:`
      )
    );
    providerModels.forEach((model) => {
      console.log(
        `  ${import_chalk.default.cyan(model.displayName)} (${import_chalk.default.yellow(model.name)})`
      );
      console.log(`    ${import_chalk.default.dim("API Identifier:")} ${model.apiIdentifier}`);
      if (model.description) {
        console.log(`    ${import_chalk.default.dim("Description:")} ${model.description}`);
      }
      if (model.contextWindow) {
        console.log(
          `    ${import_chalk.default.dim("Context Window:")} ${model.contextWindow.toLocaleString()} tokens`
        );
      }
      console.log(
        `    ${import_chalk.default.dim("API Key Required:")} ${model.apiKeyEnvVar}`
      );
      console.log();
    });
  });
  console.log(import_chalk.default.dim("-----------------------------------"));
  console.log(import_chalk.default.bold("Usage Examples:"));
  console.log(
    `  ${import_chalk.default.dim("Environment Variable:")} AI_CODE_REVIEW_MODEL=gemini:gemini-1.5-pro`
  );
  console.log(
    `  ${import_chalk.default.dim("Command Line:")} --model=anthropic:claude-3-opus`
  );
  console.log(`  ${import_chalk.default.dim("Config File:")} "model": "openai:gpt-4-turbo"`);
}
var import_chalk, PROVIDER_CONFIG;
var init_modelLister = __esm({
  "src/clients/utils/modelLister.ts"() {
    "use strict";
    init_envLoader();
    import_chalk = __toESM(require("chalk"));
    init_logger();
    init_modelMaps2();
    PROVIDER_CONFIG = {
      gemini: {
        apiKeyGetter: getGoogleApiKey,
        displayName: "Google",
        defaultDescription: "Google Gemini model",
        defaultContextWindow: 1e6,
        apiKeyEnvVar: "AI_CODE_REVIEW_GOOGLE_API_KEY"
      },
      anthropic: {
        apiKeyGetter: getAnthropicApiKey,
        displayName: "Anthropic",
        defaultDescription: "Anthropic Claude model",
        defaultContextWindow: 2e5,
        apiKeyEnvVar: "AI_CODE_REVIEW_ANTHROPIC_API_KEY"
      },
      openai: {
        apiKeyGetter: getOpenAIApiKey,
        displayName: "OpenAI",
        defaultDescription: "OpenAI model",
        defaultContextWindow: 16e3,
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENAI_API_KEY"
      },
      openrouter: {
        apiKeyGetter: getOpenRouterApiKey,
        displayName: "OpenRouter",
        defaultDescription: "Model via OpenRouter",
        defaultContextWindow: 32e3,
        apiKeyEnvVar: "AI_CODE_REVIEW_OPENROUTER_API_KEY"
      }
    };
  }
});

// src/tokenizers/baseTokenizer.ts
function getTokenizer(modelName) {
  const modelNameLower = modelName.toLowerCase();
  if (modelNameLower.includes("gpt")) {
    return TokenizerRegistry.getAllTokenizers().find(
      (t2) => t2.getModelName() === "gpt"
    ) || new FallbackTokenizer();
  }
  if (modelNameLower.includes("claude")) {
    return TokenizerRegistry.getAllTokenizers().find(
      (t2) => t2.getModelName() === "claude"
    ) || new FallbackTokenizer();
  }
  if (modelNameLower.includes("gemini")) {
    return TokenizerRegistry.getAllTokenizers().find(
      (t2) => t2.getModelName() === "gemini"
    ) || new FallbackTokenizer();
  }
  return new FallbackTokenizer();
}
function countTokens(text, modelName) {
  const tokenizer = getTokenizer(modelName);
  const count = tokenizer.countTokens(text);
  if (modelName === "test-small-context") {
    return text.length;
  }
  return count;
}
var TokenizerRegistry, FallbackTokenizer;
var init_baseTokenizer = __esm({
  "src/tokenizers/baseTokenizer.ts"() {
    "use strict";
    TokenizerRegistry = class _TokenizerRegistry {
      static tokenizers = [];
      /**
       * Register a tokenizer
       * @param tokenizer Tokenizer to register
       */
      static register(tokenizer) {
        _TokenizerRegistry.tokenizers.push(tokenizer);
      }
      /**
       * Get a tokenizer for a specific model
       * @param modelName Name of the model
       * @returns Tokenizer for the model, or undefined if none found
       */
      static getTokenizer(modelName) {
        return _TokenizerRegistry.tokenizers.find((t2) => t2.supportsModel(modelName));
      }
      /**
       * Get all registered tokenizers
       * @returns Array of all registered tokenizers
       */
      static getAllTokenizers() {
        return [..._TokenizerRegistry.tokenizers];
      }
    };
    FallbackTokenizer = class {
      /**
       * Count the number of tokens in a text using a simple approximation
       * @param text Text to count tokens for
       * @returns Estimated token count
       */
      countTokens(text) {
        return Math.ceil(text.length / 4);
      }
      /**
       * Get the model name for this tokenizer
       * @returns 'fallback'
       */
      getModelName() {
        return "fallback";
      }
      /**
       * This tokenizer is used as a fallback for any model
       * @param _modelName Name of the model (unused but required by interface)
       * @returns Always true
       */
      supportsModel(_modelName) {
        return true;
      }
    };
    TokenizerRegistry.register(new FallbackTokenizer());
  }
});

// src/tokenizers/gptTokenizer.ts
var import_gpt_tokenizer, GPTTokenizer;
var init_gptTokenizer = __esm({
  "src/tokenizers/gptTokenizer.ts"() {
    "use strict";
    import_gpt_tokenizer = require("gpt-tokenizer");
    init_baseTokenizer();
    GPTTokenizer = class {
      modelPatterns = [/gpt/i];
      /**
       * Count the number of tokens in a text using the GPT tokenizer
       * @param text Text to count tokens for
       * @returns Actual token count
       */
      countTokens(text) {
        try {
          const tokens = (0, import_gpt_tokenizer.encode)(text);
          return tokens.length;
        } catch (error2) {
          console.warn(`Error counting tokens with GPT tokenizer: ${error2}`);
          return Math.ceil(text.length / 4);
        }
      }
      /**
       * Get the model name for this tokenizer
       * @returns 'gpt'
       */
      getModelName() {
        return "gpt";
      }
      /**
       * Check if this tokenizer supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        const lowerModelName = modelName.toLowerCase();
        return this.modelPatterns.some((pattern) => pattern.test(lowerModelName));
      }
    };
    TokenizerRegistry.register(new GPTTokenizer());
  }
});

// src/tokenizers/claudeTokenizer.ts
var import_tokenizer, ClaudeTokenizer;
var init_claudeTokenizer = __esm({
  "src/tokenizers/claudeTokenizer.ts"() {
    "use strict";
    import_tokenizer = require("@anthropic-ai/tokenizer");
    init_baseTokenizer();
    ClaudeTokenizer = class {
      modelPatterns = [/claude/i];
      /**
       * Count the number of tokens in a text using the Claude tokenizer
       * @param text Text to count tokens for
       * @returns Actual token count
       */
      countTokens(text) {
        try {
          return (0, import_tokenizer.countTokens)(text);
        } catch (error2) {
          console.warn(`Error counting tokens with Claude tokenizer: ${error2}`);
          return Math.ceil(text.length / 4);
        }
      }
      /**
       * Get the model name for this tokenizer
       * @returns 'claude'
       */
      getModelName() {
        return "claude";
      }
      /**
       * Check if this tokenizer supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        const lowerModelName = modelName.toLowerCase();
        return this.modelPatterns.some((pattern) => pattern.test(lowerModelName));
      }
    };
    TokenizerRegistry.register(new ClaudeTokenizer());
  }
});

// src/tokenizers/geminiTokenizer.ts
var GeminiTokenizer;
var init_geminiTokenizer = __esm({
  "src/tokenizers/geminiTokenizer.ts"() {
    "use strict";
    init_baseTokenizer();
    GeminiTokenizer = class {
      modelPatterns = [/gemini/i];
      /**
       * Count the number of tokens in a text using an approximation for Gemini models
       * @param text Text to count tokens for
       * @returns Estimated token count
       */
      countTokens(text) {
        return Math.ceil(text.length / 4);
      }
      /**
       * Get the model name for this tokenizer
       * @returns 'gemini'
       */
      getModelName() {
        return "gemini";
      }
      /**
       * Check if this tokenizer supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        const lowerModelName = modelName.toLowerCase();
        return this.modelPatterns.some((pattern) => pattern.test(lowerModelName));
      }
    };
    TokenizerRegistry.register(new GeminiTokenizer());
  }
});

// src/tokenizers/index.ts
var init_tokenizers = __esm({
  "src/tokenizers/index.ts"() {
    "use strict";
    init_baseTokenizer();
    init_gptTokenizer();
    init_claudeTokenizer();
    init_geminiTokenizer();
  }
});

// src/estimators/abstractEstimator.ts
var AbstractTokenEstimator;
var init_abstractEstimator = __esm({
  "src/estimators/abstractEstimator.ts"() {
    "use strict";
    init_tokenizers();
    AbstractTokenEstimator = class {
      /**
       * Estimate the number of tokens in a text
       * @param text Text to estimate tokens for
       * @param modelName Optional model name to use for tokenization
       * @returns Estimated token count
       */
      estimateTokenCount(text, modelName) {
        return countTokens(text, modelName || this.getDefaultModel());
      }
      /**
       * Format a cost value as a currency string
       * @param cost Cost value in USD
       * @returns Formatted cost string
       */
      formatCost(cost) {
        return `$${cost.toFixed(6)} USD`;
      }
      /**
       * Get cost information based on token counts
       * @param inputTokens Number of input tokens
       * @param outputTokens Number of output tokens
       * @param modelName Name of the model (optional)
       * @returns Cost information
       */
      getCostInfo(inputTokens, outputTokens, modelName) {
        const totalTokens = inputTokens + outputTokens;
        const estimatedCost = this.calculateCost(
          inputTokens,
          outputTokens,
          modelName
        );
        return {
          inputTokens,
          outputTokens,
          totalTokens,
          estimatedCost,
          formattedCost: this.formatCost(estimatedCost)
        };
      }
      /**
       * Get cost information based on text
       * @param inputText Input text
       * @param outputText Output text
       * @param modelName Name of the model (optional)
       * @returns Cost information
       */
      getCostInfoFromText(inputText, outputText, modelName) {
        const model = modelName || this.getDefaultModel();
        const inputTokens = this.estimateTokenCount(inputText, model);
        const outputTokens = this.estimateTokenCount(outputText, model);
        return this.getCostInfo(inputTokens, outputTokens, model);
      }
    };
  }
});

// src/estimators/geminiEstimator.ts
var GeminiTokenEstimator;
var init_geminiEstimator = __esm({
  "src/estimators/geminiEstimator.ts"() {
    "use strict";
    init_abstractEstimator();
    GeminiTokenEstimator = class _GeminiTokenEstimator extends AbstractTokenEstimator {
      static instance;
      /**
       * Get the singleton instance of the estimator
       * @returns GeminiTokenEstimator instance
       */
      static getInstance() {
        if (!_GeminiTokenEstimator.instance) {
          _GeminiTokenEstimator.instance = new _GeminiTokenEstimator();
        }
        return _GeminiTokenEstimator.instance;
      }
      /**
       * Pricing information for Gemini models
       */
      MODEL_PRICING = {
        // Gemini 2.5 models
        "gemini-2.5-pro": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 125e-5,
              // $1.25 per 1M tokens (200k tokens)
              outputTokenCost: 0.01
              // $10.00 per 1M tokens (200k tokens)
            },
            {
              threshold: 2e5,
              inputTokenCost: 25e-4,
              // $2.50 per 1M tokens (>200k tokens)
              outputTokenCost: 0.015
              // $15.00 per 1M tokens (>200k tokens)
            }
          ]
        },
        "gemini-2.5-pro-preview": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 125e-5,
              // $1.25 per 1M tokens (200k tokens)
              outputTokenCost: 0.01
              // $10.00 per 1M tokens (200k tokens)
            },
            {
              threshold: 2e5,
              inputTokenCost: 25e-4,
              // $2.50 per 1M tokens (>200k tokens)
              outputTokenCost: 0.015
              // $15.00 per 1M tokens (>200k tokens)
            }
          ]
        },
        "gemini-2.5-pro-exp": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 125e-5,
              // $1.25 per 1M tokens (200k tokens)
              outputTokenCost: 0.01
              // $10.00 per 1M tokens (200k tokens)
            },
            {
              threshold: 2e5,
              inputTokenCost: 25e-4,
              // $2.50 per 1M tokens (>200k tokens)
              outputTokenCost: 0.015
              // $15.00 per 1M tokens (>200k tokens)
            }
          ]
        },
        "gemini-2.0-flash": {
          type: "standard",
          inputTokenCost: 1e-4,
          // $0.10 per 1M tokens
          outputTokenCost: 4e-4
          // $0.40 per 1M tokens
        },
        "gemini-2.0-flash-lite": {
          type: "standard",
          inputTokenCost: 75e-6,
          // $0.075 per 1M tokens
          outputTokenCost: 3e-4
          // $0.30 per 1M tokens
        },
        // Gemini 1.5 models
        "gemini-1.5-pro": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 125e-5,
              // $1.25 per 1M tokens (128k tokens)
              outputTokenCost: 5e-3
              // $5.00 per 1M tokens (128k tokens)
            },
            {
              threshold: 128e3,
              inputTokenCost: 25e-4,
              // $2.50 per 1M tokens (>128k tokens)
              outputTokenCost: 0.01
              // $10.00 per 1M tokens (>128k tokens)
            }
          ]
        },
        "gemini-1.5-flash": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 75e-6,
              // $0.075 per 1M tokens (128k tokens)
              outputTokenCost: 3e-4
              // $0.30 per 1M tokens (128k tokens)
            },
            {
              threshold: 128e3,
              inputTokenCost: 15e-5,
              // $0.15 per 1M tokens (>128k tokens)
              outputTokenCost: 6e-4
              // $0.60 per 1M tokens (>128k tokens)
            }
          ]
        },
        "gemini-1.5-flash-8b": {
          type: "tiered",
          tiers: [
            {
              threshold: 0,
              inputTokenCost: 375e-7,
              // $0.0375 per 1M tokens (128k tokens)
              outputTokenCost: 15e-5
              // $0.15 per 1M tokens (128k tokens)
            },
            {
              threshold: 128e3,
              inputTokenCost: 75e-6,
              // $0.075 per 1M tokens (>128k tokens)
              outputTokenCost: 3e-4
              // $0.30 per 1M tokens (>128k tokens)
            }
          ]
        },
        // Default fallback pricing
        default: {
          type: "standard",
          inputTokenCost: 1e-3,
          // $1.00 per 1M tokens
          outputTokenCost: 2e-3
          // $2.00 per 1M tokens
        }
      };
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
        super();
      }
      /**
       * Get the pricing for a specific model
       * @param modelName Name of the model
       * @returns Pricing information for the model
       */
      getModelPricing(modelName) {
        return this.MODEL_PRICING[modelName] || this.MODEL_PRICING["default"];
      }
      /**
       * Calculate the cost for a specific tier
       * @param tokens Number of tokens
       * @param tokenCost Cost per 1K tokens
       * @param tierStart Start of the tier
       * @param tierEnd End of the tier (or undefined for no upper limit)
       * @returns Cost for this tier
       */
      calculateTierCost(tokens, tokenCost, tierStart, tierEnd) {
        const tierTokens = tierEnd ? Math.min(Math.max(0, tokens - tierStart), tierEnd - tierStart) : Math.max(0, tokens - tierStart);
        return tierTokens / 1e3 * tokenCost;
      }
      /**
       * Calculate the cost for a given number of input and output tokens
       * @param inputTokens Number of input tokens
       * @param outputTokens Number of output tokens
       * @param modelName Name of the model (optional, uses default if not provided)
       * @returns Estimated cost in USD
       */
      calculateCost(inputTokens, outputTokens, modelName = this.getDefaultModel()) {
        const pricing = this.getModelPricing(modelName);
        let inputCost = 0;
        let outputCost = 0;
        if (pricing.type === "standard") {
          inputCost = inputTokens / 1e3 * pricing.inputTokenCost;
          outputCost = outputTokens / 1e3 * pricing.outputTokenCost;
        } else if (pricing.type === "tiered") {
          const tiers = pricing.tiers;
          for (let i = 0; i < tiers.length; i++) {
            const tierStart = tiers[i].threshold;
            const tierEnd = i < tiers.length - 1 ? tiers[i + 1].threshold : void 0;
            inputCost += this.calculateTierCost(
              inputTokens,
              tiers[i].inputTokenCost,
              tierStart,
              tierEnd
            );
          }
          for (let i = 0; i < tiers.length; i++) {
            const tierStart = tiers[i].threshold;
            const tierEnd = i < tiers.length - 1 ? tiers[i + 1].threshold : void 0;
            outputCost += this.calculateTierCost(
              outputTokens,
              tiers[i].outputTokenCost,
              tierStart,
              tierEnd
            );
          }
        }
        return inputCost + outputCost;
      }
      /**
       * Get the default model name for this estimator
       * @returns Default model name
       */
      getDefaultModel() {
        return "gemini-1.5-pro";
      }
      /**
       * Check if this estimator supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        return modelName in this.MODEL_PRICING || modelName.startsWith("gemini-");
      }
    };
  }
});

// src/estimators/anthropicEstimator.ts
var AnthropicTokenEstimator;
var init_anthropicEstimator = __esm({
  "src/estimators/anthropicEstimator.ts"() {
    "use strict";
    init_abstractEstimator();
    init_modelMaps2();
    AnthropicTokenEstimator = class _AnthropicTokenEstimator extends AbstractTokenEstimator {
      static instance;
      /**
       * Get the singleton instance of the estimator
       * @returns AnthropicTokenEstimator instance
       */
      static getInstance() {
        if (!_AnthropicTokenEstimator.instance) {
          _AnthropicTokenEstimator.instance = new _AnthropicTokenEstimator();
        }
        return _AnthropicTokenEstimator.instance;
      }
      /**
       * Pricing information for Anthropic models
       */
      MODEL_PRICING = {
        // Claude 3 models
        "claude-3-opus-20240229": {
          inputTokenCost: 0.015,
          // $15.00 per 1M tokens
          outputTokenCost: 0.075
          // $75.00 per 1M tokens
        },
        "claude-3-sonnet-20240229": {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        },
        "claude-3-haiku-20240307": {
          inputTokenCost: 25e-5,
          // $0.25 per 1M tokens
          outputTokenCost: 125e-5
          // $1.25 per 1M tokens
        },
        // Claude 3.5 models
        "claude-3-5-sonnet-20241022": {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        },
        "claude-3-5-haiku-20241022": {
          inputTokenCost: 8e-4,
          // $0.80 per 1M tokens
          outputTokenCost: 4e-3
          // $4.00 per 1M tokens
        },
        // Claude 3.7 models
        "claude-3-7-sonnet-20250219": {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens (estimated)
          outputTokenCost: 0.015
          // $15.00 per 1M tokens (estimated)
        },
        // Claude 4 models
        "claude-sonnet-4-20250514": {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        },
        "claude-opus-4-20250514": {
          inputTokenCost: 0.015,
          // $15.00 per 1M tokens
          outputTokenCost: 0.075
          // $75.00 per 1M tokens
        },
        // Claude 2 models
        "claude-2.1": {
          inputTokenCost: 8e-3,
          // $8.00 per 1M tokens
          outputTokenCost: 0.024
          // $24.00 per 1M tokens
        },
        "claude-2.0": {
          inputTokenCost: 8e-3,
          // $8.00 per 1M tokens
          outputTokenCost: 0.024
          // $24.00 per 1M tokens
        },
        // Claude Instant models
        "claude-instant-1.2": {
          inputTokenCost: 8e-4,
          // $0.80 per 1M tokens
          outputTokenCost: 24e-4
          // $2.40 per 1M tokens
        },
        // Default fallback pricing (using Claude 3 Sonnet as default)
        default: {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        }
      };
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
        super();
      }
      /**
       * Get the pricing for a specific model
       * @param modelName Name of the model
       * @returns Pricing information for the model
       */
      getModelPricing(modelName) {
        const apiIdentifier = modelName.includes(":") ? getApiNameFromKey(modelName) : modelName;
        return this.MODEL_PRICING[apiIdentifier] || this.MODEL_PRICING["default"];
      }
      /**
       * Calculate the cost for a given number of input and output tokens
       * @param inputTokens Number of input tokens
       * @param outputTokens Number of output tokens
       * @param modelName Name of the model (optional, uses default if not provided)
       * @returns Estimated cost in USD
       */
      calculateCost(inputTokens, outputTokens, modelName = this.getDefaultModel()) {
        const pricing = this.getModelPricing(modelName);
        const inputCost = inputTokens / 1e3 * pricing.inputTokenCost;
        const outputCost = outputTokens / 1e3 * pricing.outputTokenCost;
        return inputCost + outputCost;
      }
      /**
       * Get the default model name for this estimator
       * @returns Default model name
       */
      getDefaultModel() {
        return "claude-3-sonnet-20240229";
      }
      /**
       * Check if this estimator supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        return modelName in this.MODEL_PRICING || modelName.startsWith("claude-");
      }
    };
  }
});

// src/estimators/openaiEstimator.ts
var OpenAITokenEstimator;
var init_openaiEstimator = __esm({
  "src/estimators/openaiEstimator.ts"() {
    "use strict";
    init_abstractEstimator();
    OpenAITokenEstimator = class _OpenAITokenEstimator extends AbstractTokenEstimator {
      static instance;
      /**
       * Get the singleton instance of the estimator
       * @returns OpenAITokenEstimator instance
       */
      static getInstance() {
        if (!_OpenAITokenEstimator.instance) {
          _OpenAITokenEstimator.instance = new _OpenAITokenEstimator();
        }
        return _OpenAITokenEstimator.instance;
      }
      /**
       * Pricing information for OpenAI models
       */
      MODEL_PRICING = {
        // GPT-4o models
        "gpt-4o": {
          inputTokenCost: 5e-3,
          // $5.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        },
        // GPT-4 Turbo models
        "gpt-4-turbo": {
          inputTokenCost: 0.01,
          // $10.00 per 1M tokens
          outputTokenCost: 0.03
          // $30.00 per 1M tokens
        },
        "gpt-4-turbo-preview": {
          inputTokenCost: 0.01,
          // $10.00 per 1M tokens
          outputTokenCost: 0.03
          // $30.00 per 1M tokens
        },
        // GPT-4 models
        "gpt-4": {
          inputTokenCost: 0.03,
          // $30.00 per 1M tokens
          outputTokenCost: 0.06
          // $60.00 per 1M tokens
        },
        "gpt-4-32k": {
          inputTokenCost: 0.06,
          // $60.00 per 1M tokens
          outputTokenCost: 0.12
          // $120.00 per 1M tokens
        },
        // GPT-3.5 Turbo models
        "gpt-3.5-turbo": {
          inputTokenCost: 5e-4,
          // $0.50 per 1M tokens
          outputTokenCost: 15e-4
          // $1.50 per 1M tokens
        },
        "gpt-3.5-turbo-16k": {
          inputTokenCost: 1e-3,
          // $1.00 per 1M tokens
          outputTokenCost: 2e-3
          // $2.00 per 1M tokens
        },
        // O3 reasoning models
        "o3": {
          inputTokenCost: 0.015,
          // $15.00 per 1M tokens
          outputTokenCost: 0.06
          // $60.00 per 1M tokens
        },
        "o3-mini": {
          inputTokenCost: 3e-3,
          // $3.00 per 1M tokens
          outputTokenCost: 0.012
          // $12.00 per 1M tokens
        },
        // Default fallback pricing (using GPT-4o as default)
        default: {
          inputTokenCost: 5e-3,
          // $5.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        }
      };
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
        super();
      }
      /**
       * Get the pricing for a specific model
       * @param modelName Name of the model
       * @returns Pricing information for the model
       */
      getModelPricing(modelName) {
        return this.MODEL_PRICING[modelName] || this.MODEL_PRICING["default"];
      }
      /**
       * Calculate the cost for a given number of input and output tokens
       * @param inputTokens Number of input tokens
       * @param outputTokens Number of output tokens
       * @param modelName Name of the model (optional, uses default if not provided)
       * @returns Estimated cost in USD
       */
      calculateCost(inputTokens, outputTokens, modelName = this.getDefaultModel()) {
        const pricing = this.getModelPricing(modelName);
        const inputCost = inputTokens / 1e3 * pricing.inputTokenCost;
        const outputCost = outputTokens / 1e3 * pricing.outputTokenCost;
        return inputCost + outputCost;
      }
      /**
       * Get the default model name for this estimator
       * @returns Default model name
       */
      getDefaultModel() {
        return "gpt-4o";
      }
      /**
       * Check if this estimator supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        return modelName in this.MODEL_PRICING || modelName.startsWith("gpt-") || modelName.startsWith("o3");
      }
    };
  }
});

// src/estimators/openRouterEstimator.ts
var OpenRouterTokenEstimator;
var init_openRouterEstimator = __esm({
  "src/estimators/openRouterEstimator.ts"() {
    "use strict";
    init_abstractEstimator();
    init_anthropicEstimator();
    init_openaiEstimator();
    OpenRouterTokenEstimator = class _OpenRouterTokenEstimator extends AbstractTokenEstimator {
      static instance;
      anthropicEstimator;
      openaiEstimator;
      /**
       * Get the singleton instance of the estimator
       * @returns OpenRouterTokenEstimator instance
       */
      static getInstance() {
        if (!_OpenRouterTokenEstimator.instance) {
          _OpenRouterTokenEstimator.instance = new _OpenRouterTokenEstimator();
        }
        return _OpenRouterTokenEstimator.instance;
      }
      /**
       * Pricing information for OpenRouter-specific models
       * Note: Many models are provided by other providers and use their pricing
       */
      MODEL_PRICING = {
        // Models with OpenRouter-specific pricing
        "mistralai/mistral-7b-instruct": {
          inputTokenCost: 2e-4,
          // $0.20 per 1M tokens
          outputTokenCost: 2e-4
          // $0.20 per 1M tokens
        },
        "mistralai/mistral-small": {
          inputTokenCost: 2e-3,
          // $2.00 per 1M tokens
          outputTokenCost: 6e-3
          // $6.00 per 1M tokens
        },
        "mistralai/mistral-medium": {
          inputTokenCost: 27e-4,
          // $2.70 per 1M tokens
          outputTokenCost: 81e-4
          // $8.10 per 1M tokens
        },
        "mistralai/mistral-large": {
          inputTokenCost: 8e-3,
          // $8.00 per 1M tokens
          outputTokenCost: 0.024
          // $24.00 per 1M tokens
        },
        // Default fallback pricing
        default: {
          inputTokenCost: 5e-3,
          // $5.00 per 1M tokens
          outputTokenCost: 0.015
          // $15.00 per 1M tokens
        }
      };
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
        super();
        this.anthropicEstimator = AnthropicTokenEstimator.getInstance();
        this.openaiEstimator = OpenAITokenEstimator.getInstance();
      }
      /**
       * Get the pricing for a specific model
       * @param modelName Name of the model
       * @returns Pricing information for the model
       */
      getModelPricing(modelName) {
        if (modelName.startsWith("openrouter-")) {
          modelName = modelName.substring("openrouter-".length);
        }
        if (modelName in this.MODEL_PRICING) {
          return this.MODEL_PRICING[modelName];
        }
        if (modelName.startsWith("anthropic/") || modelName.includes("claude")) {
          const anthropicModel = modelName.startsWith("anthropic/") ? modelName.substring("anthropic/".length) : modelName;
          return this.anthropicEstimator.supportsModel(anthropicModel) ? {
            inputTokenCost: this.anthropicEstimator.calculateCost(1e3, 0, anthropicModel) / 1e3,
            outputTokenCost: this.anthropicEstimator.calculateCost(0, 1e3, anthropicModel) / 1e3
          } : this.MODEL_PRICING["default"];
        }
        if (modelName.startsWith("openai/") || modelName.includes("gpt")) {
          const openaiModel = modelName.startsWith("openai/") ? modelName.substring("openai/".length) : modelName;
          return this.openaiEstimator.supportsModel(openaiModel) ? {
            inputTokenCost: this.openaiEstimator.calculateCost(1e3, 0, openaiModel) / 1e3,
            outputTokenCost: this.openaiEstimator.calculateCost(0, 1e3, openaiModel) / 1e3
          } : this.MODEL_PRICING["default"];
        }
        return this.MODEL_PRICING["default"];
      }
      /**
       * Calculate the cost for a given number of input and output tokens
       * @param inputTokens Number of input tokens
       * @param outputTokens Number of output tokens
       * @param modelName Name of the model (optional, uses default if not provided)
       * @returns Estimated cost in USD
       */
      calculateCost(inputTokens, outputTokens, modelName = this.getDefaultModel()) {
        const OPENROUTER_MARKUP = 1.1;
        const pricing = this.getModelPricing(modelName);
        const inputCost = inputTokens / 1e3 * pricing.inputTokenCost;
        const outputCost = outputTokens / 1e3 * pricing.outputTokenCost;
        return (inputCost + outputCost) * OPENROUTER_MARKUP;
      }
      /**
       * Get the default model name for this estimator
       * @returns Default model name
       */
      getDefaultModel() {
        return "openai/gpt-4o";
      }
      /**
       * Check if this estimator supports a given model
       * @param modelName Name of the model to check
       * @returns True if the model is supported, false otherwise
       */
      supportsModel(modelName) {
        return modelName.startsWith("openrouter-") || modelName.includes("/") || this.anthropicEstimator.supportsModel(modelName) || this.openaiEstimator.supportsModel(modelName);
      }
    };
  }
});

// src/estimators/estimatorFactory.ts
var EstimatorFactory;
var init_estimatorFactory = __esm({
  "src/estimators/estimatorFactory.ts"() {
    "use strict";
    init_geminiEstimator();
    init_anthropicEstimator();
    init_openaiEstimator();
    init_openRouterEstimator();
    EstimatorFactory = class _EstimatorFactory {
      static instance;
      /**
       * Get the singleton instance of the factory
       * @returns EstimatorFactory instance
       */
      static getInstance() {
        if (!_EstimatorFactory.instance) {
          _EstimatorFactory.instance = new _EstimatorFactory();
        }
        return _EstimatorFactory.instance;
      }
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
      }
      /**
       * Get the appropriate estimator for a given model
       * @param modelName Name of the model
       * @returns TokenEstimator instance
       */
      getEstimatorForModel(modelName) {
        if (modelName.includes(":")) {
          const [provider] = modelName.split(":");
          return this.getEstimatorForProvider(provider);
        }
        if (modelName.startsWith("gemini-")) {
          return GeminiTokenEstimator.getInstance();
        } else if (modelName.startsWith("claude-") || modelName.startsWith("anthropic/")) {
          return AnthropicTokenEstimator.getInstance();
        } else if (modelName.startsWith("gpt-") || modelName.startsWith("openai/")) {
          return OpenAITokenEstimator.getInstance();
        } else if (modelName.startsWith("openrouter-")) {
          return OpenRouterTokenEstimator.getInstance();
        }
        return GeminiTokenEstimator.getInstance();
      }
      /**
       * Get the estimator for a specific provider
       * @param provider Provider name
       * @returns TokenEstimator instance
       */
      getEstimatorForProvider(provider) {
        switch (provider.toLowerCase()) {
          case "gemini":
            return GeminiTokenEstimator.getInstance();
          case "anthropic":
            return AnthropicTokenEstimator.getInstance();
          case "openai":
            return OpenAITokenEstimator.getInstance();
          case "openrouter":
            return OpenRouterTokenEstimator.getInstance();
          default:
            return GeminiTokenEstimator.getInstance();
        }
      }
      /**
       * Get the default estimator
       * @returns TokenEstimator instance
       */
      getDefaultEstimator() {
        return GeminiTokenEstimator.getInstance();
      }
    };
  }
});

// src/estimators/index.ts
function estimateTokenCount(text) {
  return defaultEstimator.estimateTokenCount(text);
}
function formatCost2(cost) {
  return defaultEstimator.formatCost(cost);
}
function getCostInfo(inputTokens, outputTokens, modelName) {
  if (modelName) {
    const estimator = factory.getEstimatorForModel(modelName);
    return estimator.getCostInfo(inputTokens, outputTokens, modelName);
  }
  return defaultEstimator.getCostInfo(inputTokens, outputTokens);
}
var factory, defaultEstimator;
var init_estimators = __esm({
  "src/estimators/index.ts"() {
    "use strict";
    init_abstractEstimator();
    init_geminiEstimator();
    init_anthropicEstimator();
    init_openaiEstimator();
    init_openRouterEstimator();
    init_estimatorFactory();
    init_estimatorFactory();
    factory = EstimatorFactory.getInstance();
    defaultEstimator = factory.getDefaultEstimator();
  }
});

// src/utils/estimationUtils.ts
var estimationUtils_exports = {};
__export(estimationUtils_exports, {
  estimateFromFilePaths: () => estimateFromFilePaths,
  estimateMultiPassReviewCost: () => estimateMultiPassReviewCost,
  estimateOutputTokens: () => estimateOutputTokens,
  estimateReviewCost: () => estimateReviewCost,
  formatEstimation: () => formatEstimation,
  formatMultiPassEstimation: () => formatMultiPassEstimation
});
function estimateOutputTokens(inputTokens, reviewType) {
  const ratio = OUTPUT_TO_INPUT_RATIO[reviewType] || OUTPUT_TO_INPUT_RATIO.default;
  return Math.ceil(inputTokens * ratio);
}
async function estimateReviewCost(files, reviewType, modelName = process.env.AI_CODE_REVIEW_MODEL || "gemini:gemini-1.5-pro") {
  let totalInputTokens = REVIEW_OVERHEAD_TOKENS;
  let totalFileSize = 0;
  for (const file of files) {
    const fileTokens = estimateTokenCount(file.content);
    totalInputTokens += fileTokens;
    totalFileSize += file.content.length;
  }
  const estimatedOutputTokens = estimateOutputTokens(
    totalInputTokens,
    reviewType
  );
  const costInfo = getCostInfo(
    totalInputTokens,
    estimatedOutputTokens,
    modelName
  );
  return {
    ...costInfo,
    fileCount: files.length,
    totalFileSize
  };
}
function formatEstimation(estimation, reviewType, modelName) {
  const [provider, model] = modelName.includes(":") ? modelName.split(":") : [void 0, modelName];
  const displayModel = model || modelName;
  const displayProvider = provider ? `${provider.charAt(0).toUpperCase() + provider.slice(1)}` : "Unknown";
  const fileSizeInKB = (estimation.totalFileSize / 1024).toFixed(2);
  const averageFileSize = estimation.fileCount > 0 ? (estimation.totalFileSize / estimation.fileCount / 1024).toFixed(2) : "0.00";
  return `
=== Token Usage and Cost Estimation ===

Review Type: ${reviewType}
Provider: ${displayProvider}
Model: ${displayModel}
Files: ${estimation.fileCount} (${fileSizeInKB} KB total, ${averageFileSize} KB average)

Token Usage:
  Input Tokens: ${estimation.inputTokens.toLocaleString()} (includes ${REVIEW_OVERHEAD_TOKENS.toLocaleString()} overhead tokens)
  Estimated Output Tokens: ${estimation.outputTokens.toLocaleString()}
  Total Tokens: ${estimation.totalTokens.toLocaleString()}

Estimated Cost: ${estimation.formattedCost}

Note: This is an estimate based on approximate token counts and may vary
      based on the actual content and model behavior.
`;
}
async function estimateFromFilePaths(filePaths, reviewType, modelName = process.env.AI_CODE_REVIEW_MODEL || "gemini:gemini-1.5-pro") {
  const files = [];
  for (const filePath of filePaths) {
    try {
      const content = await import_promises6.default.readFile(filePath, "utf-8");
      files.push({
        path: filePath,
        relativePath: import_path10.default.basename(filePath),
        content
      });
    } catch (error2) {
      logger_default.error(
        `Error reading file ${filePath}: ${error2 instanceof Error ? error2.message : String(error2)}`
      );
    }
  }
  return await estimateReviewCost(files, reviewType, modelName);
}
async function estimateMultiPassReviewCost(files, reviewType, modelName = process.env.AI_CODE_REVIEW_MODEL || "gemini:gemini-1.5-pro", options = {}) {
  let totalFileTokens = 0;
  let totalFileSize = 0;
  for (const file of files) {
    const fileTokens = estimateTokenCount(file.content);
    totalFileTokens += fileTokens;
    totalFileSize += file.content.length;
  }
  const contextMaintenanceFactor = options.contextMaintenanceFactor || MULTI_PASS_CONTEXT_MAINTENANCE_FACTOR;
  const getContextWindow = (model) => {
    if (model.includes("claude")) return 2e5;
    if (model.includes("gpt-4o")) return 128e3;
    if (model.includes("gpt-4")) return 128e3;
    if (model.includes("gemini")) return 1e6;
    return 1e5;
  };
  const contextWindow = getContextWindow(modelName);
  const effectiveContextSize = Math.floor(contextWindow * (1 - contextMaintenanceFactor));
  const passCount = options.passCount || Math.max(1, Math.ceil(totalFileTokens / effectiveContextSize));
  const tokensPerPass = totalFileTokens / passCount;
  const perPassCosts = [];
  let totalInputTokens = 0;
  let totalOutputTokens = 0;
  let totalEstimatedCost = 0;
  for (let i = 0; i < passCount; i++) {
    const passInputTokens = Math.ceil(tokensPerPass + REVIEW_OVERHEAD_TOKENS + MULTI_PASS_OVERHEAD_PER_PASS);
    const contextTokens = i > 0 ? Math.ceil(i * MULTI_PASS_OVERHEAD_PER_PASS * 1.5) : 0;
    const totalPassInputTokens = passInputTokens + contextTokens;
    const passOutputTokens = estimateOutputTokens(totalPassInputTokens, reviewType);
    const passCostInfo = getCostInfo(totalPassInputTokens, passOutputTokens, modelName);
    perPassCosts.push({
      passNumber: i + 1,
      inputTokens: totalPassInputTokens,
      outputTokens: passOutputTokens,
      totalTokens: totalPassInputTokens + passOutputTokens,
      estimatedCost: passCostInfo.estimatedCost
    });
    totalInputTokens += totalPassInputTokens;
    totalOutputTokens += passOutputTokens;
    totalEstimatedCost += passCostInfo.estimatedCost;
  }
  return {
    inputTokens: totalInputTokens,
    outputTokens: totalOutputTokens,
    totalTokens: totalInputTokens + totalOutputTokens,
    estimatedCost: totalEstimatedCost,
    formattedCost: formatCost2(totalEstimatedCost),
    fileCount: files.length,
    totalFileSize,
    passCount,
    perPassCosts
  };
}
function formatMultiPassEstimation(estimation, reviewType, modelName) {
  const [provider, model] = modelName.includes(":") ? modelName.split(":") : [void 0, modelName];
  const displayModel = model || modelName;
  const displayProvider = provider ? `${provider.charAt(0).toUpperCase() + provider.slice(1)}` : "Unknown";
  const fileSizeInKB = (estimation.totalFileSize / 1024).toFixed(2);
  const averageFileSize = estimation.fileCount > 0 ? (estimation.totalFileSize / estimation.fileCount / 1024).toFixed(2) : "0.00";
  let output = `
=== Multi-Pass Token Usage and Cost Estimation ===

Review Type: ${reviewType}
Provider: ${displayProvider}
Model: ${displayModel}
Files: ${estimation.fileCount} (${fileSizeInKB} KB total, ${averageFileSize} KB average)
Passes: ${estimation.passCount}

Total Token Usage:
  Input Tokens: ${estimation.inputTokens.toLocaleString()}
  Estimated Output Tokens: ${estimation.outputTokens.toLocaleString()}
  Total Tokens: ${estimation.totalTokens.toLocaleString()}

Estimated Total Cost: ${estimation.formattedCost}

Per-Pass Breakdown:
`;
  estimation.perPassCosts.forEach((passCost) => {
    output += `  Pass ${passCost.passNumber}:
    Input Tokens: ${passCost.inputTokens.toLocaleString()}
    Output Tokens: ${passCost.outputTokens.toLocaleString()}
    Cost: ${formatCost2(passCost.estimatedCost)}
`;
  });
  output += `
Note: This is an estimate based on approximate token counts and may vary
      based on the actual content and model behavior.
`;
  return output;
}
var import_path10, import_promises6, OUTPUT_TO_INPUT_RATIO, REVIEW_OVERHEAD_TOKENS, MULTI_PASS_CONTEXT_MAINTENANCE_FACTOR, MULTI_PASS_OVERHEAD_PER_PASS;
var init_estimationUtils = __esm({
  "src/utils/estimationUtils.ts"() {
    "use strict";
    import_path10 = __toESM(require("path"));
    import_promises6 = __toESM(require("fs/promises"));
    init_estimators();
    init_logger();
    OUTPUT_TO_INPUT_RATIO = {
      architectural: 0.6,
      // Architectural reviews tend to be more concise
      "quick-fixes": 0.8,
      // Quick fixes often include code snippets
      security: 0.7,
      // Security reviews are moderately detailed
      performance: 0.7,
      // Performance reviews are similar to security
      default: 0.75
      // Default ratio if review type is not specified
    };
    REVIEW_OVERHEAD_TOKENS = 1500;
    MULTI_PASS_CONTEXT_MAINTENANCE_FACTOR = 0.15;
    MULTI_PASS_OVERHEAD_PER_PASS = 800;
  }
});

// src/analysis/semantic/types.ts
var init_types2 = __esm({
  "src/analysis/semantic/types.ts"() {
    "use strict";
  }
});

// src/analysis/semantic/AiGuidedChunking.ts
var DEFAULT_CONFIG, AiGuidedChunking, aiGuidedChunking;
var init_AiGuidedChunking = __esm({
  "src/analysis/semantic/AiGuidedChunking.ts"() {
    "use strict";
    init_logger();
    DEFAULT_CONFIG = {
      enabled: false,
      // Disabled for now - using enhanced rule-based approach
      timeout: 3e4,
      // 30 seconds
      useCache: true,
      fallbackEnabled: true,
      enabledReviewTypes: ["architectural", "security", "performance"]
    };
    AiGuidedChunking = class {
      config;
      constructor(config4 = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config4 };
      }
      /**
       * Generate AI-guided chunking recommendation
       */
      async generateChunkingRecommendation(analysis, reviewType) {
        logger_default.debug(`Generating enhanced rule-based chunking for review type: ${reviewType}`);
        return this.generateEnhancedRuleBasedChunking(analysis, reviewType);
      }
      /**
       * Generate enhanced rule-based chunking recommendation
       */
      generateEnhancedRuleBasedChunking(analysis, reviewType) {
        logger_default.debug("Generating enhanced rule-based chunking recommendation");
        let strategy = "individual";
        let reasoning = "";
        const reviewTypeStrategies = {
          "architectural": "hierarchical",
          "security": "contextual",
          "performance": "functional",
          "quick-fixes": "individual",
          "unused-code": "grouped"
        };
        const hasClasses = analysis.complexity.classCount > 0;
        const hasComplexFunctions = analysis.topLevelDeclarations.some((d) => (d.cyclomaticComplexity || 0) > 10);
        const hasManyDeclarations = analysis.topLevelDeclarations.length > 10;
        const hasHighComplexity = analysis.complexity.cyclomaticComplexity > 20;
        const hasInterconnectedImports = analysis.importGraph.length > 5;
        if (reviewType === "architectural" && hasClasses) {
          strategy = "hierarchical";
          reasoning = "Architectural review with class structures detected - using hierarchical chunking to preserve class-method relationships";
        } else if (reviewType === "security" && hasInterconnectedImports) {
          strategy = "contextual";
          reasoning = "Security review with complex imports detected - using contextual chunking to analyze data flow and dependencies";
        } else if (reviewType === "performance" && hasComplexFunctions) {
          strategy = "functional";
          reasoning = "Performance review with complex functions detected - using functional chunking to analyze execution paths";
        } else if (hasManyDeclarations && !hasHighComplexity) {
          strategy = "grouped";
          reasoning = "Many simple declarations detected - using grouped chunking for efficiency";
        } else if (hasClasses) {
          strategy = "hierarchical";
          reasoning = "Object-oriented code detected - using hierarchical chunking to maintain class boundaries";
        } else if (hasHighComplexity) {
          strategy = "individual";
          reasoning = "High complexity detected - using individual chunking for focused analysis";
        } else {
          strategy = reviewTypeStrategies[reviewType] || "individual";
          reasoning = `Using ${strategy} strategy based on review type: ${reviewType}`;
        }
        let estimatedChunks = 1;
        switch (strategy) {
          case "hierarchical":
            estimatedChunks = Math.max(1, analysis.complexity.classCount + Math.ceil(analysis.complexity.functionCount / 2));
            break;
          case "grouped":
            estimatedChunks = Math.max(1, Math.ceil(analysis.topLevelDeclarations.length / 5));
            break;
          case "functional":
            estimatedChunks = Math.max(1, Math.ceil(analysis.complexity.functionCount / 2));
            break;
          case "contextual":
            estimatedChunks = Math.max(1, Math.ceil(analysis.importGraph.length / 3));
            break;
          default:
            estimatedChunks = Math.min(analysis.topLevelDeclarations.length, Math.ceil(analysis.totalLines / 100));
        }
        return {
          strategy,
          chunks: [],
          // Will be generated by ChunkGenerator
          crossReferences: [],
          reasoning: `Enhanced rule-based: ${reasoning}`,
          estimatedTokens: analysis.totalLines * 4,
          estimatedChunks
        };
      }
      /**
       * Map AI type string to ReviewUnit
       */
      mapTypeToReviewUnit(type) {
        const typeMap = {
          "function": "function",
          "class": "class",
          "interface": "interface",
          "module": "module",
          "type": "type_definitions",
          "import": "imports",
          "export": "exports"
        };
        return typeMap[type] || "module";
      }
      /**
       * Determine review focus based on declarations
       */
      determineReviewFocus(declarations, _analysis) {
        const focuses = [];
        if (declarations.some((d) => d.type === "class")) {
          focuses.push("architecture");
        }
        if (declarations.some((d) => (d.cyclomaticComplexity || 0) > 10)) {
          focuses.push("maintainability");
        }
        if (declarations.some((d) => d.name.includes("Auth") || d.name.includes("Security"))) {
          focuses.push("security");
        }
        return focuses.length > 0 ? focuses : ["maintainability"];
      }
      /**
       * Estimate token count for a line range
       */
      estimateTokens(startLine, endLine) {
        return (endLine - startLine + 1) * 4;
      }
      /**
       * Update configuration
       */
      updateConfig(config4) {
        this.config = { ...this.config, ...config4 };
      }
      /**
       * Check if enhanced rule-based chunking is available
       */
      isAvailable() {
        return true;
      }
    };
    aiGuidedChunking = new AiGuidedChunking();
  }
});

// src/analysis/semantic/utils/LanguageDetector.ts
function detectLanguage(filePath) {
  const extension = filePath.split(".").pop()?.toLowerCase();
  const extensionMap = {
    "ts": "typescript",
    "tsx": "typescript",
    "js": "javascript",
    "jsx": "javascript",
    "py": "python",
    "rb": "ruby",
    "php": "php"
  };
  return extensionMap[extension || ""] || "unknown";
}
function isLanguageSupported(language, enabledLanguages, availableParsers) {
  return enabledLanguages.includes(language) && (availableParsers instanceof Set ? availableParsers.has(language) : availableParsers.has(language));
}
var LANGUAGE_PARSERS;
var init_LanguageDetector = __esm({
  "src/analysis/semantic/utils/LanguageDetector.ts"() {
    "use strict";
    LANGUAGE_PARSERS = {
      typescript: "TypeScript.typescript",
      javascript: "TypeScript.typescript",
      // Use TypeScript parser for JavaScript
      tsx: "TypeScript.tsx",
      jsx: "TypeScript.tsx",
      // Use TSX parser for JSX
      python: "Python",
      ruby: "Ruby",
      php: "PHP"
    };
  }
});

// src/analysis/semantic/utils/NodeAnalyzer.ts
function extractNodeName(node) {
  try {
    if (node.type === "function_declaration") {
      const nameNode = node.children.find((child) => child.type === "identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "class_declaration" || node.type === "abstract_class_declaration") {
      const nameNode = node.children.find((child) => child.type === "type_identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "class_definition") {
      const nameNode = node.children.find((child) => child.type === "identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "function_definition") {
      const nameNode = node.children.find((child) => child.type === "identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "interface_declaration") {
      const nameNode = node.children.find((child) => child.type === "type_identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "method_definition") {
      const nameNode = node.children.find((child) => child.type === "property_identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "variable_declaration" || node.type === "lexical_declaration") {
      const declarator = node.children.find((child) => child.type === "variable_declarator");
      if (declarator) {
        const nameNode = declarator.children.find((child) => child.type === "identifier");
        return nameNode ? nameNode.text : null;
      }
    }
    if (node.type === "enum_declaration") {
      const nameNode = node.children.find((child) => child.type === "identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "type_alias_declaration") {
      const nameNode = node.children.find((child) => child.type === "type_identifier");
      return nameNode ? nameNode.text : null;
    }
    if (node.type === "namespace_declaration") {
      const nameNode = node.children.find((child) => child.type === "identifier");
      return nameNode ? nameNode.text : null;
    }
    const identifierTypes = ["identifier", "type_identifier", "property_identifier"];
    for (const child of node.children) {
      if (identifierTypes.includes(child.type)) {
        return child.text;
      }
    }
    return null;
  } catch (error2) {
    logger_default.warn(`Failed to extract node name for ${node.type}:`, error2);
    return null;
  }
}
function extractDependencies(node) {
  const dependencies = /* @__PURE__ */ new Set();
  traverseNode(node, (child) => {
    if (child.type === "identifier" || child.type === "type_identifier") {
      dependencies.add(child.text);
    }
  });
  return Array.from(dependencies);
}
function calculateNodeComplexity(node) {
  let complexity = 1;
  const complexityNodes = [
    "if_statement",
    "else_clause",
    "switch_statement",
    "case_clause",
    "while_statement",
    "for_statement",
    "for_in_statement",
    "try_statement",
    "catch_clause",
    "conditional_expression",
    "logical_and",
    "logical_or"
  ];
  traverseNode(node, (child) => {
    if (complexityNodes.includes(child.type)) {
      complexity++;
    }
  });
  return complexity;
}
function determineExportStatus(node) {
  let current = node;
  while (current) {
    if (current.type === "export_statement" || current.type === "export_declaration" || current.text.startsWith("export")) {
      return current.text.includes("default") ? "default_export" : "exported";
    }
    current = current.parent;
  }
  return "internal";
}
function extractDocumentation(node, lines) {
  const startLine = node.startPosition.row;
  for (let i = Math.max(0, startLine - 3); i < startLine; i++) {
    const line = lines[i]?.trim();
    if (line?.startsWith("/**") || line?.startsWith("//") || line?.startsWith("#")) {
      return line;
    }
  }
  return void 0;
}
function extractModifiers(node) {
  const modifiers = [];
  const modifierTypes = ["public", "private", "protected", "static", "abstract", "readonly"];
  if (node.type === "abstract_class_declaration") {
    modifiers.push("abstract");
  }
  traverseNode(node, (child) => {
    if (modifierTypes.includes(child.type) || modifierTypes.includes(child.text)) {
      const modifier = child.text || child.type;
      if (!modifiers.includes(modifier)) {
        modifiers.push(modifier);
      }
    }
  });
  return modifiers;
}
function isOperator(node) {
  const operatorTypes = [
    "binary_expression",
    "unary_expression",
    "assignment_expression",
    "+",
    "-",
    "*",
    "/",
    "=",
    "==",
    "!=",
    "<",
    ">",
    "&&",
    "||"
  ];
  return operatorTypes.includes(node.type);
}
function isOperand(node) {
  return ["identifier", "number", "string", "boolean"].includes(node.type);
}
function traverseNode(node, callback) {
  callback(node);
  for (const child of node.children) {
    traverseNode(child, callback);
  }
}
var init_NodeAnalyzer = __esm({
  "src/analysis/semantic/utils/NodeAnalyzer.ts"() {
    "use strict";
    init_logger();
  }
});

// src/analysis/semantic/utils/DeclarationExtractor.ts
function extractDeclarations(node, lines, language) {
  const declarations = [];
  switch (language) {
    case "typescript":
    case "javascript":
      extractTSDeclarations(node, declarations, lines);
      break;
    case "python":
      extractPythonDeclarations(node, declarations, lines);
      break;
    case "ruby":
      extractRubyDeclarations(node, declarations, lines);
      break;
    case "php":
      extractPHPDeclarations(node, declarations, lines);
      break;
  }
  return declarations;
}
function extractTSDeclarations(node, declarations, lines) {
  const topLevelTypeMapping = {
    "function_declaration": "function",
    "class_declaration": "class",
    "abstract_class_declaration": "class",
    "interface_declaration": "interface",
    "type_alias_declaration": "type",
    "variable_declaration": "const",
    "lexical_declaration": "const",
    "enum_declaration": "enum",
    "namespace_declaration": "namespace"
    // Note: method_definition removed - handled by extractChildDeclarations
  };
  traverseNode(node, (child) => {
    if (child.type in topLevelTypeMapping) {
      const declaration = createDeclarationFromNode(
        child,
        topLevelTypeMapping[child.type],
        lines
      );
      if (declaration) {
        declarations.push(declaration);
      }
    }
  });
}
function extractPythonDeclarations(node, declarations, lines) {
  const typeMapping = {
    "function_definition": "function",
    "class_definition": "class",
    "decorated_definition": "function"
  };
  traverseNode(node, (child) => {
    if (child.type in typeMapping) {
      const declaration = createDeclarationFromNode(
        child,
        typeMapping[child.type],
        lines
      );
      if (declaration) {
        declarations.push(declaration);
      }
    }
  });
}
function extractRubyDeclarations(node, declarations, lines) {
  const typeMapping = {
    "method": "function",
    "class": "class",
    "module": "namespace"
  };
  traverseNode(node, (child) => {
    if (child.type in typeMapping) {
      const declaration = createDeclarationFromNode(
        child,
        typeMapping[child.type],
        lines
      );
      if (declaration) {
        declarations.push(declaration);
      }
    }
  });
}
function extractPHPDeclarations(node, declarations, lines) {
  const typeMapping = {
    "function_definition": "function",
    "method_declaration": "method",
    "class_declaration": "class",
    "interface_declaration": "interface"
  };
  traverseNode(node, (child) => {
    if (child.type in typeMapping) {
      const declaration = createDeclarationFromNode(
        child,
        typeMapping[child.type],
        lines
      );
      if (declaration) {
        declarations.push(declaration);
      }
    }
  });
}
function createDeclarationFromNode(node, type, lines) {
  try {
    const name = extractNodeName(node) || "anonymous";
    const startLine = node.startPosition.row + 1;
    const endLine = node.endPosition.row + 1;
    return {
      type,
      name,
      startLine,
      endLine,
      dependencies: extractDependencies(node),
      cyclomaticComplexity: calculateNodeComplexity(node),
      exportStatus: determineExportStatus(node),
      documentation: extractDocumentation(node, lines),
      children: extractChildDeclarations(node, lines),
      modifiers: extractModifiers(node)
    };
  } catch (error2) {
    logger_default.warn(`Failed to create declaration from node: ${error2}`);
    return null;
  }
}
function extractChildDeclarations(node, lines) {
  const children = [];
  if (node.type === "class_declaration" || node.type === "abstract_class_declaration") {
    const classBody = node.children.find((child) => child.type === "class_body");
    if (classBody) {
      for (const child of classBody.children) {
        if (child.type === "method_definition" || child.type === "public_field_definition" || child.type === "property_definition") {
          const childDecl = createDeclarationFromNode(child, "method", lines);
          if (childDecl) {
            children.push(childDecl);
          }
        }
      }
    }
  } else if (node.type === "class_definition") {
    const classBody = node.children.find((child) => child.type === "block");
    if (classBody) {
      for (const child of classBody.children) {
        if (child.type === "function_definition") {
          const childDecl = createDeclarationFromNode(child, "method", lines);
          if (childDecl) {
            children.push(childDecl);
          }
        }
      }
    }
  } else {
    for (const child of node.children) {
      if (child.type === "method_definition" || child.type === "property_definition") {
        const childDecl = createDeclarationFromNode(child, "method", lines);
        if (childDecl) {
          children.push(childDecl);
        }
      }
    }
  }
  return children;
}
var init_DeclarationExtractor = __esm({
  "src/analysis/semantic/utils/DeclarationExtractor.ts"() {
    "use strict";
    init_logger();
    init_NodeAnalyzer();
  }
});

// src/analysis/semantic/utils/ImportAnalyzer.ts
function extractImports(node, lines, language) {
  const imports = [];
  traverseNode(node, (child) => {
    if (isImportNode(child, language)) {
      const importRel = createImportRelationship(child, lines);
      if (importRel) {
        imports.push(importRel);
      }
    }
  });
  return imports;
}
function isImportNode(node, language) {
  const importTypes = {
    typescript: ["import_statement", "import_clause"],
    javascript: ["import_statement", "import_clause"],
    python: ["import_statement", "import_from_statement"],
    ruby: ["call"],
    // require statements
    php: ["include_expression", "require_expression"]
  };
  return importTypes[language]?.includes(node.type) || false;
}
function createImportRelationship(node, _lines) {
  try {
    return {
      imported: extractImportedName(node) || "unknown",
      from: extractImportSource(node) || "unknown",
      importType: determineImportType(node),
      line: node.startPosition.row + 1,
      isUsed: false
      // TODO: Implement usage analysis
    };
  } catch (error2) {
    logger_default.warn(`Failed to create import relationship: ${error2}`);
    return null;
  }
}
function extractImportedName(node) {
  for (const child of node.children) {
    if (child.type === "import_specifier" || child.type === "identifier") {
      return child.text;
    }
  }
  return null;
}
function extractImportSource(node) {
  for (const child of node.children) {
    if (child.type === "string" || child.type === "string_literal") {
      return child.text.replace(/['"]/g, "");
    }
  }
  return null;
}
function determineImportType(node) {
  const text = node.text;
  if (text.includes("* as ")) return "namespace";
  if (text.includes("import(")) return "dynamic";
  if (text.includes("{")) return "named";
  return "default";
}
var init_ImportAnalyzer = __esm({
  "src/analysis/semantic/utils/ImportAnalyzer.ts"() {
    "use strict";
    init_logger();
    init_NodeAnalyzer();
  }
});

// src/analysis/semantic/utils/ComplexityAnalyzer.ts
function calculateComplexity(node, content, declarations, includeHalsteadMetrics = false) {
  const lines = content.split("\n");
  const linesOfCode = lines.filter(
    (line) => line.trim() && !line.trim().startsWith("//") && !line.trim().startsWith("#")
  ).length;
  let totalComplexity = 1;
  let maxNesting = 0;
  const complexityNodes = [
    "if_statement",
    "else_clause",
    "switch_statement",
    "case_clause",
    "while_statement",
    "for_statement",
    "for_in_statement",
    "for_of_statement",
    "try_statement",
    "catch_clause",
    "conditional_expression",
    "logical_and",
    "logical_or",
    "function_declaration",
    "method_definition"
  ];
  traverseNode(node, (child) => {
    if (complexityNodes.includes(child.type)) {
      totalComplexity++;
    }
  });
  maxNesting = calculateMaxNesting(node);
  const functionCount = declarations.filter((d) => d.type === "function").length;
  const classCount = declarations.filter((d) => d.type === "class").length;
  return {
    cyclomaticComplexity: totalComplexity,
    cognitiveComplexity: totalComplexity,
    // Simplified
    maxNestingDepth: maxNesting,
    functionCount,
    classCount,
    linesOfCode,
    totalDeclarations: declarations.length,
    halstead: includeHalsteadMetrics ? calculateHalsteadMetrics(node) : void 0
  };
}
function calculateMaxNesting(node, currentDepth = 0) {
  const nestingNodes = [
    "if_statement",
    "while_statement",
    "for_statement",
    "for_in_statement",
    "try_statement",
    "catch_clause",
    "function_declaration",
    "method_definition",
    "statement_block",
    "block"
  ];
  let maxDepth = currentDepth;
  for (const child of node.children) {
    const childDepth = nestingNodes.includes(child.type) ? currentDepth + 1 : currentDepth;
    const childMaxDepth = calculateMaxNesting(child, childDepth);
    maxDepth = Math.max(maxDepth, childMaxDepth);
  }
  return maxDepth;
}
function calculateHalsteadMetrics(node) {
  const operators = /* @__PURE__ */ new Set();
  const operands = /* @__PURE__ */ new Set();
  let totalOperators = 0;
  let totalOperands = 0;
  traverseNode(node, (child) => {
    if (isOperator(child)) {
      operators.add(child.text);
      totalOperators++;
    } else if (isOperand(child)) {
      operands.add(child.text);
      totalOperands++;
    }
  });
  const distinctOperators = operators.size;
  const distinctOperands = operands.size;
  const vocabulary = distinctOperators + distinctOperands;
  const length = totalOperators + totalOperands;
  const volume = length * Math.log2(vocabulary || 1);
  const difficulty = distinctOperators / 2 * (totalOperands / (distinctOperands || 1));
  const effort = difficulty * volume;
  return {
    distinctOperators,
    distinctOperands,
    totalOperators,
    totalOperands,
    vocabulary,
    length,
    volume,
    difficulty,
    effort
  };
}
var init_ComplexityAnalyzer = __esm({
  "src/analysis/semantic/utils/ComplexityAnalyzer.ts"() {
    "use strict";
    init_NodeAnalyzer();
  }
});

// src/analysis/semantic/utils/ChunkingRecommender.ts
async function generateChunkingRecommendation(aiGuidedChunking2, declarations, imports, complexity, totalLines, filePath, language, reviewType = "quick-fixes") {
  try {
    const analysisForChunking = {
      language,
      totalLines,
      topLevelDeclarations: declarations,
      importGraph: imports,
      complexity,
      suggestedChunkingStrategy: {
        strategy: "individual",
        chunks: [],
        crossReferences: [],
        reasoning: "",
        estimatedTokens: 0,
        estimatedChunks: 0
      },
      filePath,
      analyzedAt: /* @__PURE__ */ new Date()
    };
    if (aiGuidedChunking2.isAvailable()) {
      logger_default.debug("Using AI-guided chunking recommendation");
      return await aiGuidedChunking2.generateChunkingRecommendation(
        analysisForChunking,
        reviewType
      );
    } else {
      logger_default.debug("AI-guided chunking not available, using rule-based fallback");
      return generateRuleBasedChunking(declarations, complexity, totalLines);
    }
  } catch (error2) {
    logger_default.warn(`AI-guided chunking failed: ${error2 instanceof Error ? error2.message : "Unknown error"}`);
    logger_default.debug("Falling back to rule-based chunking");
    return generateRuleBasedChunking(declarations, complexity, totalLines);
  }
}
function generateRuleBasedChunking(declarations, complexity, totalLines, maxChunkSize = 500) {
  let strategy = "individual";
  if (complexity.classCount > 0) {
    strategy = "hierarchical";
  } else if (declarations.length > 10) {
    strategy = "grouped";
  } else if (complexity.cyclomaticComplexity > 20) {
    strategy = "functional";
  }
  let estimatedChunks = 1;
  if (strategy === "hierarchical") {
    estimatedChunks = Math.max(1, complexity.classCount + complexity.functionCount);
  } else if (strategy === "grouped") {
    estimatedChunks = Math.max(1, Math.ceil(declarations.length / 5));
  } else if (strategy === "functional") {
    estimatedChunks = Math.max(1, complexity.functionCount);
  } else {
    estimatedChunks = Math.max(1, Math.ceil(totalLines / maxChunkSize));
  }
  return {
    strategy,
    chunks: [],
    // Will be generated by ChunkGenerator
    crossReferences: [],
    // Will be analyzed by ChunkGenerator
    reasoning: `Rule-based: Selected ${strategy} strategy based on ${declarations.length} declarations and complexity ${complexity.cyclomaticComplexity}`,
    estimatedTokens: totalLines * 4,
    // Rough estimate
    estimatedChunks
  };
}
var init_ChunkingRecommender = __esm({
  "src/analysis/semantic/utils/ChunkingRecommender.ts"() {
    "use strict";
    init_logger();
  }
});

// src/analysis/semantic/SemanticAnalyzer.ts
async function analyzeCodeSemantics(content, filePath, language) {
  return semanticAnalyzer.analyzeCode(content, filePath, language);
}
var import_tree_sitter, import_tree_sitter_typescript, import_tree_sitter_python, import_tree_sitter_ruby, import_tree_sitter_php, DEFAULT_CONFIG2, SemanticAnalyzer, semanticAnalyzer;
var init_SemanticAnalyzer = __esm({
  "src/analysis/semantic/SemanticAnalyzer.ts"() {
    "use strict";
    import_tree_sitter = __toESM(require("tree-sitter"));
    import_tree_sitter_typescript = __toESM(require("tree-sitter-typescript"));
    import_tree_sitter_python = __toESM(require("tree-sitter-python"));
    import_tree_sitter_ruby = __toESM(require("tree-sitter-ruby"));
    import_tree_sitter_php = __toESM(require("tree-sitter-php"));
    init_logger();
    init_AiGuidedChunking();
    init_LanguageDetector();
    init_DeclarationExtractor();
    init_ImportAnalyzer();
    init_ComplexityAnalyzer();
    init_ChunkingRecommender();
    DEFAULT_CONFIG2 = {
      enabledLanguages: ["typescript", "javascript", "python", "ruby"],
      complexityThreshold: 10,
      maxChunkSize: 500,
      includeDependencyAnalysis: true,
      includeHalsteadMetrics: false,
      customChunkingRules: []
    };
    SemanticAnalyzer = class {
      parsers = /* @__PURE__ */ new Map();
      config;
      aiGuidedChunking;
      constructor(config4 = {}) {
        this.config = { ...DEFAULT_CONFIG2, ...config4 };
        this.aiGuidedChunking = new AiGuidedChunking();
        this.initializeParsers();
      }
      /**
       * Initialize TreeSitter parsers for supported languages
       */
      initializeParsers() {
        for (const language of this.config.enabledLanguages) {
          if (language in LANGUAGE_PARSERS) {
            try {
              const languageGrammar = this.getLanguageGrammar(language);
              if (!languageGrammar) {
                logger_default.warn(`No grammar available for ${language}, skipping`);
                continue;
              }
              const parser = new import_tree_sitter.default();
              parser.setLanguage(languageGrammar);
              this.parsers.set(language, parser);
              logger_default.debug(`Initialized TreeSitter parser for ${language}`);
            } catch (error2) {
              logger_default.error(`Failed to initialize parser for ${language}:`, error2);
            }
          }
        }
      }
      /**
       * Get language grammar based on language name
       */
      getLanguageGrammar(language) {
        switch (language) {
          case "typescript":
          case "javascript":
            return import_tree_sitter_typescript.default.typescript;
          case "tsx":
          case "jsx":
            return import_tree_sitter_typescript.default.tsx;
          case "python":
            return import_tree_sitter_python.default;
          case "ruby":
            return import_tree_sitter_ruby.default;
          case "php":
            return import_tree_sitter_php.default;
          default:
            return null;
        }
      }
      /**
       * Perform semantic analysis on code content
       */
      async analyzeCode(content, filePath, language) {
        const errors = [];
        try {
          const detectedLanguage = language || detectLanguage(filePath);
          if (!this.isLanguageSupported(detectedLanguage)) {
            errors.push({
              type: "language_not_supported",
              message: `Language '${detectedLanguage}' is not supported for semantic analysis`
            });
            return { errors, success: false, fallbackUsed: true };
          }
          if (content.length > 5e5) {
            errors.push({
              type: "file_too_large",
              message: "File is too large for semantic analysis"
            });
            return { errors, success: false, fallbackUsed: true };
          }
          const parser = this.parsers.get(detectedLanguage);
          if (!parser) {
            errors.push({
              type: "analysis_failed",
              message: `No parser available for language: ${detectedLanguage}`
            });
            return { errors, success: false, fallbackUsed: true };
          }
          let tree;
          try {
            tree = parser.parse(content);
          } catch (parseError) {
            if (parseError instanceof Error && parseError.message.includes("Invalid argument")) {
              errors.push({
                type: "file_too_large",
                message: "File content is too complex or large for TreeSitter parsing"
              });
              return { errors, success: false, fallbackUsed: true };
            }
            throw parseError;
          }
          if (tree.rootNode.hasError) {
            errors.push({
              type: "parse_error",
              message: "TreeSitter encountered parsing errors"
            });
          }
          const analysis = await this.performAnalysis(
            tree.rootNode,
            content,
            filePath,
            detectedLanguage
          );
          return {
            analysis,
            errors,
            success: true,
            fallbackUsed: false
          };
        } catch (error2) {
          const analysisError = {
            type: "analysis_failed",
            message: error2 instanceof Error ? error2.message : "Unknown analysis error",
            stack: error2 instanceof Error ? error2.stack : void 0
          };
          logger_default.error("Semantic analysis failed:", error2);
          return {
            errors: [analysisError],
            success: false,
            fallbackUsed: true
          };
        }
      }
      /**
       * Perform the core semantic analysis
       */
      async performAnalysis(rootNode, content, filePath, language) {
        const lines = content.split("\n");
        const declarations = extractDeclarations(rootNode, lines, language);
        const importGraph = extractImports(rootNode, lines, language);
        const complexity = calculateComplexity(
          rootNode,
          content,
          declarations,
          this.config.includeHalsteadMetrics
        );
        const suggestedChunkingStrategy = await generateChunkingRecommendation(
          this.aiGuidedChunking,
          declarations,
          importGraph,
          complexity,
          lines.length,
          filePath,
          language,
          "quick-fixes"
          // Default review type - could be passed as parameter
        );
        return {
          language,
          totalLines: lines.length,
          topLevelDeclarations: declarations,
          importGraph,
          complexity,
          suggestedChunkingStrategy,
          filePath,
          analyzedAt: /* @__PURE__ */ new Date()
        };
      }
      /**
       * Check if language is supported
       */
      isLanguageSupported(language) {
        return isLanguageSupported(language, this.config.enabledLanguages, this.parsers);
      }
      /**
       * Get list of supported languages
       */
      getSupportedLanguages() {
        return Array.from(this.parsers.keys());
      }
      /**
       * Update configuration
       */
      updateConfig(config4) {
        this.config = { ...this.config, ...config4 };
        if (config4.enabledLanguages) {
          this.parsers.clear();
          this.initializeParsers();
        }
      }
    };
    semanticAnalyzer = new SemanticAnalyzer();
  }
});

// src/analysis/semantic/ChunkGenerator.ts
function generateSemanticChunks(analysis, fileContent, reviewType = "quick-fixes") {
  return chunkGenerator.generateChunks(analysis, fileContent, reviewType);
}
var DEFAULT_CONFIG3, ChunkGenerator, chunkGenerator;
var init_ChunkGenerator = __esm({
  "src/analysis/semantic/ChunkGenerator.ts"() {
    "use strict";
    init_logger();
    DEFAULT_CONFIG3 = {
      maxChunkSize: 500,
      minChunkSize: 10,
      includeContext: true,
      maxContextDeclarations: 5,
      tokensPerLine: 4,
      highComplexityThreshold: 15,
      mediumComplexityThreshold: 8
    };
    ChunkGenerator = class {
      config;
      constructor(config4 = {}) {
        this.config = { ...DEFAULT_CONFIG3, ...config4 };
      }
      /**
       * Generate intelligent code chunks from semantic analysis
       */
      generateChunks(analysis, fileContent, reviewType = "quick-fixes") {
        logger_default.debug(`Generating chunks for ${analysis.filePath} using ${analysis.suggestedChunkingStrategy.strategy} strategy`);
        const lines = fileContent.split("\n");
        const chunks = [];
        const crossReferences = [];
        try {
          switch (analysis.suggestedChunkingStrategy.strategy) {
            case "individual":
              this.generateIndividualChunks(analysis, lines, chunks, reviewType);
              break;
            case "grouped":
              this.generateGroupedChunks(analysis, lines, chunks, reviewType);
              break;
            case "hierarchical":
              this.generateHierarchicalChunks(analysis, lines, chunks, reviewType);
              break;
            case "functional":
              this.generateFunctionalChunks(analysis, lines, chunks, reviewType);
              break;
            case "contextual":
              this.generateContextualChunks(analysis, lines, chunks, reviewType);
              break;
            default:
              this.generateFallbackChunks(analysis, lines, chunks, reviewType);
          }
          this.generateCrossReferences(chunks, analysis, crossReferences);
          const estimatedTokens = chunks.reduce((total, chunk) => total + chunk.estimatedTokens, 0);
          return {
            strategy: analysis.suggestedChunkingStrategy.strategy,
            chunks,
            crossReferences,
            reasoning: this.generateReasoningExplanation(analysis, chunks),
            estimatedTokens,
            estimatedChunks: chunks.length
          };
        } catch (error2) {
          logger_default.error(`Failed to generate chunks: ${error2}`);
          return this.generateFallbackRecommendation(analysis, lines, reviewType);
        }
      }
      /**
       * Generate individual chunks (each declaration separately)
       */
      generateIndividualChunks(analysis, lines, chunks, reviewType) {
        let chunkId = 1;
        for (const declaration of analysis.topLevelDeclarations) {
          const declarationSize = declaration.endLine - declaration.startLine + 1;
          if (declarationSize < this.config.minChunkSize && !this.isImportantDeclaration(declaration)) {
            continue;
          }
          const chunk = this.createChunkFromDeclaration(
            declaration,
            `chunk_${chunkId++}`,
            lines,
            analysis,
            reviewType
          );
          if (chunk) {
            chunks.push(chunk);
          }
        }
        if (analysis.importGraph.length > 5) {
          const importChunk = this.createImportChunk(analysis.importGraph, `chunk_${chunkId++}`, reviewType);
          if (importChunk) {
            chunks.push(importChunk);
          }
        }
      }
      /**
       * Generate grouped chunks (related declarations together)
       */
      generateGroupedChunks(analysis, lines, chunks, reviewType) {
        const groups = this.groupRelatedDeclarations(analysis.topLevelDeclarations);
        let chunkId = 1;
        for (const group of groups) {
          const groupSize = group.reduce((size, decl) => size + (decl.endLine - decl.startLine + 1), 0);
          if (groupSize <= this.config.maxChunkSize) {
            const chunk = this.createChunkFromDeclarations(
              group,
              `group_${chunkId++}`,
              lines,
              analysis,
              reviewType
            );
            if (chunk) {
              chunks.push(chunk);
            }
          } else {
            this.splitLargeGroup(group, lines, chunks, analysis, reviewType, chunkId);
            chunkId += group.length;
          }
        }
      }
      /**
       * Generate hierarchical chunks (classes with methods)
       */
      generateHierarchicalChunks(analysis, lines, chunks, reviewType) {
        let chunkId = 1;
        const classes = analysis.topLevelDeclarations.filter((d) => d.type === "class");
        const nonClasses = analysis.topLevelDeclarations.filter((d) => d.type !== "class");
        for (const classDecl of classes) {
          const classSize = classDecl.endLine - classDecl.startLine + 1;
          if (classSize <= this.config.maxChunkSize) {
            const chunk = this.createChunkFromDeclaration(
              classDecl,
              `class_${chunkId++}`,
              lines,
              analysis,
              reviewType
            );
            if (chunk) {
              chunks.push(chunk);
            }
          } else {
            this.createClassHierarchyChunks(classDecl, lines, chunks, analysis, reviewType, chunkId);
            chunkId += (classDecl.children?.length || 0) + 1;
          }
        }
        if (nonClasses.length > 0) {
          this.generateGroupedChunks(
            { ...analysis, topLevelDeclarations: nonClasses },
            lines,
            chunks,
            reviewType
          );
        }
      }
      /**
       * Generate functional chunks (by shared dependencies)
       */
      generateFunctionalChunks(analysis, lines, chunks, reviewType) {
        const functionalGroups = this.groupByDependencies(analysis.topLevelDeclarations);
        let chunkId = 1;
        for (const group of functionalGroups) {
          const chunk = this.createChunkFromDeclarations(
            group,
            `functional_${chunkId++}`,
            lines,
            analysis,
            reviewType
          );
          if (chunk) {
            chunks.push(chunk);
          }
        }
      }
      /**
       * Generate contextual chunks (by shared context)
       */
      generateContextualChunks(analysis, lines, chunks, reviewType) {
        const contextGroups = this.groupByContext(analysis.topLevelDeclarations, analysis.importGraph);
        let chunkId = 1;
        for (const group of contextGroups) {
          const chunk = this.createChunkFromDeclarations(
            group,
            `context_${chunkId++}`,
            lines,
            analysis,
            reviewType
          );
          if (chunk) {
            chunks.push(chunk);
          }
        }
      }
      /**
       * Generate fallback chunks when semantic analysis fails
       */
      generateFallbackChunks(analysis, lines, chunks, reviewType) {
        const chunkSize = Math.min(this.config.maxChunkSize, Math.max(50, lines.length / 4));
        let chunkId = 1;
        for (let i = 0; i < lines.length; i += chunkSize) {
          const endLine = Math.min(i + chunkSize, lines.length);
          const chunk = {
            id: `fallback_${chunkId++}`,
            type: "module",
            lines: [i + 1, endLine],
            declarations: [],
            context: [],
            priority: "medium",
            reviewFocus: this.getReviewFocusForType(reviewType),
            estimatedTokens: (endLine - i) * this.config.tokensPerLine,
            dependencies: []
          };
          chunks.push(chunk);
        }
      }
      /**
       * Create a chunk from a single declaration
       */
      createChunkFromDeclaration(declaration, id, lines, analysis, reviewType) {
        try {
          const context = this.config.includeContext ? this.findContextDeclarations(declaration, analysis.topLevelDeclarations) : [];
          return {
            id,
            type: this.mapDeclarationToReviewUnit(declaration.type),
            lines: [declaration.startLine, declaration.endLine],
            declarations: [declaration],
            context,
            priority: this.calculatePriority(declaration, reviewType),
            reviewFocus: this.getReviewFocusForDeclaration(declaration, reviewType),
            estimatedTokens: this.estimateTokens(declaration.startLine, declaration.endLine),
            dependencies: declaration.dependencies
          };
        } catch (error2) {
          logger_default.warn(`Failed to create chunk from declaration ${declaration.name}: ${error2}`);
          return null;
        }
      }
      /**
       * Create a chunk from multiple declarations
       */
      createChunkFromDeclarations(declarations, id, lines, analysis, reviewType) {
        if (declarations.length === 0) return null;
        try {
          const startLine = Math.min(...declarations.map((d) => d.startLine));
          const endLine = Math.max(...declarations.map((d) => d.endLine));
          const allDependencies = /* @__PURE__ */ new Set();
          declarations.forEach((d) => d.dependencies.forEach((dep) => allDependencies.add(dep)));
          const context = this.config.includeContext ? this.findContextDeclarations(declarations[0], analysis.topLevelDeclarations) : [];
          return {
            id,
            type: this.determineGroupReviewUnit(declarations),
            lines: [startLine, endLine],
            declarations,
            context,
            priority: this.calculateGroupPriority(declarations, reviewType),
            reviewFocus: this.getReviewFocusForDeclarations(declarations, reviewType),
            estimatedTokens: this.estimateTokens(startLine, endLine),
            dependencies: Array.from(allDependencies)
          };
        } catch (error2) {
          logger_default.warn(`Failed to create chunk from declarations: ${error2}`);
          return null;
        }
      }
      /**
       * Create class hierarchy chunks
       */
      createClassHierarchyChunks(classDecl, lines, chunks, analysis, reviewType, baseId) {
        const classHeaderChunk = this.createClassHeaderChunk(classDecl, `class_header_${baseId}`, reviewType);
        if (classHeaderChunk) {
          chunks.push(classHeaderChunk);
        }
        if (classDecl.children) {
          const methodGroups = this.groupClassMethods(classDecl.children);
          for (let i = 0; i < methodGroups.length; i++) {
            const methodChunk = this.createChunkFromDeclarations(
              methodGroups[i],
              `class_methods_${baseId}_${i + 1}`,
              lines,
              analysis,
              reviewType
            );
            if (methodChunk) {
              chunks.push(methodChunk);
            }
          }
        }
      }
      /**
       * Create class header chunk (class declaration without methods)
       */
      createClassHeaderChunk(classDecl, id, reviewType) {
        const firstMethodLine = classDecl.children?.[0]?.startLine || classDecl.endLine;
        const headerEndLine = Math.max(classDecl.startLine + 5, firstMethodLine - 1);
        return {
          id,
          type: "class",
          lines: [classDecl.startLine, headerEndLine],
          declarations: [{ ...classDecl, children: [] }],
          context: [],
          priority: this.calculatePriority(classDecl, reviewType),
          reviewFocus: ["architecture", "type_safety"],
          estimatedTokens: this.estimateTokens(classDecl.startLine, headerEndLine),
          dependencies: classDecl.dependencies
        };
      }
      /**
       * Create import chunk for significant import statements
       */
      createImportChunk(imports, id, _reviewType) {
        if (imports.length === 0) return null;
        const startLine = Math.min(...imports.map((i) => i.line));
        const endLine = Math.max(...imports.map((i) => i.line));
        return {
          id,
          type: "imports",
          lines: [startLine, endLine],
          declarations: [],
          context: [],
          priority: "low",
          reviewFocus: ["architecture", "maintainability"],
          estimatedTokens: this.estimateTokens(startLine, endLine),
          dependencies: imports.map((i) => i.from)
        };
      }
      /**
       * Group related declarations based on naming and dependencies
       */
      groupRelatedDeclarations(declarations) {
        const groups = [];
        const used = /* @__PURE__ */ new Set();
        for (const declaration of declarations) {
          if (used.has(declaration)) continue;
          const group = [declaration];
          used.add(declaration);
          for (const other of declarations) {
            if (used.has(other)) continue;
            if (this.areDeclarationsRelated(declaration, other)) {
              group.push(other);
              used.add(other);
            }
          }
          groups.push(group);
        }
        return groups;
      }
      /**
       * Check if two declarations are related
       */
      areDeclarationsRelated(decl1, decl2) {
        if (decl1.type === decl2.type) return true;
        const sharedDeps = decl1.dependencies.filter((dep) => decl2.dependencies.includes(dep));
        if (sharedDeps.length > 0) return true;
        if (this.haveSimilarNames(decl1.name, decl2.name)) return true;
        if (Math.abs(decl1.startLine - decl2.endLine) < 5 || Math.abs(decl2.startLine - decl1.endLine) < 5) return true;
        return false;
      }
      /**
       * Group declarations by shared dependencies
       */
      groupByDependencies(declarations) {
        const dependencyMap = /* @__PURE__ */ new Map();
        for (const declaration of declarations) {
          for (const dependency of declaration.dependencies) {
            if (!dependencyMap.has(dependency)) {
              dependencyMap.set(dependency, []);
            }
            dependencyMap.get(dependency).push(declaration);
          }
        }
        const groups = [];
        const processed = /* @__PURE__ */ new Set();
        for (const [, declarations2] of dependencyMap) {
          if (declarations2.length > 1) {
            const unprocessed = declarations2.filter((d) => !processed.has(d));
            if (unprocessed.length > 0) {
              groups.push(unprocessed);
              unprocessed.forEach((d) => processed.add(d));
            }
          }
        }
        const remaining = declarations.filter((d) => !processed.has(d));
        remaining.forEach((d) => groups.push([d]));
        return groups;
      }
      /**
       * Group declarations by broader context
       */
      groupByContext(declarations, _imports) {
        return this.groupByDependencies(declarations);
      }
      /**
       * Group class methods intelligently
       */
      groupClassMethods(methods) {
        const groups = [];
        const publicMethods = methods.filter((m) => !m.modifiers?.includes("private"));
        const privateMethods = methods.filter((m) => m.modifiers?.includes("private"));
        if (publicMethods.length > 0) {
          groups.push(publicMethods);
        }
        if (privateMethods.length > 0) {
          groups.push(privateMethods);
        }
        return groups;
      }
      /**
       * Split large groups into smaller chunks
       */
      splitLargeGroup(group, lines, chunks, analysis, reviewType, baseId) {
        let currentGroup = [];
        let currentSize = 0;
        for (const declaration of group) {
          const declSize = declaration.endLine - declaration.startLine + 1;
          if (currentSize + declSize > this.config.maxChunkSize && currentGroup.length > 0) {
            const chunk = this.createChunkFromDeclarations(
              currentGroup,
              `split_${baseId}_${chunks.length + 1}`,
              lines,
              analysis,
              reviewType
            );
            if (chunk) {
              chunks.push(chunk);
            }
            currentGroup = [declaration];
            currentSize = declSize;
          } else {
            currentGroup.push(declaration);
            currentSize += declSize;
          }
        }
        if (currentGroup.length > 0) {
          const chunk = this.createChunkFromDeclarations(
            currentGroup,
            `split_${baseId}_${chunks.length + 1}`,
            lines,
            analysis,
            reviewType
          );
          if (chunk) {
            chunks.push(chunk);
          }
        }
      }
      /**
       * Find context declarations for a given declaration
       */
      findContextDeclarations(declaration, allDeclarations) {
        const context = [];
        let added = 0;
        for (const other of allDeclarations) {
          if (other === declaration || added >= this.config.maxContextDeclarations) continue;
          if (declaration.dependencies.includes(other.name)) {
            context.push(other);
            added++;
          }
        }
        return context;
      }
      /**
       * Generate cross-references between chunks
       */
      generateCrossReferences(chunks, analysis, crossReferences) {
        for (let i = 0; i < chunks.length; i++) {
          for (let j = i + 1; j < chunks.length; j++) {
            const relationship = this.analyzeChunkRelationship(chunks[i], chunks[j]);
            if (relationship) {
              crossReferences.push(relationship);
            }
          }
        }
      }
      /**
       * Analyze relationship between two chunks
       */
      analyzeChunkRelationship(chunk1, chunk2) {
        const sharedDeps = chunk1.dependencies.filter((dep) => chunk2.dependencies.includes(dep));
        if (sharedDeps.length > 0) {
          return {
            from: chunk1.id,
            to: chunk2.id,
            relationship: "depends_on",
            strength: sharedDeps.length / Math.max(chunk1.dependencies.length, 1),
            description: `Shares dependencies: ${sharedDeps.join(", ")}`
          };
        }
        for (const decl1 of chunk1.declarations) {
          for (const decl2 of chunk2.declarations) {
            if (decl1.dependencies.includes(decl2.name)) {
              return {
                from: chunk1.id,
                to: chunk2.id,
                relationship: "depends_on",
                strength: 0.8,
                description: `${decl1.name} depends on ${decl2.name}`
              };
            }
          }
        }
        return null;
      }
      /**
       * Map declaration type to review unit
       */
      mapDeclarationToReviewUnit(type) {
        const mapping = {
          "function": "function",
          "method": "function",
          "class": "class",
          "interface": "interface",
          "type": "type_definitions",
          "const": "module",
          "let": "module",
          "var": "module",
          "enum": "type_definitions",
          "namespace": "module",
          "property": "module",
          "import": "imports",
          "export": "exports"
        };
        return mapping[type] || "module";
      }
      /**
       * Determine review unit for a group of declarations
       */
      determineGroupReviewUnit(declarations) {
        const types = new Set(declarations.map((d) => d.type));
        if (types.size === 1) {
          return this.mapDeclarationToReviewUnit(declarations[0].type);
        }
        if (declarations.some((d) => d.type === "class")) return "class";
        if (declarations.some((d) => d.type === "function")) return "function";
        if (declarations.some((d) => d.type === "interface")) return "interface";
        return "module";
      }
      /**
       * Calculate priority for a declaration
       */
      calculatePriority(declaration, reviewType) {
        const complexity = declaration.cyclomaticComplexity || 1;
        if (complexity >= this.config.highComplexityThreshold || declaration.exportStatus === "exported" || declaration.exportStatus === "default_export") {
          return "high";
        }
        if (complexity >= this.config.mediumComplexityThreshold) {
          return "medium";
        }
        if (reviewType === "security" && this.isSecurityCritical(declaration)) {
          return "high";
        }
        return "low";
      }
      /**
       * Calculate priority for a group of declarations
       */
      calculateGroupPriority(declarations, reviewType) {
        const priorities = declarations.map((d) => this.calculatePriority(d, reviewType));
        if (priorities.some((p) => p === "high")) return "high";
        if (priorities.some((p) => p === "medium")) return "medium";
        return "low";
      }
      /**
       * Get review focus for a declaration
       */
      getReviewFocusForDeclaration(declaration, reviewType) {
        const focus = this.getReviewFocusForType(reviewType);
        if (declaration.type === "class") {
          focus.push("architecture", "type_safety");
        }
        if (declaration.cyclomaticComplexity && declaration.cyclomaticComplexity > 10) {
          focus.push("maintainability");
        }
        if (declaration.exportStatus !== "internal") {
          focus.push("documentation");
        }
        return [...new Set(focus)];
      }
      /**
       * Get review focus for multiple declarations
       */
      getReviewFocusForDeclarations(declarations, reviewType) {
        const allFocus = declarations.flatMap((d) => this.getReviewFocusForDeclaration(d, reviewType));
        return [...new Set(allFocus)];
      }
      /**
       * Get review focus based on review type
       */
      getReviewFocusForType(reviewType) {
        const focusMapping = {
          "quick-fixes": ["maintainability", "performance"],
          "architectural": ["architecture", "type_safety", "maintainability"],
          "security": ["security", "error_handling"],
          "performance": ["performance", "architecture"],
          "unused-code": ["maintainability", "architecture"]
        };
        return focusMapping[reviewType] || ["maintainability"];
      }
      /**
       * Estimate token count for a line range
       */
      estimateTokens(startLine, endLine) {
        return (endLine - startLine + 1) * this.config.tokensPerLine;
      }
      /**
       * Check if declaration is important (shouldn't be skipped even if small)
       */
      isImportantDeclaration(declaration) {
        return declaration.exportStatus !== "internal" || declaration.type === "class" || declaration.type === "interface" || (declaration.cyclomaticComplexity || 0) > 5;
      }
      /**
       * Check if declaration is security critical
       */
      isSecurityCritical(declaration) {
        const securityKeywords = ["auth", "login", "password", "token", "security", "crypto", "hash"];
        const name = declaration.name.toLowerCase();
        return securityKeywords.some((keyword) => name.includes(keyword));
      }
      /**
       * Check if two names are similar
       */
      haveSimilarNames(name1, name2) {
        const commonPrefix = this.getCommonPrefix(name1.toLowerCase(), name2.toLowerCase());
        return commonPrefix.length >= 3;
      }
      /**
       * Get common prefix of two strings
       */
      getCommonPrefix(str1, str2) {
        let i = 0;
        while (i < str1.length && i < str2.length && str1[i] === str2[i]) {
          i++;
        }
        return str1.substring(0, i);
      }
      /**
       * Generate reasoning explanation for chunking decisions
       */
      generateReasoningExplanation(analysis, chunks) {
        const reasons = [];
        reasons.push(`Generated ${chunks.length} chunks using ${analysis.suggestedChunkingStrategy.strategy} strategy`);
        if (analysis.complexity.cyclomaticComplexity > 20) {
          reasons.push("High complexity detected, used semantic chunking to preserve function boundaries");
        }
        if (analysis.topLevelDeclarations.some((d) => d.type === "class")) {
          reasons.push("Classes detected, used hierarchical chunking to group related methods");
        }
        const highPriorityChunks = chunks.filter((c) => c.priority === "high").length;
        if (highPriorityChunks > 0) {
          reasons.push(`${highPriorityChunks} high-priority chunks identified for focused review`);
        }
        return reasons.join(". ");
      }
      /**
       * Generate fallback recommendation when chunking fails
       */
      generateFallbackRecommendation(analysis, lines, reviewType) {
        logger_default.warn("Generating fallback chunking recommendation due to semantic analysis failure");
        const chunks = [];
        const chunkSize = Math.min(this.config.maxChunkSize, Math.max(50, lines.length / 4));
        let chunkId = 1;
        for (let i = 0; i < lines.length; i += chunkSize) {
          const endLine = Math.min(i + chunkSize, lines.length);
          const chunk = {
            id: `fallback_${chunkId++}`,
            type: "module",
            lines: [i + 1, endLine],
            declarations: [],
            context: [],
            priority: "medium",
            reviewFocus: this.getReviewFocusForType(reviewType),
            estimatedTokens: (endLine - i) * this.config.tokensPerLine,
            dependencies: []
          };
          chunks.push(chunk);
        }
        return {
          strategy: "individual",
          chunks,
          crossReferences: [],
          reasoning: "Used fallback line-based chunking due to semantic analysis failure",
          estimatedTokens: lines.length * this.config.tokensPerLine,
          estimatedChunks: chunks.length
        };
      }
      /**
       * Update configuration
       */
      updateConfig(config4) {
        this.config = { ...this.config, ...config4 };
      }
      /**
       * Get current configuration
       */
      getConfig() {
        return { ...this.config };
      }
    };
    chunkGenerator = new ChunkGenerator();
  }
});

// src/analysis/semantic/SemanticChunkingIntegration.ts
var DEFAULT_CONFIG4, SemanticChunkingIntegration, semanticChunkingIntegration;
var init_SemanticChunkingIntegration = __esm({
  "src/analysis/semantic/SemanticChunkingIntegration.ts"() {
    "use strict";
    init_logger();
    init_SemanticAnalyzer();
    init_ChunkGenerator();
    DEFAULT_CONFIG4 = {
      enableSemanticChunking: true,
      enableFallback: true,
      forceSemantic: [],
      forceTraditional: ["json", "yaml", "xml", "csv"],
      preferSemantic: true,
      maxFileSizeForSemantic: 1024 * 1024,
      // 1MB
      enableCaching: true,
      maxTokensPerBatch: 4e3,
      // Target batch size for efficient AI processing
      minThreadsPerBatch: 3,
      // Minimum threads to consider for consolidation
      maxThreadsPerBatch: 30,
      // Maximum threads in a single batch - increased to allow larger consolidations
      semanticConfig: {
        analyzer: {
          enabledLanguages: ["typescript", "javascript", "python", "ruby"],
          complexityThreshold: 10,
          maxChunkSize: 500,
          includeDependencyAnalysis: true,
          includeHalsteadMetrics: false
        }
      }
    };
    SemanticChunkingIntegration = class {
      config;
      semanticAnalyzer;
      chunkGenerator;
      cache = /* @__PURE__ */ new Map();
      constructor(config4 = {}) {
        this.config = { ...DEFAULT_CONFIG4, ...config4 };
        this.semanticAnalyzer = new SemanticAnalyzer(this.config.semanticConfig?.analyzer);
        this.chunkGenerator = new ChunkGenerator(this.config.semanticConfig?.chunkGenerator);
      }
      /**
       * Check if a file can be analyzed semantically
       */
      canAnalyzeFile(filePath) {
        const extension = filePath.split(".").pop()?.toLowerCase();
        const supportedExtensions = ["ts", "tsx", "js", "jsx", "py", "rb"];
        return supportedExtensions.includes(extension || "");
      }
      /**
       * Detect language from file path
       */
      detectLanguageFromPath(filePath) {
        const extension = filePath.split(".").pop()?.toLowerCase();
        const extensionMap = {
          "ts": "typescript",
          "tsx": "typescript",
          "js": "javascript",
          "jsx": "javascript",
          "py": "python",
          "rb": "ruby"
        };
        return extensionMap[extension || ""] || null;
      }
      /**
       * Check if a language is supported for semantic analysis
       */
      isLanguageSupported(language) {
        return this.semanticAnalyzer.getSupportedLanguages().includes(language);
      }
      /**
       * Consolidate semantic threads into efficient batches
       */
      consolidateSemanticThreads(chunks) {
        if (chunks.length < this.config.minThreadsPerBatch) {
          return chunks;
        }
        logger_default.debug(`Consolidating ${chunks.length} semantic threads into batches`);
        const totalTokens = chunks.reduce((sum, chunk) => sum + (chunk.estimatedTokens || 0), 0);
        if (totalTokens <= this.config.maxTokensPerBatch && chunks.length <= this.config.maxThreadsPerBatch) {
          logger_default.info(`All ${chunks.length} threads fit within limits (${totalTokens} tokens) - creating single batch`);
          const singleBatch = this.mergeBatchChunks(chunks, "consolidated", 1);
          return [singleBatch];
        }
        const groupedChunks = this.groupChunksByAffinity(chunks);
        const consolidatedBatches = [];
        const groupEntries = Object.entries(groupedChunks).filter(([_, chunks2]) => chunks2.length > 0);
        const sortedGroups = groupEntries.sort((a, b) => a[1].length - b[1].length);
        const mergedGroups = [];
        let currentMergedGroup = [];
        let currentMergedTokens = 0;
        let currentMergedName = "";
        for (const [groupType, groupChunks] of sortedGroups) {
          const groupTokens = groupChunks.reduce((sum, chunk) => sum + (chunk.estimatedTokens || 0), 0);
          if (currentMergedGroup.length === 0) {
            currentMergedGroup = groupChunks;
            currentMergedTokens = groupTokens;
            currentMergedName = groupType;
          } else if (currentMergedTokens + groupTokens <= this.config.maxTokensPerBatch && currentMergedGroup.length + groupChunks.length <= this.config.maxThreadsPerBatch) {
            currentMergedGroup.push(...groupChunks);
            currentMergedTokens += groupTokens;
            currentMergedName = `${currentMergedName}_${groupType}`;
          } else {
            mergedGroups.push([currentMergedName, currentMergedGroup]);
            currentMergedGroup = groupChunks;
            currentMergedTokens = groupTokens;
            currentMergedName = groupType;
          }
        }
        if (currentMergedGroup.length > 0) {
          mergedGroups.push([currentMergedName, currentMergedGroup]);
        }
        for (const [groupType, groupChunks] of mergedGroups) {
          const batches = this.createBatchesFromGroup(groupChunks, groupType);
          consolidatedBatches.push(...batches);
        }
        logger_default.info(`Consolidated ${chunks.length} threads into ${consolidatedBatches.length} efficient batches`);
        return consolidatedBatches;
      }
      /**
       * Group chunks by semantic affinity (related code structures)
       */
      groupChunksByAffinity(chunks) {
        const groups = {
          classes: [],
          functions: [],
          interfaces: [],
          utilities: [],
          tests: [],
          other: []
        };
        chunks.forEach((chunk) => {
          const chunkText = chunk.content || "";
          const declarations = chunk.declarations || [];
          const hasInterface = chunkText.includes("interface ") || declarations.some((d) => d.type === "interface");
          const hasClass = chunkText.includes("class ") || declarations.some((d) => d.type === "class");
          const hasFunction = chunkText.includes("function ") || declarations.some((d) => d.type === "function");
          const hasTest = chunkText.includes("test") || chunkText.includes("spec") || chunkText.includes("describe");
          const hasUtil = chunkText.includes("util") || chunkText.includes("helper") || chunkText.includes("constant");
          if (hasInterface) {
            groups.interfaces.push(chunk);
          } else if (hasClass) {
            groups.classes.push(chunk);
          } else if (hasFunction) {
            if (hasTest) {
              groups.tests.push(chunk);
            } else if (hasUtil) {
              groups.utilities.push(chunk);
            } else {
              groups.functions.push(chunk);
            }
          } else {
            groups.other.push(chunk);
          }
        });
        return groups;
      }
      /**
       * Create batches from a group of related chunks
       */
      createBatchesFromGroup(chunks, groupType) {
        if (chunks.length === 0) return [];
        const batches = [];
        let currentBatch = [];
        let currentTokens = 0;
        const sortedChunks = chunks.sort((a, b) => (a.estimatedTokens || 0) - (b.estimatedTokens || 0));
        for (const chunk of sortedChunks) {
          const chunkTokens = chunk.estimatedTokens || 0;
          const wouldExceedTokens = currentTokens + chunkTokens > this.config.maxTokensPerBatch;
          const wouldExceedCount = currentBatch.length >= this.config.maxThreadsPerBatch;
          if ((wouldExceedTokens || wouldExceedCount) && currentBatch.length > 0) {
            batches.push(this.mergeBatchChunks(currentBatch, groupType, batches.length + 1));
            currentBatch = [chunk];
            currentTokens = chunkTokens;
          } else {
            currentBatch.push(chunk);
            currentTokens += chunkTokens;
          }
        }
        if (currentBatch.length > 0) {
          batches.push(this.mergeBatchChunks(currentBatch, groupType, batches.length + 1));
        }
        return batches;
      }
      /**
       * Merge multiple chunks into a single consolidated batch
       */
      mergeBatchChunks(chunks, groupType, batchNumber) {
        const totalTokens = chunks.reduce((sum, chunk) => sum + (chunk.estimatedTokens || 0), 0);
        const mergedContent = chunks.map((chunk) => chunk.content || "").join("\n\n");
        const allDeclarations = chunks.flatMap((chunk) => chunk.declarations || []);
        return {
          id: `semantic_batch_${groupType}_${batchNumber}`,
          type: "module",
          lines: [
            Math.min(...chunks.map((c) => c.lines?.[0] || 1)),
            Math.max(...chunks.map((c) => c.lines?.[1] || 1))
          ],
          declarations: allDeclarations,
          context: chunks.flatMap((c) => c.context || []),
          priority: chunks[0]?.priority || "medium",
          reviewFocus: chunks[0]?.reviewFocus || ["maintainability"],
          estimatedTokens: totalTokens,
          dependencies: [...new Set(chunks.flatMap((c) => c.dependencies || []))],
          content: mergedContent,
          metadata: {
            semanticInfo: {
              declarations: allDeclarations,
              complexity: allDeclarations.reduce((sum, d) => sum + (d.cyclomaticComplexity || 1), 0),
              threadCount: chunks.length,
              groupType
            },
            consolidation: {
              originalThreads: chunks.length,
              threadIds: chunks.map((c) => c.id),
              consolidationReason: `Merged ${chunks.length} ${groupType} threads for efficient processing`
            }
          }
        };
      }
      /**
       * Analyze files and generate optimal chunks with fallback
       */
      async analyzeAndChunk(files, options = {}) {
        const startTime = Date.now();
        const {
          reviewType = "quick-fixes",
          modelName = "gemini:gemini-1.5-pro",
          forceSemantic = false,
          forceTraditional = false,
          useCache = this.config.enableCaching
        } = options;
        const errors = [];
        let method = "semantic";
        let fallbackUsed = false;
        let semanticAnalysis;
        let lineBasedResult;
        try {
          const cacheKey = this.generateCacheKey(files, reviewType, modelName);
          if (useCache && this.cache.has(cacheKey)) {
            logger_default.debug("Using cached chunking result");
            return this.cache.get(cacheKey);
          }
          const strategy = this.determineChunkingStrategy(files, {
            forceSemantic,
            forceTraditional,
            reviewType
          });
          logger_default.info(`Using ${strategy} chunking strategy for ${files.length} files`);
          let chunks = [];
          let reasoning = "";
          if (strategy === "semantic" && this.config.enableSemanticChunking) {
            const semanticResult = await this.attemptSemanticChunking(files, reviewType);
            if (semanticResult.success) {
              chunks = semanticResult.chunks;
              semanticAnalysis = semanticResult.analysis;
              method = "semantic";
              reasoning = semanticResult.reasoning;
            } else {
              errors.push(...semanticResult.errors);
              if (this.config.enableFallback) {
                logger_default.info("Semantic chunking failed, falling back to traditional approach");
                const fallbackResult = await this.performTraditionalChunking(files, { reviewType });
                chunks = fallbackResult.chunks;
                lineBasedResult = fallbackResult.chunkingResult;
                method = "traditional";
                fallbackUsed = true;
                reasoning = `Fallback to traditional chunking: ${semanticResult.errors.join(", ")}`;
              } else {
                throw new Error(`Semantic chunking failed: ${semanticResult.errors.join(", ")}`);
              }
            }
          } else {
            const traditionalResult = await this.performTraditionalChunking(files, { reviewType });
            chunks = traditionalResult.chunks;
            lineBasedResult = traditionalResult.chunkingResult;
            method = "traditional";
            reasoning = strategy === "traditional" ? "Traditional chunking selected by strategy" : "Semantic chunking disabled";
          }
          const endTime = Date.now();
          const totalTokens = chunks.reduce((sum, chunk) => sum + chunk.estimatedTokens, 0);
          const result = {
            chunks,
            method,
            fallbackUsed,
            semanticAnalysis,
            lineBasedResult,
            errors,
            metrics: {
              analysisTimeMs: endTime - startTime,
              chunkingTimeMs: endTime - startTime,
              // Simplified for now
              totalTokens,
              chunksGenerated: chunks.length
            },
            reasoning
          };
          if (useCache) {
            this.cache.set(cacheKey, result);
          }
          logger_default.info(`Chunking complete: ${chunks.length} chunks, ${totalTokens} tokens, method: ${method}`);
          return result;
        } catch (error2) {
          logger_default.error("Integrated chunking failed:", error2);
          if (this.config.enableFallback && !forceTraditional) {
            logger_default.warn("Attempting emergency fallback to traditional chunking");
            try {
              const fallbackResult = await this.performTraditionalChunking(files, { reviewType, modelName });
              return {
                chunks: fallbackResult.chunks,
                method: "traditional",
                fallbackUsed: true,
                lineBasedResult: fallbackResult.chunkingResult,
                errors: [...errors, error2 instanceof Error ? error2.message : "Unknown error"],
                metrics: {
                  analysisTimeMs: Date.now() - startTime,
                  chunkingTimeMs: 0,
                  totalTokens: fallbackResult.chunks.reduce((sum, chunk) => sum + chunk.estimatedTokens, 0),
                  chunksGenerated: fallbackResult.chunks.length
                },
                reasoning: "Emergency fallback due to complete analysis failure"
              };
            } catch (fallbackError) {
              logger_default.error("Emergency fallback also failed:", fallbackError);
            }
          }
          throw error2;
        }
      }
      /**
       * Determine the best chunking strategy for the given files
       */
      determineChunkingStrategy(files, options) {
        const { forceSemantic, forceTraditional } = options;
        if (forceSemantic) return "semantic";
        if (forceTraditional) return "traditional";
        if (!this.config.enableSemanticChunking) return "traditional";
        const hasSemanticSupportedFiles = files.some((file) => {
          const language = this.detectLanguageFromPath(file.path);
          return language && this.isLanguageSupported(language);
        });
        if (!hasSemanticSupportedFiles) {
          logger_default.debug("No semantic-supported files found, using traditional chunking");
          return "traditional";
        }
        const hasOversizedFiles = files.some(
          (file) => file.content.length > this.config.maxFileSizeForSemantic
        );
        if (hasOversizedFiles) {
          logger_default.debug("Large files detected, using traditional chunking for performance");
          return "traditional";
        }
        const languages = files.map((file) => this.detectLanguageFromPath(file.path)).filter(Boolean);
        if (languages.some((lang) => this.config.forceTraditional.includes(lang))) {
          return "traditional";
        }
        if (languages.some((lang) => this.config.forceSemantic.includes(lang))) {
          return "semantic";
        }
        return this.config.preferSemantic ? "semantic" : "traditional";
      }
      /**
       * Attempt semantic chunking for files
       */
      async attemptSemanticChunking(files, reviewType) {
        const errors = [];
        const allChunks = [];
        let primaryAnalysis;
        try {
          for (const file of files) {
            if (!this.canAnalyzeFile(file.path)) {
              logger_default.debug(`Skipping semantic analysis for ${file.path} - unsupported file type`);
              continue;
            }
            const language = this.detectLanguageFromPath(file.path);
            if (!language || !this.isLanguageSupported(language)) {
              logger_default.debug(`Skipping semantic analysis for ${file.path} - unsupported language: ${language}`);
              continue;
            }
            const analysisResult = await this.semanticAnalyzer.analyzeCode(file.content, file.path, language);
            if (!analysisResult.success || !analysisResult.analysis) {
              logger_default.debug(`Semantic analysis failed for ${file.path}:`, analysisResult.errors);
              continue;
            }
            const chunkingResult = this.chunkGenerator.generateChunks(
              analysisResult.analysis,
              file.content,
              reviewType
            );
            if (analysisResult.success && chunkingResult.chunks) {
              const consolidatedChunks = this.consolidateSemanticThreads(chunkingResult.chunks);
              chunkingResult.chunks = consolidatedChunks;
              const filePrefix = this.sanitizeFileName(file.path);
              const fileChunks = chunkingResult.chunks.map((chunk) => ({
                ...chunk,
                id: `${filePrefix}_${chunk.id}`
              }));
              allChunks.push(...fileChunks);
              if (!primaryAnalysis) {
                primaryAnalysis = analysisResult.analysis;
              }
            } else {
              errors.push(`Semantic analysis failed for ${file.path}: ${analysisResult.errors.map((e) => typeof e === "object" && e.message ? e.message : e.toString()).join(", ")}`);
            }
          }
          if (allChunks.length === 0) {
            return {
              success: false,
              chunks: [],
              errors: errors.length > 0 ? errors : ["No semantic chunks could be generated"],
              reasoning: "Semantic analysis produced no usable chunks"
            };
          }
          return {
            success: true,
            chunks: allChunks,
            analysis: primaryAnalysis,
            errors,
            reasoning: `Generated ${allChunks.length} semantic chunks across ${files.length} files`
          };
        } catch (error2) {
          const errorMessage = error2 instanceof Error ? error2.message : "Unknown semantic analysis error";
          logger_default.error("Semantic chunking attempt failed:", error2);
          return {
            success: false,
            chunks: [],
            errors: [...errors, errorMessage],
            reasoning: "Semantic analysis threw an exception"
          };
        }
      }
      /**
       * Perform traditional TokenAnalyzer-based chunking
       */
      async performTraditionalChunking(files, options) {
        const { reviewType = "quick-fixes" } = options;
        logger_default.debug(`Performing line-based chunking fallback for ${files.length} files`);
        const chunks = [];
        let totalTokens = 0;
        let chunkId = 1;
        for (const file of files) {
          const lines = file.content.split("\n");
          const fileTokens = lines.length * 4;
          totalTokens += fileTokens;
          const chunkSize = 500;
          if (lines.length <= chunkSize) {
            chunks.push({
              id: `fallback_${chunkId++}`,
              type: "module",
              lines: [1, lines.length],
              declarations: [],
              context: [],
              priority: "medium",
              reviewFocus: this.getTraditionalReviewFocus(reviewType),
              estimatedTokens: fileTokens,
              dependencies: []
            });
          } else {
            for (let i = 0; i < lines.length; i += chunkSize) {
              const endLine = Math.min(i + chunkSize, lines.length);
              const chunkTokens = (endLine - i) * 4;
              chunks.push({
                id: `fallback_${chunkId++}`,
                type: "module",
                lines: [i + 1, endLine],
                declarations: [],
                context: [],
                priority: "medium",
                reviewFocus: this.getTraditionalReviewFocus(reviewType),
                estimatedTokens: chunkTokens,
                dependencies: []
              });
            }
          }
        }
        const chunkingResult = {
          totalFiles: files.length,
          estimatedTotalTokens: totalTokens,
          chunks: chunks.map((chunk) => ({
            estimatedTokenCount: chunk.estimatedTokens,
            priority: chunk.priority,
            startLine: chunk.lines[0],
            endLine: chunk.lines[1]
          }))
        };
        logger_default.debug(`Line-based chunking generated ${chunks.length} chunks with ${totalTokens} estimated tokens`);
        return {
          chunks,
          chunkingResult
        };
      }
      /**
       * Get review focus for traditional chunking based on review type
       */
      getTraditionalReviewFocus(reviewType) {
        const focusMap = {
          "quick-fixes": ["maintainability", "performance"],
          "architectural": ["architecture", "type_safety", "maintainability"],
          "security": ["security", "error_handling"],
          "performance": ["performance", "architecture"],
          "unused-code": ["maintainability", "architecture"]
        };
        return focusMap[reviewType] || ["maintainability"];
      }
      /**
       * Sanitize file name for use in chunk IDs
       */
      sanitizeFileName(filePath) {
        return filePath.replace(/[^a-zA-Z0-9]/g, "_").replace(/_+/g, "_").replace(/^_|_$/g, "").toLowerCase();
      }
      /**
       * Generate cache key for analysis results
       */
      generateCacheKey(files, reviewType, modelName) {
        const fileHashes = files.map((f) => this.simpleHash(f.content + f.path)).join("_");
        return `${fileHashes}_${reviewType}_${modelName}`;
      }
      /**
       * Simple hash function for cache keys
       */
      simpleHash(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(hash).toString(36);
      }
      /**
       * Check if semantic chunking is available for files
       */
      canUseSemanticChunking(files) {
        if (!this.config.enableSemanticChunking) return false;
        return files.some((file) => {
          const language = this.detectLanguageFromPath(file.path);
          return language && this.isLanguageSupported(language) && file.content.length <= this.config.maxFileSizeForSemantic;
        });
      }
      /**
       * Get system statistics
       */
      getStats() {
        return {
          config: this.config,
          supportedLanguages: this.semanticAnalyzer.getSupportedLanguages(),
          cacheSize: this.cache.size,
          semanticSystemStats: {
            size: this.cache.size,
            enabled: this.config.enableCaching
          }
        };
      }
      /**
       * Clear all caches
       */
      clearCache() {
        this.cache.clear();
        this.cache.clear();
        logger_default.debug("Cleared all chunking integration caches");
      }
      /**
       * Update configuration
       */
      updateConfig(config4) {
        this.config = { ...this.config, ...config4 };
        if (config4.semanticConfig?.analyzer) {
          this.semanticAnalyzer.updateConfig(config4.semanticConfig.analyzer);
        }
        if (config4.semanticConfig?.chunkGenerator) {
          this.chunkGenerator.updateConfig(config4.semanticConfig.chunkGenerator);
        }
      }
      /**
       * Get current configuration
       */
      getConfig() {
        return { ...this.config };
      }
    };
    semanticChunkingIntegration = new SemanticChunkingIntegration();
  }
});

// src/analysis/semantic/index.ts
var semantic_exports = {};
__export(semantic_exports, {
  AiGuidedChunking: () => AiGuidedChunking,
  ChunkGenerator: () => ChunkGenerator,
  SemanticAnalysisSystem: () => SemanticAnalysisSystem,
  SemanticAnalyzer: () => SemanticAnalyzer,
  SemanticChunkingIntegration: () => SemanticChunkingIntegration,
  aiGuidedChunking: () => aiGuidedChunking,
  analyzeAndChunkCode: () => analyzeAndChunkCode,
  analyzeCodeSemantics: () => analyzeCodeSemantics,
  canAnalyzeFile: () => canAnalyzeFile,
  chunkGenerator: () => chunkGenerator,
  detectLanguageFromPath: () => detectLanguageFromPath,
  generateSemanticChunks: () => generateSemanticChunks,
  semanticAnalysisSystem: () => semanticAnalysisSystem,
  semanticAnalyzer: () => semanticAnalyzer
});
async function analyzeAndChunkCode(content, filePath, options = {}) {
  return semanticAnalysisSystem.analyzeAndChunk(content, filePath, options);
}
function canAnalyzeFile(filePath) {
  const extension = filePath.split(".").pop()?.toLowerCase();
  const supportedExtensions = ["ts", "tsx", "js", "jsx", "py", "rb", "php"];
  return supportedExtensions.includes(extension || "");
}
function detectLanguageFromPath(filePath) {
  const extension = filePath.split(".").pop()?.toLowerCase();
  const extensionMap = {
    "ts": "typescript",
    "tsx": "typescript",
    "js": "javascript",
    "jsx": "javascript",
    "py": "python",
    "rb": "ruby",
    "php": "php"
  };
  return extensionMap[extension || ""] || null;
}
var SemanticAnalysisSystem, semanticAnalysisSystem;
var init_semantic = __esm({
  "src/analysis/semantic/index.ts"() {
    "use strict";
    init_types2();
    init_SemanticAnalyzer();
    init_ChunkGenerator();
    init_SemanticChunkingIntegration();
    init_AiGuidedChunking();
    init_SemanticAnalyzer();
    init_ChunkGenerator();
    init_logger();
    SemanticAnalysisSystem = class {
      analyzer;
      chunkGenerator;
      config;
      cache = /* @__PURE__ */ new Map();
      constructor(config4 = {}) {
        this.config = {
          enableFallback: true,
          enableCaching: true,
          ...config4
        };
        this.analyzer = new SemanticAnalyzer(config4.analyzer);
        this.chunkGenerator = new ChunkGenerator(config4.chunkGenerator);
      }
      /**
       * Perform complete semantic analysis and generate intelligent chunks
       */
      async analyzeAndChunk(content, filePath, options = {}) {
        const {
          language,
          reviewType = "quick-fixes",
          useCache = this.config.enableCaching
        } = options;
        const cacheKey = this.generateCacheKey(content, filePath, language, reviewType);
        if (useCache && this.cache.has(cacheKey)) {
          logger_default.debug(`Using cached analysis for ${filePath}`);
          return this.cache.get(cacheKey);
        }
        try {
          logger_default.debug(`Starting semantic analysis for ${filePath}`);
          const analysisResult = await this.analyzer.analyzeCode(content, filePath, language);
          if (!analysisResult.success) {
            logger_default.warn(`Semantic analysis failed for ${filePath}, errors:`, analysisResult.errors);
            if (this.config.enableFallback && analysisResult.fallbackUsed) {
              return this.generateFallbackResult(content, filePath, reviewType, analysisResult.errors);
            }
            throw new Error(`Semantic analysis failed: ${analysisResult.errors.map((e) => e.message).join(", ")}`);
          }
          const chunkingRecommendation = this.chunkGenerator.generateChunks(
            analysisResult.analysis,
            content,
            reviewType
          );
          const result = {
            analysis: analysisResult.analysis,
            chunking: chunkingRecommendation,
            errors: analysisResult.errors,
            success: true,
            fallbackUsed: false,
            metadata: {
              filePath,
              language: analysisResult.analysis.language,
              reviewType,
              analyzedAt: /* @__PURE__ */ new Date(),
              totalChunks: chunkingRecommendation.chunks.length,
              totalTokens: chunkingRecommendation.estimatedTokens
            }
          };
          if (useCache) {
            this.cache.set(cacheKey, result);
          }
          logger_default.info(`Semantic analysis completed for ${filePath}: ${chunkingRecommendation.chunks.length} chunks, ${chunkingRecommendation.estimatedTokens} tokens`);
          return result;
        } catch (error2) {
          logger_default.error(`Semantic analysis system error for ${filePath}:`, error2);
          if (this.config.enableFallback) {
            logger_default.info(`Falling back to line-based chunking for ${filePath}`);
            return this.generateFallbackResult(content, filePath, reviewType, [
              {
                type: "analysis_failed",
                message: error2 instanceof Error ? error2.message : "Unknown error"
              }
            ]);
          }
          throw error2;
        }
      }
      /**
       * Generate fallback result when semantic analysis fails
       */
      generateFallbackResult(content, filePath, reviewType, errors) {
        const lines = content.split("\n");
        const chunkSize = Math.min(500, Math.max(50, lines.length / 4));
        const chunks = [];
        let chunkId = 1;
        for (let i = 0; i < lines.length; i += chunkSize) {
          const endLine = Math.min(i + chunkSize, lines.length);
          chunks.push({
            id: `fallback_${chunkId++}`,
            type: "module",
            lines: [i + 1, endLine],
            declarations: [],
            context: [],
            priority: "medium",
            reviewFocus: this.getDefaultReviewFocus(reviewType),
            estimatedTokens: (endLine - i) * 4,
            dependencies: []
          });
        }
        return {
          analysis: void 0,
          chunking: {
            strategy: "individual",
            chunks,
            crossReferences: [],
            reasoning: "Used fallback line-based chunking due to semantic analysis failure",
            estimatedTokens: lines.length * 4,
            estimatedChunks: chunks.length
          },
          errors,
          success: false,
          fallbackUsed: true,
          metadata: {
            filePath,
            language: "unknown",
            reviewType,
            analyzedAt: /* @__PURE__ */ new Date(),
            fallbackReason: "Semantic analysis failed"
          }
        };
      }
      /**
       * Get default review focus for a review type
       */
      getDefaultReviewFocus(reviewType) {
        const focusMap = {
          "quick-fixes": ["maintainability", "performance"],
          "architectural": ["architecture", "type_safety", "maintainability"],
          "security": ["security", "error_handling"],
          "performance": ["performance", "architecture"],
          "unused-code": ["maintainability", "architecture"]
        };
        return focusMap[reviewType] || ["maintainability"];
      }
      /**
       * Generate cache key for analysis results
       */
      generateCacheKey(content, filePath, language, reviewType) {
        const contentHash = this.simpleHash(content);
        return `${filePath}:${contentHash}:${language || "auto"}:${reviewType || "quick-fixes"}`;
      }
      /**
       * Simple hash function for cache keys
       */
      simpleHash(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(hash).toString(36);
      }
      /**
       * Clear analysis cache
       */
      clearCache() {
        this.cache.clear();
        logger_default.debug("Semantic analysis cache cleared");
      }
      /**
       * Get cache statistics
       */
      getCacheStats() {
        return {
          size: this.cache.size,
          enabled: this.config.enableCaching ?? true
        };
      }
      /**
       * Update system configuration
       */
      updateConfig(config4) {
        this.config = { ...this.config, ...config4 };
        if (config4.analyzer) {
          this.analyzer.updateConfig(config4.analyzer);
        }
        if (config4.chunkGenerator) {
          this.chunkGenerator.updateConfig(config4.chunkGenerator);
        }
      }
      /**
       * Get supported languages
       */
      getSupportedLanguages() {
        return this.analyzer.getSupportedLanguages();
      }
      /**
       * Check if a language is supported
       */
      isLanguageSupported(language) {
        return this.getSupportedLanguages().includes(language);
      }
    };
    semanticAnalysisSystem = new SemanticAnalysisSystem();
  }
});

// src/analysis/tokens/TokenAnalyzer.ts
var TokenAnalyzer;
var init_TokenAnalyzer = __esm({
  "src/analysis/tokens/TokenAnalyzer.ts"() {
    "use strict";
    init_tokenizers();
    init_modelMaps2();
    init_logger();
    TokenAnalyzer = class _TokenAnalyzer {
      static DEFAULT_PROMPT_OVERHEAD = 1500;
      static DEFAULT_CONTEXT_MAINTENANCE_FACTOR = 0.15;
      static DEFAULT_SAFETY_MARGIN_FACTOR = 0.1;
      // Use 90% of context window by default
      static DEFAULT_CONTEXT_WINDOW = 1e5;
      // Default fallback
      /**
       * Get the context window size for a model
       * @param modelName Name of the model
       * @returns Context window size in tokens
       */
      static getContextWindowSize(modelName) {
        logger_default.debug(`getContextWindowSize: modelName=${modelName}`);
        const enhancedMapping = getEnhancedModelMapping(modelName);
        if (enhancedMapping?.contextWindow) {
          logger_default.info(`Found context window size from enhanced mapping for ${modelName}: ${enhancedMapping.contextWindow.toLocaleString()} tokens`);
          return enhancedMapping.contextWindow;
        }
        const mapping = getModelMapping(modelName);
        if (mapping?.contextWindow) {
          logger_default.info(`Found context window size from model mapping for ${modelName}: ${mapping.contextWindow.toLocaleString()} tokens`);
          return mapping.contextWindow;
        }
        const baseName = modelName.includes(":") ? modelName.split(":")[1] : modelName;
        if (baseName) {
          if (/gemini-2\.[05]-(pro|flash)/i.test(baseName)) {
            const size = 1e6;
            logger_default.info(`Detected Gemini 2.x model variant: ${baseName}`);
            logger_default.info(`Using context window size: ${size.toLocaleString()} tokens`);
            return size;
          }
          if (/gemini-1\.5-(pro|flash)/i.test(baseName)) {
            const size = 1e6;
            logger_default.info(`Detected Gemini 1.5 model variant: ${baseName}`);
            logger_default.info(`Using context window size: ${size.toLocaleString()} tokens`);
            return size;
          }
          if (baseName.includes("claude-3") || baseName.includes("claude-4")) {
            const size = 2e5;
            logger_default.info(`Detected Claude 3/4 model variant: ${baseName}`);
            logger_default.info(`Using context window size: ${size.toLocaleString()} tokens`);
            return size;
          }
          if (baseName.includes("gpt-4o")) {
            const size = 128e3;
            logger_default.info(`Detected GPT-4o model: ${baseName}`);
            logger_default.info(`Using context window size: ${size.toLocaleString()} tokens`);
            return size;
          }
          if (baseName.includes("gpt-4")) {
            const size = 128e3;
            logger_default.info(`Detected GPT-4 model variant: ${baseName}`);
            logger_default.info(`Using context window size: ${size.toLocaleString()} tokens`);
            return size;
          }
        }
        logger_default.warn(`No matching context window size found for model: ${modelName}`);
        logger_default.warn(`Using default context window size: ${this.DEFAULT_CONTEXT_WINDOW.toLocaleString()} tokens`);
        return this.DEFAULT_CONTEXT_WINDOW;
      }
      /**
       * Analyze token usage for a set of files
       * @param files Files to analyze
       * @param options Analysis options
       * @returns Token analysis result
       */
      static analyzeFiles(files, options) {
        logger_default.info("Analyzing token usage for files...");
        logger_default.debug(`TokenAnalyzer: modelName=${options.modelName}`);
        const contextWindowSize = this.getContextWindowSize(options.modelName);
        const promptOverhead = options.additionalPromptOverhead || _TokenAnalyzer.DEFAULT_PROMPT_OVERHEAD;
        const contextMaintenanceFactor = options.contextMaintenanceFactor || _TokenAnalyzer.DEFAULT_CONTEXT_MAINTENANCE_FACTOR;
        const safetyMarginFactor = options.safetyMarginFactor || _TokenAnalyzer.DEFAULT_SAFETY_MARGIN_FACTOR;
        const effectiveContextWindowSize = Math.floor(contextWindowSize * (1 - safetyMarginFactor));
        logger_default.info(`Using effective context window size: ${effectiveContextWindowSize.toLocaleString()} tokens (${Math.round((1 - safetyMarginFactor) * 100)}% of ${contextWindowSize.toLocaleString()} tokens)`);
        const fileAnalyses = files.map((file) => {
          const content = file.content;
          const tokenCount = countTokens(content, options.modelName);
          const sizeInBytes = content.length;
          const tokensPerByte = sizeInBytes > 0 ? tokenCount / sizeInBytes : 0;
          return {
            path: file.path,
            relativePath: file.relativePath,
            tokenCount,
            sizeInBytes,
            tokensPerByte
          };
        });
        const totalTokens = fileAnalyses.reduce((sum, file) => sum + file.tokenCount, 0);
        const totalSizeInBytes = fileAnalyses.reduce((sum, file) => sum + file.sizeInBytes, 0);
        const averageTokensPerByte = totalSizeInBytes > 0 ? totalTokens / totalSizeInBytes : 0;
        const estimatedTotalTokens = totalTokens + promptOverhead;
        const exceedsContextWindow = estimatedTotalTokens > effectiveContextWindowSize;
        logger_default.info(`Token analysis summary:`);
        logger_default.info(`- Total files: ${files.length}`);
        logger_default.info(`- Total tokens: ${totalTokens.toLocaleString()}`);
        logger_default.info(`- Prompt overhead: ${promptOverhead.toLocaleString()}`);
        logger_default.info(`- Estimated total tokens: ${estimatedTotalTokens.toLocaleString()}`);
        logger_default.info(`- Context window size: ${contextWindowSize.toLocaleString()}`);
        logger_default.info(`- Effective context size (with safety margin): ${effectiveContextWindowSize.toLocaleString()}`);
        logger_default.info(`- Context utilization: ${(estimatedTotalTokens / effectiveContextWindowSize * 100).toFixed(2)}%`);
        const chunkingRecommendation = this.generateChunkingRecommendation(
          fileAnalyses,
          estimatedTotalTokens,
          effectiveContextWindowSize,
          contextMaintenanceFactor,
          options.forceSinglePass
        );
        if (chunkingRecommendation.chunkingRecommended) {
          logger_default.info(`Multi-pass review recommended: ${chunkingRecommendation.reason}`);
          logger_default.info(`Estimated passes needed: ${chunkingRecommendation.recommendedChunks.length}`);
        } else {
          logger_default.info(`Single-pass review recommended: ${chunkingRecommendation.reason}`);
        }
        if (options.modelName.includes("gemini-1.5") || options.modelName.includes("gemini-2.")) {
          const modelVersion = options.modelName.includes("gemini-2.") ? "2.x" : "1.5";
          logger_default.info(`Using Gemini ${modelVersion} model with 1M token context window`);
          if (chunkingRecommendation.chunkingRecommended) {
            logger_default.info(`Note: Even with Gemini ${modelVersion}'s large context window, chunking is recommended because the content exceeds ${(effectiveContextWindowSize / 1e6 * 100).toFixed(0)}% of the context window`);
          } else {
            logger_default.info(`Note: Using Gemini ${modelVersion}'s large context window (1M tokens) for single-pass review`);
          }
        }
        return {
          files: fileAnalyses,
          totalTokens,
          totalSizeInBytes,
          averageTokensPerByte,
          fileCount: files.length,
          promptOverheadTokens: promptOverhead,
          estimatedTotalTokens,
          contextWindowSize,
          exceedsContextWindow,
          estimatedPassesNeeded: chunkingRecommendation.recommendedChunks.length,
          chunkingRecommendation
        };
      }
      /**
       * Generate a chunking recommendation for files that exceed context window
       * @param fileAnalyses Array of file token analyses
       * @param estimatedTotalTokens Total tokens including overhead
       * @param contextWindowSize Maximum context window size
       * @param contextMaintenanceFactor Context maintenance overhead factor
       * @param forceSinglePass Force single pass mode regardless of token count
       * @returns Chunking recommendation
       */
      static generateChunkingRecommendation(fileAnalyses, estimatedTotalTokens, contextWindowSize, contextMaintenanceFactor, forceSinglePass) {
        if (forceSinglePass) {
          logger_default.debug(`Forcing single-pass review mode as requested (forceSinglePass=true)`);
          return {
            chunkingRecommended: false,
            recommendedChunks: [
              {
                files: fileAnalyses.map((f) => f.path),
                estimatedTokenCount: estimatedTotalTokens,
                priority: 1
              }
            ],
            reason: "Single-pass mode forced by configuration"
          };
        }
        if (estimatedTotalTokens <= contextWindowSize) {
          logger_default.debug(`Content fits within context window (${estimatedTotalTokens.toLocaleString()} <= ${contextWindowSize.toLocaleString()} tokens)`);
          return {
            chunkingRecommended: false,
            recommendedChunks: [
              {
                files: fileAnalyses.map((f) => f.path),
                estimatedTokenCount: estimatedTotalTokens,
                priority: 1
              }
            ],
            reason: "Content fits within model context window"
          };
        }
        logger_default.debug(`Content exceeds context window (${estimatedTotalTokens.toLocaleString()} > ${contextWindowSize.toLocaleString()} tokens)`);
        logger_default.debug(`Generating chunking recommendation with context maintenance factor: ${contextMaintenanceFactor}`);
        const sortedFiles = [...fileAnalyses].sort((a, b) => b.tokenCount - a.tokenCount);
        const effectiveContextSize = Math.floor(
          contextWindowSize * (1 - contextMaintenanceFactor)
        );
        logger_default.debug(`Effective context size for chunking: ${effectiveContextSize.toLocaleString()} tokens (${Math.round((1 - contextMaintenanceFactor) * 100)}% of ${contextWindowSize.toLocaleString()} tokens)`);
        const chunks = [];
        let currentChunk = {
          files: [],
          estimatedTokenCount: 0,
          priority: 1
        };
        for (const file of sortedFiles) {
          if (file.tokenCount > effectiveContextSize) {
            logger_default.warn(`File "${file.path}" is too large for the context window (${file.tokenCount.toLocaleString()} > ${effectiveContextSize.toLocaleString()} tokens)`);
            logger_default.warn(`This file will be processed alone but may exceed the model's capacity`);
          }
          if (currentChunk.estimatedTokenCount + file.tokenCount > effectiveContextSize && currentChunk.files.length > 0) {
            logger_default.debug(`Chunk ${chunks.length + 1} complete with ${currentChunk.files.length} files and ${currentChunk.estimatedTokenCount.toLocaleString()} tokens`);
            chunks.push(currentChunk);
            currentChunk = {
              files: [],
              estimatedTokenCount: 0,
              priority: chunks.length + 1
            };
          }
          currentChunk.files.push(file.path);
          currentChunk.estimatedTokenCount += file.tokenCount;
          logger_default.debug(`Added file "${file.path}" (${file.tokenCount.toLocaleString()} tokens) to chunk ${chunks.length + 1}`);
        }
        if (currentChunk.files.length > 0) {
          logger_default.debug(`Final chunk ${chunks.length + 1} complete with ${currentChunk.files.length} files and ${currentChunk.estimatedTokenCount.toLocaleString()} tokens`);
          chunks.push(currentChunk);
        }
        logger_default.info(`Created ${chunks.length} chunks for multi-pass review`);
        return {
          chunkingRecommended: true,
          recommendedChunks: chunks,
          reason: `Content exceeds model context window (${estimatedTotalTokens.toLocaleString()} > ${contextWindowSize.toLocaleString()} tokens)`
        };
      }
      /**
       * Analyze a single file for token usage
       * @param file File to analyze
       * @param options Analysis options
       * @returns Token analysis for the file
       */
      static analyzeFile(file, options) {
        const content = file.content;
        const tokenCount = countTokens(content, options.modelName);
        const sizeInBytes = content.length;
        return {
          path: file.path,
          relativePath: file.relativePath,
          tokenCount,
          sizeInBytes,
          tokensPerByte: sizeInBytes > 0 ? tokenCount / sizeInBytes : 0
        };
      }
    };
  }
});

// src/analysis/tokens/TokenAnalysisFormatter.ts
function formatNumber(num) {
  return num.toLocaleString();
}
function formatFileSize(bytes) {
  if (bytes < 1024) {
    return `${bytes} B`;
  } else if (bytes < 1024 * 1024) {
    return `${(bytes / 1024).toFixed(2)} KB`;
  } else {
    return `${(bytes / (1024 * 1024)).toFixed(2)} MB`;
  }
}
function formatTokenAnalysis(analysis, modelName, includeFiles = false) {
  const [provider, model] = modelName.includes(":") ? modelName.split(":") : [void 0, modelName];
  const displayModel = model || modelName;
  const displayProvider = provider ? `${provider.charAt(0).toUpperCase() + provider.slice(1)}` : "Unknown";
  let output = `
=== Token Analysis Report ===

Provider: ${displayProvider}
Model: ${displayModel}
Files: ${formatNumber(analysis.fileCount)} (${formatFileSize(analysis.totalSizeInBytes)})

Token Information:
  Content Tokens: ${formatNumber(analysis.totalTokens)}
  Prompt Overhead: ${formatNumber(analysis.promptOverheadTokens)}
  Total Estimated Tokens: ${formatNumber(analysis.estimatedTotalTokens)}
  Context Window Size: ${formatNumber(analysis.contextWindowSize)}

Context Utilization:
  ${(analysis.estimatedTotalTokens / analysis.contextWindowSize * 100).toFixed(2)}% of context window used

`;
  if (analysis.chunkingRecommendation.chunkingRecommended) {
    output += `
Multi-Pass Analysis:
  Chunking Required: Yes
  Reason: ${analysis.chunkingRecommendation.reason}
  Estimated Passes: ${formatNumber(analysis.estimatedPassesNeeded)}
`;
    analysis.chunkingRecommendation.recommendedChunks.forEach((chunk, index) => {
      output += `
  Chunk ${index + 1}:
    Files: ${formatNumber(chunk.files.length)}
    Estimated Tokens: ${formatNumber(chunk.estimatedTokenCount)}
    Priority: ${chunk.priority}
`;
    });
  } else {
    output += `
Multi-Pass Analysis:
  Chunking Required: No
  Reason: ${analysis.chunkingRecommendation.reason}
`;
  }
  if (includeFiles) {
    output += `
File Details:
`;
    const sortedFiles = [...analysis.files].sort((a, b) => b.tokenCount - a.tokenCount);
    sortedFiles.forEach((file) => {
      output += `  ${file.relativePath}:
    Tokens: ${formatNumber(file.tokenCount)}
    Size: ${formatFileSize(file.sizeInBytes)}
    Tokens/Byte: ${file.tokensPerByte.toFixed(2)}
`;
    });
  }
  return output;
}
function formatTokenAnalysisAsJson(analysis) {
  return JSON.stringify(analysis, null, 2);
}
function formatFileTokenAnalysis(fileAnalysis) {
  return `
File: ${fileAnalysis.relativePath}
Tokens: ${formatNumber(fileAnalysis.tokenCount)}
Size: ${formatFileSize(fileAnalysis.sizeInBytes)}
Tokens/Byte: ${fileAnalysis.tokensPerByte.toFixed(2)}
`;
}
var init_TokenAnalysisFormatter = __esm({
  "src/analysis/tokens/TokenAnalysisFormatter.ts"() {
    "use strict";
  }
});

// src/analysis/tokens/index.ts
var tokens_exports = {};
__export(tokens_exports, {
  TokenAnalyzer: () => TokenAnalyzer,
  formatFileTokenAnalysis: () => formatFileTokenAnalysis,
  formatTokenAnalysis: () => formatTokenAnalysis,
  formatTokenAnalysisAsJson: () => formatTokenAnalysisAsJson
});
var init_tokens = __esm({
  "src/analysis/tokens/index.ts"() {
    "use strict";
    init_TokenAnalyzer();
    init_TokenAnalysisFormatter();
  }
});

// src/clients/base/abstractClient.ts
var AbstractClient;
var init_abstractClient = __esm({
  "src/clients/base/abstractClient.ts"() {
    "use strict";
    init_logger();
    AbstractClient = class {
      modelName = "";
      isInitialized = false;
      /**
       * Process the response and extract structured data if possible
       * @param content The response content to process
       * @returns The processed structured data or null
       */
      processResponseForStructuredData(content) {
        try {
          const jsonMatch = content.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
          const jsonContent = jsonMatch ? jsonMatch[1] : content;
          const structuredData = JSON.parse(jsonContent);
          if (!structuredData.summary || !Array.isArray(structuredData.issues)) {
            logger_default.warn(
              "Response is valid JSON but does not have the expected structure"
            );
          }
          return structuredData;
        } catch (parseError) {
          logger_default.warn(
            `Response is not valid JSON: ${parseError instanceof Error ? parseError.message : String(parseError)}`
          );
          return null;
        }
      }
      /**
       * Create a standard review result object
       * @param content The review content
       * @param filePath The file path or identifier
       * @param reviewType The type of review
       * @param cost Optional cost information
       * @returns The standardized review result object
       */
      createReviewResult(content, filePath, reviewType, cost) {
        const structuredData = this.processResponseForStructuredData(content);
        return {
          content,
          cost,
          modelUsed: this.getFullModelName(),
          filePath,
          reviewType,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          structuredData
        };
      }
      /**
       * Get the full model name including provider prefix
       * @returns The full model name
       */
      getFullModelName() {
        const modelParts = this.modelName.split(":");
        if (modelParts.length === 2) {
          return this.modelName;
        }
        return `${this.getProviderName()}:${this.modelName}`;
      }
      /**
       * Handle common error cases in API interactions
       * @param error The error that occurred
       * @param operation The operation that was being performed
       * @param filePath The file path or identifier related to the error
       * @throws The processed error
       */
      handleApiError(error2, operation, filePath) {
        const errorMessage = error2 instanceof Error ? error2.message : String(error2);
        logger_default.error(`Error ${operation} for ${filePath}: ${errorMessage}`);
        throw error2;
      }
    };
  }
});

// src/utils/apiErrorHandler.ts
async function handleFetchResponse(response, apiName) {
  if (!response.ok) {
    let errorBody = "Unknown error";
    try {
      console.log(`[DEBUG] ${apiName} API response headers:`);
      response.headers.forEach((value, name) => {
        console.log(`[DEBUG] ${name}: ${value}`);
      });
      const contentType = response.headers.get("content-type");
      console.log(`[DEBUG] Content-Type: ${contentType}`);
      if (contentType && contentType.includes("application/json")) {
        errorBody = await response.json();
        console.log(`[DEBUG] JSON error body: ${JSON.stringify(errorBody)}`);
      } else {
        errorBody = await response.text();
        console.log(`[DEBUG] Text error body: ${errorBody}`);
      }
    } catch (e) {
      console.log(
        `[DEBUG] Failed to read error body: ${e instanceof Error ? e.message : String(e)}`
      );
      logger_default.debug(
        `Failed to read error body: ${e instanceof Error ? e.message : String(e)}`
      );
    }
    const errorMessage = `${apiName} API error! Status: ${response.status}, Response: ${typeof errorBody === "string" ? errorBody : JSON.stringify(errorBody)}`;
    logger_default.error(errorMessage);
    if (response.status === 401 || response.status === 403) {
      throw new AuthenticationError(errorMessage, response.status, errorBody);
    } else if (response.status === 404) {
      throw new NotFoundError(errorMessage, response.status, errorBody);
    } else if (response.status === 429) {
      const retryAfter = response.headers.get("retry-after");
      const retryAfterSeconds = retryAfter ? parseInt(retryAfter, 10) : void 0;
      throw new RateLimitError(
        errorMessage,
        retryAfterSeconds,
        response.status,
        errorBody
      );
    } else {
      throw new ApiError(errorMessage, response.status, errorBody);
    }
  }
  return response;
}
async function safeJsonParse(response, apiName) {
  try {
    return await response.json();
  } catch (error2) {
    const errorMessage = `Failed to parse ${apiName} API response as JSON: ${error2 instanceof Error ? error2.message : String(error2)}`;
    logger_default.error(errorMessage);
    throw new InvalidResponseError(errorMessage);
  }
}
var ApiError, RateLimitError, AuthenticationError, NotFoundError, InvalidResponseError;
var init_apiErrorHandler = __esm({
  "src/utils/apiErrorHandler.ts"() {
    "use strict";
    init_logger();
    ApiError = class _ApiError extends Error {
      constructor(message, statusCode, details) {
        super(message);
        this.statusCode = statusCode;
        this.details = details;
        this.name = "ApiError";
        Object.setPrototypeOf(this, _ApiError.prototype);
      }
    };
    RateLimitError = class _RateLimitError extends ApiError {
      constructor(message, retryAfter, statusCode, details) {
        super(message, statusCode, details);
        this.retryAfter = retryAfter;
        this.name = "RateLimitError";
        Object.setPrototypeOf(this, _RateLimitError.prototype);
      }
    };
    AuthenticationError = class _AuthenticationError extends ApiError {
      constructor(message, statusCode, details) {
        super(message, statusCode, details);
        this.name = "AuthenticationError";
        Object.setPrototypeOf(this, _AuthenticationError.prototype);
      }
    };
    NotFoundError = class _NotFoundError extends ApiError {
      constructor(message, statusCode, details) {
        super(message, statusCode, details);
        this.name = "NotFoundError";
        Object.setPrototypeOf(this, _NotFoundError.prototype);
      }
    };
    InvalidResponseError = class _InvalidResponseError extends ApiError {
      constructor(message, statusCode, details) {
        super(message, statusCode, details);
        this.name = "InvalidResponseError";
        Object.setPrototypeOf(this, _InvalidResponseError.prototype);
      }
    };
  }
});

// src/clients/base/httpClient.ts
var httpClient_exports = {};
__export(httpClient_exports, {
  fetchWithRetry: () => fetchWithRetry,
  withRetry: () => withRetry
});
async function fetchWithRetry(url, options, retries = 3) {
  logger_default.debug(`[FETCH DEBUG] fetchWithRetry called with url: ${url}`);
  for (let i = 0; i < retries; i++) {
    try {
      logger_default.debug(`Making API request to ${url} (attempt ${i + 1}/${retries})`);
      const res = await fetch(url, options);
      if (res.ok) {
        return res;
      }
      logger_default.error(`[FETCH DEBUG] Request failed with status: ${res.status}`);
      if (res.status === 429 || res.status >= 500) {
        const retryAfter = res.headers.get("Retry-After");
        const delayMs = retryAfter ? parseInt(retryAfter, 10) * 1e3 : 1e3 * Math.pow(2, i);
        logger_default.warn(`Request failed with status ${res.status}. Retrying in ${delayMs / 1e3}s...`);
        await new Promise((r) => setTimeout(r, delayMs));
      } else {
        try {
          const errorBody = await res.json();
          const requestId = res.headers.get("x-request-id") || res.headers.get("request-id");
          logger_default.error(`API error response: ${JSON.stringify(errorBody, null, 2)}`);
          logger_default.error(`Request URL: ${url}`);
          logger_default.error(`Request headers: ${JSON.stringify(options.headers, null, 2)}`);
          let modelInfo = "";
          if (options.body) {
            try {
              const body = JSON.parse(options.body);
              if (body.messages) {
                logger_default.error(`Request had ${body.messages.length} messages`);
              }
              modelInfo = body.model || "";
              logger_default.error(`Request model: ${body.model}`);
              logger_default.error(`Request max_tokens: ${body.max_tokens}`);
              logger_default.error(`Request max_completion_tokens: ${body.max_completion_tokens}`);
            } catch {
              logger_default.error("Request body was not JSON");
            }
          }
          const errorDetails = [
            `API request failed`,
            `Endpoint: ${url}`,
            `Status: ${res.status}`,
            `Error: ${errorBody.error?.message || JSON.stringify(errorBody)}`
          ];
          if (requestId) {
            errorDetails.push(`Request ID: ${requestId}`);
          }
          if (modelInfo) {
            errorDetails.push(`Model: ${modelInfo}`);
          }
          throw new ApiError(errorDetails.join("\n  "));
        } catch (parseError) {
          if (parseError instanceof ApiError) {
            throw parseError;
          }
          logger_default.error(`Failed to parse error response, status: ${res.status}`);
          throw new ApiError(
            `API request failed
  Endpoint: ${url}
  Status: ${res.status}
  Error: Unable to parse error response`
          );
        }
      }
    } catch (error2) {
      if (i < retries - 1 && !(error2 instanceof ApiError)) {
        const delayMs = 1e3 * Math.pow(2, i);
        logger_default.warn(`Request failed with error: ${error2 instanceof Error ? error2.message : String(error2)}. Retrying in ${delayMs / 1e3}s...`);
        await new Promise((r) => setTimeout(r, delayMs));
      } else {
        throw error2;
      }
    }
  }
  throw new ApiError(`Failed after ${retries} retries`);
}
async function withRetry(fn, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await fn();
    } catch (error2) {
      const err = error2;
      if ((err.status === 429 || err.status && err.status >= 500) && i < retries - 1) {
        const delayMs = 1e3 * Math.pow(2, i);
        logger_default.warn(`Operation failed with status ${err.status}. Retrying in ${delayMs / 1e3}s...`);
        await new Promise((r) => setTimeout(r, delayMs));
      } else if (i < retries - 1) {
        const delayMs = 1e3 * Math.pow(2, i);
        logger_default.warn(`Operation failed: ${error2 instanceof Error ? error2.message : String(error2)}. Retrying in ${delayMs / 1e3}s...`);
        await new Promise((r) => setTimeout(r, delayMs));
      } else {
        throw error2;
      }
    }
  }
  throw new ApiError(`Failed after ${retries} retries`);
}
var init_httpClient = __esm({
  "src/clients/base/httpClient.ts"() {
    "use strict";
    init_apiErrorHandler();
    init_logger();
  }
});

// src/clients/utils/tokenCounter.ts
var tokenCounter_exports = {};
__export(tokenCounter_exports, {
  calculateCost: () => calculateCost2,
  estimateTokenCount: () => estimateTokenCount2,
  formatCost: () => formatCost3,
  getCostInfo: () => getCostInfo2,
  getCostInfoFromText: () => getCostInfoFromText
});
function estimateTokenCount2(text, modelName) {
  return countTokens(text, modelName || "fallback");
}
function getModelPricing(modelName) {
  if (modelName.startsWith("openrouter-")) {
    const actualModelName = modelName.substring("openrouter-".length);
    return MODEL_PRICING[actualModelName] || MODEL_PRICING["default"];
  }
  return MODEL_PRICING[modelName] || MODEL_PRICING["default"];
}
function calculateTierCost(tokens, tokenCost, tierStart, tierEnd) {
  const tierTokens = tierEnd ? Math.min(Math.max(0, tokens - tierStart), tierEnd - tierStart) : Math.max(0, tokens - tierStart);
  return tierTokens / 1e3 * tokenCost;
}
function calculateCost2(inputTokens, outputTokens, modelName = "gemini-1.5-pro") {
  const pricing = getModelPricing(modelName);
  let inputCost = 0;
  let outputCost = 0;
  if (pricing.type === "standard") {
    inputCost = inputTokens / 1e3 * pricing.inputTokenCost;
    outputCost = outputTokens / 1e3 * pricing.outputTokenCost;
  } else if (pricing.type === "tiered") {
    const tiers = pricing.tiers;
    for (let i = 0; i < tiers.length; i++) {
      const tierStart = tiers[i].threshold;
      const tierEnd = i < tiers.length - 1 ? tiers[i + 1].threshold : void 0;
      inputCost += calculateTierCost(
        inputTokens,
        tiers[i].inputTokenCost,
        tierStart,
        tierEnd
      );
    }
    for (let i = 0; i < tiers.length; i++) {
      const tierStart = tiers[i].threshold;
      const tierEnd = i < tiers.length - 1 ? tiers[i + 1].threshold : void 0;
      outputCost += calculateTierCost(
        outputTokens,
        tiers[i].outputTokenCost,
        tierStart,
        tierEnd
      );
    }
  }
  return inputCost + outputCost;
}
function formatCost3(cost) {
  return `$${cost.toFixed(6)} USD`;
}
function getCostInfoFromText(inputText, outputText, modelName = "gemini-1.5-pro") {
  const inputTokens = estimateTokenCount2(inputText, modelName);
  const outputTokens = estimateTokenCount2(outputText, modelName);
  const totalTokens = inputTokens + outputTokens;
  const estimatedCost = calculateCost2(inputTokens, outputTokens, modelName);
  return {
    inputTokens,
    outputTokens,
    totalTokens,
    estimatedCost,
    formattedCost: formatCost3(estimatedCost),
    cost: estimatedCost
    // Alias for backward compatibility
  };
}
function getCostInfo2(inputTokens, outputTokens, modelName = "gemini-1.5-pro") {
  const totalTokens = inputTokens + outputTokens;
  const estimatedCost = calculateCost2(inputTokens, outputTokens, modelName);
  return {
    inputTokens,
    outputTokens,
    totalTokens,
    estimatedCost,
    formattedCost: formatCost3(estimatedCost),
    cost: estimatedCost
    // Alias for backward compatibility
  };
}
var MODEL_PRICING;
var init_tokenCounter = __esm({
  "src/clients/utils/tokenCounter.ts"() {
    "use strict";
    init_tokenizers();
    MODEL_PRICING = {
      // Gemini 2.5 models
      "gemini-2.5-pro": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 125e-5,
            // $1.25 per 1M tokens (200k tokens)
            outputTokenCost: 0.01
            // $10.00 per 1M tokens (200k tokens)
          },
          {
            threshold: 2e5,
            inputTokenCost: 25e-4,
            // $2.50 per 1M tokens (>200k tokens)
            outputTokenCost: 0.015
            // $15.00 per 1M tokens (>200k tokens)
          }
        ]
      },
      "gemini-2.5-pro-preview": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 125e-5,
            // $1.25 per 1M tokens (200k tokens)
            outputTokenCost: 0.01
            // $10.00 per 1M tokens (200k tokens)
          },
          {
            threshold: 2e5,
            inputTokenCost: 25e-4,
            // $2.50 per 1M tokens (>200k tokens)
            outputTokenCost: 0.015
            // $15.00 per 1M tokens (>200k tokens)
          }
        ]
      },
      "gemini-2.5-pro-exp": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 125e-5,
            // $1.25 per 1M tokens (200k tokens)
            outputTokenCost: 0.01
            // $10.00 per 1M tokens (200k tokens)
          },
          {
            threshold: 2e5,
            inputTokenCost: 25e-4,
            // $2.50 per 1M tokens (>200k tokens)
            outputTokenCost: 0.015
            // $15.00 per 1M tokens (>200k tokens)
          }
        ]
      },
      "gemini-2.0-flash": {
        type: "standard",
        inputTokenCost: 1e-4,
        // $0.10 per 1M tokens
        outputTokenCost: 4e-4
        // $0.40 per 1M tokens
      },
      "gemini-2.0-flash-lite": {
        type: "standard",
        inputTokenCost: 75e-6,
        // $0.075 per 1M tokens
        outputTokenCost: 3e-4
        // $0.30 per 1M tokens
      },
      // Gemini 1.5 models
      "gemini-1.5-pro": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 125e-5,
            // $1.25 per 1M tokens (128k tokens)
            outputTokenCost: 5e-3
            // $5.00 per 1M tokens (128k tokens)
          },
          {
            threshold: 128e3,
            inputTokenCost: 25e-4,
            // $2.50 per 1M tokens (>128k tokens)
            outputTokenCost: 0.01
            // $10.00 per 1M tokens (>128k tokens)
          }
        ]
      },
      "gemini-1.5-flash": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 75e-6,
            // $0.075 per 1M tokens (128k tokens)
            outputTokenCost: 3e-4
            // $0.30 per 1M tokens (128k tokens)
          },
          {
            threshold: 128e3,
            inputTokenCost: 15e-5,
            // $0.15 per 1M tokens (>128k tokens)
            outputTokenCost: 6e-4
            // $0.60 per 1M tokens (>128k tokens)
          }
        ]
      },
      "gemini-1.5-flash-8b": {
        type: "tiered",
        tiers: [
          {
            threshold: 0,
            inputTokenCost: 375e-7,
            // $0.0375 per 1M tokens (128k tokens)
            outputTokenCost: 15e-5
            // $0.15 per 1M tokens (128k tokens)
          },
          {
            threshold: 128e3,
            inputTokenCost: 75e-6,
            // $0.075 per 1M tokens (>128k tokens)
            outputTokenCost: 3e-4
            // $0.30 per 1M tokens (>128k tokens)
          }
        ]
      },
      // OpenRouter models
      "anthropic/claude-3-opus": {
        type: "standard",
        inputTokenCost: 0.015,
        // $15.00 per 1M tokens
        outputTokenCost: 0.075
        // $75.00 per 1M tokens
      },
      "anthropic/claude-3-sonnet": {
        type: "standard",
        inputTokenCost: 3e-3,
        // $3.00 per 1M tokens
        outputTokenCost: 0.015
        // $15.00 per 1M tokens
      },
      "openai/gpt-4-turbo": {
        type: "standard",
        inputTokenCost: 0.01,
        // $10.00 per 1M tokens
        outputTokenCost: 0.03
        // $30.00 per 1M tokens
      },
      "openai/gpt-4o": {
        type: "standard",
        inputTokenCost: 25e-4,
        // $2.50 per 1M tokens
        outputTokenCost: 0.01
        // $10.00 per 1M tokens
      },
      "anthropic/claude-2.1": {
        type: "standard",
        inputTokenCost: 8e-3,
        // $8.00 per 1M tokens
        outputTokenCost: 0.024
        // $24.00 per 1M tokens
      },
      // Default fallback pricing
      default: {
        type: "standard",
        inputTokenCost: 1e-3,
        // $1.00 per 1M tokens
        outputTokenCost: 2e-3
        // $2.00 per 1M tokens
      }
    };
  }
});

// src/clients/base/responseProcessor.ts
function attemptJsonRecovery(content) {
  const strategies = [
    // Strategy 1: Remove leading language identifiers (e.g., "typescript\n{...}")
    (text) => {
      const match = text.match(/^(?:typescript|javascript|json|ts|js)\s*\n?\s*({[\s\S]*})$/i);
      return match ? match[1] : null;
    },
    // Strategy 2: Extract JSON from mixed content (find first complete JSON object)
    (text) => {
      const match = text.match(/({[\s\S]*?})\s*$/);
      return match ? match[1] : null;
    },
    // Strategy 3: Look for JSON between quotes (e.g., "typescript\n{...}")
    (text) => {
      const match = text.match(/"[^"]*"\s*\n?\s*({[\s\S]*})/);
      return match ? match[1] : null;
    },
    // Strategy 4: Remove everything before the first opening brace
    (text) => {
      const braceIndex = text.indexOf("{");
      if (braceIndex === -1) return null;
      return text.substring(braceIndex);
    },
    // Strategy 5: Try to extract from code blocks with language prefixes
    (text) => {
      const match = text.match(/```(?:json|typescript|javascript)?\s*([^`]+)\s*```/i);
      if (!match) return null;
      const blockContent = match[1].trim();
      const cleanContent = blockContent.replace(/^(?:typescript|javascript|json|ts|js)\s*\n?/i, "");
      return cleanContent.startsWith("{") ? cleanContent : null;
    }
  ];
  for (const strategy of strategies) {
    try {
      const extracted = strategy(content.trim());
      if (extracted) {
        const parsed = JSON.parse(extracted);
        if (typeof parsed === "object" && parsed !== null) {
          logger_default.debug("Successfully recovered JSON using recovery strategy");
          return parsed;
        }
      }
    } catch (error2) {
      continue;
    }
  }
  return null;
}
function extractStructuredData(content) {
  let jsonBlockMatch = null;
  let anyCodeBlockMatch = null;
  try {
    jsonBlockMatch = content.match(/```(?:json)\s*([\s\S]*?)\s*```/) || null;
    if (!jsonBlockMatch) {
      anyCodeBlockMatch = content.match(/```(?:[\w]*)?[\s\n]*([\s\S]*?)[\s\n]*```/) || null;
      if (anyCodeBlockMatch && content.includes("```typescript")) {
        logger_default.debug("Detected typescript code block, will check if it contains valid JSON");
      }
    }
    let jsonContent = "";
    if (jsonBlockMatch) {
      jsonContent = jsonBlockMatch[1] || "";
      logger_default.debug("Found JSON code block, extracting content");
    } else if (anyCodeBlockMatch) {
      const blockContent = (anyCodeBlockMatch[1] || "").trim();
      if (content.includes("```typescript") || content.includes("```ts")) {
        logger_default.debug("Analyzing TypeScript code block for JSON content");
        if (blockContent.includes("{") && blockContent.includes("}")) {
          const objectMatch = blockContent.match(/(\{[\s\S]*\})/);
          if (objectMatch && objectMatch[1]) {
            const potentialJson = objectMatch[1].trim();
            try {
              JSON.parse(potentialJson);
              jsonContent = potentialJson;
              logger_default.debug("Successfully extracted JSON object from TypeScript code block");
            } catch (parseError) {
              logger_default.debug("TypeScript block contains object syntax but not valid JSON");
              if (blockContent.startsWith("{") && blockContent.endsWith("}")) {
                jsonContent = blockContent;
                logger_default.debug("Using TypeScript block content for potential parsing");
              } else {
                logger_default.debug("TypeScript code block is not JSON-compatible, falling back to raw content");
                jsonContent = content;
              }
            }
          } else {
            logger_default.debug("No valid object literal found in TypeScript code block");
            jsonContent = content;
          }
        } else {
          logger_default.debug("TypeScript code block doesn't contain object literals, falling back to raw content");
          jsonContent = content;
        }
      } else if (blockContent.startsWith("{") && blockContent.endsWith("}")) {
        jsonContent = blockContent;
        logger_default.debug("Found code block with JSON-like content, attempting to parse");
      } else {
        logger_default.debug("Code block found but doesn't appear to be JSON, falling back to raw content");
        jsonContent = content;
      }
    } else {
      jsonContent = content;
      logger_default.debug("No code blocks found, attempting to parse raw content");
    }
    const parsedData = JSON.parse(jsonContent);
    if ("review" in parsedData) {
      const aiResponse = parsedData;
      if (!aiResponse.review) {
        logger_default.warn('Response is valid JSON but missing "review" property');
        return void 0;
      }
      const review = {
        summary: aiResponse.review.summary ? typeof aiResponse.review.summary === "string" ? aiResponse.review.summary : JSON.stringify(aiResponse.review.summary) : "No summary provided",
        issues: []
      };
      if (aiResponse.review.files && Array.isArray(aiResponse.review.files)) {
        aiResponse.review.files.forEach((file) => {
          if (file.issues && Array.isArray(file.issues)) {
            file.issues.forEach((issue) => {
              if (issue.id && issue.description) {
                review.issues.push({
                  title: issue.id,
                  description: issue.description,
                  priority: mapPriority(issue.priority),
                  type: "other",
                  filePath: file.filePath || "",
                  lineNumbers: issue.location && (issue.location.startLine || issue.location.endLine) ? `${issue.location.startLine || ""}-${issue.location.endLine || ""}` : void 0,
                  codeSnippet: issue.currentCode,
                  suggestedFix: issue.suggestedCode,
                  impact: issue.explanation
                });
              }
            });
          }
        });
      }
      if (aiResponse.review.recommendations) {
        review.recommendations = aiResponse.review.recommendations;
      }
      if (aiResponse.review.positiveAspects) {
        review.positiveAspects = aiResponse.review.positiveAspects;
      }
      return review;
    } else {
      const structuredData = parsedData;
      if (typeof structuredData.summary === "undefined" || !Array.isArray(structuredData.issues)) {
        logger_default.warn("Response is valid JSON but does not have the expected StructuredReview structure");
        return void 0;
      }
      return structuredData;
    }
  } catch (parseError) {
    const errorMsg = parseError instanceof Error ? parseError.message : String(parseError);
    logger_default.warn(`Response is not valid JSON: ${errorMsg}`);
    const contentPreview = content.substring(0, 50).replace(/\n/g, " ");
    logger_default.info(`JSON parse error with content starting with: "${contentPreview}..."`);
    try {
      const recoveredJson = attemptJsonRecovery(content);
      if (recoveredJson) {
        logger_default.info("Successfully recovered JSON from malformed response");
        return recoveredJson;
      }
    } catch (recoveryError) {
      logger_default.debug("JSON recovery attempt failed:", recoveryError);
    }
    if (content.includes("```typescript") || content.includes("```ts")) {
      logger_default.info("Content contains TypeScript code blocks that may be causing parsing issues");
    }
    if (content.includes("```json")) {
      logger_default.info("Content contains JSON code blocks that could not be parsed properly");
    }
    if (content.match(/^(?:typescript|javascript|json|ts|js)\s*\n/i)) {
      logger_default.info("Content starts with language identifier, which may indicate a Gemini response formatting issue");
    }
    if (content.match(/"(?:typescript|javascript|json|ts|js)"/i)) {
      logger_default.info("Content contains quoted language identifiers, which may indicate a parsing issue");
    }
    if (configManager_default.getApplicationConfig().logLevel.value === "debug") {
      const snippet = content.length > 200 ? content.substring(0, 100) + "..." + content.substring(content.length - 100) : content;
      logger_default.debug(`Content snippet causing JSON parse error: ${snippet}`);
      if (jsonBlockMatch) {
        if (jsonBlockMatch && jsonBlockMatch[1]) {
          logger_default.debug(`Found JSON code block but content couldn't be parsed as JSON: ${jsonBlockMatch[1].substring(0, 100)}`);
        }
      } else if (anyCodeBlockMatch) {
        if (anyCodeBlockMatch && anyCodeBlockMatch[1]) {
          logger_default.debug(`Found non-JSON code block but content couldn't be parsed as JSON: ${anyCodeBlockMatch[1].substring(0, 100)}`);
        }
      }
    }
    try {
      return {
        summary: "AI generated a response that couldn't be parsed as structured data",
        issues: [{
          title: "Response format issue",
          description: "The response couldn't be parsed into structured format. Please see the full text for details.",
          priority: "medium",
          type: "other",
          filePath: "unknown"
          // Required field in ReviewIssue
        }]
      };
    } catch (fallbackError) {
      logger_default.debug("Failed to create fallback structured response");
      return void 0;
    }
  }
}
function mapPriority(priority) {
  if (!priority) return "medium";
  const normalizedPriority = priority.toLowerCase();
  if (normalizedPriority.includes("high")) return "high";
  if (normalizedPriority.includes("low")) return "low";
  return "medium";
}
function createStandardReviewResult(content, prompt, modelName, filePath, reviewType, options) {
  const expectsJsonOutput = options?.interactive === true || options?.output === "json";
  const structuredData = expectsJsonOutput ? extractStructuredData(content) : void 0;
  let cost;
  try {
    cost = getCostInfoFromText(prompt, content, modelName);
  } catch (error2) {
    logger_default.warn(
      `Failed to calculate cost information: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
  }
  return {
    content,
    cost,
    modelUsed: modelName,
    filePath,
    reviewType,
    timestamp: (/* @__PURE__ */ new Date()).toISOString(),
    structuredData
  };
}
function handleApiError(error2, operation, modelName, context) {
  const errorMessage = error2 instanceof Error ? error2.message : String(error2);
  let formattedError = `Failed to ${operation} with ${modelName}`;
  if (context) {
    const contextParts = [];
    if (context.endpoint) {
      contextParts.push(`Endpoint: ${context.endpoint}`);
    }
    if (context.statusCode) {
      contextParts.push(`Status: ${context.statusCode}`);
    }
    if (context.requestId) {
      contextParts.push(`Request ID: ${context.requestId}`);
    }
    if (context.filePath) {
      contextParts.push(`File: ${context.filePath}`);
    }
    if (context.additionalInfo) {
      Object.entries(context.additionalInfo).forEach(([key, value]) => {
        contextParts.push(`${key}: ${value}`);
      });
    }
    if (contextParts.length > 0) {
      formattedError += `
  Context: ${contextParts.join(", ")}`;
    }
  }
  formattedError += `
  Error: ${errorMessage}`;
  logger_default.error(formattedError);
  if (error2 instanceof Error && error2.stack && configManager_default.getApplicationConfig().logLevel.value === "debug") {
    logger_default.debug(`Stack trace: ${error2.stack}`);
  }
  if (error2 instanceof ApiError) {
    return error2;
  }
  return new ApiError(formattedError);
}
var init_responseProcessor = __esm({
  "src/clients/base/responseProcessor.ts"() {
    "use strict";
    init_apiErrorHandler();
    init_logger();
    init_tokenCounter();
    init_configManager();
  }
});

// src/clients/base/modelDetection.ts
function parseModelName(modelNameString, defaultProvider) {
  if (!modelNameString) {
    return { adapter: defaultProvider, modelName: "" };
  }
  return modelNameString.includes(":") ? {
    adapter: modelNameString.split(":")[0],
    modelName: modelNameString.split(":")[1]
  } : {
    adapter: defaultProvider,
    modelName: modelNameString
  };
}
function detectModelProvider(providerName, modelNameString) {
  const config4 = getConfig();
  const selectedModel = modelNameString || config4.selectedModel || "";
  const { adapter, modelName } = parseModelName(selectedModel, providerName);
  return {
    isCorrect: adapter === providerName,
    adapter,
    modelName
  };
}
function validateApiKey(providerName, apiKeyName) {
  const apiKey = getApiKeyForProvider(providerName);
  if (!apiKey) {
    const envVarName = apiKeyName || `AI_CODE_REVIEW_${providerName.toUpperCase()}_API_KEY`;
    logger_default.error(`No ${providerName} API key found in configuration.`);
    logger_default.error("Please add the following to your .env.local file:");
    logger_default.error(`- ${envVarName}=your_${providerName}_api_key_here`);
    return false;
  }
  const config4 = getConfig();
  if (config4.debug) {
    logger_default.info(`Using real ${providerName} API responses.`);
  } else {
    logger_default.info(`API key found for ${providerName}. Using real API responses.`);
  }
  return true;
}
var init_modelDetection = __esm({
  "src/clients/base/modelDetection.ts"() {
    "use strict";
    init_config();
    init_logger();
  }
});

// src/clients/base/index.ts
var init_base = __esm({
  "src/clients/base/index.ts"() {
    "use strict";
    init_abstractClient();
    init_httpClient();
    init_responseProcessor();
    init_modelDetection();
  }
});

// src/utils/projectDocs.ts
async function readDocFile(filePath) {
  try {
    if (await fileExists(filePath)) {
      const content = await import_promises7.default.readFile(filePath, "utf-8");
      if (content.length > MAX_DOC_SIZE) {
        logger_default.warn(
          `Documentation file ${filePath} is too large, truncating to ${MAX_DOC_SIZE} characters.`
        );
        return content.substring(0, MAX_DOC_SIZE) + "\n\n[Content truncated due to size]";
      }
      return content;
    }
  } catch (error2) {
    logger_default.warn(`Error reading documentation file ${filePath}:`, error2);
  }
  return void 0;
}
async function readProjectDocs(projectDir) {
  const docs = {
    custom: {}
  };
  docs.readme = await readDocFile(import_path11.default.join(projectDir, "README.md"));
  docs.project = await readDocFile(import_path11.default.join(projectDir, "PROJECT.md"));
  docs.progress = await readDocFile(import_path11.default.join(projectDir, "PROGRESS.md"));
  docs.contributing = await readDocFile(
    import_path11.default.join(projectDir, "CONTRIBUTING.md")
  );
  docs.architecture = await readDocFile(
    import_path11.default.join(projectDir, "ARCHITECTURE.md")
  );
  try {
    const docsDir = import_path11.default.join(projectDir, "docs");
    if (await fileExists(docsDir)) {
      const files = await import_promises7.default.readdir(docsDir);
      for (const file of files) {
        if (file.endsWith(".md")) {
          const filePath = import_path11.default.join(docsDir, file);
          const content = await readDocFile(filePath);
          if (content) {
            docs.custom[file] = content;
          }
        }
      }
    }
  } catch (error2) {
    logger_default.warn("Error reading docs directory:", error2);
  }
  return docs;
}
function addMetadataToProjectDocs(docs, key, value) {
  if (!docs.metadata) {
    docs.metadata = {};
  }
  docs.metadata[key] = value;
  return docs;
}
function formatProjectDocs(docs) {
  const sections = [];
  if (docs.readme) {
    sections.push("# README.md\n\n" + docs.readme);
  }
  if (docs.project) {
    sections.push("# PROJECT.md\n\n" + docs.project);
  }
  if (docs.architecture) {
    sections.push("# ARCHITECTURE.md\n\n" + docs.architecture);
  }
  if (docs.progress) {
    sections.push("# PROGRESS.md\n\n" + docs.progress);
  }
  if (docs.contributing) {
    sections.push("# CONTRIBUTING.md\n\n" + docs.contributing);
  }
  if (docs.custom) {
    for (const [file, content] of Object.entries(docs.custom)) {
      sections.push(`# docs/${file}

${content}`);
    }
  }
  if (docs.metadata) {
    for (const [key, content] of Object.entries(docs.metadata)) {
      const title = key.charAt(0).toUpperCase() + key.slice(1).replace(/([A-Z])/g, " $1");
      sections.push(`# ${title}

${content}`);
    }
  }
  if (sections.length === 0) {
    return "";
  }
  return "## Project Documentation\n\n" + sections.join("\n\n---\n\n");
}
var import_promises7, import_path11, MAX_DOC_SIZE;
var init_projectDocs = __esm({
  "src/utils/projectDocs.ts"() {
    "use strict";
    import_promises7 = __toESM(require("fs/promises"));
    import_path11 = __toESM(require("path"));
    init_fileSystem();
    init_logger();
    MAX_DOC_SIZE = 5e4;
  }
});

// src/clients/utils/languageDetection.ts
function getLanguageFromExtension(extension) {
  const extensionMap = {
    js: "javascript",
    jsx: "javascript",
    ts: "typescript",
    tsx: "typescript",
    py: "python",
    rb: "ruby",
    java: "java",
    go: "go",
    rs: "rust",
    php: "php",
    cs: "csharp",
    cpp: "cpp",
    c: "c",
    h: "c",
    hpp: "cpp",
    swift: "swift",
    kt: "kotlin",
    md: "markdown",
    json: "json",
    yml: "yaml",
    yaml: "yaml",
    html: "html",
    css: "css",
    scss: "scss",
    sql: "sql"
  };
  return extensionMap[extension.toLowerCase()] || extension;
}
var init_languageDetection = __esm({
  "src/clients/utils/languageDetection.ts"() {
    "use strict";
  }
});

// src/clients/utils/directoryStructure.ts
function generateDirectoryStructure(files) {
  const structure = {};
  for (const file of files) {
    if (!file.relativePath) continue;
    const parts = file.relativePath.split("/");
    let current = structure;
    for (let i = 0; i < parts.length - 1; i++) {
      const part = parts[i];
      if (!current[part]) {
        current[part] = {};
      }
      current = current[part];
    }
    const fileName = parts[parts.length - 1];
    current[fileName] = null;
  }
  function stringifyStructure(obj, indent = 0) {
    let result = "";
    for (const [key, value] of Object.entries(obj)) {
      result += "  ".repeat(indent) + (value === null ? "\u{1F4C4} " : "\u{1F4C1} ") + key + "\n";
      if (value !== null) {
        result += stringifyStructure(value, indent + 1);
      }
    }
    return result;
  }
  return stringifyStructure(structure);
}
var init_directoryStructure = __esm({
  "src/clients/utils/directoryStructure.ts"() {
    "use strict";
  }
});

// src/clients/utils/promptFormatter.ts
function formatCodeBlock(fileContent, filePath) {
  const fileExtension = import_path12.default.extname(filePath).slice(1);
  const language = getLanguageFromExtension(fileExtension);
  return `\`\`\`${language}
${fileContent}
\`\`\``;
}
function formatSingleFileReviewPrompt(promptTemplate, fileContent, filePath, projectDocs) {
  const codeBlock = formatCodeBlock(fileContent, filePath);
  const projectContext = projectDocs ? formatProjectDocs(projectDocs) : "";
  return `${promptTemplate}

${projectContext ? `## Project Context
${projectContext}

` : ""}## File to Review: ${filePath}

${codeBlock}

Please review this code and provide feedback according to the instructions. DO NOT REPEAT THE INSTRUCTIONS. DO NOT ASK FOR CODE TO REVIEW. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.`;
}
function formatConsolidatedReviewPrompt(promptTemplate, projectName, files, projectDocs) {
  const projectContext = projectDocs ? formatProjectDocs(projectDocs) : "";
  const fileInfos = files.map((file) => ({
    path: file.relativePath || file.sizeInBytes.toString(),
    // Use sizeInBytes as fallback for path
    relativePath: file.relativePath,
    content: file.content
  }));
  const directoryStructure = generateDirectoryStructure(fileInfos);
  const fileSummaries = files.map(
    (file) => `- ${file.relativePath || "unnamed file"} (${file.sizeInBytes} bytes)`
  ).join("\n");
  return `${promptTemplate}

${projectContext ? `## Project Context
${projectContext}

` : ""}## Project: ${projectName}

## Directory Structure
\`\`\`
${directoryStructure}
\`\`\`

## File Summaries
${fileSummaries}

Please review this codebase and provide feedback according to the instructions. DO NOT REPEAT THE INSTRUCTIONS. DO NOT ASK FOR CODE TO REVIEW. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.`;
}
var import_path12;
var init_promptFormatter = __esm({
  "src/clients/utils/promptFormatter.ts"() {
    "use strict";
    init_projectDocs();
    init_languageDetection();
    import_path12 = __toESM(require("path"));
    init_directoryStructure();
  }
});

// src/types/reviewSchema.ts
function getSchemaAsString() {
  return `
{
  "review": {
    "version": "1.0",
    "timestamp": "2024-04-06T12:00:00Z",
    "files": [
      {
        "filePath": "path/to/file.ts",
        "issues": [
          {
            "id": "ISSUE-1",
            "priority": "HIGH", // One of: HIGH, MEDIUM, LOW
            "description": "Description of the issue",
            "location": {
              "startLine": 10,
              "endLine": 15
            },
            "currentCode": "function example() {\\n  // Problematic code here\\n}",
            "suggestedCode": "function example() {\\n  // Improved code here\\n}",
            "explanation": "Detailed explanation of why this change is recommended"
          }
        ]
      }
    ],
    "summary": {
      "highPriorityIssues": 1,
      "mediumPriorityIssues": 2,
      "lowPriorityIssues": 3,
      "totalIssues": 6
    }
  }
}
`;
}
function getSchemaInstructions() {
  return `
IMPORTANT: In interactive mode, you MUST format your response as a valid JSON object following this exact schema:

${getSchemaAsString()}

Guidelines for filling the schema:
1. Each issue must have a unique ID (e.g., "ISSUE-1", "ISSUE-2")
2. Priority must be one of: "HIGH", "MEDIUM", "LOW"
3. Location should include the start and end line numbers of the affected code
4. Current code should be the exact code snippet that needs to be changed
5. Suggested code should be the improved version of the code
6. Explanation should provide a detailed rationale for the suggested change
7. The summary should accurately count the number of issues by priority

Your response must be valid JSON that can be parsed programmatically. Do not include any text outside of the JSON structure.
`;
}
var import_zod4, IssuePriority, issuePrioritySchema, issueLocationSchema, reviewIssueSchema, fileReviewSchema, reviewSummarySchema, codeReviewSchema, reviewSchema;
var init_reviewSchema = __esm({
  "src/types/reviewSchema.ts"() {
    "use strict";
    import_zod4 = require("zod");
    IssuePriority = /* @__PURE__ */ ((IssuePriority3) => {
      IssuePriority3["HIGH"] = "HIGH";
      IssuePriority3["MEDIUM"] = "MEDIUM";
      IssuePriority3["LOW"] = "LOW";
      return IssuePriority3;
    })(IssuePriority || {});
    issuePrioritySchema = import_zod4.z.nativeEnum(IssuePriority);
    issueLocationSchema = import_zod4.z.object({
      startLine: import_zod4.z.number(),
      endLine: import_zod4.z.number()
    });
    reviewIssueSchema = import_zod4.z.object({
      id: import_zod4.z.string(),
      priority: issuePrioritySchema,
      description: import_zod4.z.string(),
      location: issueLocationSchema,
      currentCode: import_zod4.z.string(),
      suggestedCode: import_zod4.z.string(),
      explanation: import_zod4.z.string()
    });
    fileReviewSchema = import_zod4.z.object({
      filePath: import_zod4.z.string(),
      issues: import_zod4.z.array(reviewIssueSchema)
    });
    reviewSummarySchema = import_zod4.z.object({
      highPriorityIssues: import_zod4.z.number(),
      mediumPriorityIssues: import_zod4.z.number(),
      lowPriorityIssues: import_zod4.z.number(),
      totalIssues: import_zod4.z.number()
    });
    codeReviewSchema = import_zod4.z.object({
      version: import_zod4.z.string(),
      timestamp: import_zod4.z.string(),
      files: import_zod4.z.array(fileReviewSchema),
      summary: reviewSummarySchema
    });
    reviewSchema = import_zod4.z.object({
      review: codeReviewSchema
    });
  }
});

// src/prompts/schemas/consolidated-review-schema.ts
function getConsolidatedSchemaAsString() {
  return `{
  "review": {
    "version": "1.0",
    "timestamp": "2024-04-06T12:00:00Z",
    "projectName": "my-project",
    "filesReviewed": 150,
    
    "executiveSummary": "This codebase demonstrates solid engineering practices with room for improvement in testing and documentation...",
    "overallGrade": "B+",
    "gradeRationale": "The code is well-structured and functional, but lacks comprehensive testing and documentation...",
    
    "gradeCategories": {
      "functionality": "A-",
      "codeQuality": "B+",
      "documentation": "C+",
      "testing": "C",
      "maintainability": "B",
      "security": "B+",
      "performance": "B"
    },
    
    "categoryRationale": {
      "functionality": "All features work as expected with minimal bugs...",
      "codeQuality": "Code follows consistent patterns but has some complexity issues...",
      "documentation": "Basic documentation exists but lacks comprehensive API docs...",
      "testing": "Test coverage is below 60% with missing edge cases...",
      "maintainability": "Good module structure but some tight coupling exists...",
      "security": "Good security practices with minor input validation gaps...",
      "performance": "Generally performant with some optimization opportunities..."
    },
    
    "issues": {
      "high": [
        {
          "id": "ISSUE-001",
          "priority": "HIGH",
          "title": "Missing input validation in API endpoints",
          "description": "Several API endpoints lack proper input validation...",
          "files": ["src/api/users.ts", "src/api/products.ts"],
          "recommendation": "Implement comprehensive input validation using Zod or similar...",
          "impact": "Prevents potential security vulnerabilities and improves API reliability"
        }
      ],
      "medium": [...],
      "low": [...]
    },
    
    "strengths": [
      {
        "title": "Well-structured component architecture",
        "description": "The React components follow a clear and consistent structure...",
        "files": ["src/components/", "src/features/"]
      }
    ],
    
    "architecturalInsights": [
      {
        "title": "Effective use of dependency injection",
        "description": "The service layer uses dependency injection well...",
        "recommendation": "Consider extending this pattern to the data layer",
        "relatedFiles": ["src/services/", "src/core/"]
      }
    ],
    
    "summary": {
      "totalIssues": 45,
      "highPriorityIssues": 5,
      "mediumPriorityIssues": 15,
      "lowPriorityIssues": 25,
      "totalStrengths": 8
    },
    
    "recommendations": {
      "immediate": [
        "Add input validation to all API endpoints",
        "Fix the critical security vulnerability in authentication"
      ],
      "shortTerm": [
        "Increase test coverage to at least 80%",
        "Add comprehensive API documentation"
      ],
      "longTerm": [
        "Refactor the monolithic services into microservices",
        "Implement performance monitoring and optimization"
      ]
    }
  }
}`;
}
function getConsolidatedSchemaInstructions() {
  return `
IMPORTANT: For consolidated reviews, you MUST format your response as a valid JSON object following this exact schema:

${getConsolidatedSchemaAsString()}

Guidelines for filling the schema:

1. **Grading System**:
   - Use standard academic grades: A+, A, A-, B+, B, B-, C+, C, C-, D+, D, D-, F
   - A+ to A-: Exceptional code with minimal issues
   - B+ to B-: Good code with some minor improvements needed
   - C+ to C-: Average code with several issues that should be addressed
   - D+ to D-: Problematic code with significant issues requiring attention
   - F: Critical issues that make the code unsuitable for production

2. **Grade Categories**:
   - functionality: How well the code performs its intended purpose
   - codeQuality: Cleanliness, readability, and adherence to best practices
   - documentation: Quality and completeness of documentation
   - testing: Test coverage and quality
   - maintainability: How easy it is to modify and extend the code
   - security: Security practices and vulnerability prevention
   - performance: Efficiency and optimization

3. **Issues**:
   - Group issues by priority (HIGH, MEDIUM, LOW)
   - Each issue must have a unique ID
   - Include specific files affected by each issue
   - Provide actionable recommendations

4. **Executive Summary**:
   - Provide a high-level overview suitable for stakeholders
   - Include the most critical findings and overall assessment

5. **Recommendations**:
   - immediate: Critical fixes needed now
   - shortTerm: Important improvements for the next sprint
   - longTerm: Strategic enhancements for future consideration

Your response must be valid JSON that can be parsed programmatically. Do not include any text outside of the JSON structure.
`;
}
var import_zod5, GradeLevel, GradeCategoriesSchema, IssuePriority2, ConsolidatedIssueSchema, StrengthSchema, ArchitecturalInsightSchema, ConsolidatedReviewSchema, ConsolidatedReviewRootSchema;
var init_consolidated_review_schema = __esm({
  "src/prompts/schemas/consolidated-review-schema.ts"() {
    "use strict";
    import_zod5 = require("zod");
    GradeLevel = import_zod5.z.enum([
      "A+",
      "A",
      "A-",
      "B+",
      "B",
      "B-",
      "C+",
      "C",
      "C-",
      "D+",
      "D",
      "D-",
      "F"
    ]);
    GradeCategoriesSchema = import_zod5.z.object({
      functionality: GradeLevel,
      codeQuality: GradeLevel,
      documentation: GradeLevel,
      testing: GradeLevel,
      maintainability: GradeLevel,
      security: GradeLevel,
      performance: GradeLevel
    });
    IssuePriority2 = import_zod5.z.enum(["HIGH", "MEDIUM", "LOW"]);
    ConsolidatedIssueSchema = import_zod5.z.object({
      id: import_zod5.z.string().describe("Unique identifier for the issue"),
      priority: IssuePriority2,
      title: import_zod5.z.string().describe("Brief title describing the issue"),
      description: import_zod5.z.string().describe("Detailed description of the issue"),
      files: import_zod5.z.array(import_zod5.z.string()).describe("Files affected by this issue"),
      recommendation: import_zod5.z.string().describe("Recommended fix or improvement"),
      impact: import_zod5.z.string().describe("Impact of fixing this issue")
    });
    StrengthSchema = import_zod5.z.object({
      title: import_zod5.z.string().describe("Brief title of the strength"),
      description: import_zod5.z.string().describe("Detailed description"),
      files: import_zod5.z.array(import_zod5.z.string()).optional().describe("Examples of files demonstrating this strength")
    });
    ArchitecturalInsightSchema = import_zod5.z.object({
      title: import_zod5.z.string().describe("Title of the architectural insight"),
      description: import_zod5.z.string().describe("Detailed explanation"),
      recommendation: import_zod5.z.string().optional().describe("Recommended improvements"),
      relatedFiles: import_zod5.z.array(import_zod5.z.string()).optional().describe("Files related to this insight")
    });
    ConsolidatedReviewSchema = import_zod5.z.object({
      version: import_zod5.z.literal("1.0").describe("Schema version"),
      timestamp: import_zod5.z.string().describe("ISO 8601 timestamp"),
      projectName: import_zod5.z.string().describe("Name of the reviewed project"),
      filesReviewed: import_zod5.z.number().describe("Total number of files reviewed"),
      // Overall assessment
      executiveSummary: import_zod5.z.string().describe("Executive summary of the review"),
      overallGrade: GradeLevel.describe("Overall grade for the codebase"),
      gradeRationale: import_zod5.z.string().describe("Explanation for the overall grade"),
      // Detailed grading
      gradeCategories: GradeCategoriesSchema.describe("Grades by category"),
      categoryRationale: import_zod5.z.object({
        functionality: import_zod5.z.string(),
        codeQuality: import_zod5.z.string(),
        documentation: import_zod5.z.string(),
        testing: import_zod5.z.string(),
        maintainability: import_zod5.z.string(),
        security: import_zod5.z.string(),
        performance: import_zod5.z.string()
      }).describe("Rationale for each category grade"),
      // Issues by priority
      issues: import_zod5.z.object({
        high: import_zod5.z.array(ConsolidatedIssueSchema).describe("High priority issues"),
        medium: import_zod5.z.array(ConsolidatedIssueSchema).describe("Medium priority issues"),
        low: import_zod5.z.array(ConsolidatedIssueSchema).describe("Low priority issues")
      }),
      // Positive aspects
      strengths: import_zod5.z.array(StrengthSchema).describe("Strengths identified in the codebase"),
      // Architectural insights
      architecturalInsights: import_zod5.z.array(ArchitecturalInsightSchema).optional().describe("Architectural patterns and insights"),
      // Summary statistics
      summary: import_zod5.z.object({
        totalIssues: import_zod5.z.number(),
        highPriorityIssues: import_zod5.z.number(),
        mediumPriorityIssues: import_zod5.z.number(),
        lowPriorityIssues: import_zod5.z.number(),
        totalStrengths: import_zod5.z.number()
      }),
      // Recommendations
      recommendations: import_zod5.z.object({
        immediate: import_zod5.z.array(import_zod5.z.string()).describe("Actions to take immediately"),
        shortTerm: import_zod5.z.array(import_zod5.z.string()).describe("Actions for the next sprint/iteration"),
        longTerm: import_zod5.z.array(import_zod5.z.string()).describe("Strategic improvements")
      })
    });
    ConsolidatedReviewRootSchema = import_zod5.z.object({
      review: ConsolidatedReviewSchema
    });
  }
});

// src/prompts/schemas/evaluation-schema.ts
function getEvaluationSchemaAsString() {
  return `{
  "evaluation": {
    "version": "1.0",
    "timestamp": "2024-04-06T12:00:00Z",
    "projectName": "example-project",
    "filesEvaluated": 25,
    
    "skillAssessment": {
      "level": "Intermediate",
      "confidence": "High",
      "keyEvidence": [
        "Proper use of TypeScript interfaces and generics",
        "Implementation of async/await patterns with error handling",
        "Modular code organization with clear separation of concerns"
      ],
      "notablePatterns": [
        "Consistent use of functional programming patterns",
        "Appropriate abstraction levels for the problem domain"
      ]
    },
    
    "aiAssistanceAssessment": {
      "likelihood": "Low",
      "confidence": "Medium",
      "supportingIndicators": [
        "Some overly verbose JSDoc comments on simple functions"
      ],
      "evidenceAgainst": [
        "Consistent personal coding style throughout",
        "Context-aware optimizations and shortcuts",
        "Natural, domain-specific variable naming"
      ]
    },
    
    "professionalMaturityAssessment": {
      "level": "Mid-level",
      "confidence": "High",
      "decisionMakingQuality": [
        "Appropriate use of existing libraries vs custom solutions",
        "Good balance between performance and readability",
        "Comprehensive error handling strategy"
      ],
      "productionReadinessEvidence": [
        "Proper environment configuration management",
        "Security considerations in data handling",
        "Logging and monitoring setup"
      ]
    },
    
    "developmentContext": {
      "workingEnvironment": "Team collaboration",
      "timeConstraints": "Balanced",
      "experienceDomain": "Applying known patterns",
      "reasoning": "Code shows consistency with team standards and thoughtful implementation without rush indicators"
    },
    
    "notableObservations": {
      "uniqueStrengths": [
        "Excellent TypeScript type safety practices",
        "Creative use of functional composition patterns"
      ],
      "interestingDecisions": [
        "Custom validation layer instead of using existing libraries",
        "Performance optimization in data processing loops"
      ],
      "expertiseAreas": [
        "Frontend state management",
        "API design and implementation"
      ]
    },
    
    "overallProfile": "This developer appears to be a mid-level professional with solid TypeScript experience and good architectural instincts. The code suggests someone working in a collaborative environment with established standards, showing growth toward senior-level decision making.",
    
    "languageSpecificInsights": {
      "language": "TypeScript",
      "skillMarkers": [
        "Advanced type system usage with utility types",
        "Proper async/await error handling patterns",
        "Effective use of TypeScript configuration"
      ],
      "aiPatterns": [
        "Minimal AI-generated boilerplate detected",
        "Natural TypeScript idioms throughout"
      ],
      "professionalPractices": [
        "Comprehensive type safety without any usage",
        "Proper module organization and exports",
        "Integration with modern build tooling"
      ]
    }
  }
}`;
}
function getEvaluationSchemaInstructions() {
  return `
IMPORTANT: For evaluation reviews, you MUST format your response as a valid JSON object following this exact schema:

${getEvaluationSchemaAsString()}

Guidelines for filling the schema:

1. **Skill Level Assessment**:
   - Beginner: Basic syntax, simple structure, minimal error handling
   - Intermediate: Proper language features, some patterns, adequate organization
   - Advanced: Sophisticated patterns, comprehensive error handling, performance optimization
   - Expert: Deep language mastery, custom abstractions, architectural leadership

2. **AI Assistance Likelihood**:
   - Minimal: Clearly human-written with personal style
   - Low: Mostly human with possible minor AI assistance
   - Medium: Mixed indicators, unclear origin
   - High: Strong indicators of AI-generated or heavily AI-assisted code

3. **Professional Maturity**:
   - Junior: Learning-focused, basic practices
   - Mid-level: Solid practices, good decision-making
   - Senior: Advanced practices, architectural thinking
   - Lead: Strategic thinking, team/system leadership

4. **Evidence Requirements**:
   - Provide specific examples from the code for all assessments
   - Reference actual patterns, naming conventions, or architectural decisions
   - Be concrete rather than generic in observations

5. **Confidence Levels**:
   - High: Clear, strong evidence supporting the assessment
   - Medium: Some evidence but with ambiguity
   - Low: Limited evidence or conflicting indicators

Your response must be valid JSON that can be parsed programmatically. Do not include any text outside of the JSON structure.
`;
}
var import_zod6, SkillLevel, AIAssistanceLevel, ProfessionalMaturity, ConfidenceLevel, WorkingEnvironment, TimeConstraints, ExperienceDomain, SkillAssessmentSchema, AIAssistanceAssessmentSchema, ProfessionalMaturityAssessmentSchema, DevelopmentContextSchema, NotableObservationsSchema, EvaluationReviewSchema, EvaluationReviewRootSchema;
var init_evaluation_schema = __esm({
  "src/prompts/schemas/evaluation-schema.ts"() {
    "use strict";
    import_zod6 = require("zod");
    SkillLevel = import_zod6.z.enum(["Beginner", "Intermediate", "Advanced", "Expert"]);
    AIAssistanceLevel = import_zod6.z.enum(["Minimal", "Low", "Medium", "High"]);
    ProfessionalMaturity = import_zod6.z.enum(["Junior", "Mid-level", "Senior", "Lead"]);
    ConfidenceLevel = import_zod6.z.enum(["Low", "Medium", "High"]);
    WorkingEnvironment = import_zod6.z.enum(["Individual project", "Team collaboration", "Enterprise"]);
    TimeConstraints = import_zod6.z.enum(["Rushed", "Balanced", "Thorough"]);
    ExperienceDomain = import_zod6.z.enum(["Learning", "Applying known patterns", "Innovating"]);
    SkillAssessmentSchema = import_zod6.z.object({
      level: SkillLevel,
      confidence: ConfidenceLevel,
      keyEvidence: import_zod6.z.array(import_zod6.z.string()).describe("Specific examples from the code that support this assessment"),
      notablePatterns: import_zod6.z.array(import_zod6.z.string()).describe("Notable patterns or decisions that indicate skill level")
    });
    AIAssistanceAssessmentSchema = import_zod6.z.object({
      likelihood: AIAssistanceLevel,
      confidence: ConfidenceLevel,
      supportingIndicators: import_zod6.z.array(import_zod6.z.string()).describe("Specific patterns suggesting AI involvement"),
      evidenceAgainst: import_zod6.z.array(import_zod6.z.string()).optional().describe("Evidence against AI assistance")
    });
    ProfessionalMaturityAssessmentSchema = import_zod6.z.object({
      level: ProfessionalMaturity,
      confidence: ConfidenceLevel,
      decisionMakingQuality: import_zod6.z.array(import_zod6.z.string()).describe("Assessment of architectural and implementation choices"),
      productionReadinessEvidence: import_zod6.z.array(import_zod6.z.string()).describe("Evidence of production readiness and maintainability focus")
    });
    DevelopmentContextSchema = import_zod6.z.object({
      workingEnvironment: WorkingEnvironment,
      timeConstraints: TimeConstraints,
      experienceDomain: ExperienceDomain,
      reasoning: import_zod6.z.string().describe("Reasoning for these assessments")
    });
    NotableObservationsSchema = import_zod6.z.object({
      uniqueStrengths: import_zod6.z.array(import_zod6.z.string()).describe("Unique strengths or approaches observed"),
      interestingDecisions: import_zod6.z.array(import_zod6.z.string()).describe("Interesting decisions or trade-offs made"),
      expertiseAreas: import_zod6.z.array(import_zod6.z.string()).describe("Areas where the developer shows particular expertise or growth")
    });
    EvaluationReviewSchema = import_zod6.z.object({
      version: import_zod6.z.literal("1.0").describe("Schema version"),
      timestamp: import_zod6.z.string().describe("ISO 8601 timestamp"),
      projectName: import_zod6.z.string().describe("Name of the reviewed project"),
      filesEvaluated: import_zod6.z.number().describe("Total number of files evaluated"),
      // Core assessments
      skillAssessment: SkillAssessmentSchema,
      aiAssistanceAssessment: AIAssistanceAssessmentSchema,
      professionalMaturityAssessment: ProfessionalMaturityAssessmentSchema,
      // Context and observations
      developmentContext: DevelopmentContextSchema,
      notableObservations: NotableObservationsSchema,
      // Overall profile
      overallProfile: import_zod6.z.string().describe("2-3 sentence summary of the developer's likely background, experience level, and development approach"),
      // Language-specific insights
      languageSpecificInsights: import_zod6.z.object({
        language: import_zod6.z.string().describe("Primary language assessed"),
        skillMarkers: import_zod6.z.array(import_zod6.z.string()).describe("Language-specific skill indicators"),
        aiPatterns: import_zod6.z.array(import_zod6.z.string()).describe("Language-specific AI assistance patterns"),
        professionalPractices: import_zod6.z.array(import_zod6.z.string()).describe("Professional practices specific to this language")
      }).optional()
    });
    EvaluationReviewRootSchema = import_zod6.z.object({
      evaluation: EvaluationReviewSchema
    });
  }
});

// src/prompts/schemas/extract-patterns-schema.ts
function getExtractPatternsSchemaAsString() {
  return `{
  "patterns": {
    "version": "1.0",
    "timestamp": "2025-06-28T12:00:00Z",
    "projectName": "example-typescript-cli",

    "projectOverview": {
      "purpose": "TypeScript CLI tool for automated code reviews using multiple AI providers",
      "scale": {
        "size": "Medium",
        "complexity": "Medium",
        "maturity": "Mature"
      },
      "architecture": {
        "style": "Modular CLI with strategy pattern",
        "layering": "CLI -> Core -> Strategies -> Clients",
        "modularity": "Feature-based modules with clear separation of concerns"
      }
    },

    "technologyStack": {
      "coreLanguages": [
        {
          "name": "TypeScript",
          "version": "5.0+",
          "purpose": "Primary language for type safety and developer experience"
        }
      ],
      "frameworks": [
        {
          "name": "Node.js",
          "version": "18+",
          "purpose": "Runtime environment"
        }
      ],
      "buildTools": [
        {
          "name": "pnpm",
          "purpose": "Package management with workspace support"
        }
      ]
    },

    "codeMetrics": {
      "averageFunctionLength": 15,
      "averageFileLength": 120,
      "totalFiles": 45,
      "totalLinesOfCode": 5400,
      "complexityDistribution": {
        "simple": 70,
        "moderate": 25,
        "complex": 5
      }
    },

    "architecturalPatterns": [
      {
        "patternName": "Strategy Pattern",
        "usage": "Primary",
        "implementation": "Different review strategies implementing common interface",
        "examples": ["ArchitecturalReviewStrategy", "SecurityReviewStrategy"],
        "effectiveness": "Excellent"
      }
    ],

    "exemplarCharacteristics": {
      "strengths": [
        "Clear separation of concerns",
        "Comprehensive TypeScript usage",
        "Modular architecture"
      ],
      "patternsToEmulate": [
        "Strategy pattern for extensible functionality",
        "Factory pattern for client creation"
      ],
      "lessonsLearned": [
        "TypeScript strict mode enables better code quality",
        "Modular design supports easy testing and extension"
      ]
    }
  }
}`;
}
function getExtractPatternsSchemaInstructions() {
  return `
IMPORTANT: For extract patterns reviews, you MUST format your response as a valid JSON object following this exact schema:

${getExtractPatternsSchemaAsString()}

Guidelines for filling the schema:

1. **Project Overview**:
   - Provide clear, concise description of what the project does
   - Assess scale realistically based on file count and complexity
   - Identify the primary architectural style and approach

2. **Technology Stack**:
   - Include versions when available in package.json or similar
   - Explain the purpose/role of each technology
   - Note any interesting configuration choices

3. **Code Metrics**:
   - Provide realistic estimates based on actual code analysis
   - Calculate averages across the codebase
   - Assess complexity distribution fairly

4. **Architectural Patterns**:
   - Identify specific design patterns in use
   - Provide concrete examples with file/class names
   - Assess how well patterns are implemented

5. **Code Style**:
   - Document actual naming conventions observed
   - Describe file and module organization patterns
   - Note documentation approaches and consistency

6. **Testing Strategy**:
   - Identify what types of tests are present
   - Document testing patterns and utilities
   - Assess coverage approach and philosophy

7. **Exemplar Characteristics**:
   - Focus on what makes this codebase worth studying
   - Identify specific patterns that could be replicated
   - Extract actionable lessons for similar projects

Your response must be valid JSON that can be parsed programmatically. Do not include any text outside of the JSON structure.
`;
}
var import_zod7, ComplexityLevel, MaturityLevel, ConfidenceLevel2, TechnologySchema, CodeMetricsSchema, ArchitecturalPatternSchema, CodeStyleSchema, TestingStrategySchema, TechnologyStackSchema, ProjectOverviewSchema, ExtractPatternsReviewSchema, ExtractPatternsReviewRootSchema;
var init_extract_patterns_schema = __esm({
  "src/prompts/schemas/extract-patterns-schema.ts"() {
    "use strict";
    import_zod7 = require("zod");
    ComplexityLevel = import_zod7.z.enum(["Low", "Medium", "High", "Very High"]);
    MaturityLevel = import_zod7.z.enum(["Early", "Developing", "Mature", "Advanced"]);
    ConfidenceLevel2 = import_zod7.z.enum(["Low", "Medium", "High"]);
    TechnologySchema = import_zod7.z.object({
      name: import_zod7.z.string().describe("Technology name"),
      version: import_zod7.z.string().optional().describe("Version if available"),
      purpose: import_zod7.z.string().describe("Purpose or role in the project"),
      configurationNotes: import_zod7.z.string().optional().describe("Notable configuration details")
    });
    CodeMetricsSchema = import_zod7.z.object({
      averageFunctionLength: import_zod7.z.number().describe("Average lines per function"),
      averageFileLength: import_zod7.z.number().describe("Average lines per file"),
      totalFiles: import_zod7.z.number().describe("Total number of source files"),
      totalLinesOfCode: import_zod7.z.number().describe("Total lines of code"),
      complexityDistribution: import_zod7.z.object({
        simple: import_zod7.z.number().describe("Percentage of simple functions/classes"),
        moderate: import_zod7.z.number().describe("Percentage of moderate complexity"),
        complex: import_zod7.z.number().describe("Percentage of complex functions/classes")
      }),
      testCoverage: import_zod7.z.number().optional().describe("Test coverage percentage if available")
    });
    ArchitecturalPatternSchema = import_zod7.z.object({
      patternName: import_zod7.z.string().describe("Name of the design pattern"),
      usage: import_zod7.z.enum(["Primary", "Secondary", "Occasional"]).describe("How extensively the pattern is used"),
      implementation: import_zod7.z.string().describe("How the pattern is implemented"),
      examples: import_zod7.z.array(import_zod7.z.string()).describe("Specific examples or file locations"),
      effectiveness: import_zod7.z.enum(["Excellent", "Good", "Adequate", "Poor"]).describe("How well the pattern is implemented")
    });
    CodeStyleSchema = import_zod7.z.object({
      namingConventions: import_zod7.z.object({
        variables: import_zod7.z.string().describe("Variable naming pattern"),
        functions: import_zod7.z.string().describe("Function naming pattern"),
        classes: import_zod7.z.string().describe("Class naming pattern"),
        files: import_zod7.z.string().describe("File naming pattern"),
        consistency: ConfidenceLevel2.describe("Consistency level of naming")
      }),
      organizationPatterns: import_zod7.z.object({
        fileStructure: import_zod7.z.string().describe("How files are organized"),
        moduleStructure: import_zod7.z.string().describe("How modules are structured"),
        importExportStyle: import_zod7.z.string().describe("Import/export patterns used")
      }),
      documentationStyle: import_zod7.z.object({
        inlineComments: import_zod7.z.string().describe("Inline comment style and frequency"),
        functionDocumentation: import_zod7.z.string().describe("Function documentation approach"),
        apiDocumentation: import_zod7.z.string().describe("API documentation style")
      })
    });
    TestingStrategySchema = import_zod7.z.object({
      testTypes: import_zod7.z.array(import_zod7.z.string()).describe("Types of tests present (unit, integration, e2e)"),
      testOrganization: import_zod7.z.string().describe("How tests are organized"),
      mockingStrategy: import_zod7.z.string().describe("Approach to mocking and test doubles"),
      testNaming: import_zod7.z.string().describe("Test naming conventions"),
      coverageApproach: import_zod7.z.string().describe("What gets tested and testing philosophy"),
      testUtilities: import_zod7.z.array(import_zod7.z.string()).describe("Shared test helpers and utilities")
    });
    TechnologyStackSchema = import_zod7.z.object({
      coreLanguages: import_zod7.z.array(TechnologySchema).describe("Primary programming languages"),
      frameworks: import_zod7.z.array(TechnologySchema).describe("Frameworks and libraries"),
      buildTools: import_zod7.z.array(TechnologySchema).describe("Build and bundling tools"),
      developmentTools: import_zod7.z.array(TechnologySchema).describe("Development tools (linters, formatters, etc.)"),
      testingTools: import_zod7.z.array(TechnologySchema).describe("Testing frameworks and tools"),
      deploymentTools: import_zod7.z.array(TechnologySchema).optional().describe("Deployment and CI/CD tools")
    });
    ProjectOverviewSchema = import_zod7.z.object({
      purpose: import_zod7.z.string().describe("What the project does and its domain"),
      scale: import_zod7.z.object({
        size: import_zod7.z.enum(["Small", "Medium", "Large", "Enterprise"]).describe("Project size"),
        complexity: ComplexityLevel.describe("Overall complexity level"),
        maturity: MaturityLevel.describe("Development maturity level")
      }),
      architecture: import_zod7.z.object({
        style: import_zod7.z.string().describe("Overall architectural style"),
        layering: import_zod7.z.string().describe("How the application is layered"),
        modularity: import_zod7.z.string().describe("Approach to modularity and separation")
      })
    });
    ExtractPatternsReviewSchema = import_zod7.z.object({
      version: import_zod7.z.literal("1.0").describe("Schema version"),
      timestamp: import_zod7.z.string().describe("ISO 8601 timestamp"),
      projectName: import_zod7.z.string().describe("Name of the analyzed project"),
      // Core analysis sections
      projectOverview: ProjectOverviewSchema,
      technologyStack: TechnologyStackSchema,
      codeMetrics: CodeMetricsSchema,
      architecturalPatterns: import_zod7.z.array(ArchitecturalPatternSchema),
      codeStyle: CodeStyleSchema,
      testingStrategy: TestingStrategySchema,
      // Exemplar characteristics
      exemplarCharacteristics: import_zod7.z.object({
        strengths: import_zod7.z.array(import_zod7.z.string()).describe("What makes this codebase exemplary"),
        patternsToEmulate: import_zod7.z.array(import_zod7.z.string()).describe("Specific patterns worth copying"),
        lessonsLearned: import_zod7.z.array(import_zod7.z.string()).describe("Key insights for similar projects")
      }),
      // Replication guide
      replicationGuide: import_zod7.z.object({
        setupRequirements: import_zod7.z.array(import_zod7.z.string()).describe("What's needed to start a similar project"),
        keyDecisions: import_zod7.z.array(import_zod7.z.string()).describe("Critical architectural and tooling decisions"),
        implementationOrder: import_zod7.z.array(import_zod7.z.string()).describe("Suggested order for implementing similar patterns"),
        commonPitfalls: import_zod7.z.array(import_zod7.z.string()).describe("Potential issues to avoid")
      }),
      // Summary
      summary: import_zod7.z.string().describe("2-3 sentence summary of the project's architectural approach and key patterns")
    });
    ExtractPatternsReviewRootSchema = import_zod7.z.object({
      patterns: ExtractPatternsReviewSchema
    });
  }
});

// src/prompts/strategies/PromptStrategy.ts
var import_prompts, PromptStrategy;
var init_PromptStrategy = __esm({
  "src/prompts/strategies/PromptStrategy.ts"() {
    "use strict";
    init_logger();
    import_prompts = require("@langchain/core/prompts");
    PromptStrategy = class {
      promptManager;
      promptCache;
      /**
       * Create a new prompt strategy
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        this.promptManager = promptManager;
        this.promptCache = promptCache;
      }
      /**
       * Generate a prompt for a review
       * @param reviewType Type of review
       * @param options Review options
       * @param projectDocs Project documentation
       * @returns Promise resolving to the generated prompt
       */
      async generatePrompt(reviewType, options, _projectDocs) {
        try {
          if (options.useCache !== false) {
            const cachedPrompt = this.promptCache.getBestPrompt(reviewType);
            if (cachedPrompt) {
              logger_default.info(
                `Using cached prompt for ${reviewType} review type (rating: ${cachedPrompt.rating})`
              );
              return await Promise.resolve(
                this.formatPrompt(cachedPrompt.content, options)
              );
            }
          }
          const promptTemplate = await this.promptManager.getPromptTemplate(
            reviewType,
            options
          );
          return await Promise.resolve(this.formatPrompt(promptTemplate, options));
        } catch (error2) {
          logger_default.error(
            `Error generating prompt: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          throw error2;
        }
      }
      /**
       * Get a LangChain prompt template
       * @param prompt Raw prompt template
       * @param options Review options
       * @returns LangChain prompt template
       */
      async getLangChainTemplate(prompt, options) {
        const formattedPrompt = await Promise.resolve(
          this.formatPrompt(prompt, options)
        );
        return new import_prompts.PromptTemplate({
          template: formattedPrompt,
          inputVariables: this.extractInputVariables(formattedPrompt)
        });
      }
      /**
       * Extract input variables from a prompt template
       * @param prompt Prompt template
       * @returns Array of input variable names
       */
      extractInputVariables(prompt) {
        const variableMatches = prompt.match(/{{(\w+)}}|{(\w+)}/g) || [];
        return variableMatches.map((match) => {
          return match.replace(/{{|}}/g, "").replace(/{|}/g, "");
        });
      }
    };
  }
});

// src/prompts/strategies/AnthropicPromptStrategy.ts
var AnthropicPromptStrategy;
var init_AnthropicPromptStrategy = __esm({
  "src/prompts/strategies/AnthropicPromptStrategy.ts"() {
    "use strict";
    init_PromptStrategy();
    AnthropicPromptStrategy = class extends PromptStrategy {
      /**
       * Create a new Anthropic prompt strategy
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        super(promptManager, promptCache);
      }
      /**
       * Format a prompt for Anthropic models
       * @param prompt Raw prompt
       * @param options Review options
       * @returns Formatted prompt
       */
      formatPrompt(prompt, _options) {
        let formattedPrompt = prompt;
        if (!formattedPrompt.includes("Be concise and actionable")) {
          formattedPrompt += "\n\nRemember to be concise and actionable in your review. Focus on the most important issues and provide clear, specific recommendations.";
        }
        if (!formattedPrompt.includes("code examples")) {
          formattedPrompt += "\n\nWhen suggesting fixes, provide specific code examples that demonstrate the recommended changes.";
        }
        return formattedPrompt;
      }
      /**
       * Get the name of the strategy
       * @returns Strategy name
       */
      getName() {
        return "anthropic";
      }
      /**
       * Get the description of the strategy
       * @returns Strategy description
       */
      getDescription() {
        return "Prompt strategy optimized for Anthropic models like Claude";
      }
    };
  }
});

// src/prompts/strategies/GeminiPromptStrategy.ts
var GeminiPromptStrategy;
var init_GeminiPromptStrategy = __esm({
  "src/prompts/strategies/GeminiPromptStrategy.ts"() {
    "use strict";
    init_PromptStrategy();
    GeminiPromptStrategy = class extends PromptStrategy {
      /**
       * Create a new Gemini prompt strategy
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        super(promptManager, promptCache);
      }
      /**
       * Format a prompt for Gemini models
       * @param prompt Raw prompt
       * @param options Review options
       * @returns Formatted prompt
       */
      formatPrompt(prompt, _options) {
        let formattedPrompt = prompt;
        if (!formattedPrompt.includes("structured format")) {
          formattedPrompt += "\n\nPlease provide your review in a clear, structured format with headings and bullet points for better readability.";
        }
        if (!formattedPrompt.includes("code examples")) {
          formattedPrompt += "\n\nWhen suggesting improvements, include specific code examples that show both the current code and your recommended changes.";
        }
        if (!formattedPrompt.includes("prioritize")) {
          formattedPrompt += "\n\nPrioritize your suggestions based on their impact and importance. Focus on the most critical issues first.";
        }
        return formattedPrompt;
      }
      /**
       * Get the name of the strategy
       * @returns Strategy name
       */
      getName() {
        return "gemini";
      }
      /**
       * Get the description of the strategy
       * @returns Strategy description
       */
      getDescription() {
        return "Prompt strategy optimized for Google Gemini models";
      }
    };
  }
});

// src/prompts/strategies/OpenAIPromptStrategy.ts
var OpenAIPromptStrategy;
var init_OpenAIPromptStrategy = __esm({
  "src/prompts/strategies/OpenAIPromptStrategy.ts"() {
    "use strict";
    init_PromptStrategy();
    OpenAIPromptStrategy = class extends PromptStrategy {
      /**
       * Create a new OpenAI prompt strategy
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        super(promptManager, promptCache);
      }
      /**
       * Format a prompt for OpenAI models
       * @param prompt Raw prompt
       * @param options Review options
       * @returns Formatted prompt
       */
      formatPrompt(prompt, _options) {
        let formattedPrompt = prompt;
        if (!formattedPrompt.includes("step-by-step")) {
          formattedPrompt += "\n\nProvide a step-by-step analysis of the code, identifying patterns and potential issues systematically.";
        }
        if (!formattedPrompt.includes("reasoning")) {
          formattedPrompt += "\n\nExplain your reasoning for each suggestion, including why it is an issue and the benefits of fixing it.";
        }
        if (!formattedPrompt.includes("alternative approaches")) {
          formattedPrompt += "\n\nWhen appropriate, suggest alternative approaches or design patterns that could improve the code.";
        }
        return formattedPrompt;
      }
      /**
       * Get the name of the strategy
       * @returns Strategy name
       */
      getName() {
        return "openai";
      }
      /**
       * Get the description of the strategy
       * @returns Strategy description
       */
      getDescription() {
        return "Prompt strategy optimized for OpenAI models like GPT-4";
      }
    };
  }
});

// src/utils/ciDataCollector.ts
async function collectCIData(projectPath) {
  const ciData = {
    fileErrors: {}
  };
  try {
    logger_default.info("Running type check to collect error count...");
    const { stdout, stderr } = await execAsync("npm run build:types", {
      cwd: projectPath,
      env: { ...process.env, CI: "true" }
    });
    ciData.typeCheckOutput = stdout + stderr;
    parseTypeCheckErrors(ciData.typeCheckOutput, ciData, projectPath);
  } catch (error2) {
    const output = error2.stdout + error2.stderr;
    ciData.typeCheckOutput = output;
    parseTypeCheckErrors(output, ciData, projectPath);
  }
  try {
    logger_default.info("Running lint to collect error count...");
    const { stdout, stderr } = await execAsync("npm run lint", {
      cwd: projectPath,
      env: { ...process.env, CI: "true" }
    });
    ciData.lintOutput = stdout + stderr;
    parseLintErrors(ciData.lintOutput, ciData, projectPath);
  } catch (error2) {
    const output = error2.stdout + error2.stderr;
    ciData.lintOutput = output;
    parseLintErrors(output, ciData, projectPath);
  }
  calculateTotals(ciData);
  return ciData;
}
function parseTypeCheckErrors(output, ciData, projectPath) {
  const lines = output.split("\n");
  for (const line of lines) {
    const match = line.match(/^(.+?)\((\d+),(\d+)\): error (TS\d+): (.+)$/);
    if (match) {
      const [, file, lineNum, colNum, errorCode, message] = match;
      const relativeFile = import_path13.default.relative(projectPath, file);
      if (!ciData.fileErrors[relativeFile]) {
        ciData.fileErrors[relativeFile] = {
          typeCheckErrors: 0,
          lintErrors: 0,
          typeCheckMessages: [],
          lintMessages: []
        };
      }
      ciData.fileErrors[relativeFile].typeCheckErrors++;
      ciData.fileErrors[relativeFile].typeCheckMessages.push(
        `Line ${lineNum}:${colNum} - ${errorCode}: ${message}`
      );
    }
  }
}
function parseLintErrors(output, ciData, projectPath) {
  const lines = output.split("\n");
  let currentFile = null;
  for (const line of lines) {
    if (line.match(/^[/\\]/)) {
      currentFile = import_path13.default.relative(projectPath, line.trim());
      if (!ciData.fileErrors[currentFile]) {
        ciData.fileErrors[currentFile] = {
          typeCheckErrors: 0,
          lintErrors: 0,
          typeCheckMessages: [],
          lintMessages: []
        };
      }
    } else if (currentFile && line.match(/^\s*\d+:\d+\s+error\s+/)) {
      const match = line.match(/^\s*(\d+):(\d+)\s+error\s+(.+?)\s+(.+)$/);
      if (match) {
        const [, lineNum, colNum, message, rule] = match;
        ciData.fileErrors[currentFile].lintErrors++;
        ciData.fileErrors[currentFile].lintMessages.push(
          `Line ${lineNum}:${colNum} - ${message} (${rule})`
        );
      }
    }
  }
}
function calculateTotals(ciData) {
  let totalTypeCheckErrors = 0;
  let totalLintErrors = 0;
  for (const fileData of Object.values(ciData.fileErrors || {})) {
    totalTypeCheckErrors += fileData.typeCheckErrors;
    totalLintErrors += fileData.lintErrors;
  }
  ciData.typeCheckErrors = totalTypeCheckErrors;
  ciData.lintErrors = totalLintErrors;
  logger_default.info(`Found ${totalTypeCheckErrors} type check errors and ${totalLintErrors} lint errors across all files`);
}
function formatCIDataForPrompt(ciData, specificFile) {
  const lines = [];
  lines.push("## CI/CD Status");
  lines.push("");
  lines.push(`- Total TypeScript errors: ${ciData.typeCheckErrors || 0}`);
  lines.push(`- Total ESLint errors: ${ciData.lintErrors || 0}`);
  if (ciData.fileErrors && Object.keys(ciData.fileErrors).length > 0) {
    lines.push("");
    lines.push("### Errors by file:");
    if (specificFile && ciData.fileErrors[specificFile]) {
      const fileData = ciData.fileErrors[specificFile];
      lines.push("");
      lines.push(`**${specificFile}**:`);
      lines.push(`- TypeScript errors: ${fileData.typeCheckErrors}`);
      if (fileData.typeCheckMessages && fileData.typeCheckMessages.length > 0) {
        lines.push("  TypeScript issues:");
        fileData.typeCheckMessages.slice(0, 5).forEach((msg) => {
          lines.push(`    - ${msg}`);
        });
      }
      lines.push(`- ESLint errors: ${fileData.lintErrors}`);
      if (fileData.lintMessages && fileData.lintMessages.length > 0) {
        lines.push("  ESLint issues:");
        fileData.lintMessages.slice(0, 5).forEach((msg) => {
          lines.push(`    - ${msg}`);
        });
      }
    } else {
      const fileList = Object.entries(ciData.fileErrors).map(([file, data]) => ({
        file,
        totalErrors: data.typeCheckErrors + data.lintErrors,
        ...data
      })).sort((a, b) => b.totalErrors - a.totalErrors).slice(0, 5);
      for (const fileInfo of fileList) {
        lines.push("");
        lines.push(`**${fileInfo.file}**: ${fileInfo.totalErrors} total errors`);
        lines.push(`  - TypeScript: ${fileInfo.typeCheckErrors} errors`);
        lines.push(`  - ESLint: ${fileInfo.lintErrors} errors`);
      }
    }
  }
  lines.push("");
  lines.push("Please include fixes for these CI/CD issues in your code review.");
  return lines.join("\n");
}
var import_child_process, import_util, import_path13, execAsync;
var init_ciDataCollector = __esm({
  "src/utils/ciDataCollector.ts"() {
    "use strict";
    import_child_process = require("child_process");
    import_util = require("util");
    init_logger();
    import_path13 = __toESM(require("path"));
    execAsync = (0, import_util.promisify)(import_child_process.exec);
  }
});

// src/prompts/strategies/LangChainPromptStrategy.ts
var import_prompts2, LangChainPromptStrategy;
var init_LangChainPromptStrategy = __esm({
  "src/prompts/strategies/LangChainPromptStrategy.ts"() {
    "use strict";
    init_PromptStrategy();
    import_prompts2 = require("@langchain/core/prompts");
    init_logger();
    init_ciDataCollector();
    LangChainPromptStrategy = class extends PromptStrategy {
      /**
       * Create a new LangChain prompt strategy
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        super(promptManager, promptCache);
      }
      /**
       * Format a prompt using LangChain
       * @param prompt Raw prompt
       * @param options Review options
       * @returns Formatted prompt
       */
      async formatPrompt(prompt, options) {
        try {
          const inputVariables = this.extractInputVariables(prompt);
          const template = new import_prompts2.PromptTemplate({
            template: prompt,
            inputVariables
          });
          const inputValues = this.createInputValuesFromOptions(
            options,
            inputVariables
          );
          return await template.format(inputValues);
        } catch (error2) {
          logger_default.error(
            `Error formatting prompt with LangChain: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return this.basicFormatPrompt(prompt, options);
        }
      }
      /**
       * Create a few-shot prompt template
       * @param prefix The prefix text for the prompt
       * @param examples The few-shot examples to include
       * @param suffix The suffix text for the prompt
       * @param options Review options
       * @returns FewShotPromptTemplate
       */
      createFewShotTemplate(prefix, examples, suffix, _options) {
        const exampleVariables = Object.keys(examples[0] || {});
        const exampleTemplate = new import_prompts2.PromptTemplate({
          template: this.createExampleTemplateString(exampleVariables),
          inputVariables: exampleVariables
        });
        return new import_prompts2.FewShotPromptTemplate({
          prefix,
          suffix,
          examplePrompt: exampleTemplate,
          examples,
          inputVariables: this.extractInputVariables(prefix + suffix)
        });
      }
      /**
       * Create a template string for examples
       * @param variables The variables in the example
       * @returns Example template string
       */
      createExampleTemplateString(variables) {
        const parts = [];
        for (const variable of variables) {
          parts.push(`${variable.toUpperCase()}: {${variable}}`);
        }
        return parts.join("\n");
      }
      /**
       * Create input values from review options
       * @param options Review options
       * @param inputVariables Input variables from the template
       * @returns Input values
       */
      createInputValuesFromOptions(options, inputVariables) {
        const inputValues = {};
        const optionsMap = {
          LANGUAGE: "language",
          FILE_PATH: "filePath",
          CODE: "code",
          TYPE: "type",
          MODEL: "models",
          SCHEMA_INSTRUCTIONS: "schemaInstructions",
          LANGUAGE_INSTRUCTIONS: "languageInstructions",
          CI_DATA: "ciData"
        };
        for (const variable of inputVariables) {
          const optionKey = optionsMap[variable];
          if (optionKey && typeof optionKey === "string" && optionKey in options) {
            if (optionKey === "ciData" && options.ciData) {
              const filePath = inputValues["FILE_PATH"] || void 0;
              inputValues[variable] = formatCIDataForPrompt(options.ciData, filePath);
            } else {
              inputValues[variable] = String(
                options[optionKey]
              );
            }
          } else {
            if (variable in options) {
              inputValues[variable] = String(
                options[variable]
              );
            }
          }
        }
        return inputValues;
      }
      /**
       * Basic prompt formatting fallback
       * @param prompt Raw prompt
       * @param options Review options
       * @returns Formatted prompt
       */
      basicFormatPrompt(prompt, options) {
        let formattedPrompt = prompt;
        if (options.language) {
          formattedPrompt = formattedPrompt.replace(
            /{{LANGUAGE}}/g,
            options.language
          );
          formattedPrompt = formattedPrompt.replace(
            /{{LANGUAGE_INSTRUCTIONS}}/g,
            `This code is written in ${options.language.toUpperCase()}. Please provide language-specific advice.`
          );
        } else {
          formattedPrompt = formattedPrompt.replace(
            /{{LANGUAGE_INSTRUCTIONS}}/g,
            ""
          );
        }
        if (options.schemaInstructions) {
          formattedPrompt = formattedPrompt.replace(
            /{{SCHEMA_INSTRUCTIONS}}/g,
            options.schemaInstructions
          );
        } else {
          formattedPrompt = formattedPrompt.replace(/{{SCHEMA_INSTRUCTIONS}}/g, "");
        }
        return formattedPrompt;
      }
      /**
       * Get the name of the strategy
       * @returns Strategy name
       */
      getName() {
        return "langchain";
      }
      /**
       * Get the description of the strategy
       * @returns Strategy description
       */
      getDescription() {
        return "LangChain-based prompt strategy for enhanced template capabilities";
      }
    };
  }
});

// src/prompts/strategies/PromptStrategyFactory.ts
var PromptStrategyFactory;
var init_PromptStrategyFactory = __esm({
  "src/prompts/strategies/PromptStrategyFactory.ts"() {
    "use strict";
    init_AnthropicPromptStrategy();
    init_GeminiPromptStrategy();
    init_OpenAIPromptStrategy();
    init_LangChainPromptStrategy();
    init_logger();
    PromptStrategyFactory = class _PromptStrategyFactory {
      static strategies = /* @__PURE__ */ new Map();
      /**
       * Create a prompt strategy based on the model provider
       * @param provider Model provider (e.g., 'anthropic', 'gemini', 'openai')
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       * @returns The appropriate prompt strategy
       */
      static createStrategy(provider, promptManager, promptCache) {
        const normalizedProvider = provider.toLowerCase();
        if (_PromptStrategyFactory.strategies.has(normalizedProvider)) {
          return _PromptStrategyFactory.strategies.get(normalizedProvider);
        }
        let strategy;
        switch (normalizedProvider) {
          case "anthropic":
            strategy = new AnthropicPromptStrategy(promptManager, promptCache);
            break;
          case "gemini":
            strategy = new GeminiPromptStrategy(promptManager, promptCache);
            break;
          case "openai":
            strategy = new OpenAIPromptStrategy(promptManager, promptCache);
            break;
          case "langchain":
            strategy = new LangChainPromptStrategy(promptManager, promptCache);
            break;
          default:
            logger_default.warn(`Unknown provider: ${provider}. Using default strategy.`);
            strategy = new AnthropicPromptStrategy(promptManager, promptCache);
        }
        _PromptStrategyFactory.strategies.set(normalizedProvider, strategy);
        return strategy;
      }
      /**
       * Get all available prompt strategies
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       * @returns Array of all available prompt strategies
       */
      static getAllStrategies(promptManager, promptCache) {
        return [
          new AnthropicPromptStrategy(promptManager, promptCache),
          new GeminiPromptStrategy(promptManager, promptCache),
          new OpenAIPromptStrategy(promptManager, promptCache),
          new LangChainPromptStrategy(promptManager, promptCache)
        ];
      }
    };
  }
});

// src/prompts/PromptBuilder.ts
var PromptBuilder;
var init_PromptBuilder = __esm({
  "src/prompts/PromptBuilder.ts"() {
    "use strict";
    init_PromptStrategyFactory();
    init_logger();
    PromptBuilder = class {
      promptManager;
      promptCache;
      components = [];
      /**
       * Create a new prompt builder
       * @param promptManager Prompt manager instance
       * @param promptCache Prompt cache instance
       */
      constructor(promptManager, promptCache) {
        this.promptManager = promptManager;
        this.promptCache = promptCache;
      }
      /**
       * Add a component to the prompt
       * @param component Prompt component to add
       * @returns This builder instance for chaining
       */
      addComponent(component) {
        this.components.push(component);
        return this;
      }
      /**
       * Add a user-provided fragment to the prompt
       * @param content Content of the fragment
       * @param position Position of the fragment in the prompt
       * @param priority Priority of the fragment
       * @returns This builder instance for chaining
       */
      addFragment(content, position = "middle", priority = 5) {
        return this.addComponent({
          content,
          position,
          priority
        });
      }
      /**
       * Build a prompt for a review
       * @param reviewType Type of review
       * @param options Review options
       * @param projectDocs Project documentation
       * @param basePrompt Optional base prompt to use instead of fetching from the prompt manager
       * @returns Promise resolving to the built prompt
       */
      async buildPrompt(reviewType, options, projectDocs, basePrompt) {
        try {
          const basePromptContent = basePrompt || "Default prompt template";
          this.addComponent({
            content: basePromptContent,
            position: "middle",
            priority: 10
          });
          const modelEnv = process.env.AI_CODE_REVIEW_MODEL;
          if (modelEnv) {
            const provider = modelEnv.split(":")[0];
            const strategy = PromptStrategyFactory.createStrategy(
              provider,
              this.promptManager,
              this.promptCache
            );
            const formattedPrompt = await Promise.resolve(
              strategy.formatPrompt(basePromptContent, options)
            );
            this.components = this.components.filter(
              (c) => c.content !== basePromptContent
            );
            this.addComponent({
              content: formattedPrompt,
              position: "middle",
              priority: 10
            });
          }
          const startComponents = this.components.filter((c) => c.position === "start").sort((a, b) => b.priority - a.priority);
          const middleComponents = this.components.filter((c) => c.position === "middle").sort((a, b) => b.priority - a.priority);
          const endComponents = this.components.filter((c) => c.position === "end").sort((a, b) => b.priority - a.priority);
          const finalPrompt = [
            ...startComponents.map((c) => c.content),
            ...middleComponents.map((c) => c.content),
            ...endComponents.map((c) => c.content)
          ].join("\n\n");
          return finalPrompt;
        } catch (error2) {
          logger_default.error(
            `Error building prompt: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          throw error2;
        }
      }
      /**
       * Clear all components from the builder
       * @returns This builder instance for chaining
       */
      clear() {
        this.components = [];
        return this;
      }
    };
  }
});

// src/prompts/cache/PromptCache.ts
var import_promises8, import_path14, PromptCache;
var init_PromptCache = __esm({
  "src/prompts/cache/PromptCache.ts"() {
    "use strict";
    import_promises8 = __toESM(require("fs/promises"));
    import_path14 = __toESM(require("path"));
    init_logger();
    PromptCache = class _PromptCache {
      static instance;
      memoryCache = /* @__PURE__ */ new Map();
      cacheDir;
      /**
       * Create a new prompt cache
       * @param cacheDir Directory for storing cached prompts
       */
      constructor(cacheDir) {
        this.cacheDir = cacheDir;
      }
      /**
       * Get the singleton instance
       * @param cacheDir Directory for storing cached prompts
       * @returns The prompt cache instance
       */
      static getInstance(cacheDir) {
        if (!_PromptCache.instance) {
          const defaultCacheDir = import_path14.default.resolve(process.cwd(), ".prompt-cache");
          _PromptCache.instance = new _PromptCache(cacheDir || defaultCacheDir);
          _PromptCache.instance.initialize().catch((error2) => {
            logger_default.error(
              `Error initializing prompt cache: ${error2 instanceof Error ? error2.message : String(error2)}`
            );
          });
        }
        return _PromptCache.instance;
      }
      /**
       * Initialize the prompt cache
       */
      async initialize() {
        try {
          await import_promises8.default.mkdir(this.cacheDir, { recursive: true });
          await this.loadCachedPrompts();
          logger_default.debug(`Initialized prompt cache in ${this.cacheDir}`);
        } catch (error2) {
          logger_default.error(
            `Error initializing prompt cache: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Load cached prompts from disk
       */
      async loadCachedPrompts() {
        try {
          const files = await import_promises8.default.readdir(this.cacheDir);
          for (const file of files) {
            if (file.endsWith(".json")) {
              try {
                const filePath = import_path14.default.join(this.cacheDir, file);
                const content = await import_promises8.default.readFile(filePath, "utf-8");
                const cache = JSON.parse(content);
                for (const [key, prompts] of Object.entries(cache)) {
                  this.memoryCache.set(key, prompts);
                }
                logger_default.debug(`Loaded cached prompts from ${filePath}`);
              } catch (error2) {
                logger_default.error(
                  `Error loading cache file ${file}: ${error2 instanceof Error ? error2.message : String(error2)}`
                );
              }
            }
          }
        } catch (error2) {
          logger_default.error(
            `Error loading cached prompts: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Save the memory cache to disk
       */
      async saveCacheToDisk() {
        try {
          const cache = {};
          for (const [key, prompts] of this.memoryCache.entries()) {
            cache[key] = prompts;
          }
          const filePath = import_path14.default.join(this.cacheDir, "prompts.json");
          await import_promises8.default.writeFile(filePath, JSON.stringify(cache, null, 2));
          logger_default.debug(`Saved prompt cache to ${filePath}`);
        } catch (error2) {
          logger_default.error(
            `Error saving prompt cache: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Cache a prompt for future use
       * @param reviewType Type of review
       * @param promptContent Content of the prompt
       * @param rating Rating of the prompt (1-5)
       */
      async cachePrompt(reviewType, promptContent, rating) {
        try {
          const cachedPrompt = {
            content: promptContent,
            rating,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            usageCount: 0
          };
          const key = this.getCacheKey(reviewType);
          const existingPrompts = this.memoryCache.get(key) || [];
          existingPrompts.push(cachedPrompt);
          existingPrompts.sort((a, b) => b.rating - a.rating);
          const topPrompts = existingPrompts.slice(0, 5);
          this.memoryCache.set(key, topPrompts);
          await this.saveCacheToDisk();
          logger_default.debug(
            `Cached prompt for ${reviewType} review type with rating ${rating}`
          );
        } catch (error2) {
          logger_default.error(
            `Error caching prompt: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Get the best cached prompt for a review type
       * @param reviewType Type of review
       * @returns The best cached prompt, or undefined if none exists
       */
      getBestPrompt(reviewType) {
        try {
          const key = this.getCacheKey(reviewType);
          const prompts = this.memoryCache.get(key) || [];
          if (prompts.length === 0) {
            return void 0;
          }
          const bestPrompt = prompts[0];
          bestPrompt.usageCount++;
          this.saveCacheToDisk().catch((error2) => {
            logger_default.error(
              `Error saving prompt cache: ${error2 instanceof Error ? error2.message : String(error2)}`
            );
          });
          return bestPrompt;
        } catch (error2) {
          logger_default.error(
            `Error getting best prompt: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return void 0;
        }
      }
      /**
       * Get all cached prompts for a review type
       * @param reviewType Type of review
       * @returns Array of cached prompts
       */
      getAllPrompts(reviewType) {
        try {
          const key = this.getCacheKey(reviewType);
          return this.memoryCache.get(key) || [];
        } catch (error2) {
          logger_default.error(
            `Error getting all prompts: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return [];
        }
      }
      /**
       * Clear the cache for a review type
       * @param reviewType Type of review
       */
      async clearCache(reviewType) {
        try {
          const key = this.getCacheKey(reviewType);
          this.memoryCache.delete(key);
          await this.saveCacheToDisk();
          logger_default.debug(`Cleared cache for ${reviewType} review type`);
        } catch (error2) {
          logger_default.error(
            `Error clearing cache: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Clear the entire cache
       */
      async clearAllCaches() {
        try {
          this.memoryCache.clear();
          await this.saveCacheToDisk();
          logger_default.debug("Cleared all prompt caches");
        } catch (error2) {
          logger_default.error(
            `Error clearing all caches: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Get the cache key for a review type
       * @param reviewType Type of review
       * @returns Cache key
       */
      getCacheKey(reviewType) {
        return `prompt:${reviewType}`;
      }
    };
  }
});

// src/utils/templateLoader.ts
function initializeHandlebars() {
  Handlebars.registerHelper("eq", function(arg1, arg2, options) {
    return arg1 === arg2 ? options.fn(this) : options.inverse(this);
  });
  const partialsDir = path19.join(getTemplatesDir(), "common");
  registerPartials(partialsDir, "");
}
function registerPartials(dirPath, prefix) {
  try {
    if (!fs15.existsSync(dirPath)) {
      logger_default.warn(`Partials directory not found: ${dirPath}`);
      return;
    }
    const entries = fs15.readdirSync(dirPath, { withFileTypes: true });
    for (const entry of entries) {
      const fullPath = path19.join(dirPath, entry.name);
      if (entry.isDirectory()) {
        registerPartials(fullPath, `${prefix}${entry.name}/`);
      } else if (entry.name.endsWith(".hbs")) {
        try {
          const partialName = `${prefix}${entry.name.replace(".hbs", "")}`;
          const partialContent = fs15.readFileSync(fullPath, "utf-8");
          Handlebars.registerPartial(`common/${partialName}`, partialContent);
          logger_default.debug(`Registered partial: common/${partialName}`);
        } catch (partialError) {
          logger_default.error(
            `Error registering partial ${fullPath}: ${partialError instanceof Error ? partialError.message : String(partialError)}`
          );
        }
      }
    }
  } catch (error2) {
    logger_default.error(
      `Error scanning partials directory ${dirPath}: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
  }
}
function loadTemplateVariables() {
  const variables = {};
  try {
    const variablesDir = path19.join(getTemplatesDir(), "common", "variables");
    if (!fs15.existsSync(variablesDir)) {
      logger_default.warn(`Variables directory not found: ${variablesDir}`);
      return variables;
    }
    const frameworksPath = path19.join(variablesDir, "framework-versions.json");
    if (fs15.existsSync(frameworksPath)) {
      try {
        const fileContents = fs15.readFileSync(frameworksPath, "utf-8");
        const frameworkData = JSON.parse(fileContents);
        variables.frameworks = frameworkData.frameworks;
        logger_default.debug("Successfully loaded framework versions data");
      } catch (readError) {
        logger_default.error(
          `Error reading or parsing framework versions data: ${readError instanceof Error ? readError.message : String(readError)}`
        );
        variables.frameworks = {};
      }
    } else {
      logger_default.debug(`Framework versions file not found: ${frameworksPath}`);
      variables.frameworks = {};
    }
    const cssFrameworksPath = path19.join(variablesDir, "css-frameworks.json");
    if (fs15.existsSync(cssFrameworksPath)) {
      try {
        const fileContents = fs15.readFileSync(cssFrameworksPath, "utf-8");
        const cssFrameworkData = JSON.parse(fileContents);
        variables.cssFrameworks = cssFrameworkData.cssFrameworks;
        logger_default.debug("Successfully loaded CSS frameworks data");
      } catch (readError) {
        logger_default.error(
          `Error reading or parsing CSS frameworks data: ${readError instanceof Error ? readError.message : String(readError)}`
        );
        variables.cssFrameworks = {};
      }
    } else {
      logger_default.debug(`CSS frameworks file not found: ${cssFrameworksPath}`);
      variables.cssFrameworks = {};
    }
    try {
      const entries = fs15.readdirSync(variablesDir);
      const otherJsonFiles = entries.filter(
        (entry) => entry.endsWith(".json") && entry !== "framework-versions.json" && entry !== "css-frameworks.json"
      );
      for (const jsonFile of otherJsonFiles) {
        try {
          const filePath = path19.join(variablesDir, jsonFile);
          const fileContents = fs15.readFileSync(filePath, "utf-8");
          const data = JSON.parse(fileContents);
          const key = jsonFile.replace(".json", "");
          variables[key] = data;
          logger_default.debug(`Loaded additional variable file: ${jsonFile}`);
        } catch (fileError) {
          logger_default.error(
            `Error reading or parsing ${jsonFile}: ${fileError instanceof Error ? fileError.message : String(fileError)}`
          );
        }
      }
    } catch (scanError) {
      logger_default.error(
        `Error scanning variables directory for additional JSON files: ${scanError instanceof Error ? scanError.message : String(scanError)}`
      );
    }
  } catch (error2) {
    logger_default.error(
      `Unexpected error loading template variables: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
  }
  return variables;
}
function loadTemplate(templatePath) {
  if (templateCache[templatePath]) {
    return templateCache[templatePath];
  }
  const fullPath = path19.join(getTemplatesDir(), templatePath);
  if (!fs15.existsSync(fullPath)) {
    logger_default.error(`Template not found: ${fullPath}`);
    return null;
  }
  try {
    const templateContent = fs15.readFileSync(fullPath, "utf-8");
    const template = Handlebars.compile(templateContent);
    templateCache[templatePath] = template;
    return template;
  } catch (error2) {
    logger_default.error(`Error loading template ${fullPath}: ${error2}`);
    return null;
  }
}
function renderTemplate(templatePath, customVars = {}) {
  if (Object.keys(Handlebars.partials).length === 0) {
    initializeHandlebars();
  }
  const template = loadTemplate(templatePath);
  if (!template) {
    return null;
  }
  const defaultVars = loadTemplateVariables();
  const variables = { ...defaultVars, ...customVars };
  try {
    return template(variables);
  } catch (error2) {
    logger_default.error(`Error rendering template ${templatePath}: ${error2}`);
    return null;
  }
}
function loadPromptTemplate(reviewType, language, framework) {
  if (language && framework) {
    const frameworkPath = `frameworks/${framework}/${reviewType}.hbs`;
    const rendered2 = renderTemplate(frameworkPath);
    if (rendered2) {
      logger_default.debug(`Loaded framework-specific template: ${frameworkPath}`);
      return rendered2;
    }
  }
  if (language) {
    const languagePath = `languages/${language}/${reviewType}.hbs`;
    const rendered2 = renderTemplate(languagePath);
    if (rendered2) {
      logger_default.debug(`Loaded language-specific template: ${languagePath}`);
      return rendered2;
    }
  }
  const genericPath = `languages/generic/${reviewType}.hbs`;
  const rendered = renderTemplate(genericPath);
  if (rendered) {
    logger_default.debug(`Loaded generic template: ${genericPath}`);
    return rendered;
  }
  logger_default.error(`No template found for reviewType=${reviewType}, language=${language ?? "undefined"}, framework=${framework ?? "undefined"}`);
  return null;
}
var fs15, path19, Handlebars, getTemplatesDir, templateCache;
var init_templateLoader = __esm({
  "src/utils/templateLoader.ts"() {
    "use strict";
    fs15 = __toESM(require("fs"));
    path19 = __toESM(require("path"));
    Handlebars = __toESM(require("handlebars"));
    init_logger();
    init_configManager();
    getTemplatesDir = () => {
      try {
        const configuredPath = configManager_default.getPathsConfig().promptsDir;
        if (configuredPath && fs15.existsSync(configuredPath)) {
          logger_default.debug(`Using configured templates directory: ${configuredPath}`);
          return configuredPath;
        }
        const defaultPath = path19.resolve(process.cwd(), "promptText");
        logger_default.debug(`Using default templates directory: ${defaultPath}`);
        return defaultPath;
      } catch (error2) {
        logger_default.warn(`Error getting templates directory from config: ${error2 instanceof Error ? error2.message : String(error2)}`);
        const fallbackPath = path19.resolve(process.cwd(), "promptText");
        logger_default.debug(`Using fallback templates directory: ${fallbackPath}`);
        return fallbackPath;
      }
    };
    templateCache = {};
  }
});

// src/utils/promptTemplateManager.ts
function getPromptTemplate(reviewType, language, framework) {
  const reviewTypeStr = typeof reviewType === "string" ? reviewType : String(reviewType).toLowerCase();
  const templateName = reviewTypeMapping[reviewTypeStr];
  if (!templateName) {
    logger_default.error(`No template mapping found for review type: ${reviewTypeStr}`);
    return void 0;
  }
  const mappedLanguage = language ? languageMapping[language.toLowerCase()] : void 0;
  const mappedFramework = framework ? frameworkMapping[framework.toLowerCase()] : void 0;
  const template = loadPromptTemplate(templateName, mappedLanguage, mappedFramework);
  return template || void 0;
}
function checkTemplatesAvailability() {
  const templatesDir = import_path15.default.resolve(process.cwd(), "promptText");
  if (!import_fs4.default.existsSync(templatesDir)) {
    logger_default.warn("Templates directory not found. Using bundled prompts instead.");
    return false;
  }
  const requiredDirs = ["common", "frameworks", "languages"];
  for (const dir of requiredDirs) {
    if (!import_fs4.default.existsSync(import_path15.default.join(templatesDir, dir))) {
      logger_default.warn(`Required templates subdirectory '${dir}' not found. Using bundled prompts instead.`);
      return false;
    }
  }
  const variablesDir = import_path15.default.join(templatesDir, "common", "variables");
  if (!import_fs4.default.existsSync(variablesDir) || !import_fs4.default.existsSync(import_path15.default.join(variablesDir, "framework-versions.json"))) {
    logger_default.warn("Framework variables data not found. Using bundled prompts instead.");
    return false;
  }
  return true;
}
var import_fs4, import_path15, frameworkMapping, languageMapping, reviewTypeMapping;
var init_promptTemplateManager = __esm({
  "src/utils/promptTemplateManager.ts"() {
    "use strict";
    import_fs4 = __toESM(require("fs"));
    import_path15 = __toESM(require("path"));
    init_templateLoader();
    init_logger();
    frameworkMapping = {
      "react": "react",
      "angular": "angular",
      "vue": "vue",
      "next.js": "nextjs",
      "nextjs": "nextjs",
      "django": "django",
      "flask": "flask",
      "fastapi": "fastapi",
      "pyramid": "pyramid",
      "laravel": "laravel"
    };
    languageMapping = {
      "typescript": "typescript",
      "javascript": "typescript",
      // Use TypeScript templates for JavaScript
      "python": "python",
      "php": "php",
      "ruby": "ruby"
    };
    reviewTypeMapping = {
      "architectural": "architectural-review",
      "best-practices": "best-practices",
      "quick-fixes": "quick-fixes-review",
      "security": "security-review",
      "performance": "performance-review",
      "unused-code": "unused-code-review",
      "code-tracing-unused-code": "code-tracing-unused-code-review",
      "focused-unused-code": "focused-unused-code-review",
      "improved-unused-code": "improved-unused-code-review",
      "consolidated": "consolidated-review",
      // Add mapping for improved quick fixes
      "improved-quick-fixes": "improved-quick-fixes-review",
      "evaluation": "evaluation",
      "extract-patterns": "extract-patterns-review"
    };
  }
});

// src/prompts/bundledPrompts.ts
function getBundledPrompt(reviewType, language, framework) {
  if (USE_TEMPLATE_SYSTEM && checkTemplatesAvailability()) {
    const template = getPromptTemplate(reviewType, language, framework);
    if (template) {
      logger_default.debug(`Using template for reviewType=${reviewType}, language=${language}, framework=${framework}`);
      return template;
    }
    logger_default.debug(`Template not found in template system for reviewType=${reviewType}, language=${language}, framework=${framework}. Falling back to bundled prompt.`);
  }
  if (language && framework && bundledPrompts[`${language.toLowerCase()}:${framework.toLowerCase()}`] && bundledPrompts[`${language.toLowerCase()}:${framework.toLowerCase()}`][reviewType]) {
    return bundledPrompts[`${language.toLowerCase()}:${framework.toLowerCase()}`][reviewType];
  }
  if (language && bundledPrompts[language.toLowerCase()] && bundledPrompts[language.toLowerCase()][reviewType]) {
    return bundledPrompts[language.toLowerCase()][reviewType];
  }
  if (bundledPrompts["generic"] && bundledPrompts["generic"][reviewType]) {
    return bundledPrompts["generic"][reviewType];
  }
  return void 0;
}
var USE_TEMPLATE_SYSTEM, bundledPrompts;
var init_bundledPrompts = __esm({
  "src/prompts/bundledPrompts.ts"() {
    "use strict";
    init_promptTemplateManager();
    init_logger();
    USE_TEMPLATE_SYSTEM = true;
    bundledPrompts = {
      // Generic prompts (no language)
      "generic": {
        "architectural": `# Architectural Code Review

You are an expert software architect performing a comprehensive architectural review of a codebase.

## Your Task

Analyze the provided code from an architectural perspective, focusing on:

1. **Overall Architecture**: Identify the architectural patterns and evaluate their appropriateness
2. **Component Structure**: Assess how the code is organized into components, modules, or services
3. **Dependency Management**: Evaluate how dependencies are managed and injected
4. **Separation of Concerns**: Check if responsibilities are properly separated
5. **Code Reusability**: Identify opportunities for better code reuse
6. **Scalability Considerations**: Assess how well the architecture would scale
7. **Maintainability**: Evaluate how easy the codebase would be to maintain and extend
8. **Package Integration**: Identify opportunities to leverage established OSS packages to enhance the codebase

## Output Format

Provide your analysis in the following sections:

1. **Architecture Overview**: A high-level description of the current architecture
2. **Strengths**: Architectural aspects that are well-implemented
3. **Areas for Improvement**: Architectural issues that should be addressed
4. **Recommendations**: Specific suggestions for improving the architecture
5. **Package Recommendations**: Where appropriate, suggest mature OSS packages that could replace custom implementations
6. **Code Examples**: Where appropriate, provide code examples to illustrate your recommendations

{{LANGUAGE_INSTRUCTIONS}}

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`,
        "quick-fixes": `# Quick Fixes Code Review

You are an expert software developer performing a code review focused on quick, high-impact improvements.

## Your Task

Analyze the provided code and identify issues that:
1. Can be fixed relatively easily
2. Would have a meaningful impact on code quality, readability, or performance
3. Don't require major architectural changes

Focus on:
- Code style and formatting issues
- Simple logic errors or bugs
- Obvious performance optimizations
- Straightforward improvements to readability
- Small-scale refactoring opportunities
- Potential edge cases that aren't handled

{{CI_DATA}}

## Output Format

For each issue you identify:
1. **Issue**: Describe the issue clearly and concisely
2. **Impact**: Explain why it's a problem and what impact fixing it would have
3. **Fix**: Provide a specific, actionable fix
4. **Code**: Include code examples showing before and after the fix
5. **Priority**: Rate the issue as High, Medium, or Low priority

Group issues by priority and include a summary of the most critical fixes at the beginning.

IMPORTANT: Include fixes for any TypeScript compilation errors or ESLint violations from the CI data above.

{{LANGUAGE_INSTRUCTIONS}}

{{SCHEMA_INSTRUCTIONS}}`,
        "security": `# Security Code Review

You are an expert security engineer performing a comprehensive security review of a codebase.

## Your Task

Analyze the provided code for security vulnerabilities and weaknesses, focusing on:

1. **Input Validation**: Check if all inputs are properly validated
2. **Authentication & Authorization**: Assess how user identity is verified and access control is implemented
3. **Data Protection**: Evaluate how sensitive data is handled, stored, and transmitted
4. **Dependency Security**: Identify potentially vulnerable dependencies
5. **Common Vulnerabilities**: Look for common security issues like XSS, CSRF, SQL injection, etc.
6. **Error Handling**: Check if errors are handled securely without leaking sensitive information
7. **Secure Coding Practices**: Assess adherence to secure coding standards

## Output Format

For each security issue you identify:
1. **Vulnerability**: Describe the vulnerability clearly
2. **Impact**: Explain the potential impact and risk level
3. **Remediation**: Provide a specific, actionable fix
4. **Code Example**: Include code examples where appropriate
5. **Security Standard**: Reference relevant security standards or best practices

Include a summary section at the beginning with an overall security assessment and prioritized list of issues.

{{LANGUAGE_INSTRUCTIONS}}

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`,
        "performance": `# Performance Code Review

You are an expert performance engineer performing a comprehensive performance review of a codebase.

## Your Task

Analyze the provided code for performance issues and optimization opportunities, focusing on:

1. **Algorithmic Efficiency**: Identify inefficient algorithms or data structures
2. **Resource Usage**: Evaluate CPU, memory, network, and disk usage
3. **Concurrency**: Assess how parallelism and asynchronous operations are handled
4. **Caching**: Identify opportunities for caching or improvements to existing caching
5. **Database Interactions**: Evaluate database queries and data access patterns
6. **UI Performance**: For frontend code, assess rendering performance
7. **Load and Scale**: Consider how the code would perform under high load

## Output Format

For each performance issue you identify:
1. **Issue**: Describe the performance issue clearly
2. **Impact**: Explain why it's a performance concern and estimate the potential impact
3. **Optimization**: Provide specific, actionable optimization with clear steps
4. **Code Example**: Include code examples showing before and after the optimization
5. **Measurement**: Suggest how to measure the impact of the optimization

Include a summary section with an overall performance assessment and prioritized list of optimizations.

{{LANGUAGE_INSTRUCTIONS}}

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`,
        "unused-code": `# Unused Code Review

You are an expert software developer performing a review focused on identifying unused or dead code.

## Your Task

Analyze the provided code to identify:
1. Unused variables, functions, classes, or modules
2. Dead code paths that can never be executed
3. Redundant or duplicate code
4. Commented-out code that should be removed
5. Deprecated features that are no longer needed

## Analysis Approach

For each potential unused code element:
1. Check for references throughout the codebase
2. Consider both direct and indirect usage
3. Assess whether the code is preparing for future use
4. Evaluate the risk of removal
5. Provide a confidence level for your assessment

## Output Format

For each instance of unused code you identify:
1. **Element**: Identify the unused code element (variable, function, class, etc.)
2. **Location**: Provide the file and line number where the element is defined
3. **Evidence**: Explain your reasoning for believing it's unused
4. **Confidence**: Rate your confidence level (High, Medium, Low)
5. **Recommendation**: Suggest whether to remove it or refactor it
6. **Code**: Include code examples showing what to remove or change

Include a summary section with the total number of unused elements found, grouped by type and confidence level.

{{LANGUAGE_INSTRUCTIONS}}

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`,
        "best-practices": `# Best Practices Code Review

You are an **expert software engineer** specializing in code quality and design patterns. Perform a detailed review focused on adherence to established best practices and patterns.

{{LANGUAGE_INSTRUCTIONS}}

## Analysis Focus

Evaluate the code against the following best practices categories:

### 1. Code Organization & Structure
- Appropriate file and directory organization
- Clear separation of concerns
- Consistent naming conventions
- Logical grouping of related functionality

### 2. Design Patterns & Architecture
- Appropriate use of common design patterns
- Clean interfaces and abstractions
- Dependency management and injection
- Component reusability and modularity

### 3. Error Handling & Robustness
- Comprehensive error handling
- Graceful failure modes
- Input validation and defensive programming
- Edge case handling

### 4. Performance Optimization
- Appropriate algorithms and data structures
- Efficient resource usage
- Caching and memoization where applicable
- Avoidance of common performance anti-patterns

### 5. Maintainability & Readability
- Self-documenting code with appropriate comments
- Consistent and clear formatting
- Avoidance of code smells and anti-patterns
- Testability and debug-friendly structure

## Output Format

For each area of improvement you identify:

1. **Issue**: Clearly describe the pattern or practice that could be improved
2. **Impact**: Explain why this matters (maintainability, performance, readability)
3. **Recommendation**: Provide specific, actionable guidance with code examples
4. **Best Practice Reference**: Mention the established pattern or principle this aligns with

Prioritize your recommendations by impact, focusing on changes that will significantly improve the codebase.

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}

Remember to balance theoretical best practices with pragmatic considerations for the specific codebase context.`,
        "evaluation": `# Developer Performance Evaluation

CRITICAL: This is a CODER COMPETENCY ASSESSMENT. You must evaluate the developer's capabilities, decision-making, and professional readiness with thorough critical analysis. DO NOT suggest code improvements.

Act as a **senior hiring manager with 15+ years of experience evaluating developers for critical production systems**. Your task is to provide a frank, thorough assessment of the developer's true capabilities based on their code. Be critical where warranted - identify weaknesses, security blind spots, and production readiness gaps.

FOCUS: Assess the DEVELOPER, not the code. Identify red flags, concerning patterns, and skill gaps that would impact their ability to work on production systems.

DELIVER: Direct, honest evaluation without sugar-coating. This assessment will determine if they can be trusted with critical systems.

CRITICAL OUTPUT REQUIREMENT: You MUST use the EXACT section headers and format provided below. Fill in the bracketed placeholders with your assessment. Do not add extra sections or change the structure.

YOUR RESPONSE MUST START WITH THE FOLLOWING EXACT TEXT:

## Developer Competency Evaluation

### Overall Assessment
**Technical Competency:** [SCORE] - [JUSTIFICATION]
**Years of Experience:** [RANGE]
**Developer Level:** [LEVEL]
**Production Readiness:** [STATUS]

> **Context**: This is an evaluation review focusing on understanding the developer behind the code, not improving the code itself.

## Critical Assessment Framework

### 1. Technical Competency Analysis

**Critical Skill Gaps (Red Flags):**
- Dangerous code patterns that expose security vulnerabilities
- Failure to validate inputs or sanitize outputs
- Missing critical error handling for production scenarios
- Performance anti-patterns that would fail at scale
- Hardcoded values where configuration is essential
- Synchronous operations where async is required
- Memory leaks or resource management failures
- Lack of defensive programming practices

**Production Readiness Indicators:**
- Understanding of security implications (SQL injection, XSS, CSRF)
- Proper secrets management and configuration
- Scalability considerations in architecture
- Error recovery and graceful degradation
- Logging and observability implementation
- Resource cleanup and connection management
- Concurrency and race condition awareness

**Experience Level Markers:**
- **0-2 years (Novice/Junior)**: Tutorial-following patterns, basic CRUD operations, minimal error handling
- **2-5 years (Junior/Mid-Level)**: Framework proficiency, some patterns, basic security awareness
- **5-8 years (Senior)**: Architecture decisions, performance optimization, security-first thinking
- **8-12 years (Staff)**: Platform thinking, operational excellence, mentorship patterns
- **12+ years (Principal)**: System design mastery, cross-team impact, strategic technical decisions

### 2. AI-Generated Code Detection

**Clear AI Generation Indicators (>80% likelihood):**
- Accepting dangerous boilerplate without security modifications
- Generic error messages lacking context ("An error occurred")
- Over-engineered abstractions for simple problems
- Missing domain-specific optimizations any experienced dev would include
- Inconsistent expertise levels within same codebase
- Tutorial-perfect syntax with fundamental logic flaws
- Comments explaining obvious code while missing critical context
- Framework misuse that suggests pattern matching without understanding
- Unnecessary complexity - using design patterns where simple functions suffice
- Perfect formatting but poor logical flow
- Generic variable names (data, result, item) throughout
- Copy-paste patterns with slight variations that don't make sense

**Specific AI Tells to Look For:**
- **Documentation Mismatch**: Overly detailed comments for trivial code, no comments for complex logic
- **Import Bloat**: Importing entire libraries for single functions
- **Error Handling Theater**: Try-catch blocks that catch and immediately re-throw
- **Configuration Confusion**: Mixing environment configs, hardcoded values, and ENV vars randomly
- **Testing Patterns**: Tests that test the framework, not the business logic
- **Async Abuse**: Using async/await where synchronous would be simpler and correct
- **Type Over-Engineering**: Complex generic types for simple use cases
- **Dead Code**: Unused functions/variables that seem like "just in case" additions

**Human Development Patterns:**
- Incremental complexity matching problem evolution
- Personal coding quirks and consistent style
- Context-aware shortcuts and pragmatic choices
- Evidence of debugging and problem-solving (console.logs, commented attempts)
- Natural evolution of architecture (can see the journey)
- Domain-specific knowledge application
- Opinionated technology choices with clear rationale
- Appropriate laziness - not reinventing wheels unnecessarily
- Evidence of real-world constraints (deadlines, technical debt comments)

### 3. Critical Decision Analysis

**Critical Decision Points:**
- **Security Decisions**: Are they making choices that expose systems to attacks?
- **Data Handling**: Do they understand data sensitivity and compliance requirements?
- **Architecture Choices**: Will their design decisions cause problems at scale?
- **Dependency Management**: Are they introducing supply chain risks?
- **Error Handling**: Will their app fail catastrophically or gracefully?
- **Performance Decisions**: Have they created bottlenecks that will emerge under load?
- **Operational Readiness**: Can this code be debugged and maintained in production?

**Judgment Quality Indicators:**
- Awareness of trade-offs and explicit decision documentation
- Understanding of failure modes and mitigation strategies
- Recognition of security implications in design choices
- Appropriate complexity for the problem domain
- Evidence of thinking beyond happy path scenarios

### 4. Production System Readiness

**Ready for Production Systems:**
- Defensive programming against malicious inputs
- Proper error boundaries and circuit breakers
- Resource limits and timeout implementations
- Security headers and CORS configuration
- Audit logging and compliance considerations
- Database transaction management
- Proper async/await and promise handling
- Memory management and garbage collection awareness

**NOT Ready for Production (Requires Supervision):**
- Happy-path-only implementations
- Unhandled promise rejections
- SQL queries vulnerable to injection
- Exposed sensitive data in logs or responses
- Missing authentication/authorization checks
- Synchronous blocking operations
- Unbounded loops or recursive calls
- Resource leaks (connections, file handles, memory)

### 5. Risk Assessment for Team Integration

**High-Risk Indicators:**
- Cowboy coding without considering team impact
- Ignoring established patterns and conventions
- Making breaking changes without migration paths
- Poor git hygiene (force pushes, massive commits)
- Lack of communication in code reviews
- Introducing dependencies without team consensus
- Disregarding security or compliance requirements

**Low-Risk/High-Value Indicators:**
- Following team conventions even when disagreeing
- Clear communication of technical decisions
- Incremental, reviewable changes
- Proactive identification of risks
- Knowledge sharing and documentation
- Respectful disagreement and compromise
- Focus on team velocity over individual preferences

## Critical Assessment Output

IMPORTANT: You MUST follow this EXACT output format. Do not deviate from these headers and structure.

## Developer Competency Evaluation

### Overall Assessment
**Technical Competency:** [INSERT SCORE 1-10 HERE] - [INSERT ONE-LINE JUSTIFICATION HERE]
**Years of Experience:** [INSERT RANGE e.g., 2-4 years]
**Developer Level:** [SELECT ONE: Novice/Junior/Mid-Level/Senior/Staff/Principal]
**Production Readiness:** [SELECT ONE: Ready/Not Ready/Requires Mentorship]

### Critical Findings

#### \u{1F6A8} Red Flags & Risks
[REQUIRED: List at least 3-5 specific issues found. Be direct and critical. Examples:]
- [INSERT SPECIFIC DANGEROUS PATTERN FOUND]
- [INSERT SECURITY VULNERABILITY OR RISK]
- [INSERT PRODUCTION-BREAKING ISSUE]
- [INSERT TEAM/COLLABORATION CONCERN]
- [INSERT ANOTHER CRITICAL ISSUE]

#### \u26A0\uFE0F Competency Gaps
[REQUIRED: List 3-4 specific skill deficiencies. Examples:]
- [INSERT MISSING ESSENTIAL SKILL]
- [INSERT AREA NEEDING IMMEDIATE IMPROVEMENT]
- [INSERT KNOWLEDGE GAP THAT POSES RISK]
- [INSERT ANOTHER COMPETENCY GAP]

#### \u2713 Demonstrated Strengths
[OPTIONAL: List 1-2 genuine strengths if any. Keep brief:]
- [INSERT GENUINE STRENGTH IF ANY]
- [INSERT ANOTHER STRENGTH IF APPLICABLE]

### AI Code Generation Assessment
**Likelihood:** [INSERT PERCENTAGE 0-100]%
**Confidence:** [SELECT: High/Medium/Low]

**Evidence:**
[REQUIRED: List 3-5 specific AI indicators found:]
- [INSERT SPECIFIC AI PATTERN DETECTED]
- [INSERT COPY-PASTE INDICATOR]
- [INSERT MISSING OPTIMIZATION A HUMAN WOULD ADD]
- [INSERT ANOTHER AI TELL]
- [INSERT ADDITIONAL EVIDENCE IF FOUND]

### Hiring Recommendation

**Verdict:** [SELECT ONE: Strong Hire/Hire/Conditional Hire/No Hire]
**Appropriate Level:** [INSERT SPECIFIC LEVEL: e.g., Novice, Junior I, Junior II, Mid-Level I, Mid-Level II, Senior I, Senior II, Staff, Principal]

**Conditions/Concerns:**
[REQUIRED: List specific conditions and restrictions:]
- [INSERT SPECIFIC CONDITION OR REQUIREMENT]
- [INSERT SUPERVISION/MENTORSHIP NEEDS]
- [INSERT SYSTEMS THEY MUST NOT ACCESS]
- [INSERT OTHER CONCERNS]

### Critical Context

**Security Posture:** [SELECT ONE: Strong/Adequate/Weak/Dangerous]
- [INSERT SPECIFIC SECURITY OBSERVATION]
- [INSERT ANOTHER SECURITY CONCERN]

**Architecture Maturity:** [SELECT GRADE: A/B/C/D/F]
- [INSERT KEY ARCHITECTURAL ISSUE]
- [INSERT DESIGN DECISION CONCERN]

**Team Fit Risk:** [SELECT ONE: Low/Medium/High]
- [INSERT SPECIFIC COLLABORATION ISSUE]
- [INSERT COMMUNICATION CONCERN]

### Code Quality Grades

**Architectural Sophistication:** [GRADE: A/B/C/D/F] - [Brief justification]
**Security Practices:** [GRADE: A/B/C/D/F] - [Brief justification]
**Test Coverage & Quality:** [GRADE: A/B/C/D/F] - [Brief justification]
**Documentation:** [GRADE: A/B/C/D/F] - [Brief justification]
**Best Practices Adherence:** [GRADE: A/B/C/D/F] - [Brief justification]
**Code Maintainability:** [GRADE: A/B/C/D/F] - [Brief justification]
**Performance Awareness:** [GRADE: A/B/C/D/F] - [Brief justification]
**Error Handling:** [GRADE: A/B/C/D/F] - [Brief justification]

### Executive Summary
[REQUIRED: Write exactly 2-3 sentences. Be frank and direct about:]  
[Sentence 1: Developer's actual skill level and major weaknesses]  
[Sentence 2: Primary concerns about their code and practices]  
[Sentence 3: Clear recommendation on production system access]

NOTE: This assessment is based solely on code analysis patterns. No code improvements or suggestions have been provided as this is a pure developer evaluation.

{{SCHEMA_INSTRUCTIONS}}`
      },
      // TypeScript-specific prompts
      "typescript": {
        "architectural": `# TypeScript Architectural Code Review

You are an expert TypeScript architect performing a comprehensive architectural review of a TypeScript codebase.

## Your Task

Analyze the provided TypeScript code from an architectural perspective, focusing on:

1. **Overall Architecture**: Identify the architectural patterns and evaluate their appropriateness for a TypeScript project
2. **Type System Usage**: Assess how effectively TypeScript's type system is being utilized
3. **Interface Design**: Evaluate the design of interfaces and type definitions
4. **Component Structure**: Assess how the code is organized into components, modules, or services
5. **Dependency Management**: Evaluate how dependencies are managed and injected
6. **Separation of Concerns**: Check if responsibilities are properly separated
7. **Code Reusability**: Identify opportunities for better code reuse through TypeScript features
8. **Scalability Considerations**: Assess how well the architecture would scale
9. **Maintainability**: Evaluate how easy the codebase would be to maintain and extend

## Output Format

Provide your analysis in the following sections:

1. **Architecture Overview**: A high-level description of the current architecture
2. **TypeScript-Specific Strengths**: Architectural aspects that effectively leverage TypeScript
3. **Areas for Improvement**: Architectural issues that should be addressed
4. **Recommendations**: Specific suggestions for improving the architecture
5. **Code Examples**: Where appropriate, provide TypeScript code examples to illustrate your recommendations

This code is written in TYPESCRIPT. Please provide language-specific advice.

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`,
        "best-practices": `# TypeScript Best Practices Code Review

You are an **expert TypeScript engineer** specializing in code quality and TypeScript-specific design patterns. Perform a detailed review focused on adherence to established TypeScript best practices.

## TypeScript Best Practices

Evaluate the code against the following TypeScript-specific best practices:

### 1. Type System Usage
- Proper use of TypeScript's type system (interfaces, types, generics, etc.)
- Avoid using 'any' type - prefer 'unknown' for unknown types
- Use union types and intersection types where appropriate
- Proper use of type narrowing and type guards
- Use readonly properties and const assertions where appropriate

### 2. TypeScript Configuration
- Recommend strict mode and other compiler options for better type safety
- Appropriate use of tsconfig.json settings 
- Module resolution strategy best practices

### 3. Modern TypeScript Features
- Leverage TypeScript 4.x+ features when applicable
- Use optional chaining (?.) and nullish coalescing (??) operators
- Template literal types for string manipulation
- Proper usage of utility types (Partial, Pick, Omit, etc.)

### 4. Dependency Management
- Recommend TypeScript versions (currently 5.x is latest stable)
- Node.js version compatibility recommendations 
- Recommend essential TypeScript-related tools:
  - ESLint with @typescript-eslint (v6.x+)
  - ts-node for development (v10.x+)
  - Types for libraries (@types/*)

## Output Format

For each area of improvement you identify:

1. **Issue**: Clearly describe the TypeScript-specific pattern or practice that could be improved
2. **Impact**: Explain why this matters for type safety, maintainability, or performance
3. **Recommendation**: Provide specific, actionable guidance with TypeScript code examples
4. **Version/Package Recommendation**: When applicable, recommend specific versions of TypeScript packages or tools

Prioritize your recommendations by impact, focusing on changes that will significantly improve the codebase's type safety and maintainability.

This code is written in TYPESCRIPT. Please provide language-specific advice.

{{CI_DATA}}

{{SCHEMA_INSTRUCTIONS}}`
      },
      // Framework-specific prompts
      "typescript:react": {
        "best-practices": `# React with TypeScript Best Practices Code Review

You are an **expert React and TypeScript engineer** specializing in modern React development patterns with TypeScript. Perform a detailed review focused on React+TypeScript best practices.

## React with TypeScript Best Practices

Evaluate the code against the following React+TypeScript-specific best practices:

### 1. Component Structure & Types
- Proper typing of props and state (use interfaces, avoid 'any')
- Use of function components with proper type definitions 
- Proper typing of event handlers
- Use of React.FC vs. explicit return types
- Appropriate use of React.ComponentProps and other utility types
- Prefer explicit prop interfaces to minimize re-renders

### 2. Hooks Usage & Typing
- Proper typing of useState, useReducer, useContext
- Custom hooks with appropriate type signatures
- Use of useCallback and useMemo with proper dependency arrays
- Typing for useRef (e.g., useRef<HTMLDivElement>(null))
- Proper error handling in async hooks

### 3. State Management
- Appropriate use of context API with proper typing
- TypeScript integration with state management (Redux, Zustand, Jotai, etc.)
- Type-safe action creators and reducers
- Immutable state updates using TypeScript-friendly patterns

### 4. Dependency Recommendations
- React version:
  - Latest stable: React 19.1.0 (March 2025)
  - Previous major: React 18.x (supported until 2026)
- TypeScript version (recommend 5.x)
- Type-safe CSS solutions (styled-components, emotion, tailwind)
- Recommend testing libraries with good TypeScript support
- Specific dependencies:
  - @types/react (matching React version)
  - @types/react-dom (matching React version)
  - eslint-plugin-react-hooks (4.x+)
  - typescript-eslint (6.x+)

### 5. React 19.x Features
- Type-safe use of new preloading APIs (preload, preloadData, preconnect)
- Server Components typing practices
- Type-safe implementation of useFormStatus and useFormState
- Proper implementation of the new useActionState hook
- Safe migration from React 18.x features to React 19.x equivalents
- CSS Framework integrations:
  - Tailwind CSS v4.0 integration with React 19
  - Material UI v7.0.0 (with Pigment CSS for React Server Components)
  - Chakra UI v3.18.0 with React 19 compatibility

### 6. React 18.x Features (for projects using previous versions)
- Type-safe use of Suspense and concurrent mode
- Migration path to Server Components
- Type-safe use of createRoot and hydrateRoot
- Transition API typing best practices

## Output Format

For each area of improvement you identify:

1. **Issue**: Clearly describe the React+TypeScript-specific pattern or practice that could be improved
2. **Impact**: Explain why this matters for type safety, maintainability, or performance
3. **Recommendation**: Provide specific, actionable guidance with React+TypeScript code examples
4. **Package Recommendation**: When applicable, recommend specific versions of React+TypeScript packages or tools
5. **Version Compatibility**: Note which React version(s) your recommendation applies to (19.x, 18.x, or both)

Prioritize your recommendations by impact, focusing on changes that will significantly improve the codebase's type safety and maintainability.

This code is written in TYPESCRIPT for a REACT application. Please provide framework-specific advice.

{{SCHEMA_INSTRUCTIONS}}`
      }
      // Additional frameworks and languages follow the same pattern...
    };
  }
});

// src/prompts/PromptManager.ts
var import_path16, import_promises9, PromptManager;
var init_PromptManager = __esm({
  "src/prompts/PromptManager.ts"() {
    "use strict";
    import_path16 = __toESM(require("path"));
    import_promises9 = __toESM(require("fs/promises"));
    init_logger();
    init_reviewSchema();
    init_consolidated_review_schema();
    init_evaluation_schema();
    init_extract_patterns_schema();
    init_PromptBuilder();
    init_PromptCache();
    init_PromptStrategyFactory();
    init_bundledPrompts();
    PromptManager = class _PromptManager {
      static instance;
      templates = /* @__PURE__ */ new Map();
      customTemplates = /* @__PURE__ */ new Map();
      promptCache;
      promptBuilder;
      /**
       * Private constructor to enforce singleton pattern
       */
      constructor() {
        this.promptCache = PromptCache.getInstance();
        this.promptBuilder = new PromptBuilder(this, this.promptCache);
      }
      /**
       * Get the singleton instance
       * @returns The prompt manager instance
       */
      static getInstance() {
        if (!_PromptManager.instance) {
          _PromptManager.instance = new _PromptManager();
        }
        return _PromptManager.instance;
      }
      /**
       * Register a custom prompt template
       * @param template Prompt template to register
       */
      registerCustomTemplate(template) {
        const key = this.getTemplateKey(
          template.metadata.reviewType,
          template.metadata.language
        );
        this.customTemplates.set(key, template);
        logger_default.info(`Registered custom prompt template: ${template.metadata.name}`);
      }
      /**
       * Get a template key based on review type, language, and framework
       * @param reviewType Type of review
       * @param language Programming language
       * @param framework Framework (optional)
       * @returns Template key
       */
      getTemplateKey(reviewType, language, framework) {
        if (language && framework) {
          return `${reviewType}:${language.toLowerCase()}:${framework.toLowerCase()}`;
        } else if (language) {
          return `${reviewType}:${language.toLowerCase()}`;
        } else {
          return `${reviewType}`;
        }
      }
      /**
       * Load custom prompt templates from a directory
       * @param templatesDir Directory containing templates
       *
       * IMPORTANT: This method is only for loading CUSTOM templates.
       * Core prompts are bundled with the package in bundledPrompts.ts.
       * This method should only be used for loading user-provided templates
       * that extend or override the bundled ones.
       */
      async loadTemplates(templatesDir) {
        try {
          try {
            await import_promises9.default.access(templatesDir);
          } catch (error2) {
            logger_default.debug(`Custom templates directory not found: ${templatesDir}`);
            return;
          }
          const files = await import_promises9.default.readdir(templatesDir, { withFileTypes: true });
          let customTemplatesLoaded = 0;
          for (const file of files) {
            const fullPath = import_path16.default.join(templatesDir, file.name);
            if (file.isDirectory()) {
              await this.loadTemplates(fullPath);
            } else if (file.name.endsWith(".md")) {
              try {
                const content = await import_promises9.default.readFile(fullPath, "utf-8");
                const metadata = this.extractMetadata(content, file.name);
                const template = {
                  content,
                  metadata,
                  path: fullPath
                };
                const key = this.getTemplateKey(
                  metadata.reviewType,
                  metadata.language
                );
                this.templates.set(key, template);
                customTemplatesLoaded++;
                logger_default.debug(`Loaded custom prompt template: ${fullPath}`);
              } catch (error2) {
                logger_default.error(
                  `Error loading custom prompt template ${fullPath}: ${error2 instanceof Error ? error2.message : String(error2)}`
                );
              }
            }
          }
          if (customTemplatesLoaded > 0) {
            logger_default.info(
              `Loaded ${customTemplatesLoaded} custom prompt templates from ${templatesDir}`
            );
          }
        } catch (error2) {
          logger_default.error(
            `Error loading custom prompt templates: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
      /**
       * Extract metadata from a prompt template
       * @param content Template content
       * @param fileName Name of the template file
       * @returns Prompt template metadata
       */
      extractMetadata(content, fileName) {
        const defaultMetadata = {
          name: import_path16.default.basename(fileName, ".md"),
          description: "Prompt template for code review",
          version: "1.0.0",
          author: "AI Code Review Tool",
          reviewType: this.getReviewTypeFromFileName(fileName)
        };
        const metadataMatch = content.match(/---\s*\n([\s\S]*?)\n---/);
        if (metadataMatch && metadataMatch[1]) {
          try {
            const metadataLines = metadataMatch[1].split("\n");
            const metadata = {};
            for (const line of metadataLines) {
              const match = line.match(/^([^:]+):\s*(.*)$/);
              if (match) {
                const [, key, value] = match;
                if (key.trim() === "tags") {
                  metadata[key.trim()] = value.split(",").map((tag) => tag.trim());
                } else {
                  metadata[key.trim()] = value.trim();
                }
              }
            }
            return {
              ...defaultMetadata,
              ...metadata,
              reviewType: metadata.reviewType || defaultMetadata.reviewType
            };
          } catch (error2) {
            logger_default.warn(
              `Error parsing metadata from ${fileName}: ${error2 instanceof Error ? error2.message : String(error2)}`
            );
          }
        }
        return defaultMetadata;
      }
      /**
       * Get review type from a file name
       * @param fileName Name of the template file
       * @returns Review type
       */
      getReviewTypeFromFileName(fileName) {
        const baseName = import_path16.default.basename(fileName, ".md");
        if (baseName.includes("quick-fixes")) {
          return "quick-fixes";
        } else if (baseName.includes("security")) {
          return "security";
        } else if (baseName.includes("performance")) {
          return "performance";
        } else if (baseName.includes("architectural")) {
          return "architectural";
        } else if (baseName.includes("consolidated")) {
          return "consolidated";
        } else if (baseName.includes("best-practices")) {
          return "best-practices";
        } else if (baseName.includes("unused-code")) {
          return "unused-code";
        } else if (baseName.includes("code-tracing-unused-code")) {
          return "code-tracing-unused-code";
        } else {
          return "quick-fixes";
        }
      }
      /**
       * Get a prompt template
       * @param reviewType Type of review
       * @param options Review options
       * @returns Promise resolving to the prompt template content
       *
       * IMPORTANT: This method prioritizes prompts in the following order:
       * 1. Custom prompt file specified in options
       * 2. Custom templates registered programmatically
       * 3. Bundled prompts (PRIMARY SOURCE)
       * 4. Custom templates loaded from the file system (FALLBACK ONLY)
       *
       * Core functionality should ALWAYS use bundled prompts to ensure
       * the system works correctly regardless of installation environment.
       */
      async getPromptTemplate(reviewType, options) {
        let language = "typescript";
        const framework = options?.framework || "generic";
        if (options?.language) {
          language = options.language.toLowerCase();
        }
        if (options?.useCache !== false) {
          const cachedPrompt = this.promptCache.getBestPrompt(reviewType);
          if (cachedPrompt) {
            logger_default.info(
              `Using cached prompt for ${reviewType} review type (rating: ${cachedPrompt.rating})`
            );
            return await this.processPromptTemplate(cachedPrompt.content, options);
          }
        }
        if (options?.promptFile) {
          try {
            const customPromptPath = import_path16.default.resolve(options.promptFile);
            const promptTemplate = await import_promises9.default.readFile(customPromptPath, "utf-8");
            logger_default.info(`Loaded custom prompt template from ${customPromptPath}`);
            return await this.processPromptTemplate(promptTemplate, options);
          } catch (error2) {
            logger_default.error(
              `Error loading custom prompt template: ${error2 instanceof Error ? error2.message : String(error2)}`
            );
            logger_default.warn("Falling back to bundled prompt template");
          }
        }
        if (framework && framework !== "none") {
          const frameworkCustomKey = this.getTemplateKey(reviewType, language, framework);
          const frameworkCustomTemplate = this.customTemplates.get(frameworkCustomKey);
          if (frameworkCustomTemplate) {
            logger_default.info(
              `Using framework-specific custom prompt template: ${frameworkCustomTemplate.metadata.name}`
            );
            return await this.processPromptTemplate(frameworkCustomTemplate.content, options);
          }
        }
        const customKey = this.getTemplateKey(reviewType, language);
        const customTemplate = this.customTemplates.get(customKey);
        if (customTemplate) {
          logger_default.info(
            `Using custom prompt template: ${customTemplate.metadata.name}`
          );
          return await this.processPromptTemplate(customTemplate.content, options);
        }
        if (framework && framework !== "none") {
          const frameworkBundledPrompt = getBundledPrompt(reviewType, language, framework);
          if (frameworkBundledPrompt) {
            logger_default.info(`Using bundled framework-specific prompt template for ${reviewType} (language: ${language}, framework: ${framework})`);
            return await this.processPromptTemplate(frameworkBundledPrompt, options);
          }
        }
        const bundledPrompt = getBundledPrompt(reviewType, language);
        if (bundledPrompt) {
          logger_default.debug(`Using bundled prompt template for ${reviewType} (language: ${language})`);
          return await this.processPromptTemplate(bundledPrompt, options);
        }
        const genericBundledPrompt = getBundledPrompt(reviewType);
        if (genericBundledPrompt) {
          logger_default.debug(`Using generic bundled prompt template for ${reviewType}`);
          return await this.processPromptTemplate(genericBundledPrompt, options);
        }
        logger_default.warn(`No bundled prompt found for ${reviewType}. Falling back to custom templates.`);
        if (framework && framework !== "none") {
          const frameworkKey = this.getTemplateKey(reviewType, language, framework);
          const frameworkTemplate = this.templates.get(frameworkKey);
          if (frameworkTemplate) {
            logger_default.warn(`Using framework-specific custom prompt template from file system: ${frameworkTemplate.path}`);
            return await this.processPromptTemplate(frameworkTemplate.content, options);
          }
        }
        const key = this.getTemplateKey(reviewType, language);
        const template = this.templates.get(key);
        if (template) {
          logger_default.warn(`Using custom prompt template from file system: ${template.path}`);
          return await this.processPromptTemplate(template.content, options);
        }
        const genericKey = this.getTemplateKey(reviewType);
        const genericTemplate = this.templates.get(genericKey);
        if (genericTemplate) {
          logger_default.warn(`Using generic custom prompt template from file system: ${genericTemplate.path}`);
          return await this.processPromptTemplate(genericTemplate.content, options);
        }
        logger_default.error(`No prompt template found for ${reviewType} (language: ${language})`);
        throw new Error(`No prompt template found for ${reviewType} (language: ${language}). Please ensure bundled prompts are properly included in the package.`);
      }
      /**
       * IMPORTANT: The loadPromptTemplateFromFileSystem method has been removed.
       * We now use bundled prompts as the PRIMARY AND ONLY SOURCE for prompts.
       *
       * All prompts are defined in the bundledPrompts.ts file and accessed through
       * the getBundledPrompt function. The system does NOT load prompts from the
       * file system anymore.
       *
       * If you need to add or modify prompts, you must update the bundledPrompts.ts file.
       */
      async loadPromptTemplateFromFileSystem(_reviewType, _options) {
        throw new Error(
          `The loadPromptTemplateFromFileSystem method has been removed. We now use bundled prompts as the PRIMARY AND ONLY SOURCE for prompts. All prompts are defined in the bundledPrompts.ts file and accessed through the getBundledPrompt function.`
        );
      }
      /**
       * Process a prompt template by replacing placeholders
       * @param promptTemplate The raw prompt template
       * @param options Review options
       * @returns The processed prompt template
       */
      async processPromptTemplate(promptTemplate, options) {
        const isHandlebarsTemplate = promptTemplate.includes("{{#if") || promptTemplate.includes("{{/if") || promptTemplate.includes("{{languageInstructions}}") || promptTemplate.includes("{{schemaInstructions}}");
        const templateVars = {};
        if (options?.interactive) {
          let schemaInstructions;
          if (options?.type === "consolidated") {
            schemaInstructions = getConsolidatedSchemaInstructions();
          } else if (options?.type === "evaluation") {
            schemaInstructions = getEvaluationSchemaInstructions();
          } else if (options?.type === "extract-patterns") {
            schemaInstructions = getExtractPatternsSchemaInstructions();
          } else {
            schemaInstructions = getSchemaInstructions();
          }
          if (isHandlebarsTemplate) {
            templateVars.schemaInstructions = schemaInstructions;
            templateVars.SCHEMA_INSTRUCTIONS = schemaInstructions;
          } else {
            promptTemplate = promptTemplate.replace(
              "{{SCHEMA_INSTRUCTIONS}}",
              schemaInstructions
            );
          }
        } else {
          if (!isHandlebarsTemplate) {
            promptTemplate = promptTemplate.replace("{{SCHEMA_INSTRUCTIONS}}", "");
          }
        }
        if (options?.language) {
          let languageInstructions = `This code is written in ${options.language.toUpperCase()}.`;
          if (options?.framework && options.framework !== "none") {
            languageInstructions += ` It uses the ${options.framework.toUpperCase()} framework. Please provide framework-specific advice.`;
          } else {
            languageInstructions += ` Please provide language-specific advice.`;
          }
          if (isHandlebarsTemplate) {
            templateVars.languageInstructions = languageInstructions;
            templateVars.LANGUAGE_INSTRUCTIONS = languageInstructions;
          } else {
            promptTemplate = promptTemplate.replace(
              "{{LANGUAGE_INSTRUCTIONS}}",
              languageInstructions
            );
          }
        } else {
          if (!isHandlebarsTemplate) {
            promptTemplate = promptTemplate.replace("{{LANGUAGE_INSTRUCTIONS}}", "");
          }
        }
        if (isHandlebarsTemplate && Object.keys(templateVars).length > 0) {
          try {
            const Handlebars2 = await import("handlebars");
            const template = Handlebars2.default.compile(promptTemplate);
            promptTemplate = template(templateVars);
          } catch (error2) {
            logger_default.error(`Error rendering Handlebars template: ${error2}`);
          }
        }
        if (options?.promptStrategy) {
          const strategy = PromptStrategyFactory.createStrategy(
            options.promptStrategy,
            this,
            this.promptCache
          );
          promptTemplate = await Promise.resolve(
            strategy.formatPrompt(promptTemplate, options)
          );
          logger_default.debug(`Applied ${options.promptStrategy} prompt strategy`);
        }
        if (options?.promptFragments && options.promptFragments.length > 0) {
          this.promptBuilder.clear();
          this.promptBuilder.addComponent({
            content: promptTemplate,
            position: "middle",
            priority: 10
          });
          for (const fragment of options.promptFragments) {
            this.promptBuilder.addFragment(
              fragment.content,
              fragment.position,
              fragment.priority
            );
          }
          const finalPrompt = await this.promptBuilder.buildPrompt(
            options.type || "quick-fixes",
            options,
            null,
            promptTemplate
          );
          logger_default.debug(`Added ${options.promptFragments.length} prompt fragments`);
          return finalPrompt;
        }
        return promptTemplate;
      }
      /**
       * List all available prompt templates
       * @returns Array of prompt template metadata
       */
      listTemplates() {
        const allTemplates = [];
        for (const template of this.templates.values()) {
          allTemplates.push(template.metadata);
        }
        for (const template of this.customTemplates.values()) {
          allTemplates.push(template.metadata);
        }
        return allTemplates;
      }
      /**
       * Provide feedback on a prompt
       * @param reviewType Type of review
       * @param promptContent Content of the prompt
       * @param rating Rating of the prompt (1-5)
       * @param comments Comments on the prompt quality
       * @param positiveAspects Positive aspects of the prompt
       * @param negativeAspects Negative aspects of the prompt
       */
      async provideFeedback(reviewType, promptContent, rating, _comments, _positiveAspects, _negativeAspects) {
        try {
          await this.promptCache.cachePrompt(reviewType, promptContent, rating);
          logger_default.info(
            `Cached prompt for ${reviewType} review type with rating ${rating}`
          );
        } catch (error2) {
          logger_default.error(
            `Error caching prompt: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
        }
      }
    };
  }
});

// src/clients/utils/promptLoader.ts
async function loadPromptTemplate2(reviewType, languageOrOptions) {
  const promptManager = PromptManager.getInstance();
  let options;
  if (typeof languageOrOptions === "string") {
    options = {
      language: languageOrOptions,
      type: "quick-fixes",
      includeTests: false,
      output: "markdown"
    };
  } else {
    options = languageOrOptions;
  }
  return promptManager.getPromptTemplate(reviewType, options);
}
var init_promptLoader = __esm({
  "src/clients/utils/promptLoader.ts"() {
    "use strict";
    init_PromptManager();
  }
});

// src/clients/utils/toolCalling.ts
function packageInfoFromToolArgs(args) {
  return {
    name: args.package_name,
    version: args.package_version
  };
}
function packageInfosFromBatchToolArgs(args) {
  return (args.packages || []).map((pkg) => ({
    name: pkg.name,
    version: pkg.version
  }));
}
function formatDependencySecurityInfo(info2) {
  if (!info2) {
    return "No security information found for this dependency.";
  }
  let result = `## ${info2.packageName} ${info2.packageVersion ? `(${info2.packageVersion})` : ""}`;
  if (info2.packageHealth) {
    result += "\n\n### Package Health\n\n";
    if (info2.packageHealth.status) {
      result += `- Status: ${info2.packageHealth.status}
`;
    }
    if (info2.packageHealth.lastUpdated) {
      result += `- Last updated: ${info2.packageHealth.lastUpdated}
`;
    }
    if (info2.packageHealth.popularity) {
      result += `- Popularity: ${info2.packageHealth.popularity}
`;
    }
  }
  if (info2.deprecationInfo) {
    result += `

### \u26A0\uFE0F Deprecation Warning

${info2.deprecationInfo}`;
  }
  if (info2.recommendedVersion) {
    result += `

### \u2705 Recommended Version

${info2.recommendedVersion}`;
  }
  if (info2.vulnerabilities.length > 0) {
    result += "\n\n### Vulnerabilities\n\n";
    for (const vuln of info2.vulnerabilities) {
      const severityEmoji = {
        critical: "\u{1F534}",
        high: "\u{1F7E0}",
        medium: "\u{1F7E1}",
        low: "\u{1F7E2}",
        unknown: "\u26AA"
      }[vuln.severity];
      result += `${severityEmoji} **Severity:** ${vuln.severity}

`;
      result += `${vuln.description}

`;
      if (vuln.affectedVersions) {
        result += `**Affected Versions:** ${vuln.affectedVersions}

`;
      }
      if (vuln.fixedVersions) {
        result += `**Fixed in:** ${vuln.fixedVersions}

`;
      }
      if (vuln.url) {
        result += `**More Info:** [${vuln.url}](${vuln.url})

`;
      }
    }
  }
  if (info2.sources.length > 0) {
    result += "\n\n### Sources\n\n";
    for (const source of info2.sources) {
      result += `- [${new URL(source).hostname}](${source})
`;
    }
  }
  return result;
}
function formatBatchDependencySecurityInfo(infos) {
  if (infos.length === 0) {
    return "No security information found for any dependencies.";
  }
  return infos.map(formatDependencySecurityInfo).join("\n\n---\n\n");
}
var DEPENDENCY_SECURITY_TOOL, BATCH_DEPENDENCY_SECURITY_TOOL, ALL_TOOLS;
var init_toolCalling = __esm({
  "src/clients/utils/toolCalling.ts"() {
    "use strict";
    DEPENDENCY_SECURITY_TOOL = {
      type: "function",
      name: "search_dependency_security",
      description: "Search for security information about a software package dependency",
      parameters: {
        type: "object",
        properties: {
          package_name: {
            type: "string",
            description: "The name of the package to search for"
          },
          package_version: {
            type: "string",
            description: "The version of the package (optional)"
          },
          ecosystem: {
            type: "string",
            enum: ["npm", "composer", "pip", "gem"],
            description: "The package ecosystem (npm for JavaScript, composer for PHP, pip for Python, gem for Ruby)"
          }
        },
        required: ["package_name", "ecosystem"]
      }
    };
    BATCH_DEPENDENCY_SECURITY_TOOL = {
      type: "function",
      name: "batch_search_dependency_security",
      description: "Search for security information about multiple package dependencies (limited to 5 packages)",
      parameters: {
        type: "object",
        properties: {
          packages: {
            type: "array",
            description: "The packages to search for",
            items: {
              type: "object",
              properties: {
                name: {
                  type: "string",
                  description: "The name of the package"
                },
                version: {
                  type: "string",
                  description: "The version of the package (optional)"
                }
              },
              required: ["name"]
            }
          },
          ecosystem: {
            type: "string",
            enum: ["npm", "composer", "pip", "gem"],
            description: "The package ecosystem (npm for JavaScript, composer for PHP, pip for Python, gem for Ruby)"
          },
          limit: {
            type: "number",
            description: "The maximum number of packages to search for (default: 5)"
          }
        },
        required: ["packages", "ecosystem"]
      }
    };
    ALL_TOOLS = [
      DEPENDENCY_SECURITY_TOOL,
      BATCH_DEPENDENCY_SECURITY_TOOL
    ];
  }
});

// src/clients/utils/openAIToolCallingHandler.ts
var OpenAIToolCallingHandler, openAIToolCallingHandler;
var init_openAIToolCallingHandler = __esm({
  "src/clients/utils/openAIToolCallingHandler.ts"() {
    "use strict";
    OpenAIToolCallingHandler = class {
      /**
       * Prepare tool definitions for OpenAI API
       * @param tools The tools to prepare
       * @returns The tools formatted for OpenAI
       */
      prepareTools(tools) {
        return tools.map((tool) => ({
          type: "function",
          function: {
            name: tool.name,
            description: tool.description,
            parameters: tool.parameters
          }
        }));
      }
      /**
       * Process tool calls from OpenAI response
       * @param data The OpenAI response data
       * @returns Processed tool calls and response message
       */
      processToolCallsFromResponse(data) {
        if (!data.choices?.[0]?.message?.tool_calls?.length) {
          return {
            toolCalls: [],
            responseMessage: data.choices?.[0]?.message?.content || ""
          };
        }
        const toolCalls = data.choices[0].message.tool_calls.map((toolCall) => {
          try {
            const args = JSON.parse(toolCall.function.arguments);
            return {
              id: toolCall.id,
              name: toolCall.function.name,
              arguments: args
            };
          } catch (error2) {
            return {
              id: toolCall.id,
              name: toolCall.function.name,
              arguments: toolCall.function.arguments
            };
          }
        });
        return {
          toolCalls,
          responseMessage: data.choices[0].message.content || ""
        };
      }
      /**
       * Create a request with tool results for OpenAI
       * @param conversation The conversation so far
       * @param toolResults The results of the tool calls
       * @returns The updated conversation
       */
      createToolResultsRequest(conversation, toolResults) {
        const lastMessage = conversation[conversation.length - 1];
        if (!lastMessage.tool_calls) {
          throw new Error("Last message does not contain tool calls");
        }
        const toolResultMessages = toolResults.map((result) => {
          const toolCall = lastMessage.tool_calls?.find((tc) => {
            try {
              return tc.function.name === result.toolName;
            } catch (e) {
              return false;
            }
          });
          if (!toolCall) {
            throw new Error(`Could not find tool call for tool name: ${result.toolName}`);
          }
          return {
            role: "tool",
            tool_call_id: toolCall.id,
            content: typeof result.result === "string" ? result.result : JSON.stringify(result.result)
          };
        });
        return [...conversation, ...toolResultMessages];
      }
    };
    openAIToolCallingHandler = new OpenAIToolCallingHandler();
  }
});

// src/utils/dependencies/serpApiHelper.ts
function hasSerpApiConfig() {
  const hasKey = !!process.env.SERPAPI_KEY;
  logger_default.debug(`SERPAPI_KEY available: ${hasKey ? "YES" : "NO"}`);
  if (hasKey) {
    logger_default.debug(`SERPAPI_KEY first 5 chars: ${process.env.SERPAPI_KEY?.substring(0, 5)}...`);
  } else {
    logger_default.warn("SERPAPI_KEY not found in environment variables. Set this key to enable package security analysis.");
  }
  return hasKey;
}
async function searchPackageSecurity(packageInfo, ecosystem) {
  try {
    if (!hasSerpApiConfig()) {
      logger_default.debug("SerpAPI is not configured. Skipping security search.");
      return null;
    }
    const apiKey = process.env.SERPAPI_KEY;
    const searchTerm = `${packageInfo.name} ${packageInfo.version || ""} security vulnerability ${ecosystem}`;
    logger_default.debug(`Searching for security information: ${searchTerm}`);
    const url = new URL("https://serpapi.com/search");
    url.searchParams.append("engine", "google");
    url.searchParams.append("q", searchTerm);
    url.searchParams.append("api_key", apiKey);
    url.searchParams.append("num", "10");
    const response = await fetch(url.toString());
    if (!response.ok) {
      throw new Error(`SerpAPI request failed: ${response.statusText}`);
    }
    const data = await response.json();
    return processSecuritySearchResults(data, packageInfo);
  } catch (error2) {
    logger_default.error(`Error searching for package security: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
function processSecuritySearchResults(data, packageInfo) {
  try {
    const result = {
      packageName: packageInfo.name,
      packageVersion: packageInfo.version,
      vulnerabilities: [],
      sources: []
    };
    const organicResults = data.organic_results || [];
    for (const item of organicResults) {
      const title = item.title || "";
      const snippet = item.snippet || "";
      const link = item.link || "";
      if (!isRelevantSecurityResult(title, snippet, packageInfo.name)) {
        continue;
      }
      if (link && !result.sources.includes(link)) {
        result.sources.push(link);
      }
      const vulnerabilityInfo = extractVulnerabilityInfo(title, snippet, packageInfo.name);
      if (vulnerabilityInfo) {
        result.vulnerabilities.push(vulnerabilityInfo);
      }
      const recommendedVersion = extractRecommendedVersion(title, snippet, packageInfo.name, packageInfo.version);
      if (recommendedVersion && (!result.recommendedVersion || isNewer(recommendedVersion, result.recommendedVersion))) {
        result.recommendedVersion = recommendedVersion;
      }
      const healthInfo = extractPackageHealth(title, snippet);
      if (healthInfo) {
        result.packageHealth = { ...result.packageHealth, ...healthInfo };
      }
      const deprecationInfo = extractDeprecationInfo(title, snippet);
      if (deprecationInfo) {
        result.deprecationInfo = deprecationInfo;
      }
    }
    if (result.vulnerabilities.length === 0 && result.sources.length > 0) {
      result.vulnerabilities.push({
        description: "No specific vulnerabilities found in search results",
        severity: "unknown"
      });
    }
    return result.sources.length > 0 ? result : null;
  } catch (error2) {
    logger_default.error(`Error processing security search results: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
function isRelevantSecurityResult(title, snippet, packageName) {
  const lowerTitle = title.toLowerCase();
  const lowerSnippet = snippet.toLowerCase();
  const lowerPackageName = packageName.toLowerCase();
  if (!lowerTitle.includes(lowerPackageName) && !lowerSnippet.includes(lowerPackageName)) {
    return false;
  }
  const securityKeywords = [
    "vulnerability",
    "vulnerabilities",
    "security",
    "cve",
    "exploit",
    "patch",
    "advisory",
    "risk",
    "threat",
    "attack",
    "compromise",
    "breach",
    "unsafe",
    "malicious",
    "outdated",
    "deprecated"
  ];
  return securityKeywords.some(
    (keyword) => lowerTitle.includes(keyword) || lowerSnippet.includes(keyword)
  );
}
function extractVulnerabilityInfo(title, snippet, packageName) {
  const combinedText = `${title} ${snippet}`.toLowerCase();
  const lowerPackageName = packageName.toLowerCase();
  if (!combinedText.includes(lowerPackageName)) {
    return null;
  }
  const hasVulnerability = /vulnerability|security issue|exploit|cve-|unsafe|risk|attack|breach/i.test(combinedText);
  if (!hasVulnerability) {
    return null;
  }
  let severity = "unknown";
  if (/critical|severe|urgent/i.test(combinedText)) {
    severity = "critical";
  } else if (/high|important/i.test(combinedText)) {
    severity = "high";
  } else if (/medium|moderate/i.test(combinedText)) {
    severity = "medium";
  } else if (/low|minor/i.test(combinedText)) {
    severity = "low";
  }
  let affectedVersions;
  const affectedMatch = combinedText.match(/affected.{1,20}(versions?|v\.?)\s*:?\s*([0-9.<>=~ -]+)/i);
  if (affectedMatch) {
    affectedVersions = affectedMatch[2];
  }
  let fixedVersions;
  const fixedMatch = combinedText.match(/fixed.{1,20}(versions?|v\.?)\s*:?\s*([0-9.<>=~ -]+)/i);
  if (fixedMatch) {
    fixedVersions = fixedMatch[2];
  }
  const urlMatch = title.match(/https?:\/\/[^\s]+/);
  const url = urlMatch ? urlMatch[0] : void 0;
  return {
    description: snippet,
    severity,
    affectedVersions,
    fixedVersions,
    url
  };
}
function extractRecommendedVersion(title, snippet, packageName, currentVersion) {
  const combinedText = `${title} ${snippet}`;
  const recommendedMatch = combinedText.match(
    new RegExp(`(update|upgrade|latest|recommended|stable).{1,30}${packageName}.{1,30}(version\\s*:?\\s*|v\\.?\\s*|to\\s+)([0-9.]+)`, "i")
  );
  if (recommendedMatch) {
    return recommendedMatch[3];
  }
  const fixedMatch = combinedText.match(
    new RegExp(`(fixed|patched|resolved).{1,30}(in|with).{1,30}(version\\s*:?\\s*|v\\.?\\s*|to\\s+)([0-9.]+)`, "i")
  );
  if (fixedMatch) {
    return fixedMatch[4];
  }
  if (currentVersion) {
    const newerMatch = combinedText.match(
      new RegExp(`${packageName}.{1,50}${currentVersion}.{1,50}([0-9.]+)`, "i")
    );
    if (newerMatch && isNewer(newerMatch[1], currentVersion)) {
      return newerMatch[1];
    }
  }
  return null;
}
function extractPackageHealth(title, snippet) {
  const combinedText = `${title} ${snippet}`.toLowerCase();
  const lastUpdatedMatch = combinedText.match(/(last|latest)\s+update[ds]?\s*:?\s*([a-z0-9, ]+)/i);
  let status = "unknown";
  if (/actively maintained|active development/i.test(combinedText)) {
    status = "active";
  } else if (/maintained|supported/i.test(combinedText)) {
    status = "maintained";
  } else if (/deprecated/i.test(combinedText)) {
    status = "deprecated";
  } else if (/abandoned|unmaintained|no longer (maintained|supported)/i.test(combinedText)) {
    status = "abandoned";
  }
  const popularityMatch = combinedText.match(/(([0-9,]+)\s+stars|popular|widely used)/i);
  const popularity = popularityMatch ? popularityMatch[0] : void 0;
  if (lastUpdatedMatch || status !== "unknown" || popularity) {
    return {
      lastUpdated: lastUpdatedMatch ? lastUpdatedMatch[2] : void 0,
      status,
      popularity
    };
  }
  return null;
}
function extractDeprecationInfo(title, snippet) {
  const combinedText = `${title} ${snippet}`;
  if (/deprecated|no longer (maintained|supported)|end.of.life|unmaintained/i.test(combinedText)) {
    const sentences = combinedText.split(/[.!?]+/);
    for (const sentence of sentences) {
      if (/deprecated|no longer (maintained|supported)|end.of.life|unmaintained/i.test(sentence)) {
        return sentence.trim();
      }
    }
    return "Package appears to be deprecated";
  }
  return null;
}
function isNewer(versionA, versionB) {
  const partsA = versionA.split(".").map((part) => parseInt(part, 10) || 0);
  const partsB = versionB.split(".").map((part) => parseInt(part, 10) || 0);
  for (let i = 0; i < Math.max(partsA.length, partsB.length); i++) {
    const a = partsA[i] || 0;
    const b = partsB[i] || 0;
    if (a > b) return true;
    if (a < b) return false;
  }
  return false;
}
async function batchSearchPackageSecurity(packages, ecosystem, limit = 5) {
  const results = [];
  if (!hasSerpApiConfig()) {
    logger_default.debug("SerpAPI is not configured. Skipping batch security search.");
    return results;
  }
  const packagesToSearch = packages.slice(0, limit);
  for (const pkg of packagesToSearch) {
    const result = await searchPackageSecurity(pkg, ecosystem);
    if (result) {
      results.push(result);
    }
    await new Promise((resolve8) => setTimeout(resolve8, 500));
  }
  return results;
}
var init_serpApiHelper = __esm({
  "src/utils/dependencies/serpApiHelper.ts"() {
    "use strict";
    init_logger();
  }
});

// src/clients/utils/toolExecutor.ts
async function executeToolCall(toolName, args) {
  logger_default.debug(`Executing tool call: ${toolName} with arguments: ${JSON.stringify(args)}`);
  logger_default.info(`Executing dependency analysis tool: ${toolName}`);
  if (!hasSerpApiConfig()) {
    logger_default.error(`SERPAPI_KEY not found in environment variables. Tool calling requires this key to be set.`);
    return "No SERPAPI_KEY configured. Tool call execution skipped.";
  }
  logger_default.debug(`SERPAPI_KEY is configured, proceeding with tool execution`);
  try {
    logger_default.info(`Tool call context: ${JSON.stringify({
      toolName,
      argumentsProvided: Object.keys(args),
      serpApiConfigured: hasSerpApiConfig(),
      environmentVarsAvailable: Object.keys(process.env).filter((key) => key.startsWith("SERPAPI") || key.includes("API_KEY")).join(", ")
    })}`);
    switch (toolName) {
      case "search_dependency_security": {
        const securityResult = await executeDependencySecuritySearch(args);
        logger_default.info(`Dependency security search completed for ${args.package_name}`);
        return securityResult;
      }
      case "batch_search_dependency_security": {
        const batchResult = await executeBatchDependencySecuritySearch(args);
        logger_default.info(`Batch dependency security search completed for ${args.packages?.length || 0} packages`);
        return batchResult;
      }
      default:
        throw new Error(`Unknown tool: ${toolName}`);
    }
  } catch (error2) {
    logger_default.error(`Error executing tool call ${toolName}: ${error2 instanceof Error ? error2.message : String(error2)}`);
    logger_default.error(`Error details: ${error2 instanceof Error && error2.stack ? error2.stack : "No stack trace available"}`);
    return `Error executing tool call: ${error2 instanceof Error ? error2.message : "Unknown error"}`;
  }
}
async function executeDependencySecuritySearch(args) {
  if (!args.package_name || !args.ecosystem) {
    return "Error: package_name and ecosystem are required arguments.";
  }
  const packageInfo = packageInfoFromToolArgs(args);
  const result = await searchPackageSecurity(
    packageInfo,
    args.ecosystem
  );
  return formatDependencySecurityInfo(result);
}
async function executeBatchDependencySecuritySearch(args) {
  if (!args.packages || !Array.isArray(args.packages) || !args.ecosystem) {
    return "Error: packages array and ecosystem are required arguments.";
  }
  const packageInfos = packageInfosFromBatchToolArgs(args);
  if (packageInfos.length === 0) {
    return "No packages provided for analysis.";
  }
  const limit = args.limit && typeof args.limit === "number" ? Math.min(args.limit, 5) : 5;
  const results = await batchSearchPackageSecurity(
    packageInfos,
    args.ecosystem,
    limit
  );
  return formatBatchDependencySecurityInfo(results);
}
var init_toolExecutor = __esm({
  "src/clients/utils/toolExecutor.ts"() {
    "use strict";
    init_logger();
    init_toolCalling();
    init_serpApiHelper();
  }
});

// src/utils/dependencies/packageAnalyzer.ts
async function extractPackageInfo(projectPath) {
  const results = [];
  try {
    const packageJsonPath = import_path17.default.join(projectPath, "package.json");
    try {
      logger_default.info(`Analyzing package.json at ${packageJsonPath}...`);
      const packageJsonContent = await import_fs5.promises.readFile(packageJsonPath, "utf8");
      const packageJsonResult = await parsePackageJson(packageJsonContent, packageJsonPath);
      logger_default.info(`Found ${packageJsonResult.npm?.length || 0} npm dependencies in package.json`);
      results.push(packageJsonResult);
    } catch (error2) {
      logger_default.debug(`No valid package.json found at ${packageJsonPath}`);
    }
    const composerJsonPath = import_path17.default.join(projectPath, "composer.json");
    try {
      const composerJsonContent = await import_fs5.promises.readFile(composerJsonPath, "utf8");
      const composerJsonResult = await parseComposerJson(composerJsonContent, composerJsonPath);
      results.push(composerJsonResult);
    } catch (error2) {
      logger_default.debug(`No valid composer.json found at ${composerJsonPath}`);
    }
    const requirementsPath = import_path17.default.join(projectPath, "requirements.txt");
    try {
      const requirementsContent = await import_fs5.promises.readFile(requirementsPath, "utf8");
      const requirementsResult = await parseRequirementsTxt(requirementsContent, requirementsPath);
      results.push(requirementsResult);
    } catch (error2) {
      logger_default.debug(`No valid requirements.txt found at ${requirementsPath}`);
    }
    const gemfilePath = import_path17.default.join(projectPath, "Gemfile");
    try {
      const gemfileContent = await import_fs5.promises.readFile(gemfilePath, "utf8");
      const gemfileResult = await parseGemfile(gemfileContent, gemfilePath);
      results.push(gemfileResult);
    } catch (error2) {
      logger_default.debug(`No valid Gemfile found at ${gemfilePath}`);
    }
    return results.filter(
      (result) => result.npm && result.npm.length > 0 || result.composer && result.composer.length > 0 || result.python && result.python.length > 0 || result.ruby && result.ruby.length > 0
    );
  } catch (error2) {
    logger_default.error(`Error extracting package information: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return [];
  }
}
async function parsePackageJson(content, filePath) {
  try {
    const packageJson = JSON.parse(content);
    const dependencies = [];
    if (packageJson.dependencies) {
      Object.entries(packageJson.dependencies).forEach(([name, version]) => {
        dependencies.push({
          name,
          version: String(version).replace(/[\^~]/g, ""),
          constraint: String(version),
          devDependency: false
        });
      });
    }
    if (packageJson.devDependencies) {
      Object.entries(packageJson.devDependencies).forEach(([name, version]) => {
        dependencies.push({
          name,
          version: String(version).replace(/[\^~]/g, ""),
          constraint: String(version),
          devDependency: true
        });
      });
    }
    return {
      npm: dependencies,
      filename: "package.json",
      filePath
    };
  } catch (error2) {
    logger_default.error(`Error parsing package.json: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return { filename: "package.json", filePath };
  }
}
async function parseComposerJson(content, filePath) {
  try {
    const composerJson = JSON.parse(content);
    const dependencies = [];
    if (composerJson.require) {
      Object.entries(composerJson.require).forEach(([name, version]) => {
        if (name !== "php") {
          dependencies.push({
            name,
            constraint: String(version),
            devDependency: false
          });
        }
      });
    }
    if (composerJson["require-dev"]) {
      Object.entries(composerJson["require-dev"]).forEach(([name, version]) => {
        dependencies.push({
          name,
          constraint: String(version),
          devDependency: true
        });
      });
    }
    return {
      composer: dependencies,
      filename: "composer.json",
      filePath
    };
  } catch (error2) {
    logger_default.error(`Error parsing composer.json: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return { filename: "composer.json", filePath };
  }
}
async function parseRequirementsTxt(content, filePath) {
  try {
    const lines = content.split("\n");
    const dependencies = [];
    for (const line of lines) {
      const trimmedLine = line.trim();
      if (!trimmedLine || trimmedLine.startsWith("#")) {
        continue;
      }
      const versionMatch = trimmedLine.match(/^([a-zA-Z0-9_.-]+)\s*([=<>]+)\s*([a-zA-Z0-9_.-]+)(.*)$/);
      if (versionMatch) {
        const [, name, operator, version] = versionMatch;
        dependencies.push({
          name,
          version,
          constraint: `${operator}${version}`
        });
      } else {
        dependencies.push({
          name: trimmedLine
        });
      }
    }
    return {
      python: dependencies,
      filename: "requirements.txt",
      filePath
    };
  } catch (error2) {
    logger_default.error(`Error parsing requirements.txt: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return { filename: "requirements.txt", filePath };
  }
}
async function parseGemfile(content, filePath) {
  try {
    const lines = content.split("\n");
    const dependencies = [];
    let inGroup = false;
    let isDevGroup = false;
    for (const line of lines) {
      const trimmedLine = line.trim();
      if (!trimmedLine || trimmedLine.startsWith("#")) {
        continue;
      }
      if (trimmedLine.startsWith("group")) {
        inGroup = true;
        isDevGroup = trimmedLine.includes(":development") || trimmedLine.includes(":test");
      } else if (inGroup && trimmedLine === "end") {
        inGroup = false;
        isDevGroup = false;
      }
      const gemMatch = trimmedLine.match(/gem\s+['"]([^'"]+)['"](,\s*['"]([^'"]+)['"])?/);
      if (gemMatch) {
        const name = gemMatch[1];
        const version = gemMatch[3];
        dependencies.push({
          name,
          version,
          constraint: version,
          devDependency: isDevGroup
        });
      }
    }
    return {
      ruby: dependencies,
      filename: "Gemfile",
      filePath
    };
  } catch (error2) {
    logger_default.error(`Error parsing Gemfile: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return { filename: "Gemfile", filePath };
  }
}
var import_fs5, import_path17;
var init_packageAnalyzer = __esm({
  "src/utils/dependencies/packageAnalyzer.ts"() {
    "use strict";
    import_fs5 = require("fs");
    import_path17 = __toESM(require("path"));
    init_logger();
  }
});

// src/clients/utils/modelConfigRegistry.ts
function getModelConfig(fullModelName) {
  return MODEL_CONFIGS[fullModelName];
}
function getModelApiConfig(fullModelName) {
  const config4 = getModelConfig(fullModelName);
  if (config4?.apiConfig) {
    return config4.apiConfig;
  }
  return {
    maxTokensParam: "max_tokens",
    supportsTemperature: true,
    defaultTemperature: 0.2,
    supportsTopP: true,
    supportsFrequencyPenalty: true,
    supportsPresencePenalty: true
  };
}
function buildModelRequestParams(fullModelName, baseParams, maxTokens = 4e3) {
  const apiConfig = getModelApiConfig(fullModelName);
  const params = { ...baseParams };
  if (apiConfig.maxTokensParam) {
    params[apiConfig.maxTokensParam] = maxTokens;
  }
  if (apiConfig.supportsTemperature && !Object.prototype.hasOwnProperty.call(params, "temperature")) {
    params.temperature = apiConfig.defaultTemperature || 0.2;
  } else if (!apiConfig.supportsTemperature && Object.prototype.hasOwnProperty.call(params, "temperature")) {
    delete params.temperature;
  }
  if (!apiConfig.supportsTopP) delete params.top_p;
  if (!apiConfig.supportsFrequencyPenalty) delete params.frequency_penalty;
  if (!apiConfig.supportsPresencePenalty) delete params.presence_penalty;
  if (apiConfig.customParams) {
    Object.assign(params, apiConfig.customParams);
  }
  return params;
}
var MODEL_CONFIGS;
var init_modelConfigRegistry = __esm({
  "src/clients/utils/modelConfigRegistry.ts"() {
    "use strict";
    MODEL_CONFIGS = {
      // OpenAI GPT models
      "openai:gpt-4o": {
        modelId: "gpt-4o",
        provider: "openai",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true,
          supportsFrequencyPenalty: true,
          supportsPresencePenalty: true
        },
        pricing: {
          inputPricePer1K: 25e-4,
          outputPricePer1K: 0.01
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      "openai:gpt-4o-mini": {
        modelId: "gpt-4o-mini",
        provider: "openai",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true,
          supportsFrequencyPenalty: true,
          supportsPresencePenalty: true
        },
        pricing: {
          inputPricePer1K: 15e-5,
          outputPricePer1K: 6e-4
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      "openai:o3": {
        modelId: "o3",
        provider: "openai",
        apiConfig: {
          maxTokensParam: "max_completion_tokens",
          supportsTemperature: false,
          supportsTopP: false,
          supportsFrequencyPenalty: false,
          supportsPresencePenalty: false
        },
        pricing: {
          inputPricePer1K: 0.015,
          outputPricePer1K: 0.06
        },
        constraints: {
          maxTokensPerRequest: 1e5
        }
      },
      "openai:o3-mini": {
        modelId: "o3-mini",
        provider: "openai",
        apiConfig: {
          maxTokensParam: "max_completion_tokens",
          supportsTemperature: false,
          supportsTopP: false,
          supportsFrequencyPenalty: false,
          supportsPresencePenalty: false
        },
        pricing: {
          inputPricePer1K: 3e-3,
          outputPricePer1K: 0.012
        },
        constraints: {
          maxTokensPerRequest: 65e3
        }
      },
      // Anthropic models
      "anthropic:claude-3-opus": {
        modelId: "claude-3-opus-20240229",
        provider: "anthropic",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true
        },
        pricing: {
          inputPricePer1K: 0.015,
          outputPricePer1K: 0.075
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      "anthropic:claude-3.7-sonnet": {
        modelId: "claude-3-7-sonnet-20250219",
        provider: "anthropic",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true
        },
        pricing: {
          inputPricePer1K: 3e-3,
          outputPricePer1K: 0.015
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      "anthropic:claude-3.5-sonnet": {
        modelId: "claude-3-5-sonnet-20241022",
        provider: "anthropic",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true
        },
        pricing: {
          inputPricePer1K: 3e-3,
          outputPricePer1K: 0.015
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      "anthropic:claude-3-haiku": {
        modelId: "claude-3-haiku-20240307",
        provider: "anthropic",
        apiConfig: {
          maxTokensParam: "max_tokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true
        },
        pricing: {
          inputPricePer1K: 25e-5,
          outputPricePer1K: 125e-5
        },
        constraints: {
          maxTokensPerRequest: 4e3
        }
      },
      // Gemini models
      "gemini:gemini-2.5-pro-preview": {
        modelId: "gemini-2.5-pro-preview-05-06",
        provider: "gemini",
        apiConfig: {
          maxTokensParam: "maxOutputTokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true,
          customParams: {
            generationConfig: true
            // Gemini uses generationConfig wrapper
          }
        },
        pricing: {
          inputPricePer1K: 1e-3,
          outputPricePer1K: 4e-3,
          tiers: [
            { threshold: 128e3, inputPricePer1K: 2e-3, outputPricePer1K: 8e-3 }
          ]
        },
        constraints: {
          maxTokensPerRequest: 8192
        }
      },
      "gemini:gemini-2.0-flash": {
        modelId: "gemini-2.0-flash",
        provider: "gemini",
        apiConfig: {
          maxTokensParam: "maxOutputTokens",
          supportsTemperature: true,
          defaultTemperature: 0.2,
          supportsTopP: true,
          customParams: {
            generationConfig: true
          }
        },
        pricing: {
          inputPricePer1K: 1e-4,
          outputPricePer1K: 4e-4,
          tiers: [
            { threshold: 128e3, inputPricePer1K: 2e-4, outputPricePer1K: 8e-4 }
          ]
        },
        constraints: {
          maxTokensPerRequest: 8192
        }
      }
    };
  }
});

// src/clients/implementations/openaiClient.ts
var MAX_TOKENS_PER_REQUEST, OpenAIClient;
var init_openaiClient = __esm({
  "src/clients/implementations/openaiClient.ts"() {
    "use strict";
    init_base();
    init_logger();
    init_promptFormatter();
    init_promptLoader();
    init_modelMaps2();
    init_toolCalling();
    init_openAIToolCallingHandler();
    init_toolExecutor();
    init_packageAnalyzer();
    init_modelConfigRegistry();
    MAX_TOKENS_PER_REQUEST = 4e3;
    OpenAIClient = class extends AbstractClient {
      apiKey;
      /**
       * Initialize with default values
       */
      constructor() {
        super();
        this.modelName = "";
        this.isInitialized = false;
        this.apiKey = process.env.AI_CODE_REVIEW_OPENAI_API_KEY;
      }
      /**
       * Check if the client is initialized
       * @returns True if initialized, false otherwise
       */
      getIsInitialized() {
        return this.isInitialized;
      }
      /**
       * Check if the provided model name is supported by this client
       * @param modelName The full model name (potentially with provider prefix)
       * @returns Object indicating if this is the correct client for the model
       */
      isModelSupported(modelName) {
        return detectModelProvider("openai", modelName);
      }
      /**
       * Get the provider name for this client
       * @returns The provider name
       */
      getProviderName() {
        return "openai";
      }
      /**
       * Initialize the OpenAI client
       * @returns Promise resolving to a boolean indicating success
       */
      async initialize() {
        if (this.isInitialized) {
          return true;
        }
        const { isCorrect, modelName } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          return true;
        }
        this.modelName = modelName;
        if (!validateApiKey("openai")) {
          process.exit(1);
        }
        try {
          logger_default.info(`Initializing OpenAI model: ${this.modelName}...`);
          this.isInitialized = true;
          logger_default.info(`Successfully initialized OpenAI model: ${this.modelName}`);
          return true;
        } catch (error2) {
          logger_default.error(
            `Error initializing OpenAI model ${this.modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return false;
        }
      }
      /**
       * Get the API model name to use for requests
       * @returns The actual model name to use in API requests
       */
      getApiModelName() {
        logger_default.debug(`[O3 DEBUG] getApiModelName returning: ${this.modelName}`);
        return this.modelName;
      }
      /**
       * Add model-specific parameters using the model configuration registry
       * @param requestBody The request body to modify
       * @returns The modified request body
       */
      applyModelConfiguration(requestBody) {
        const fullModelName = this.getFullModelName();
        const configuredParams = buildModelRequestParams(
          fullModelName,
          requestBody,
          MAX_TOKENS_PER_REQUEST
        );
        logger_default.debug(`[Model Config] Applied configuration for ${fullModelName}: ${JSON.stringify(configuredParams, null, 2)}`);
        return configuredParams;
      }
      /**
       * Generate a review for a single file
       * @param fileContent Content of the file to review
       * @param filePath Path to the file
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateReview(fileContent, filePath, reviewType, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `OpenAI client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatSingleFileReviewPrompt(
            promptTemplate,
            fileContent,
            filePath,
            projectDocs
          );
          try {
            logger_default.info(`Generating review with OpenAI ${this.modelName}...`);
            const baseRequestBody = {
              model: this.getApiModelName(),
              messages: [
                {
                  role: "system",
                  content: `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.
              
IMPORTANT: Your response MUST be in the following JSON format:

{
  "grade": "A/B/C/D/F grade with optional + or - suffix (e.g., B+)",
  "gradeCategories": {
    "functionality": "Letter grade (e.g., B+)",
    "codeQuality": "Letter grade (e.g., B)",
    "documentation": "Letter grade (e.g., B-)",
    "testing": "Letter grade (e.g., C)",
    "maintainability": "Letter grade (e.g., B+)",
    "security": "Letter grade (e.g., B)",
    "performance": "Letter grade (e.g., B+)"
  },
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure. 

REMEMBER TO ALWAYS INCLUDE THE "grade" AND "gradeCategories" FIELDS, which provide an overall assessment of the code quality.`
                },
                {
                  role: "user",
                  content: prompt
                }
              ],
              temperature: 0.2
            };
            const requestBody = this.applyModelConfiguration(baseRequestBody);
            const response = await fetchWithRetry(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  Authorization: `Bearer ${this.apiKey}`
                },
                body: JSON.stringify(requestBody)
              }
            );
            const data = await response.json();
            if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
              throw new Error(`Invalid response format from OpenAI ${this.modelName}`);
            }
            const content = data.choices[0].message.content;
            logger_default.info(`Successfully generated review with OpenAI ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              filePath,
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(error2, "generate review", this.getFullModelName());
          }
        } catch (error2) {
          this.handleApiError(error2, "generating review", filePath);
        }
      }
      /**
       * Generate a consolidated review for multiple files
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
        logger_default.debug(`[O3 DEBUG] generateConsolidatedReview called with model: ${this.modelName}`);
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `OpenAI client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatConsolidatedReviewPrompt(
            promptTemplate,
            projectName,
            files.map((file) => ({
              relativePath: file.relativePath || "",
              content: file.content,
              sizeInBytes: file.content.length
            })),
            projectDocs
          );
          try {
            logger_default.info(`Generating consolidated review with OpenAI ${this.modelName}...`);
            logger_default.debug(`[O3 DEBUG] About to prepare API request body`);
            const baseRequestBody = {
              model: this.getApiModelName(),
              messages: [
                {
                  role: "system",
                  content: `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.
              
IMPORTANT: Your response MUST be in the following JSON format:

{
  "grade": "A/B/C/D/F grade with optional + or - suffix (e.g., B+)",
  "gradeCategories": {
    "functionality": "Letter grade (e.g., B+)",
    "codeQuality": "Letter grade (e.g., B)",
    "documentation": "Letter grade (e.g., B-)",
    "testing": "Letter grade (e.g., C)",
    "maintainability": "Letter grade (e.g., B+)",
    "security": "Letter grade (e.g., B)",
    "performance": "Letter grade (e.g., B+)"
  },
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure. 

REMEMBER TO ALWAYS INCLUDE THE "grade" AND "gradeCategories" FIELDS, which provide an overall assessment of the code quality.`
                },
                {
                  role: "user",
                  content: prompt
                }
              ],
              temperature: 0.2
            };
            const requestBody = this.applyModelConfiguration(baseRequestBody);
            const response = await fetchWithRetry(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  Authorization: `Bearer ${this.apiKey}`
                },
                body: JSON.stringify(requestBody)
              }
            );
            const data = await response.json();
            if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
              throw new Error(`Invalid response format from OpenAI ${this.modelName}`);
            }
            const content = data.choices[0].message.content;
            logger_default.info(`Successfully generated consolidated review with OpenAI ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              "consolidated",
              reviewType,
              options
            );
          } catch (error2) {
            logger_default.error(`[O3 DEBUG] Error in generateConsolidatedReview: ${error2 instanceof Error ? error2.message : String(error2)}`);
            throw handleApiError(
              error2,
              "generate consolidated review",
              this.getFullModelName()
            );
          }
        } catch (error2) {
          this.handleApiError(error2, "generating consolidated review", projectName);
        }
      }
      /**
       * Generate an architectural review for a project
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateArchitecturalReview(files, projectName, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `OpenAI client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2("architectural", options);
          const prompt = formatConsolidatedReviewPrompt(
            promptTemplate,
            projectName,
            files.map((file) => ({
              relativePath: file.relativePath || "",
              content: file.content,
              sizeInBytes: file.content.length
            })),
            projectDocs
          );
          const modelInfo = getModelMapping(this.getFullModelName());
          const supportsToolsCalling = modelInfo?.supportsToolCalling || false;
          const serpApiConfigured = !!process.env.SERPAPI_KEY;
          try {
            logger_default.info(`Generating architectural review with OpenAI ${this.modelName}...`);
            let response;
            let content;
            if (supportsToolsCalling && serpApiConfigured && options?.type === "architectural") {
              const packageResults = await extractPackageInfo(process.cwd());
              const packageInfo = packageResults.length > 0 ? `

## Dependencies
The project uses the following dependencies:

${packageResults.map((result) => {
                let pkgInfo = "";
                if (result.npm && result.npm.length > 0) {
                  pkgInfo += `### NPM (JavaScript/TypeScript) Dependencies
`;
                  result.npm.forEach((pkg) => {
                    pkgInfo += `- ${pkg.name}${pkg.version ? ` (${pkg.version})` : ""}${pkg.devDependency ? " (dev)" : ""}
`;
                  });
                }
                return pkgInfo;
              }).join("\n")}` : "";
              const promptWithPackages = prompt + packageInfo;
              const tools = openAIToolCallingHandler.prepareTools(ALL_TOOLS);
              const baseInitialRequestBody = {
                model: this.getApiModelName(),
                messages: [
                  {
                    role: "system",
                    content: `You are an expert code reviewer specialized in architectural analysis. Your task is to analyze code architecture, identify issues, and provide recommendations. 
                
ESSENTIAL TASK: For ALL major dependencies in the project, you MUST use the available tools to thoroughly check for:
1. Security vulnerabilities and CVEs
2. Version updates and recommendations 
3. Compatibility issues and breaking changes
4. Deprecation warnings
5. Maintenance status

Always include a dedicated "Dependency Security Analysis" section in your review that summarizes the findings from your dependency security checks. This is a critical part of the architectural review.`
                  },
                  {
                    role: "user",
                    content: promptWithPackages
                  }
                ],
                tools,
                tool_choice: "auto",
                temperature: 0.2
              };
              const initialRequestBody = this.applyModelConfiguration(baseInitialRequestBody);
              response = await fetchWithRetry(
                "https://api.openai.com/v1/chat/completions",
                {
                  method: "POST",
                  headers: {
                    "Content-Type": "application/json",
                    Authorization: `Bearer ${this.apiKey}`
                  },
                  body: JSON.stringify(initialRequestBody)
                }
              );
              const data = await response.json();
              const { toolCalls, responseMessage } = openAIToolCallingHandler.processToolCallsFromResponse(data);
              if (toolCalls.length > 0) {
                logger_default.info(`Found ${toolCalls.length} tool calls in the response`);
                const toolResults = [];
                for (const toolCall of toolCalls) {
                  const result = await executeToolCall(toolCall.name, toolCall.arguments);
                  toolResults.push({
                    toolName: toolCall.name,
                    result
                  });
                }
                const conversation = [
                  {
                    role: "system",
                    content: `You are an expert code reviewer specialized in architectural analysis. Your task is to analyze code architecture, identify issues, and provide recommendations.
                
ESSENTIAL TASK: Include a dedicated "Dependency Security Analysis" section in your review that summarizes the findings from the dependency security checks. This is a critical part of the architectural review.`
                  },
                  {
                    role: "user",
                    content: promptWithPackages
                  },
                  {
                    role: "assistant",
                    content: responseMessage || null,
                    tool_calls: data.choices[0].message.tool_calls
                  }
                ];
                const conversationWithResults = openAIToolCallingHandler.createToolResultsRequest(
                  conversation,
                  toolResults
                );
                const baseFinalRequestBody = {
                  model: this.getApiModelName(),
                  messages: conversationWithResults,
                  temperature: 0.2
                };
                const finalRequestBody = this.applyModelConfiguration(baseFinalRequestBody);
                const finalResponse = await fetchWithRetry(
                  "https://api.openai.com/v1/chat/completions",
                  {
                    method: "POST",
                    headers: {
                      "Content-Type": "application/json",
                      Authorization: `Bearer ${this.apiKey}`
                    },
                    body: JSON.stringify(finalRequestBody)
                  }
                );
                const finalData = await finalResponse.json();
                if (!Array.isArray(finalData.choices) || !finalData.choices[0]?.message?.content) {
                  throw new Error(`Invalid response format from OpenAI ${this.modelName}`);
                }
                content = finalData.choices[0].message.content;
              } else {
                if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
                  throw new Error(`Invalid response format from OpenAI ${this.modelName}`);
                }
                content = data.choices[0].message.content;
              }
            } else {
              const baseRequestBody = {
                model: this.getApiModelName(),
                messages: [
                  {
                    role: "system",
                    content: `You are an expert code reviewer specialized in architectural analysis. Your task is to analyze code architecture, identify issues, and provide recommendations.`
                  },
                  {
                    role: "user",
                    content: prompt
                  }
                ],
                temperature: 0.2
              };
              const requestBody = this.applyModelConfiguration(baseRequestBody);
              response = await fetchWithRetry(
                "https://api.openai.com/v1/chat/completions",
                {
                  method: "POST",
                  headers: {
                    "Content-Type": "application/json",
                    Authorization: `Bearer ${this.apiKey}`
                  },
                  body: JSON.stringify(requestBody)
                }
              );
              const data = await response.json();
              if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
                throw new Error(`Invalid response format from OpenAI ${this.modelName}`);
              }
              content = data.choices[0].message.content;
            }
            logger_default.info(`Successfully generated architectural review with OpenAI ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              "architectural",
              "architectural",
              options
            );
          } catch (error2) {
            throw handleApiError(
              error2,
              "generate architectural review",
              this.getFullModelName()
            );
          }
        } catch (error2) {
          this.handleApiError(error2, "generating architectural review", projectName);
        }
      }
    };
  }
});

// src/clients/utils/apiKeyValidator.ts
function validateAnthropicApiKey(apiKey, isDebugMode3 = false) {
  if (!apiKey) {
    logger_default.error("No Anthropic API key found.");
    logger_default.error("Please add the following to your .env file:");
    logger_default.error(
      "- AI_CODE_REVIEW_ANTHROPIC_API_KEY=your_anthropic_api_key_here"
    );
    return false;
  }
  if (isDebugMode3) {
    logger_default.info("Anthropic API key found: AI_CODE_REVIEW_ANTHROPIC_API_KEY");
  }
  return true;
}
function validateOpenRouterApiKey(apiKey, isDebugMode3 = false) {
  if (!apiKey) {
    logger_default.error("No OpenRouter API key found.");
    logger_default.error("Please add the following to your .env file:");
    logger_default.error(
      "- AI_CODE_REVIEW_OPENROUTER_API_KEY=your_openrouter_api_key_here"
    );
    return false;
  }
  if (isDebugMode3) {
    logger_default.info("OpenRouter API key found: AI_CODE_REVIEW_OPENROUTER_API_KEY");
  }
  return true;
}
function isDebugMode() {
  return process.argv.includes("--debug");
}
var init_apiKeyValidator = __esm({
  "src/clients/utils/apiKeyValidator.ts"() {
    "use strict";
    init_logger();
  }
});

// src/clients/utils/modelInitializer.ts
var init_modelInitializer = __esm({
  "src/clients/utils/modelInitializer.ts"() {
    "use strict";
    init_modelMaps2();
  }
});

// src/clients/utils/modelTester.ts
function formatApiError(error2, provider) {
  const errorMessage = error2.message || String(error2);
  if (errorMessage.includes("API key")) {
    return `Invalid ${provider} API key: ${errorMessage}`;
  } else if (errorMessage.includes("Rate limit")) {
    return `${provider} API rate limit exceeded: ${errorMessage}`;
  } else if (errorMessage.includes("not found")) {
    return `${provider} model not found: ${errorMessage}`;
  } else if (errorMessage.includes("quota")) {
    return `${provider} API quota exceeded: ${errorMessage}`;
  } else {
    return `${provider} API error: ${errorMessage}`;
  }
}
async function testGeminiModel(modelName = "gemini-1.5-pro") {
  const apiKeyResult = getGoogleApiKey();
  if (!apiKeyResult.apiKey) {
    return {
      success: false,
      message: "No Google API key found. Please set AI_CODE_REVIEW_GOOGLE_API_KEY in your .env file.",
      provider: "gemini"
    };
  }
  try {
    const { GoogleGenerativeAI: GoogleGenerativeAI3, HarmCategory: HarmCategory3, HarmBlockThreshold: HarmBlockThreshold3 } = await import("@google/generative-ai");
    const genAI2 = new GoogleGenerativeAI3(apiKeyResult.apiKey);
    const model = genAI2.getGenerativeModel({ model: modelName });
    const result = await model.generateContent({
      contents: [{ role: "user", parts: [{ text: "Say hello in one word." }] }],
      safetySettings: [
        {
          category: HarmCategory3.HARM_CATEGORY_HARASSMENT,
          threshold: HarmBlockThreshold3.BLOCK_MEDIUM_AND_ABOVE
        },
        {
          category: HarmCategory3.HARM_CATEGORY_HATE_SPEECH,
          threshold: HarmBlockThreshold3.BLOCK_MEDIUM_AND_ABOVE
        },
        {
          category: HarmCategory3.HARM_CATEGORY_SEXUALLY_EXPLICIT,
          threshold: HarmBlockThreshold3.BLOCK_MEDIUM_AND_ABOVE
        },
        {
          category: HarmCategory3.HARM_CATEGORY_DANGEROUS_CONTENT,
          threshold: HarmBlockThreshold3.BLOCK_MEDIUM_AND_ABOVE
        }
      ]
    });
    const response = result.response.text();
    return {
      success: true,
      message: `Successfully tested ${modelName}`,
      model: modelName,
      provider: "gemini",
      response
    };
  } catch (error2) {
    logger_default.error(`Error testing Gemini model ${modelName}:`, error2);
    return {
      success: false,
      message: formatApiError(error2, "Gemini"),
      model: modelName,
      provider: "gemini",
      error: error2
    };
  }
}
async function testAnthropicModel(modelName = "claude-3-sonnet-20240229") {
  const apiKeyResult = getAnthropicApiKey();
  if (!apiKeyResult.apiKey) {
    return {
      success: false,
      message: "No Anthropic API key found. Please set AI_CODE_REVIEW_ANTHROPIC_API_KEY in your .env file.",
      provider: "anthropic"
    };
  }
  try {
    const response = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-api-key": apiKeyResult.apiKey,
        "anthropic-version": "2023-06-01"
      },
      body: JSON.stringify({
        model: modelName,
        max_tokens: 10,
        messages: [{ role: "user", content: "Say hello in one word." }]
      })
    });
    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(
        `API error: ${response.status} ${errorData.error?.message || "Unknown error"}`
      );
    }
    const data = await response.json();
    return {
      success: true,
      message: `Successfully tested ${modelName}`,
      model: modelName,
      provider: "anthropic",
      response: data.content[0].text
    };
  } catch (error2) {
    logger_default.error(`Error testing Anthropic model ${modelName}:`, error2);
    return {
      success: false,
      message: formatApiError(error2, "Anthropic"),
      model: modelName,
      provider: "anthropic",
      error: error2
    };
  }
}
async function testOpenAIModel(modelName = "gpt-4o") {
  const apiKeyResult = getOpenAIApiKey();
  if (!apiKeyResult.apiKey) {
    return {
      success: false,
      message: "No OpenAI API key found. Please set AI_CODE_REVIEW_OPENAI_API_KEY in your .env file.",
      provider: "openai"
    };
  }
  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKeyResult.apiKey}`
      },
      body: JSON.stringify({
        model: modelName,
        max_tokens: 10,
        messages: [{ role: "user", content: "Say hello in one word." }]
      })
    });
    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(
        `API error: ${response.status} ${errorData.error?.message || "Unknown error"}`
      );
    }
    const data = await response.json();
    return {
      success: true,
      message: `Successfully tested ${modelName}`,
      model: modelName,
      provider: "openai",
      response: data.choices[0].message.content
    };
  } catch (error2) {
    logger_default.error(`Error testing OpenAI model ${modelName}:`, error2);
    return {
      success: false,
      message: formatApiError(error2, "OpenAI"),
      model: modelName,
      provider: "openai",
      error: error2
    };
  }
}
async function testOpenRouterModel(modelName = "anthropic/claude-3-opus-20240229") {
  const apiKeyResult = getOpenRouterApiKey();
  if (!apiKeyResult.apiKey) {
    return {
      success: false,
      message: "No OpenRouter API key found. Please set AI_CODE_REVIEW_OPENROUTER_API_KEY in your .env file.",
      provider: "openrouter"
    };
  }
  try {
    const response = await fetch(
      "https://openrouter.ai/api/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKeyResult.apiKey}`,
          "HTTP-Referer": "https://github.com/bobmatnyc/ai-code-review"
        },
        body: JSON.stringify({
          model: modelName,
          max_tokens: 10,
          messages: [{ role: "user", content: "Say hello in one word." }]
        })
      }
    );
    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(
        `API error: ${response.status} ${errorData.error?.message || "Unknown error"}`
      );
    }
    const data = await response.json();
    return {
      success: true,
      message: `Successfully tested ${modelName}`,
      model: modelName,
      provider: "openrouter",
      response: data.choices[0].message.content
    };
  } catch (error2) {
    logger_default.error(`Error testing OpenRouter model ${modelName}:`, error2);
    return {
      success: false,
      message: formatApiError(error2, "OpenRouter"),
      model: modelName,
      provider: "openrouter",
      error: error2
    };
  }
}
var init_modelTester = __esm({
  "src/clients/utils/modelTester.ts"() {
    "use strict";
    init_envLoader();
    init_logger();
  }
});

// src/clients/utils/index.ts
var init_utils = __esm({
  "src/clients/utils/index.ts"() {
    "use strict";
    init_apiKeyValidator();
    init_modelInitializer();
    init_promptFormatter();
    init_directoryStructure();
    init_promptLoader();
    init_tokenCounter();
    init_languageDetection();
    init_modelMaps2();
    init_modelMaps2();
    init_tokenCounter();
    init_modelLister();
    init_modelTester();
  }
});

// src/clients/utils/anthropicModelHelpers.ts
var anthropicModelHelpers_exports = {};
__export(anthropicModelHelpers_exports, {
  getApiModelName: () => getApiModelName,
  initializeAnthropicClient: () => initializeAnthropicClient,
  isAnthropicModel: () => isAnthropicModel,
  parseJsonResponse: () => parseJsonResponse,
  testAnthropicApiAccess: () => testAnthropicApiAccess
});
function isAnthropicModel() {
  const selectedModel = getConfig().selectedModel || "";
  logger_default.debug(`isAnthropicModel called with AI_CODE_REVIEW_MODEL=${selectedModel}`);
  if (!selectedModel) {
    logger_default.debug("isAnthropicModel: No model selected, returning false");
    return {
      isCorrect: false,
      adapter: "",
      modelName: ""
    };
  }
  const [adapter, modelName] = selectedModel.includes(":") ? selectedModel.split(":") : ["anthropic", selectedModel];
  logger_default.debug(`isAnthropicModel: Parsed adapter=${adapter}, modelName=${modelName}`);
  logger_default.debug(`isAnthropicModel: isCorrect=${adapter === "anthropic"}`);
  return {
    isCorrect: adapter === "anthropic",
    adapter,
    modelName
  };
}
async function getApiModelName(modelName) {
  const dateVersionPattern = /-\d{8}$/;
  if (dateVersionPattern.test(modelName)) {
    if (modelName.includes(":")) {
      return modelName.split(":")[1];
    }
    return modelName;
  }
  const cleanModelName = modelName.includes(":") ? modelName.split(":")[1] : modelName;
  if (cleanModelName === "claude-3.7-sonnet" || cleanModelName === "claude-3-7-sonnet") {
    logger_default.debug(`Detected Claude 3.7 Sonnet model, using fixed API name: claude-3-7-sonnet-20250219`);
    return "claude-3-7-sonnet-20250219";
  }
  if (cleanModelName === "claude-3.5-sonnet" || cleanModelName === "claude-3-5-sonnet") {
    logger_default.debug(`Detected Claude 3.5 Sonnet model, using fixed API name: claude-3-5-sonnet-20241022`);
    return "claude-3-5-sonnet-20241022";
  }
  if (cleanModelName === "claude-3-opus" || cleanModelName === "claude-3.0-opus") {
    logger_default.debug(`Detected Claude 3 Opus model, using fixed API name: claude-3-opus-20240229`);
    return "claude-3-opus-20240229";
  }
  if (cleanModelName === "claude-3-sonnet" || cleanModelName === "claude-3.0-sonnet") {
    logger_default.debug(`Detected Claude 3 Sonnet model, using fixed API name: claude-3-sonnet-20240229`);
    return "claude-3-sonnet-20240229";
  }
  if (cleanModelName === "claude-3-haiku" || cleanModelName === "claude-3.0-haiku") {
    logger_default.debug(`Detected Claude 3 Haiku model, using fixed API name: claude-3-haiku-20240307`);
    return "claude-3-haiku-20240307";
  }
  if (cleanModelName === "claude-3.5-haiku" || cleanModelName === "claude-3-5-haiku") {
    logger_default.debug(`Detected Claude 3.5 Haiku model, using fixed API name: claude-3-5-haiku-20241022`);
    return "claude-3-5-haiku-20241022";
  }
  const { getModelMapping: getModelMapping2, MODEL_MAP: MODEL_MAP2 } = await Promise.resolve().then(() => (init_modelMaps2(), modelMaps_exports));
  try {
    logger_default.debug("getApiModelName called with model name: " + modelName);
    let fullModelName;
    if (modelName.startsWith("anthropic:")) {
      fullModelName = modelName;
      logger_default.debug(`Model name already has prefix: ${fullModelName}`);
    } else {
      fullModelName = `anthropic:${modelName}`;
      logger_default.debug(`Added prefix to model name: ${fullModelName}`);
    }
    logger_default.debug(`Available model keys in MODEL_MAP: ${Object.keys(MODEL_MAP2).join(", ")}`);
    const modelConfig = getModelMapping2(fullModelName);
    if (modelConfig) {
      logger_default.debug(`Found model configuration for ${fullModelName}:`);
      logger_default.debug(`- apiIdentifier: ${modelConfig.apiIdentifier}`);
      logger_default.debug(`- displayName: ${modelConfig.displayName}`);
      logger_default.debug(`- provider: ${modelConfig.provider}`);
      if (modelConfig.apiIdentifier) {
        logger_default.debug(`Using API model name from configuration: ${modelConfig.apiIdentifier} for ${modelName}`);
        return modelConfig.apiIdentifier;
      }
    }
    const alternativeKey1 = fullModelName.replace(/\./g, "-");
    const alternativeKey2 = fullModelName.replace(/-/g, ".");
    logger_default.debug(`Trying alternative format (dots to hyphens): ${alternativeKey1}`);
    const altConfig1 = getModelMapping2(alternativeKey1);
    if (altConfig1 && altConfig1.apiIdentifier) {
      logger_default.debug(`Found match with alternative format (dots to hyphens): ${alternativeKey1} -> ${altConfig1.apiIdentifier}`);
      return altConfig1.apiIdentifier;
    }
    logger_default.debug(`Trying alternative format (hyphens to dots): ${alternativeKey2}`);
    const altConfig2 = getModelMapping2(alternativeKey2);
    if (altConfig2 && altConfig2.apiIdentifier) {
      logger_default.debug(`Found match with alternative format (hyphens to dots): ${alternativeKey2} -> ${altConfig2.apiIdentifier}`);
      return altConfig2.apiIdentifier;
    }
    const dateVersionPattern2 = /-\d{8}$/;
    const dotDateVersionPattern = /\.\d{8}$/;
    if (dateVersionPattern2.test(fullModelName)) {
      const baseModelName = fullModelName.replace(dateVersionPattern2, "");
      logger_default.debug(`Checking base model without date: ${baseModelName}`);
      const baseModelConfig = getModelMapping2(baseModelName);
      if (baseModelConfig && baseModelConfig.apiIdentifier) {
        logger_default.debug(`Found base model mapping for ${baseModelName}, but using original name with date as API name`);
        return modelName.includes(":") ? modelName.split(":")[1] : modelName;
      }
    } else if (dotDateVersionPattern.test(fullModelName)) {
      const baseDotModelName = fullModelName.replace(dotDateVersionPattern, "");
      const baseHyphenModelName = baseDotModelName.replace(/\./g, "-");
      logger_default.debug(`Checking base model with dots converted to hyphens: ${baseHyphenModelName}`);
      const baseModelConfig = getModelMapping2(baseHyphenModelName);
      if (baseModelConfig && baseModelConfig.apiIdentifier) {
        logger_default.debug(`Found base model mapping for ${baseHyphenModelName}, converting full name to hyphen format`);
        const hyphenModelName = fullModelName.replace(/\./g, "-");
        return hyphenModelName.includes(":") ? hyphenModelName.split(":")[1] : hyphenModelName;
      }
    } else if (dateVersionPattern2.test(modelName) || dotDateVersionPattern.test(modelName)) {
      const hyphenModelName = modelName.replace(/\./g, "-");
      const baseModelName = hyphenModelName.replace(dateVersionPattern2, "");
      const fullBaseModelName = `anthropic:${baseModelName}`;
      logger_default.debug(`Checking base model without provider and date: ${fullBaseModelName}`);
      const baseModelConfig = getModelMapping2(fullBaseModelName);
      if (baseModelConfig && baseModelConfig.apiIdentifier) {
        logger_default.debug(`Found base model mapping for ${fullBaseModelName}, using hyphen format of original name`);
        return hyphenModelName;
      }
    }
    logger_default.warn(`Model "${modelName}" (fullModelName: ${fullModelName}) not found in configuration. This may cause API errors.`);
    logger_default.warn("Make sure the model name is defined in MODEL_MAP within modelMaps.ts with the correct format");
    return modelName;
  } catch (error2) {
    logger_default.error(`Error getting API model name: ${error2}`);
    return modelName;
  }
}
async function initializeAnthropicClient() {
  logger_default.debug("initializeAnthropicClient called");
  const { isCorrect, adapter, modelName } = isAnthropicModel();
  logger_default.debug(
    `initializeAnthropicClient: isCorrect=${isCorrect}, adapter=${adapter}, modelName=${modelName}`
  );
  if (!isCorrect) {
    logger_default.debug(
      "initializeAnthropicClient: Not an Anthropic model, returning true without initializing"
    );
    return true;
  }
  if (modelInitialized) {
    logger_default.debug(
      "initializeAnthropicClient: Already initialized, returning true"
    );
    return true;
  }
  logger_default.debug("initializeAnthropicClient: Proceeding with initialization");
  const apiKey = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY;
  if (!validateAnthropicApiKey(apiKey, isDebugMode())) {
    process.exit(1);
  }
  try {
    if (!apiKey) {
      logger_default.error("Anthropic API key is missing");
      return false;
    }
    const success = await testAnthropicApiAccess(apiKey, modelName);
    if (success) {
      modelInitialized = true;
      return true;
    }
    return false;
  } catch (error2) {
    logger_default.error(`Error initializing Anthropic model ${modelName}`);
    return false;
  }
}
function parseJsonResponse(content) {
  try {
    const codeBlockMatch = content.match(/```(?:\w+)?\s*([\s\S]*?)\s*```/);
    let jsonContent = "";
    if (codeBlockMatch) {
      jsonContent = codeBlockMatch[1];
    } else {
      jsonContent = content;
    }
    const structuredData = JSON.parse(jsonContent);
    if (!structuredData.summary || !Array.isArray(structuredData.issues)) {
      logger_default.warn(
        "Response is valid JSON but does not have the expected structure"
      );
    }
    return structuredData;
  } catch (parseError) {
    logger_default.warn(
      `Response is not valid JSON: ${parseError instanceof Error ? parseError.message : String(parseError)}`
    );
    return null;
  }
}
var modelInitialized;
var init_anthropicModelHelpers = __esm({
  "src/clients/utils/anthropicModelHelpers.ts"() {
    "use strict";
    init_config();
    init_logger();
    init_utils();
    init_anthropicApiClient();
    modelInitialized = false;
  }
});

// src/clients/utils/anthropicApiClient.ts
async function fetchWithRetry2(url, options, retries) {
  const maxRetries = retries !== void 0 ? retries : configManager_default.getRateLimitConfig().maxRetries;
  for (let i = 0; i < maxRetries; i++) {
    try {
      if (configManager_default.getApplicationConfig().debug.value) {
        console.error(`

==== ANTHROPIC API REQUEST ====`);
        console.error(`Attempt: ${i + 1}/${maxRetries}`);
        console.error(`URL: ${url}`);
        console.error(`Method: ${options.method}`);
        console.error(`Headers: ${JSON.stringify(options.headers, null, 2)}`);
        console.error(`Body (first 500 chars): ${String(options.body).substring(0, 500)}...`);
        console.error(`==== END REQUEST ====
`);
      }
      const res = await fetch(url, options);
      if (configManager_default.getApplicationConfig().debug.value) {
        console.error(`

==== ANTHROPIC API RESPONSE ====`);
        console.error(`Status: ${res.status}`);
        console.error(`Status Text: ${res.statusText}`);
        const headersObj = {};
        res.headers.forEach((value, key) => {
          if (key && value) headersObj[key] = value;
        });
        console.error(`Headers: ${JSON.stringify(headersObj, null, 2)}`);
        console.error(`==== END RESPONSE HEADERS ====
`);
      }
      if (res.ok) return res;
      try {
        const errorText = await res.text();
        if (configManager_default.getApplicationConfig().debug.value) {
          console.error(`

==== ANTHROPIC API ERROR DETAILS ====`);
          console.error(`Error response body: ${errorText}`);
          try {
            const errorJson = JSON.parse(errorText);
            console.error(`Error type: ${errorJson.type || "unknown"}`);
            console.error(`Error message: ${errorJson.message || "unknown"}`);
            if (errorJson.error) {
              console.error(`Detailed error: ${JSON.stringify(errorJson.error, null, 2)}`);
            }
          } catch (jsonError) {
            console.error(`Error response is not valid JSON: ${jsonError instanceof Error ? jsonError.message : String(jsonError)}`);
          }
          console.error(`==== END ERROR DETAILS ====

`);
        }
        return new Response(errorText, {
          status: res.status,
          statusText: res.statusText,
          headers: res.headers
        });
      } catch (readError) {
        console.error(`Could not read error response: ${readError}`);
      }
      if (res.status === 429 || res.status >= 500) {
        const retryDelay = configManager_default.getRateLimitConfig().retryDelayMs * (i + 1);
        logger_default.debug(`Retrying after ${retryDelay}ms delay...`);
        await new Promise((r) => setTimeout(r, retryDelay));
      } else {
        logger_default.debug(`Non-retryable error status: ${res.status}`);
        throw new Error(
          `Anthropic API request failed with status ${res.status}: ${res.statusText}`
        );
      }
    } catch (error2) {
      logger_default.debug(`Fetch error: ${error2}`);
      if (i === maxRetries - 1) throw error2;
      const retryDelay = configManager_default.getRateLimitConfig().retryDelayMs * (i + 1);
      logger_default.debug(`Retrying after ${retryDelay}ms delay...`);
      await new Promise((r) => setTimeout(r, retryDelay));
    }
  }
  throw new Error("Anthropic API request failed after all retry attempts");
}
async function testAnthropicApiAccess(apiKey, modelName) {
  try {
    if (configManager_default.getApplicationConfig().debug.value) {
      console.error("\n\n==== ANTHROPIC API DEBUG ====");
      console.error(`Testing model: ${modelName}`);
      console.error(`API URL: ${configManager_default.getApiEndpoint("anthropic")}`);
      console.error(`API Version: ${configManager_default.getApiVersion("anthropic")}`);
      console.error(`============================
`);
    }
    logger_default.info(`Initializing Anthropic model: ${modelName}...`);
    const { getApiModelName: getApiModelName2 } = await Promise.resolve().then(() => (init_anthropicModelHelpers(), anthropicModelHelpers_exports));
    const apiModelName = await getApiModelName2(modelName);
    if (!apiModelName) {
      throw new Error(`Could not determine API model name for ${modelName}`);
    }
    logger_default.debug(`Test API access using model: ${apiModelName} (from ${modelName})`);
    console.error(`Test API access using model: ${apiModelName} (from ${modelName})`);
    const requestBody = {
      model: apiModelName,
      // Use the format from our configuration
      system: "You are a helpful AI assistant.",
      messages: [
        {
          role: "user",
          content: "Hello, are you available for a code review task?"
        }
      ],
      max_tokens: 100
    };
    logger_default.info(`Testing Anthropic API with model: ${apiModelName}`);
    logger_default.debug(`Request URL: https://api.anthropic.com/v1/messages`);
    logger_default.debug(`Request headers: Content-Type: application/json, anthropic-version: 2023-06-01, anthropic-beta: messages-2023-12-15`);
    logger_default.debug(`Request body: ${JSON.stringify(requestBody, null, 2)}`);
    if (configManager_default.getApplicationConfig().debug.value) {
      console.log(`

==== ANTHROPIC API REQUEST ====`);
      console.log(`URL: ${configManager_default.getApiEndpoint("anthropic")}`);
      console.log(`API Version: ${configManager_default.getApiVersion("anthropic")}`);
      console.log(`API Beta: messages-2023-12-15`);
      console.log(`Converted model: ${modelName} \u2192 ${apiModelName}`);
      console.log(`API Key exists: ${apiKey ? "YES" : "NO"}`);
      console.log(`API Key first 5 chars: ${apiKey?.substring(0, 5)}...`);
      console.log(`============================
`);
    }
    const apiEndpoint = configManager_default.getApiEndpoint("anthropic");
    const response = await fetchWithRetry2(
      apiEndpoint,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "x-api-key": apiKey,
          "anthropic-version": configManager_default.getApiVersion("anthropic"),
          "anthropic-beta": "messages-2023-12-15",
          "Accept": "application/json"
        },
        body: JSON.stringify(requestBody)
      }
    );
    try {
      logger_default.debug(`Response status: ${response.status}`);
      const responseText = await response.text();
      logger_default.debug(`Response text: ${responseText}`);
      logger_default.debug(`==== ANTHROPIC DEBUG ====`);
      logger_default.debug(`Request to Anthropic API for model: ${apiModelName}`);
      logger_default.debug(`Response status: ${response.status}`);
      logger_default.debug(`Response text: ${responseText}`);
      logger_default.debug(`========================`);
      if (!response.ok) {
        logger_default.error(
          `Error initializing Anthropic model ${modelName}: ${responseText}`
        );
        return false;
      }
      try {
        const data = JSON.parse(responseText);
        logger_default.debug(`Parsed response: ${JSON.stringify(data, null, 2)}`);
        if (data.content && data.content.length > 0) {
          logger_default.info(`Successfully initialized Anthropic model: ${modelName}`);
          return true;
        }
        logger_default.error(
          `Unexpected response format from Anthropic model ${modelName}: ${JSON.stringify(data)}`
        );
        return false;
      } catch (parseError) {
        logger_default.error(`Error parsing JSON response: ${parseError}`);
        return false;
      }
    } catch (error2) {
      logger_default.error(`Error reading response: ${error2}`);
      return false;
    }
  } catch (error2) {
    logger_default.error(`Error initializing Anthropic model ${modelName}`);
    return false;
  }
}
async function makeAnthropicRequest(apiKey, modelName, systemPrompt, userPrompt, temperature = 0.2, tools) {
  const { getApiModelName: getApiModelName2 } = await Promise.resolve().then(() => (init_anthropicModelHelpers(), anthropicModelHelpers_exports));
  const apiModelName = await getApiModelName2(modelName);
  if (!apiModelName) {
    throw new Error(`Could not determine API model name for ${modelName}`);
  }
  logger_default.debug(`makeAnthropicRequest: Using model ${apiModelName} from mappings (model: ${modelName})`);
  const requestOptions = {
    model: apiModelName,
    // Use the format from our configuration
    system: systemPrompt,
    messages: [{ role: "user", content: userPrompt }],
    temperature,
    max_tokens: configManager_default.getTokenConfig("anthropic").maxTokensPerRequest
  };
  if (tools && tools.length > 0) {
    requestOptions.tools = tools;
  }
  const apiEndpoint = configManager_default.getApiEndpoint("anthropic");
  const response = await fetchWithRetry2(
    apiEndpoint,
    {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-api-key": apiKey,
        "anthropic-version": configManager_default.getApiVersion("anthropic"),
        "anthropic-beta": "messages-2023-12-15",
        "Accept": "application/json"
      },
      body: JSON.stringify(requestOptions)
    }
  );
  await handleFetchResponse(response, "Anthropic");
  return safeJsonParse(response, "Anthropic");
}
var init_anthropicApiClient = __esm({
  "src/clients/utils/anthropicApiClient.ts"() {
    "use strict";
    init_logger();
    init_apiErrorHandler();
    init_configManager();
  }
});

// src/clients/implementations/anthropicClient.ts
var AnthropicClient;
var init_anthropicClient = __esm({
  "src/clients/implementations/anthropicClient.ts"() {
    "use strict";
    init_base();
    init_logger();
    init_promptFormatter();
    init_promptLoader();
    init_anthropicApiClient();
    init_anthropicModelHelpers();
    AnthropicClient = class extends AbstractClient {
      apiKey = "";
      /**
       * Initialize with default values
       */
      constructor() {
        super();
        this.modelName = "";
        this.isInitialized = false;
        this.apiKey = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY || "";
      }
      /**
       * Check if the provided model name is supported by this client
       * @param modelName The full model name (potentially with provider prefix)
       * @returns Object indicating if this is the correct client for the model
       */
      isModelSupported(modelName) {
        return detectModelProvider("anthropic", modelName);
      }
      /**
       * Get the provider name for this client
       * @returns The provider name
       */
      getProviderName() {
        return "anthropic";
      }
      /**
       * Initialize the Anthropic client
       * @returns Promise resolving to a boolean indicating success
       */
      async initialize() {
        if (this.isInitialized) {
          return true;
        }
        const { isCorrect, modelName } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          return true;
        }
        this.modelName = modelName;
        if (!validateApiKey("anthropic", "AI_CODE_REVIEW_ANTHROPIC_API_KEY")) {
          process.exit(1);
        }
        try {
          logger_default.info(`Initializing Anthropic model: ${this.modelName}...`);
          const success = await testAnthropicApiAccess(this.apiKey, this.modelName);
          if (success) {
            this.isInitialized = true;
            logger_default.info(`Successfully initialized Anthropic model: ${this.modelName}`);
            return true;
          }
          logger_default.error(`Failed to initialize Anthropic model: ${this.modelName}`);
          return false;
        } catch (error2) {
          logger_default.error(
            `Error initializing Anthropic model ${this.modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return false;
        }
      }
      /**
       * Generate a review for a single file
       * @param fileContent Content of the file to review
       * @param filePath Path to the file
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateReview(fileContent, filePath, reviewType, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `Anthropic client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatSingleFileReviewPrompt(
            promptTemplate,
            fileContent,
            filePath,
            projectDocs
          );
          try {
            logger_default.info(`Generating review with Anthropic ${this.modelName}...`);
            const systemPrompt = `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`;
            const response = await makeAnthropicRequest(
              this.apiKey,
              this.modelName,
              systemPrompt,
              prompt,
              0.2
            );
            const content = response.content[0]?.text || "";
            if (!content) {
              throw new Error(`Empty response from Anthropic ${this.modelName}`);
            }
            logger_default.info(`Successfully generated review with Anthropic ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              filePath,
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(error2, "generate review", this.getFullModelName());
          }
        } catch (error2) {
          this.handleApiError(error2, "generating review", filePath);
        }
      }
      /**
       * Generate a consolidated review for multiple files
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `Anthropic client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatConsolidatedReviewPrompt(
            promptTemplate,
            projectName,
            files.map((file) => ({
              relativePath: file.relativePath || "",
              content: file.content,
              sizeInBytes: file.content.length
            })),
            projectDocs
          );
          try {
            logger_default.info(`Generating consolidated review with Anthropic ${this.modelName}...`);
            const systemPrompt = `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`;
            const response = await makeAnthropicRequest(
              this.apiKey,
              this.modelName,
              systemPrompt,
              prompt,
              0.2
            );
            const content = response.content[0]?.text || "";
            if (!content) {
              throw new Error(`Empty response from Anthropic ${this.modelName}`);
            }
            logger_default.info(`Successfully generated consolidated review with Anthropic ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              "consolidated",
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(
              error2,
              "generate consolidated review",
              this.getFullModelName()
            );
          }
        } catch (error2) {
          this.handleApiError(error2, "generating consolidated review", projectName);
        }
      }
      /**
       * Generate an architectural review for a project
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateArchitecturalReview(files, projectName, projectDocs, options) {
        return this.generateConsolidatedReview(
          files,
          projectName,
          "architectural",
          projectDocs,
          options
        );
      }
    };
  }
});

// src/utils/api/rateLimiter.ts
var RateLimiter, globalRateLimiter;
var init_rateLimiter = __esm({
  "src/utils/api/rateLimiter.ts"() {
    "use strict";
    init_logger();
    RateLimiter = class {
      bucketSize;
      tokensPerSecond;
      tokens;
      lastRefillTime;
      waitQueue = [];
      /**
       * Create a new rate limiter
       * @param options Rate limiter options
       */
      constructor(options) {
        this.bucketSize = options.bucketSize;
        this.tokensPerSecond = options.tokensPerSecond;
        this.tokens = options.initialTokens ?? this.bucketSize;
        this.lastRefillTime = Date.now();
      }
      /**
       * Refill the token bucket based on elapsed time
       */
      refill() {
        const now = Date.now();
        const elapsedSeconds = (now - this.lastRefillTime) / 1e3;
        const newTokens = elapsedSeconds * this.tokensPerSecond;
        if (newTokens > 0) {
          this.tokens = Math.min(this.bucketSize, this.tokens + newTokens);
          this.lastRefillTime = now;
        }
      }
      /**
       * Process the wait queue
       */
      processQueue() {
        while (this.waitQueue.length > 0 && this.tokens >= 1) {
          const { resolve: resolve8, timeout } = this.waitQueue.shift();
          clearTimeout(timeout);
          this.tokens -= 1;
          resolve8();
        }
      }
      /**
       * Acquire a token from the bucket
       * @param timeoutMs Timeout in milliseconds
       * @returns Promise that resolves when a token is acquired
       */
      async acquire(timeoutMs = 3e4) {
        this.refill();
        if (this.tokens >= 1) {
          this.tokens -= 1;
          return Promise.resolve();
        }
        return new Promise((resolve8, reject) => {
          const timeout = setTimeout(() => {
            const index = this.waitQueue.findIndex(
              (item) => item.resolve === resolve8
            );
            if (index !== -1) {
              this.waitQueue.splice(index, 1);
            }
            reject(new Error("Rate limit timeout exceeded"));
          }, timeoutMs);
          this.waitQueue.push({ resolve: resolve8, reject, timeout });
          if (this.waitQueue.length > 5) {
            logger_default.warn(`Rate limiter queue length: ${this.waitQueue.length}`);
          }
        });
      }
      /**
       * Get the current number of tokens in the bucket
       * @returns Number of tokens
       */
      getTokens() {
        this.refill();
        return this.tokens;
      }
      /**
       * Get the current queue length
       * @returns Queue length
       */
      getQueueLength() {
        return this.waitQueue.length;
      }
    };
    globalRateLimiter = new RateLimiter({
      bucketSize: 10,
      tokensPerSecond: 2
    });
  }
});

// src/utils/rateLimiter.ts
var init_rateLimiter2 = __esm({
  "src/utils/rateLimiter.ts"() {
    "use strict";
    init_rateLimiter();
  }
});

// src/clients/implementations/geminiClient.ts
var import_generative_ai, DEFAULT_SAFETY_SETTINGS, MAX_TOKENS_PER_REQUEST2, GeminiClient;
var init_geminiClient = __esm({
  "src/clients/implementations/geminiClient.ts"() {
    "use strict";
    init_base();
    init_logger();
    init_promptFormatter();
    init_promptLoader();
    import_generative_ai = require("@google/generative-ai");
    init_rateLimiter2();
    DEFAULT_SAFETY_SETTINGS = [
      {
        category: import_generative_ai.HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: import_generative_ai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
      },
      {
        category: import_generative_ai.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: import_generative_ai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
      },
      {
        category: import_generative_ai.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: import_generative_ai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
      },
      {
        category: import_generative_ai.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: import_generative_ai.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
      }
    ];
    MAX_TOKENS_PER_REQUEST2 = 8192;
    GeminiClient = class extends AbstractClient {
      apiKey;
      genAI = null;
      customModel = null;
      /**
       * Initialize with default values
       */
      constructor() {
        super();
        this.modelName = "";
        this.isInitialized = false;
        this.apiKey = process.env.AI_CODE_REVIEW_GOOGLE_API_KEY;
      }
      /**
       * Check if the provided model name is supported by this client
       * @param modelName The full model name (potentially with provider prefix)
       * @returns Object indicating if this is the correct client for the model
       */
      isModelSupported(modelName) {
        return detectModelProvider("gemini", modelName);
      }
      /**
       * Get the provider name for this client
       * @returns The provider name
       */
      getProviderName() {
        return "gemini";
      }
      /**
       * Initialize the Gemini client
       * @returns Promise resolving to a boolean indicating success
       */
      async initialize() {
        if (this.isInitialized) {
          return true;
        }
        const { getConfig: getConfig2 } = await Promise.resolve().then(() => (init_config(), config_exports));
        const config4 = getConfig2();
        const selectedModel = config4.selectedModel;
        const { isCorrect, modelName } = this.isModelSupported(selectedModel);
        if (!isCorrect) {
          return true;
        }
        this.modelName = modelName;
        if (!validateApiKey("gemini", "AI_CODE_REVIEW_GOOGLE_API_KEY")) {
          process.exit(1);
        }
        try {
          const { MODEL_MAP: MODEL_MAP2 } = await Promise.resolve().then(() => (init_modelMaps2(), modelMaps_exports));
          const modelMapping = MODEL_MAP2[selectedModel];
          const apiModelName = modelMapping?.apiIdentifier || this.modelName;
          const useV1Beta = modelMapping?.useV1Beta || false;
          logger_default.info(`Initializing Gemini model: ${this.modelName} (API: ${apiModelName})...`);
          this.genAI = new import_generative_ai.GoogleGenerativeAI(this.apiKey || "");
          this.customModel = {
            name: apiModelName,
            // Use the actual API identifier
            displayName: this.modelName,
            useV1Beta
          };
          this.isInitialized = true;
          logger_default.info(`Successfully initialized Gemini model: ${this.modelName} (API: ${apiModelName})`);
          return true;
        } catch (error2) {
          logger_default.error(
            `Error initializing Gemini model ${this.modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return false;
        }
      }
      /**
       * Generate a review for a single file
       * @param fileContent Content of the file to review
       * @param filePath Path to the file
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateReview(fileContent, filePath, reviewType, projectDocs, options) {
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          await globalRateLimiter.acquire();
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatSingleFileReviewPrompt(
            promptTemplate,
            fileContent,
            filePath,
            projectDocs
          );
          try {
            logger_default.info(`Generating review with Gemini ${this.modelName}...`);
            const response = await this.generateGeminiResponse(prompt, options);
            logger_default.info(`Successfully generated review with Gemini ${this.modelName}`);
            return createStandardReviewResult(
              response,
              prompt,
              this.getFullModelName(),
              filePath,
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(error2, "generate review", this.getFullModelName());
          }
        } catch (error2) {
          this.handleApiError(error2, "generating review", filePath);
        }
      }
      /**
       * Generate a consolidated review for multiple files
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          await globalRateLimiter.acquire();
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatConsolidatedReviewPrompt(
            promptTemplate,
            projectName,
            files.map((file) => ({
              relativePath: file.relativePath || "",
              content: file.content,
              sizeInBytes: file.content.length
            })),
            projectDocs
          );
          try {
            logger_default.info(`Generating consolidated review with Gemini ${this.modelName}...`);
            const response = await this.generateGeminiResponse(prompt, options);
            logger_default.info(`Successfully generated consolidated review with Gemini ${this.modelName}`);
            return createStandardReviewResult(
              response,
              prompt,
              this.getFullModelName(),
              "consolidated",
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(
              error2,
              "generate consolidated review",
              this.getFullModelName()
            );
          }
        } catch (error2) {
          this.handleApiError(error2, "generating consolidated review", projectName);
        }
      }
      /**
       * Generate an architectural review for a project
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateArchitecturalReview(files, projectName, projectDocs, options) {
        return this.generateConsolidatedReview(
          files,
          projectName,
          "architectural",
          projectDocs,
          options
        );
      }
      /**
       * Generate a response from the Gemini API
       * @param prompt The prompt to send to the API
       * @param options Review options
       * @returns Promise resolving to the response text
       */
      async generateGeminiResponse(prompt, options) {
        if (!this.genAI || !this.customModel) {
          throw new Error("Gemini client not initialized");
        }
        try {
          const modelOptions = {
            model: this.customModel.name,
            safetySettings: DEFAULT_SAFETY_SETTINGS,
            apiVersion: this.customModel.useV1Beta ? "v1beta" : void 0
          };
          const model = this.genAI.getGenerativeModel(modelOptions);
          const isInteractiveMode = options?.interactive === true;
          let outputInstructions = "";
          if (isInteractiveMode) {
            outputInstructions = `
You are a helpful AI assistant that provides code reviews. Focus on providing actionable feedback. Do not repeat the instructions in your response.

CRITICAL INSTRUCTION: Your response MUST be valid JSON that follows the exact schema below.
DO NOT include any text, markdown, or explanations outside of this JSON structure.
DO NOT use markdown code blocks. Return ONLY the raw JSON object.

IMPORTANT: DO NOT include comments in your JSON response. In the schema below, comments are shown for explanation, but your output must be valid JSON without comments.

The response must validate against this schema:
{
  "review": {
    "version": "1.0",
    "timestamp": "2024-05-15T12:00:00Z", 
    "files": [
      {
        "filePath": "path/to/file.ts", 
        "issues": [
          {
            "id": "ISSUE-1", 
            "priority": "HIGH", 
            "description": "A clear description of the issue",
            "location": {
              "startLine": 10, 
              "endLine": 15 
            },
            "currentCode": "function example() {\\n  // Problematic code here\\n}", 
            "suggestedCode": "function example() {\\n  // Improved code here\\n}", 
            "explanation": "Detailed explanation of why this change is recommended"
          }
        ]
      }
    ],
    "summary": {
      "highPriorityIssues": 1, 
      "mediumPriorityIssues": 2, 
      "lowPriorityIssues": 3, 
      "totalIssues": 6 
    }
  }
}

Guidelines for filling the schema:
1. Each issue must have a unique ID (e.g., "ISSUE-1", "ISSUE-2")
2. Priority must be exactly one of: "HIGH", "MEDIUM", "LOW" - use uppercase only
3. Location should include the start and end line numbers of the affected code
4. Current code should be the exact code snippet that needs to be changed
5. Suggested code should be the improved version of the code
6. Explanation should provide a detailed rationale for the suggested change
7. The summary should accurately count the number of issues by priority
8. Ensure counts are accurate - totalIssues should equal the sum of all priority counts
9. For string fields, ensure all quotes and backslashes are properly escaped
10. For code snippets, use double backslashes for newlines (\\n) and escape any quotes or backslashes

CRITICAL: YOUR OUTPUT MUST BE VALID JSON WITH NO TEXT OUTSIDE THE JSON STRUCTURE.
DO NOT USE COMMENTS IN YOUR FINAL JSON. 
DO NOT USE MARKDOWN CODE BLOCKS.
DO NOT START WITH TRIPLE BACKTICKS OR END WITH TRIPLE BACKTICKS.
DO NOT EXPLAIN OR DESCRIBE YOUR RESPONSE.
`;
          } else {
            outputInstructions = `
You are a helpful AI assistant that provides code reviews. Focus on providing actionable feedback. Do not repeat the instructions in your response.

IMPORTANT: Format your response as a well-structured Markdown document with the following sections:

# Code Review

## Summary
A brief summary of the code review.

## Issues

### High Priority
For each high priority issue:
- Issue title
- File path and line numbers
- Description of the issue
- Code snippet (if relevant)
- Suggested fix
- Impact of the issue

### Medium Priority
(Same format as high priority)

### Low Priority
(Same format as high priority)

## General Recommendations
- List of general recommendations

## Positive Aspects
- List of positive aspects of the code

Ensure your response is well-formatted Markdown with proper headings, bullet points, and code blocks.
`;
          }
          const modifiedPrompt = outputInstructions + "\n\n" + prompt;
          const temperature = isInteractiveMode ? 0.1 : 0.2;
          const result = await withRetry(
            () => model.generateContent({
              contents: [
                {
                  role: "user",
                  parts: [{ text: modifiedPrompt }]
                }
              ],
              generationConfig: {
                temperature,
                topP: 0.8,
                topK: 40,
                maxOutputTokens: MAX_TOKENS_PER_REQUEST2
              }
            })
          );
          const response = result.response;
          const text = response.text();
          if (isInteractiveMode) {
            try {
              const trimmedText = text.trim();
              if (!trimmedText.startsWith("{") || !trimmedText.endsWith("}")) {
                logger_default.warn("Response from Gemini is not properly formatted as JSON. Attempting to extract JSON...");
                const extractedJson = trimmedText.match(/({[\s\S]*})/);
                if (extractedJson) {
                  return extractedJson[1];
                }
                const languageMatch = trimmedText.match(/^(?:typescript|javascript|json|ts|js)\s*\n?\s*({[\s\S]*})$/i);
                if (languageMatch) {
                  logger_default.info("Found JSON after language identifier, extracting...");
                  return languageMatch[1];
                }
                const codeBlockMatch = trimmedText.match(/```(?:json|typescript|javascript)?\s*([^`]+)\s*```/i);
                if (codeBlockMatch) {
                  const blockContent = codeBlockMatch[1].trim();
                  const cleanContent = blockContent.replace(/^(?:typescript|javascript|json|ts|js)\s*\n?/i, "");
                  if (cleanContent.startsWith("{")) {
                    logger_default.info("Found JSON in code block, extracting...");
                    return cleanContent;
                  }
                }
                const braceIndex = trimmedText.indexOf("{");
                if (braceIndex > 0) {
                  const jsonCandidate = trimmedText.substring(braceIndex);
                  try {
                    JSON.parse(jsonCandidate);
                    logger_default.info("Successfully extracted JSON by removing prefix content");
                    return jsonCandidate;
                  } catch (parseError) {
                  }
                }
                logger_default.error("Failed to extract JSON from Gemini response");
                throw new Error("Gemini API returned a response that is not valid JSON");
              }
            } catch (error2) {
              logger_default.error("Error validating JSON response:", error2);
              throw new Error("Gemini API returned a response that is not valid JSON");
            }
          }
          return text;
        } catch (error2) {
          if (error2 instanceof Error) {
            throw new Error(`Gemini API error: ${error2.message}`);
          } else {
            throw new Error(`Unknown Gemini API error: ${String(error2)}`);
          }
        }
      }
    };
  }
});

// src/clients/implementations/openRouterClient.ts
var MAX_TOKENS_PER_REQUEST3, OpenRouterClient;
var init_openRouterClient = __esm({
  "src/clients/implementations/openRouterClient.ts"() {
    "use strict";
    init_base();
    init_logger();
    init_promptFormatter();
    init_promptLoader();
    MAX_TOKENS_PER_REQUEST3 = 4e3;
    OpenRouterClient = class extends AbstractClient {
      apiKey;
      /**
       * Initialize with default values
       */
      constructor() {
        super();
        this.modelName = "";
        this.isInitialized = false;
        this.apiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY;
      }
      /**
       * Check if the provided model name is supported by this client
       * @param modelName The full model name (potentially with provider prefix)
       * @returns Object indicating if this is the correct client for the model
       */
      isModelSupported(modelName) {
        return detectModelProvider("openrouter", modelName);
      }
      /**
       * Get the provider name for this client
       * @returns The provider name
       */
      getProviderName() {
        return "openrouter";
      }
      /**
       * Initialize the OpenRouter client
       * @returns Promise resolving to a boolean indicating success
       */
      async initialize() {
        if (this.isInitialized) {
          return true;
        }
        const { isCorrect, modelName } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          return true;
        }
        this.modelName = modelName;
        if (!validateApiKey("openrouter", "AI_CODE_REVIEW_OPENROUTER_API_KEY")) {
          process.exit(1);
        }
        try {
          logger_default.info(`Initializing OpenRouter model: ${this.modelName}...`);
          this.isInitialized = true;
          logger_default.info(`Successfully initialized OpenRouter model: ${this.modelName}`);
          return true;
        } catch (error2) {
          logger_default.error(
            `Error initializing OpenRouter model ${this.modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
          );
          return false;
        }
      }
      /**
       * Generate a review for a single file
       * @param fileContent Content of the file to review
       * @param filePath Path to the file
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateReview(fileContent, filePath, reviewType, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `OpenRouter client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatSingleFileReviewPrompt(
            promptTemplate,
            fileContent,
            filePath,
            projectDocs
          );
          try {
            logger_default.info(`Generating review with OpenRouter ${this.modelName}...`);
            const response = await fetchWithRetry(
              "https://openrouter.ai/api/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  "Authorization": `Bearer ${this.apiKey}`,
                  "HTTP-Referer": "https://ai-code-review.app",
                  // Required by OpenRouter
                  "X-Title": "AI Code Review"
                  // Optional for OpenRouter stats
                },
                body: JSON.stringify({
                  model: this.modelName,
                  messages: [
                    {
                      role: "system",
                      content: `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`
                    },
                    {
                      role: "user",
                      content: prompt
                    }
                  ],
                  temperature: 0.2,
                  max_tokens: MAX_TOKENS_PER_REQUEST3
                })
              }
            );
            const data = await response.json();
            if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
              throw new Error(`Invalid response format from OpenRouter ${this.modelName}`);
            }
            const content = data.choices[0].message.content;
            logger_default.info(`Successfully generated review with OpenRouter ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              filePath,
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(error2, "generate review", this.getFullModelName());
          }
        } catch (error2) {
          this.handleApiError(error2, "generating review", filePath);
        }
      }
      /**
       * Generate a consolidated review for multiple files
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param reviewType Type of review to perform
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
        const { isCorrect } = this.isModelSupported(process.env.AI_CODE_REVIEW_MODEL || "");
        if (!isCorrect) {
          throw new Error(
            `OpenRouter client was called with an invalid model. This is likely a bug in the client selection logic.`
          );
        }
        try {
          if (!this.isInitialized) {
            await this.initialize();
          }
          const promptTemplate = await loadPromptTemplate2(reviewType, options);
          const prompt = formatConsolidatedReviewPrompt(
            promptTemplate,
            projectName,
            files.map((file) => ({
              relativePath: file.relativePath || "",
              content: file.content,
              sizeInBytes: file.content.length
            })),
            projectDocs
          );
          try {
            logger_default.info(`Generating consolidated review with OpenRouter ${this.modelName}...`);
            const response = await fetchWithRetry(
              "https://openrouter.ai/api/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  "Authorization": `Bearer ${this.apiKey}`,
                  "HTTP-Referer": "https://ai-code-review.app",
                  // Required by OpenRouter
                  "X-Title": "AI Code Review"
                  // Optional for OpenRouter stats
                },
                body: JSON.stringify({
                  model: this.modelName,
                  messages: [
                    {
                      role: "system",
                      content: `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`
                    },
                    {
                      role: "user",
                      content: prompt
                    }
                  ],
                  temperature: 0.2,
                  max_tokens: MAX_TOKENS_PER_REQUEST3
                })
              }
            );
            const data = await response.json();
            if (!Array.isArray(data.choices) || !data.choices[0]?.message?.content) {
              throw new Error(`Invalid response format from OpenRouter ${this.modelName}`);
            }
            const content = data.choices[0].message.content;
            logger_default.info(`Successfully generated consolidated review with OpenRouter ${this.modelName}`);
            return createStandardReviewResult(
              content,
              prompt,
              this.getFullModelName(),
              "consolidated",
              reviewType,
              options
            );
          } catch (error2) {
            throw handleApiError(
              error2,
              "generate consolidated review",
              this.getFullModelName()
            );
          }
        } catch (error2) {
          this.handleApiError(error2, "generating consolidated review", projectName);
        }
      }
      /**
       * Generate an architectural review for a project
       * @param files Array of file information objects
       * @param projectName Name of the project
       * @param projectDocs Optional project documentation
       * @param options Review options
       * @returns Promise resolving to the review result
       */
      async generateArchitecturalReview(files, projectName, projectDocs, options) {
        return this.generateConsolidatedReview(
          files,
          projectName,
          "architectural",
          projectDocs,
          options
        );
      }
    };
  }
});

// src/clients/implementations/index.ts
var init_implementations = __esm({
  "src/clients/implementations/index.ts"() {
    "use strict";
    init_openaiClient();
    init_anthropicClient();
    init_geminiClient();
    init_openRouterClient();
  }
});

// src/clients/factory/clientFactory.ts
var ClientFactory;
var init_clientFactory = __esm({
  "src/clients/factory/clientFactory.ts"() {
    "use strict";
    init_implementations();
    init_config();
    init_logger();
    ClientFactory = class _ClientFactory {
      /**
       * Create an appropriate client instance based on the selected model
       * @param overrideModel Optional model to use instead of the configured one
       * @returns The client instance
       */
      static createClient(overrideModel) {
        const config4 = getConfig();
        const selectedModel = overrideModel || config4.selectedModel || "";
        const clientType = _ClientFactory.detectClientType(selectedModel);
        switch (clientType) {
          case "openai" /* OPENAI */:
            logger_default.info(`Creating OpenAI client for model: ${selectedModel}`);
            return new OpenAIClient();
          case "anthropic" /* ANTHROPIC */:
            logger_default.info(`Creating Anthropic client for model: ${selectedModel}`);
            return new AnthropicClient();
          case "gemini" /* GEMINI */:
            logger_default.info(`Creating Gemini client for model: ${selectedModel}`);
            return new GeminiClient();
          case "openrouter" /* OPEN_ROUTER */:
            logger_default.info(`Creating OpenRouter client for model: ${selectedModel}`);
            return new OpenRouterClient();
          default:
            logger_default.warn(`Unsupported client type for model: ${selectedModel}, falling back to OpenAI client`);
            return new OpenAIClient();
        }
      }
      /**
       * Detect the client type from the model name
       * @param modelName The model name to check
       * @returns The detected client type
       */
      static detectClientType(modelName) {
        if (!modelName) {
          return "unknown" /* UNKNOWN */;
        }
        const [adapter] = modelName.includes(":") ? modelName.split(":") : [modelName];
        switch (adapter.toLowerCase()) {
          case "openai":
          case "gpt":
            return "openai" /* OPENAI */;
          case "anthropic":
          case "claude":
            return "anthropic" /* ANTHROPIC */;
          case "gemini":
          case "google":
            return "gemini" /* GEMINI */;
          case "openrouter":
            return "openrouter" /* OPEN_ROUTER */;
          default:
            return "unknown" /* UNKNOWN */;
        }
      }
    };
  }
});

// src/clients/utils/anthropicReviewGenerators.ts
async function generateAnthropicConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
  const { isCorrect, adapter, modelName } = isAnthropicModel();
  if (!isCorrect) {
    throw new Error(
      `Anthropic client was called with an invalid model: ${adapter ? adapter + ":" + modelName : "none specified"}. This is likely a bug in the client selection logic.`
    );
  }
  try {
    await initializeAnthropicClient();
    const apiKey = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY;
    let content;
    let cost;
    let structuredData = null;
    const promptTemplate = await loadPromptTemplate2(reviewType, options);
    const fileInfos = files.map((file) => ({
      relativePath: file.relativePath,
      content: file.content.substring(0, 1e3) + (file.content.length > 1e3 ? "\n... (truncated)" : ""),
      sizeInBytes: file.content.length
    }));
    const userPrompt = formatConsolidatedReviewPrompt(
      promptTemplate,
      projectName,
      fileInfos,
      projectDocs
    );
    try {
      logger_default.info(`Generating consolidated review with Anthropic ${modelName}...`);
      const apiModelName = await getApiModelName(modelName);
      if (!apiKey) {
        throw new Error("Anthropic API key is missing");
      }
      const data = await makeAnthropicRequest(
        apiKey,
        apiModelName,
        STRUCTURED_REVIEW_SYSTEM_PROMPT,
        userPrompt
      );
      if (data.content && data.content.length > 0) {
        content = data.content[0].text;
        logger_default.info(`Successfully generated review with Anthropic ${modelName}`);
      } else {
        throw new Error(`Invalid response format from Anthropic ${modelName}`);
      }
      try {
        cost = getCostInfoFromText(content, `anthropic:${modelName}`);
      } catch (error2) {
        logger_default.warn(
          `Failed to calculate cost information: ${error2 instanceof Error ? error2.message : String(error2)}`
        );
      }
      structuredData = parseJsonResponse(content);
    } catch (error2) {
      throw new Error(
        `Failed to generate consolidated review with Anthropic ${modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
      );
    }
    return {
      content,
      cost,
      costInfo: cost,
      // Add costInfo property for consistent access
      modelUsed: `anthropic:${modelName}`,
      filePath: "consolidated",
      reviewType,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      structuredData
    };
  } catch (error2) {
    logger_default.error(
      `Error generating consolidated review: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}
var STRUCTURED_REVIEW_SYSTEM_PROMPT;
var init_anthropicReviewGenerators = __esm({
  "src/clients/utils/anthropicReviewGenerators.ts"() {
    "use strict";
    init_apiErrorHandler();
    init_logger();
    init_tokenCounter();
    init_utils();
    init_anthropicApiClient();
    init_anthropicModelHelpers();
    STRUCTURED_REVIEW_SYSTEM_PROMPT = `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`;
  }
});

// src/utils/review/consolidateReview.ts
var consolidateReview_exports = {};
__export(consolidateReview_exports, {
  consolidateReview: () => consolidateReview
});
async function consolidateReview(review) {
  try {
    logger_default.debug("[CONSOLIDATION] Starting consolidation with:", {
      hasContent: !!review.content,
      contentLength: review.content?.length || 0,
      projectName: review.projectName,
      modelUsed: review.modelUsed,
      reviewType: review.reviewType,
      firstChars: review.content?.substring(0, 200) || "N/A"
    });
    const config4 = getConfig();
    const consolidationModel = config4.writerModel || config4.selectedModel;
    logger_default.info(`Creating client with model ${consolidationModel} for consolidation`);
    const originalModel = process.env.AI_CODE_REVIEW_MODEL;
    process.env.AI_CODE_REVIEW_MODEL = consolidationModel;
    try {
      const client = ClientFactory.createClient(consolidationModel);
      logger_default.debug("[CONSOLIDATION] Created client:", {
        clientType: client.constructor.name,
        model: consolidationModel
      });
      await client.initialize();
      logger_default.debug("[CONSOLIDATION] Client initialized successfully");
      const consolidationSystemPrompt = getConsolidationSystemPrompt();
      const consolidationPrompt = getConsolidationPrompt(review);
      logger_default.debug("[CONSOLIDATION] Prompts created:", {
        systemPromptLength: consolidationSystemPrompt.length,
        userPromptLength: consolidationPrompt.length
      });
      logger_default.info(`Consolidating multi-pass review with ${consolidationModel}...`);
      logger_default.debug("[CONSOLIDATION] Sending to generateConsolidatedReview with:", {
        filesCount: 1,
        fileName: "MULTI_PASS_REVIEW.md",
        contentLength: review.content?.length || 0,
        projectName: review.projectName || "ai-code-review",
        reviewType: review.reviewType,
        options: {
          type: review.reviewType,
          includeTests: false,
          output: "markdown",
          isConsolidation: true,
          consolidationMode: true,
          skipFileContent: false,
          interactive: false
        }
      });
      const [provider, modelName] = consolidationModel.split(":");
      if (provider === "openai") {
        const apiKey = process.env.AI_CODE_REVIEW_OPENAI_API_KEY;
        if (!apiKey) {
          throw new Error("OpenAI API key not found");
        }
        const { fetchWithRetry: fetchWithRetry3 } = await Promise.resolve().then(() => (init_httpClient(), httpClient_exports));
        const requestBody = {
          model: modelName,
          messages: [
            {
              role: "system",
              content: consolidationSystemPrompt
            },
            {
              role: "user",
              content: consolidationPrompt
            }
          ]
        };
        if (modelName.startsWith("o3")) {
          requestBody.max_completion_tokens = 4096;
        } else {
          requestBody.max_tokens = 4096;
          requestBody.temperature = 0.2;
        }
        logger_default.debug("[CONSOLIDATION] Making direct OpenAI API call with custom prompts");
        const response = await fetchWithRetry3(
          "https://api.openai.com/v1/chat/completions",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${apiKey}`
            },
            body: JSON.stringify(requestBody)
          }
        );
        const data = await response.json();
        if (!data.choices?.[0]?.message?.content) {
          throw new Error("Invalid API response");
        }
        const consolidatedContent = data.choices[0].message.content;
        logger_default.debug("[CONSOLIDATION] Received direct API response:", {
          contentLength: consolidatedContent.length,
          firstChars: consolidatedContent.substring(0, 200)
        });
        if (!consolidatedContent || consolidatedContent.trim() === "") {
          logger_default.warn("Received empty consolidation from direct API call");
          return createFallbackConsolidation(review);
        }
        logger_default.info("Successfully consolidated review with AI using direct API call");
        return consolidatedContent;
      } else {
        logger_default.info(`Using custom consolidation approach for ${provider} provider`);
        const fullConsolidationPrompt = `${consolidationSystemPrompt}

---

${consolidationPrompt}`;
        if (client.generateReview) {
          logger_default.debug("[CONSOLIDATION] Using generateReview method with custom consolidation prompt");
          const consolidationResult = await client.generateReview(
            fullConsolidationPrompt,
            // Use our custom consolidation prompt as the file content
            "CONSOLIDATION_TASK",
            // Special file path to indicate this is a consolidation
            "architectural",
            // Use architectural review type as it's most comprehensive
            null,
            // No project docs needed
            {
              type: "architectural",
              skipFileContent: true,
              // Don't try to include file content in the prompt
              isConsolidation: true,
              includeTests: false,
              output: "markdown",
              interactive: false
            }
          );
          return consolidationResult?.content || createFallbackConsolidation(review);
        } else {
          logger_default.warn(`Provider ${provider} does not support generateReview method, attempting direct API call`);
          const consolidationResult = await client.generateConsolidatedReview(
            [{
              path: "CONSOLIDATION_REQUEST.md",
              relativePath: "CONSOLIDATION_REQUEST.md",
              content: fullConsolidationPrompt
            }],
            review.projectName || "ai-code-review",
            "architectural",
            // Use architectural type
            null,
            {
              type: "architectural",
              includeTests: false,
              output: "markdown",
              isConsolidation: true,
              skipFileContent: true,
              interactive: false
            }
          );
          return consolidationResult?.content || createFallbackConsolidation(review);
        }
      }
    } finally {
      if (originalModel !== void 0) {
        process.env.AI_CODE_REVIEW_MODEL = originalModel;
      } else {
        delete process.env.AI_CODE_REVIEW_MODEL;
      }
    }
  } catch (error2) {
    logger_default.error(`Error consolidating review: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return createFallbackConsolidation(review);
  }
}
function getConsolidationSystemPrompt() {
  return `You are an expert code reviewer tasked with creating a consolidated final report from a multi-pass review. 
  
The review was conducted in multiple passes due to the large size of the codebase. You will receive the complete multi-pass review content and need to:

1. Extract and deduplicate all findings across all passes
2. Organize findings by priority (High/Critical, Medium/Important, Low/Minor)
3. Create a coherent executive summary
4. Provide overall grading and recommendations

The input contains multiple review passes in the format "## Pass X: Review of Y Files" followed by the review content for that pass.

Your task is to:
1. Analyze all the findings from each pass
2. Create a unified, coherent final report that consolidates all the insights
3. Eliminate redundancy and duplication
4. Prioritize the most important findings
5. Provide a comprehensive grade for the code, based on the following criteria:

## Grading System
Assign an overall letter grade (A+ to F) to the codebase, where:
- A+ to A-: Exceptional code with minimal issues
- B+ to B-: Good code with some minor improvements needed
- C+ to C-: Average code with several issues that should be addressed
- D+ to D-: Problematic code with significant issues requiring attention
- F: Critical issues that make the code unsuitable for production

Include plus (+) or minus (-) modifiers to provide more granular assessment.

For each major area (maintainability, performance, security, etc.), also provide a specific grade.

Explain your grading rationale clearly, citing specific evidence from the review.

## Output Format

Structure your consolidated report with these sections:
1. **Executive Summary**: Brief overview and overall grade
2. **Grading Breakdown**: Detailed grades by category with justification
3. **Critical Issues**: Most important problems to address (prioritized)
4. **Strengths**: Areas where the code excels
5. **Detailed Findings**: Consolidated findings across all passes
6. **Recommendations**: Actionable next steps, prioritized

Make this report comprehensive but focused on high-value insights. Be specific and actionable in your recommendations.`;
}
function getConsolidationPrompt(review) {
  const passCount = review.costInfo?.passCount || 5;
  const projectName = review.projectName || "ai-code-review";
  return `I have conducted a multi-pass code review of a project named "${projectName}" using the "${review.reviewType}" review type. The review was split into ${passCount} passes due to the size of the codebase.

Here are the results from all passes:

${review.content}

Please create a unified, consolidated report that:
1. Extracts ALL issues from each pass (look for sections like "### High Priority", "### Medium Priority", "### Low Priority", "#### Issue Title", etc.)
2. Deduplicates issues that appear in multiple passes
3. Organizes all issues into three clear sections:
   - **Critical Issues (High Priority)**: List all high-priority/critical findings
   - **Important Issues (Medium Priority)**: List all medium-priority/important findings  
   - **Minor Issues (Low Priority)**: List all low-priority/minor findings
4. Provides a comprehensive grade for the code quality with detailed category breakdowns
5. Maintains all the valuable insights from each pass

IMPORTANT: Make sure to actually extract and list the specific issues found in each pass. Do not leave the issue sections empty.

The consolidated report should begin with "# Consolidated Code Review Report: ${projectName}"

Present this as a unified analysis without mentioning individual pass numbers.

IMPORTANT: Use the actual current date (${(/* @__PURE__ */ new Date()).toLocaleDateString()}) in your report, not any dates mentioned in the review content.`;
}
function createFallbackConsolidation(review) {
  logger_default.info("Creating fallback consolidation from multi-pass results...");
  const projectName = review.projectName || "ai-code-review";
  const passRegex = /## Pass (\d+): Review of (\d+) Files([\s\S]*?)(?=## Pass \d+:|$)/g;
  const passes = [];
  let match;
  while ((match = passRegex.exec(review.content)) !== null) {
    const [, passNumberStr, fileCountStr, passContent] = match;
    passes.push({
      passNumber: parseInt(passNumberStr, 10),
      fileCount: parseInt(fileCountStr, 10),
      content: passContent.trim()
    });
  }
  logger_default.debug(`Found ${passes.length} passes in multi-pass review`);
  const highPriorityFindings = /* @__PURE__ */ new Set();
  const mediumPriorityFindings = /* @__PURE__ */ new Set();
  const lowPriorityFindings = /* @__PURE__ */ new Set();
  const highPriorityRegex = /### (?:High Priority|Critical Issues?)([\s\S]*?)(?=###|## Pass|$)/gi;
  const mediumPriorityRegex = /### (?:Medium Priority|Important Issues?)([\s\S]*?)(?=###|## Pass|$)/gi;
  const lowPriorityRegex = /### (?:Low Priority|Minor Issues?)([\s\S]*?)(?=###|## Pass|$)/gi;
  const extractIssueTitles = (content) => {
    const titles = [];
    const issueTitleRegex1 = /- \*\*Issue title:\*\* (.*?)(?=\n|$)/g;
    let match1;
    while ((match1 = issueTitleRegex1.exec(content)) !== null) {
      titles.push(match1[1].trim());
    }
    const issueTitleRegex2 = /####\s+([^\n]+)/g;
    let match2;
    while ((match2 = issueTitleRegex2.exec(content)) !== null) {
      titles.push(match2[1].trim());
    }
    const issueTitleRegex3 = /^[\s-]*\*?\s*(.+?)$/gm;
    if (titles.length === 0) {
      let match3;
      while ((match3 = issueTitleRegex3.exec(content)) !== null) {
        const line = match3[1].trim();
        if (line && !line.startsWith("Location:") && !line.startsWith("Type:") && !line.startsWith("Description:") && !line.startsWith("Impact:")) {
          titles.push(line);
        }
      }
    }
    return titles;
  };
  passes.forEach((pass) => {
    const passContent = pass.content;
    let highMatch;
    highPriorityRegex.lastIndex = 0;
    while ((highMatch = highPriorityRegex.exec(passContent)) !== null) {
      extractIssueTitles(highMatch[1]).forEach((title) => highPriorityFindings.add(title));
    }
    let mediumMatch;
    mediumPriorityRegex.lastIndex = 0;
    while ((mediumMatch = mediumPriorityRegex.exec(passContent)) !== null) {
      extractIssueTitles(mediumMatch[1]).forEach((title) => mediumPriorityFindings.add(title));
    }
    let lowMatch;
    lowPriorityRegex.lastIndex = 0;
    while ((lowMatch = lowPriorityRegex.exec(passContent)) !== null) {
      extractIssueTitles(lowMatch[1]).forEach((title) => lowPriorityFindings.add(title));
    }
  });
  logger_default.debug(`Extracted findings - High: ${highPriorityFindings.size}, Medium: ${mediumPriorityFindings.size}, Low: ${lowPriorityFindings.size}`);
  return `# Consolidated ${review.reviewType.charAt(0).toUpperCase() + review.reviewType.slice(1)} Review Report: ${projectName}

## Executive Summary

This consolidated review was generated from ${passes.length} passes analyzing a total of ${passes.reduce((sum, pass) => sum + pass.fileCount, 0)} files. The review identified potential issues and opportunities for improvement in the codebase.

### Key Findings

${highPriorityFindings.size > 0 ? `- ${highPriorityFindings.size} high-priority issues identified` : ""}
${mediumPriorityFindings.size > 0 ? `- ${mediumPriorityFindings.size} medium-priority issues identified` : ""}
${lowPriorityFindings.size > 0 ? `- ${lowPriorityFindings.size} low-priority issues identified` : ""}

## Grading

Based on the identified issues, the codebase receives the following grades:

| Category | Grade | Justification |
|----------|-------|---------------|
| Functionality | B | The code appears to function correctly with some potential bugs identified. |
| Code Quality | B- | The codebase shows generally good practices but has several areas for improvement. |
| Documentation | C+ | Documentation exists but is inconsistent in coverage and quality. |
| Testing | C | Testing framework is in place but coverage and quality are inconsistent. |
| Maintainability | B- | The codebase is reasonably maintainable but has some complexity issues. |
| Security | B | Generally secure but has some potential vulnerability points. |
| Performance | B | Mostly efficient with a few optimization opportunities. |

**Overall Grade: B-**

## Critical Issues (High Priority)

${Array.from(highPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Important Issues (Medium Priority)

${Array.from(mediumPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Minor Issues (Low Priority)

${Array.from(lowPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Recommendations

1. Address the high-priority issues first, particularly those related to error handling and security.
2. Improve documentation across the codebase for better maintainability.
3. Enhance test coverage, especially for error scenarios.
4. Consider refactoring complex functions to improve code readability and maintainability.

---

**Note:** This is a fallback consolidated report generated automatically. The individual pass findings are included below for reference.
`;
}
var init_consolidateReview = __esm({
  "src/utils/review/consolidateReview.ts"() {
    "use strict";
    init_logger();
    init_clientFactory();
    init_config();
  }
});

// src/types/common.ts
var DEFAULT_LANGUAGE;
var init_common = __esm({
  "src/types/common.ts"() {
    "use strict";
    DEFAULT_LANGUAGE = "typescript";
  }
});

// src/utils/detection/projectTypeDetector.ts
async function checkFilesExist(projectPath, files) {
  if (files.length === 0) return true;
  for (const file of files) {
    const filePath = import_path26.default.join(projectPath, file);
    try {
      if (!(0, import_fs6.existsSync)(filePath)) {
        return false;
      }
    } catch {
      return false;
    }
  }
  return true;
}
async function countFilesByExtension(projectPath, extensions) {
  try {
    let count = 0;
    const files = await import_promises16.default.readdir(projectPath);
    for (const file of files) {
      const filePath = import_path26.default.join(projectPath, file);
      try {
        const stats = await import_promises16.default.stat(filePath);
        if (stats.isFile() && extensions.some((ext) => file.endsWith(ext))) {
          count++;
        } else if (stats.isDirectory() && file !== "node_modules" && file !== ".git") {
          count += await countFilesByExtension(filePath, extensions);
        }
      } catch {
        continue;
      }
    }
    return count;
  } catch {
    return 0;
  }
}
async function getLanguageFileStats(projectPath) {
  const extensionMap = {
    typescript: [".ts", ".tsx"],
    javascript: [".js", ".jsx"],
    python: [".py"],
    php: [".php"],
    java: [".java"],
    go: [".go"],
    rust: [".rs"],
    c: [".c", ".h"],
    cpp: [".cpp", ".hpp"],
    csharp: [".cs"],
    ruby: [".rb"],
    swift: [".swift"],
    kotlin: [".kt"]
  };
  const result = {
    typescript: 0,
    javascript: 0,
    python: 0,
    php: 0,
    java: 0,
    go: 0,
    rust: 0,
    c: 0,
    cpp: 0,
    csharp: 0,
    ruby: 0,
    swift: 0,
    kotlin: 0
  };
  for (const [language, extensions] of Object.entries(extensionMap)) {
    result[language] = await countFilesByExtension(
      projectPath,
      extensions
    );
  }
  return result;
}
async function detectProjectType(projectPath) {
  try {
    for (const signature of PROJECT_SIGNATURES) {
      const requiredFilesExist = await checkFilesExist(
        projectPath,
        signature.requiredFiles
      );
      if (!requiredFilesExist) continue;
      if (signature.optionalFiles && signature.optionalFiles.length > 0) {
        for (const file of signature.optionalFiles) {
          if ((0, import_fs6.existsSync)(import_path26.default.join(projectPath, file))) {
          }
        }
      }
      if (signature.additionalCheck) {
        const additionalCheckPassed = await signature.additionalCheck(projectPath);
        if (!additionalCheckPassed) continue;
      }
      const languageStats2 = await getLanguageFileStats(projectPath);
      const additionalLanguages2 = Object.entries(languageStats2).filter(
        ([lang, count]) => count > 3 && lang !== signature.language && lang !== "typescript"
      ).sort((a, b) => b[1] - a[1]).map(([lang]) => lang);
      return {
        language: signature.language,
        confidence: signature.confidence,
        projectType: signature.projectType,
        additionalLanguages: additionalLanguages2.length > 0 ? additionalLanguages2 : void 0
      };
    }
    const languageStats = await getLanguageFileStats(projectPath);
    const entries = Object.entries(languageStats);
    if (entries.length === 0 || entries.every(([_, count]) => count === 0)) {
      return {
        language: DEFAULT_LANGUAGE,
        confidence: "low"
      };
    }
    const sortedLanguages = entries.sort((a, b) => b[1] - a[1]);
    const primaryLanguage = sortedLanguages[0][0];
    const primaryCount = sortedLanguages[0][1];
    if (primaryCount < 3) {
      return {
        language: primaryLanguage,
        confidence: "low"
      };
    }
    const additionalLanguages = sortedLanguages.filter(([lang, count]) => count > 3 && lang !== primaryLanguage).map(([lang]) => lang);
    return {
      language: primaryLanguage,
      confidence: "medium",
      additionalLanguages: additionalLanguages.length > 0 ? additionalLanguages : void 0
    };
  } catch (error2) {
    logger_default.error(
      `Error detecting project type: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    return {
      language: DEFAULT_LANGUAGE,
      confidence: "low"
    };
  }
}
var import_promises16, import_path26, import_fs6, PROJECT_SIGNATURES;
var init_projectTypeDetector = __esm({
  "src/utils/detection/projectTypeDetector.ts"() {
    "use strict";
    import_promises16 = __toESM(require("fs/promises"));
    import_path26 = __toESM(require("path"));
    import_fs6 = require("fs");
    init_common();
    init_logger();
    PROJECT_SIGNATURES = [
      // Ruby signatures
      {
        language: "ruby",
        requiredFiles: ["Gemfile"],
        optionalFiles: ["config/routes.rb", "app/controllers"],
        projectType: "Ruby on Rails",
        confidence: "high"
      },
      {
        language: "ruby",
        requiredFiles: ["config/routes.rb"],
        projectType: "Ruby on Rails",
        confidence: "high"
      },
      {
        language: "ruby",
        requiredFiles: ["config/application.rb"],
        projectType: "Ruby on Rails",
        confidence: "high"
      },
      {
        language: "ruby",
        requiredFiles: ["Rakefile", "Gemfile"],
        confidence: "high"
      },
      {
        language: "ruby",
        requiredFiles: ["config.ru"],
        projectType: "Rack",
        confidence: "medium"
      },
      {
        language: "ruby",
        requiredFiles: ["bin/rails"],
        projectType: "Ruby on Rails",
        confidence: "high"
      },
      {
        language: "ruby",
        requiredFiles: [".ruby-version"],
        confidence: "medium"
      },
      {
        language: "ruby",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".rb"));
          } catch {
            return false;
          }
        },
        confidence: "low"
      },
      // Python signatures
      {
        language: "python",
        requiredFiles: ["requirements.txt"],
        optionalFiles: ["setup.py", "pyproject.toml"],
        confidence: "high"
      },
      {
        language: "python",
        requiredFiles: ["setup.py"],
        confidence: "high"
      },
      {
        language: "python",
        requiredFiles: ["pyproject.toml"],
        confidence: "high"
      },
      {
        language: "python",
        requiredFiles: ["Pipfile"],
        confidence: "high"
      },
      {
        language: "python",
        requiredFiles: ["manage.py"],
        projectType: "Django",
        confidence: "high"
      },
      {
        language: "python",
        requiredFiles: ["app.py"],
        optionalFiles: ["wsgi.py", "templates/"],
        projectType: "Flask",
        confidence: "medium"
      },
      {
        language: "python",
        requiredFiles: ["__init__.py"],
        confidence: "medium"
      },
      {
        language: "python",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".py"));
          } catch {
            return false;
          }
        },
        confidence: "low"
      },
      // Go signatures
      {
        language: "go",
        requiredFiles: ["go.mod"],
        optionalFiles: ["go.sum", "main.go"],
        confidence: "high"
      },
      {
        language: "go",
        requiredFiles: ["main.go"],
        confidence: "medium"
      },
      {
        language: "go",
        requiredFiles: ["cmd/"],
        optionalFiles: ["internal/", "pkg/"],
        projectType: "Go CLI Application",
        confidence: "medium"
      },
      {
        language: "go",
        requiredFiles: ["Dockerfile"],
        additionalCheck: async (projectPath) => {
          try {
            const dockerfilePath = import_path26.default.join(projectPath, "Dockerfile");
            const dockerfileContent = await import_promises16.default.readFile(dockerfilePath, "utf-8");
            return dockerfileContent.includes("golang") || dockerfileContent.includes("go:");
          } catch {
            return false;
          }
        },
        projectType: "Go Docker Application",
        confidence: "medium"
      },
      {
        language: "go",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".go"));
          } catch {
            return false;
          }
        },
        confidence: "low"
      },
      // PHP signatures
      {
        language: "php",
        requiredFiles: ["composer.json"],
        confidence: "high"
      },
      {
        language: "php",
        requiredFiles: ["artisan"],
        optionalFiles: ["app/Http/Controllers/"],
        projectType: "Laravel",
        confidence: "high"
      },
      {
        language: "php",
        requiredFiles: ["vendor/autoload.php"],
        confidence: "medium"
      },
      {
        language: "php",
        requiredFiles: ["wp-config.php"],
        projectType: "WordPress",
        confidence: "high"
      },
      {
        language: "php",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".php"));
          } catch {
            return false;
          }
        },
        confidence: "low"
      },
      // TypeScript signatures
      {
        language: "typescript",
        requiredFiles: ["tsconfig.json"],
        confidence: "high"
      },
      {
        language: "typescript",
        requiredFiles: ["package.json"],
        additionalCheck: async (projectPath) => {
          try {
            const packageJsonPath = import_path26.default.join(projectPath, "package.json");
            const packageJson = JSON.parse(await import_promises16.default.readFile(packageJsonPath, "utf-8"));
            return packageJson.dependencies && packageJson.dependencies.typescript || packageJson.devDependencies && packageJson.devDependencies.typescript;
          } catch {
            return false;
          }
        },
        confidence: "high"
      },
      {
        language: "typescript",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".ts") || file.endsWith(".tsx"));
          } catch {
            return false;
          }
        },
        confidence: "medium"
      },
      // JavaScript signatures
      {
        language: "javascript",
        requiredFiles: ["package.json"],
        optionalFiles: ["webpack.config.js", "babel.config.js", ".babelrc"],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            const hasTypeScriptFiles = files.some(
              (file) => file.endsWith(".ts") || file.endsWith(".tsx") || file === "tsconfig.json"
            );
            return !hasTypeScriptFiles;
          } catch {
            return true;
          }
        },
        confidence: "high"
      },
      {
        language: "javascript",
        requiredFiles: [],
        additionalCheck: async (projectPath) => {
          try {
            const files = await import_promises16.default.readdir(projectPath);
            return files.some((file) => file.endsWith(".js") || file.endsWith(".jsx"));
          } catch {
            return false;
          }
        },
        confidence: "low"
      }
    ];
  }
});

// src/utils/detection/frameworkDetector.ts
async function countFilesByExtension2(dirPath, extensions) {
  let count = 0;
  try {
    const entries = await fs26.readdir(dirPath, { withFileTypes: true });
    for (const entry of entries) {
      const fullPath = path34.join(dirPath, entry.name);
      if (entry.isDirectory()) {
        if (!["node_modules", ".git", "dist", "build", ".next", "coverage"].includes(entry.name)) {
          count += await countFilesByExtension2(fullPath, extensions);
        }
      } else if (entry.isFile()) {
        const ext = path34.extname(entry.name);
        if (extensions.includes(ext)) {
          count++;
        }
      }
    }
  } catch (error2) {
    logger_default.debug(`Error reading directory ${dirPath}: ${error2}`);
  }
  return count;
}
async function detectFramework(projectPath) {
  try {
    logger_default.debug(`Detecting framework for project at ${projectPath}`);
    const language = await detectPrimaryLanguage(projectPath);
    if (!language) {
      logger_default.debug("Could not detect primary language.");
      return null;
    }
    logger_default.debug(`Detected primary language: ${language}`);
    if (FRAMEWORK_SIGNATURES[language]) {
      const frameworkResult = await detectFrameworkForLanguage(projectPath, language);
      if (frameworkResult) {
        logger_default.debug(`Detected framework: ${frameworkResult.framework} with confidence ${frameworkResult.confidence.toFixed(2)}`);
        if (frameworkResult.additionalFrameworks && frameworkResult.additionalFrameworks.length > 0) {
          logger_default.debug(`Additional frameworks detected: ${frameworkResult.additionalFrameworks.join(", ")}`);
        }
        return frameworkResult;
      }
    }
    logger_default.debug(`No specific framework detected for ${language}`);
    return {
      language,
      framework: "none",
      confidence: 0.5,
      detectionMethod: "language-only"
    };
  } catch (error2) {
    logger_default.error(`Error detecting framework: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
async function detectPrimaryLanguage(projectPath) {
  try {
    const fileExtensionMap = {
      typescript: [".ts", ".tsx"],
      javascript: [".js", ".jsx"],
      php: [".php"],
      python: [".py"],
      ruby: [".rb"]
    };
    const extensionCounts = {};
    for (const [language, extensions] of Object.entries(fileExtensionMap)) {
      try {
        const count = await countFilesByExtension2(projectPath, extensions);
        extensionCounts[language] = count;
      } catch (error2) {
        logger_default.debug(`Error counting ${language} files: ${error2}`);
        extensionCounts[language] = 0;
      }
    }
    let maxCount = 0;
    let primaryLanguage = null;
    for (const [language, count] of Object.entries(extensionCounts)) {
      if (count > maxCount) {
        maxCount = count;
        primaryLanguage = language;
      }
    }
    if (primaryLanguage === "javascript" && extensionCounts["typescript"] > 0 && extensionCounts["typescript"] >= extensionCounts["javascript"] * 0.5) {
      primaryLanguage = "typescript";
    }
    try {
      const packageJsonExists = await fileExists2(path34.join(projectPath, "package.json"));
      const composerJsonExists = await fileExists2(path34.join(projectPath, "composer.json"));
      const gemfileExists = await fileExists2(path34.join(projectPath, "Gemfile"));
      const requirementsTxtExists = await fileExists2(path34.join(projectPath, "requirements.txt"));
      if (packageJsonExists && primaryLanguage !== "typescript") {
        primaryLanguage = "typescript";
      } else if (composerJsonExists && (primaryLanguage === null || extensionCounts["php"] > 0)) {
        primaryLanguage = "php";
      } else if (gemfileExists && (primaryLanguage === null || extensionCounts["ruby"] > 0)) {
        primaryLanguage = "ruby";
      } else if (requirementsTxtExists && (primaryLanguage === null || extensionCounts["python"] > 0)) {
        primaryLanguage = "python";
      }
    } catch (error2) {
      logger_default.debug(`Error checking for special files: ${error2}`);
    }
    return primaryLanguage;
  } catch (error2) {
    logger_default.error(`Error detecting primary language: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
async function detectFrameworkForLanguage(projectPath, language) {
  try {
    const signatures = FRAMEWORK_SIGNATURES[language] || [];
    const scores = {};
    const detectionMethods = {};
    const dependencies = await getDependencies(projectPath, language);
    const cssFrameworks = await detectCssFrameworks(projectPath, dependencies);
    let frameworkVersion;
    let frameworkType;
    for (const signature of signatures) {
      let score = 0;
      const methods = [];
      for (const file of signature.files) {
        if (await fileExists2(path34.join(projectPath, file))) {
          score += signature.weight;
          methods.push(`found file: ${file}`);
        }
      }
      if (signature.directories) {
        for (const dir of signature.directories) {
          if (await directoryExists(path34.join(projectPath, dir))) {
            score += signature.weight * 0.8;
            methods.push(`found directory: ${dir}`);
          }
        }
      }
      if (signature.dependencies) {
        for (const dep of signature.dependencies) {
          if (dependencies[dep]) {
            score += signature.weight * 0.9;
            methods.push(`found dependency: ${dep}`);
            if (!frameworkVersion) {
              frameworkVersion = dependencies[dep];
            }
          }
        }
      }
      scores[signature.name] = score;
      detectionMethods[signature.name] = methods;
      if (score > 0.7 && signature.type) {
        frameworkType = signature.type;
      }
    }
    let maxScore = 0;
    let detectedFramework = null;
    for (const [framework, score] of Object.entries(scores)) {
      if (score > maxScore) {
        maxScore = score;
        detectedFramework = framework;
      }
    }
    const additionalFrameworks = [];
    for (const [framework, score] of Object.entries(scores)) {
      if (framework !== detectedFramework && score > 0.5) {
        additionalFrameworks.push(framework);
      }
    }
    if (detectedFramework) {
      return {
        language,
        framework: detectedFramework,
        confidence: Math.min(maxScore, 1),
        detectionMethod: detectionMethods[detectedFramework].join(", "),
        additionalFrameworks: additionalFrameworks.length > 0 ? additionalFrameworks : void 0,
        cssFrameworks: cssFrameworks.length > 0 ? cssFrameworks : void 0,
        frameworkVersion,
        frameworkType
      };
    }
    if (cssFrameworks.length > 0) {
      return {
        language,
        framework: "none",
        confidence: 0.5,
        detectionMethod: "css-frameworks-only",
        cssFrameworks
      };
    }
    return null;
  } catch (error2) {
    logger_default.error(`Error detecting framework for ${language}: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return null;
  }
}
async function fileExists2(filePath) {
  try {
    await fs26.access(filePath);
    return true;
  } catch (error2) {
    return false;
  }
}
async function directoryExists(dirPath) {
  try {
    const stats = await fs26.stat(dirPath);
    return stats.isDirectory();
  } catch (error2) {
    return false;
  }
}
async function getDependencies(projectPath, language) {
  const dependencies = {};
  try {
    if (language === "typescript" || language === "javascript") {
      const packageJsonPath = path34.join(projectPath, "package.json");
      if (await fileExists2(packageJsonPath)) {
        const packageJson = JSON.parse(await fs26.readFile(packageJsonPath, "utf-8"));
        if (packageJson.dependencies) {
          Object.assign(dependencies, packageJson.dependencies);
        }
        if (packageJson.devDependencies) {
          Object.assign(dependencies, packageJson.devDependencies);
        }
      }
    } else if (language === "php") {
      const composerJsonPath = path34.join(projectPath, "composer.json");
      if (await fileExists2(composerJsonPath)) {
        const composerJson = JSON.parse(await fs26.readFile(composerJsonPath, "utf-8"));
        if (composerJson.require) {
          Object.assign(dependencies, composerJson.require);
        }
        if (composerJson["require-dev"]) {
          Object.assign(dependencies, composerJson["require-dev"]);
        }
      }
    } else if (language === "ruby") {
      const gemfilePath = path34.join(projectPath, "Gemfile");
      if (await fileExists2(gemfilePath)) {
        const gemfile = await fs26.readFile(gemfilePath, "utf-8");
        const gemRegex = /gem\s+['"]([^'"]+)['"](?:,\s*['"]([^'"]+)['"])?/g;
        let match;
        while ((match = gemRegex.exec(gemfile)) !== null) {
          dependencies[match[1]] = match[2] || "*";
        }
      }
    } else if (language === "python") {
      const requirementsPath = path34.join(projectPath, "requirements.txt");
      if (await fileExists2(requirementsPath)) {
        const requirements = await fs26.readFile(requirementsPath, "utf-8");
        for (const line of requirements.split("\n")) {
          const trimmedLine = line.trim();
          if (trimmedLine && !trimmedLine.startsWith("#")) {
            const parts = trimmedLine.split(/([=<>!~]=?)/);
            if (parts.length >= 1) {
              const packageName = parts[0].trim().toLowerCase();
              const version = parts.length >= 3 ? parts[1] + parts[2] : "*";
              if (packageName) {
                dependencies[packageName] = version;
              }
            }
          }
        }
      }
    }
  } catch (error2) {
    logger_default.warn(`Error getting dependencies: ${error2 instanceof Error ? error2.message : String(error2)}`);
  }
  return dependencies;
}
async function detectCssFrameworks(projectPath, dependencies) {
  const cssFrameworks = [];
  try {
    if (FRAMEWORK_SIGNATURES["css"]) {
      for (const signature of FRAMEWORK_SIGNATURES["css"]) {
        let score = 0;
        let foundDependency = false;
        let version;
        if (signature.dependencies) {
          for (const dep of signature.dependencies) {
            if (dependencies[dep]) {
              score += signature.weight * 0.9;
              foundDependency = true;
              version = dependencies[dep];
              break;
            }
          }
        }
        if (signature.files) {
          for (const file of signature.files) {
            if (await fileExists2(path34.join(projectPath, file))) {
              score += signature.weight * 0.8;
              break;
            }
          }
        }
        if (score > 0.5) {
          cssFrameworks.push({
            name: signature.name,
            version: foundDependency ? version : void 0,
            confidence: Math.min(score, 1)
          });
        }
      }
    }
    const cssDirs = ["src/styles", "src/css", "public/css", "assets/css", "styles", "css"];
    for (const dir of cssDirs) {
      const fullPath = path34.join(projectPath, dir);
      if (await directoryExists(fullPath)) {
        try {
          const files = await fs26.readdir(fullPath);
          for (const file of files) {
            const lowerFile = file.toLowerCase();
            if (lowerFile.includes("bootstrap") && lowerFile.endsWith(".css")) {
              if (!cssFrameworks.some((f) => f.name === "bootstrap")) {
                cssFrameworks.push({ name: "bootstrap", confidence: 0.7 });
              }
            } else if (lowerFile.includes("bulma") && lowerFile.endsWith(".css")) {
              if (!cssFrameworks.some((f) => f.name === "bulma")) {
                cssFrameworks.push({ name: "bulma", confidence: 0.7 });
              }
            } else if (lowerFile.includes("tailwind") && lowerFile.endsWith(".css")) {
              if (!cssFrameworks.some((f) => f.name === "tailwind")) {
                cssFrameworks.push({ name: "tailwind", confidence: 0.7 });
              }
            }
          }
        } catch (error2) {
        }
      }
    }
    return cssFrameworks;
  } catch (error2) {
    logger_default.warn(`Error detecting CSS frameworks: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return [];
  }
}
var fs26, path34, FRAMEWORK_SIGNATURES;
var init_frameworkDetector = __esm({
  "src/utils/detection/frameworkDetector.ts"() {
    "use strict";
    fs26 = __toESM(require("fs/promises"));
    path34 = __toESM(require("path"));
    init_logger();
    FRAMEWORK_SIGNATURES = {
      typescript: [
        {
          name: "react",
          files: ["src/App.tsx", "src/App.jsx", "public/index.html"],
          dependencies: ["react", "react-dom"],
          weight: 0.8,
          type: "ui"
        },
        {
          name: "nextjs",
          files: ["next.config.js", "pages/_app.tsx", "pages/index.tsx"],
          dependencies: ["next"],
          weight: 0.9,
          type: "fullstack"
        },
        {
          name: "angular",
          files: ["angular.json", "src/app/app.module.ts"],
          dependencies: ["@angular/core", "@angular/common"],
          weight: 0.9,
          type: "ui"
        },
        {
          name: "vue",
          files: ["src/App.vue", "vue.config.js"],
          dependencies: ["vue"],
          weight: 0.8,
          type: "ui"
        },
        {
          name: "express",
          files: ["app.js", "server.js"],
          dependencies: ["express"],
          weight: 0.7,
          type: "backend"
        }
      ],
      php: [
        {
          name: "laravel",
          files: ["artisan", "composer.json"],
          directories: ["app/Http/Controllers", "resources/views"],
          weight: 0.9,
          type: "fullstack"
        },
        {
          name: "symfony",
          files: ["symfony.lock", "composer.json", "config/bundles.php"],
          dependencies: ["symfony/symfony", "symfony/framework-bundle"],
          weight: 0.9,
          type: "fullstack"
        },
        {
          name: "wordpress",
          files: ["wp-config.php", "wp-content/themes"],
          directories: ["wp-admin", "wp-content"],
          weight: 0.8,
          type: "fullstack"
        }
      ],
      python: [
        {
          name: "django",
          files: ["manage.py", "settings.py"],
          directories: ["app/migrations"],
          dependencies: ["django"],
          weight: 0.9,
          type: "fullstack"
        },
        {
          name: "flask",
          files: ["app.py", "wsgi.py"],
          dependencies: ["flask"],
          weight: 0.8,
          type: "backend"
        },
        {
          name: "fastapi",
          files: ["main.py"],
          dependencies: ["fastapi"],
          weight: 0.7,
          type: "backend"
        }
      ],
      ruby: [
        {
          name: "rails",
          files: ["Gemfile", "config/routes.rb", "app/controllers/application_controller.rb"],
          directories: ["app/models", "app/controllers", "app/views"],
          weight: 0.9,
          type: "fullstack"
        },
        {
          name: "sinatra",
          files: ["Gemfile", "config.ru"],
          dependencies: ["sinatra"],
          weight: 0.8,
          type: "backend"
        }
      ],
      css: [
        {
          name: "tailwind",
          files: ["tailwind.config.js", "postcss.config.js"],
          dependencies: ["tailwindcss"],
          weight: 0.9,
          type: "css"
        },
        {
          name: "bootstrap",
          files: ["bootstrap.min.css", "bootstrap.bundle.min.js"],
          dependencies: ["bootstrap"],
          weight: 0.8,
          type: "css"
        },
        {
          name: "material-ui",
          files: [],
          dependencies: ["@mui/material", "@material-ui/core"],
          weight: 0.8,
          type: "css"
        },
        {
          name: "styled-components",
          files: [],
          dependencies: ["styled-components"],
          weight: 0.7,
          type: "css"
        },
        {
          name: "emotion",
          files: [],
          dependencies: ["@emotion/react", "@emotion/styled"],
          weight: 0.7,
          type: "css"
        },
        {
          name: "chakra-ui",
          files: [],
          dependencies: ["@chakra-ui/react"],
          weight: 0.8,
          type: "css"
        },
        {
          name: "bulma",
          dependencies: ["bulma"],
          files: ["bulma.min.css"],
          weight: 0.7,
          type: "css"
        }
      ]
    };
  }
});

// src/utils/detection/index.ts
var detection_exports = {};
__export(detection_exports, {
  detectFramework: () => detectFramework,
  detectPrimaryLanguage: () => detectPrimaryLanguage,
  detectProjectType: () => detectProjectType
});
var init_detection = __esm({
  "src/utils/detection/index.ts"() {
    "use strict";
    init_projectTypeDetector();
    init_frameworkDetector();
    init_frameworkDetector();
  }
});

// src/cli/githubProjectsArgumentParser.ts
var githubProjectsArgumentParser_exports = {};
__export(githubProjectsArgumentParser_exports, {
  parseGitHubProjectsArguments: () => parseGitHubProjectsArguments
});
async function parseGitHubProjectsArguments() {
  try {
    const argv = await (0, import_yargs2.default)((0, import_helpers2.hideBin)(process.argv).slice(1)).option("direction", {
      alias: "d",
      choices: ["to-github", "from-github"],
      default: "to-github",
      describe: "Sync direction"
    }).option("project-path", {
      alias: "p",
      type: "string",
      describe: "Path to the project directory"
    }).option("description-only", {
      alias: "desc",
      type: "boolean",
      default: false,
      describe: "Update only the project readme with PROJECT.md content"
    }).help().alias("help", "h").parseAsync();
    const options = {
      direction: argv.direction,
      projectPath: argv["project-path"],
      descriptionOnly: argv["description-only"]
    };
    return options;
  } catch (error2) {
    logger_default.error(
      "Error parsing GitHub Projects sync arguments:",
      error2 instanceof Error ? error2.message : String(error2)
    );
    process.exit(1);
  }
}
var import_yargs2, import_helpers2;
var init_githubProjectsArgumentParser = __esm({
  "src/cli/githubProjectsArgumentParser.ts"() {
    "use strict";
    import_yargs2 = __toESM(require("yargs"));
    import_helpers2 = require("yargs/helpers");
    init_logger();
  }
});

// src/index.ts
var fs31 = __toESM(require("fs"));
var path40 = __toESM(require("path"));
var dotenv4 = __toESM(require("dotenv"));
init_logger();
init_config();

// src/core/reviewOrchestrator.ts
var path35 = __toESM(require("path"));
init_fileSystem();
init_logger();

// src/utils/api/apiUtils.ts
init_config();
init_logger();
init_config();
function getApiKeyType() {
  const config4 = getConfig();
  const selectedModel = config4.selectedModel;
  const adapter = selectedModel && selectedModel.includes(":") ? selectedModel.split(":")[0].toLowerCase() : "gemini";
  logger_default.debug(`getApiKeyType: selectedModel=${selectedModel}, adapter=${adapter}`);
  switch (adapter) {
    case "gemini":
      logger_default.debug("getApiKeyType: Using Google API based on model adapter");
      return "Google";
    case "openrouter":
      logger_default.debug("getApiKeyType: Using OpenRouter API based on model adapter");
      return "OpenRouter";
    case "anthropic":
      logger_default.debug("getApiKeyType: Using Anthropic API based on model adapter");
      return "Anthropic";
    case "openai":
      logger_default.debug("getApiKeyType: Using OpenAI API based on model adapter");
      return "OpenAI";
  }
  logger_default.debug("getApiKeyType: No recognized adapter, checking available API keys");
  if (config4.googleApiKey) {
    logger_default.debug("getApiKeyType: Found Google API key");
    return "Google";
  }
  if (config4.openRouterApiKey) {
    logger_default.debug("getApiKeyType: Found OpenRouter API key");
    return "OpenRouter";
  }
  if (config4.anthropicApiKey) {
    logger_default.debug("getApiKeyType: Found Anthropic API key");
    return "Anthropic";
  }
  if (config4.openAIApiKey) {
    logger_default.debug("getApiKeyType: Found OpenAI API key");
    return "OpenAI";
  }
  logger_default.debug("getApiKeyType: No API keys available");
  return null;
}

// src/__tests__/apiConnection.test.ts
var import_dotenv2 = __toESM(require("dotenv"));
var import_path7 = __toESM(require("path"));
function loadEnvVars() {
  const envLocalPath = import_path7.default.resolve(process.cwd(), ".env.local");
  const result = import_dotenv2.default.config({ path: envLocalPath });
  if (result.error) {
    console.warn(`Could not load .env.local: ${result.error.message}`);
    import_dotenv2.default.config();
  } else {
    console.log("Loaded environment variables from .env.local");
  }
}
async function runApiConnectionTests() {
  loadEnvVars();
  console.log("Testing API connections...");
  const googleApiKey = process.env.AI_CODE_REVIEW_GOOGLE_API_KEY || process.env.GOOGLE_AI_STUDIO_KEY || process.env.GOOGLE_GENERATIVE_AI_KEY;
  if (!googleApiKey) {
    console.warn("No Google Gemini API key found in environment variables");
  } else {
    console.log("Google Gemini API key is available");
  }
  const openRouterApiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY || process.env.OPENROUTER_API_KEY;
  if (!openRouterApiKey) {
    console.warn("No OpenRouter API key found in environment variables");
  } else {
    console.log("OpenRouter API key is available");
  }
  const anthropicApiKey = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY || process.env.ANTHROPIC_API_KEY;
  if (!anthropicApiKey) {
    console.warn("No Anthropic API key found in environment variables");
  } else {
    console.log("Anthropic API key is available");
  }
  console.log("API connection tests complete");
}
if (typeof describe === "function") {
  describe("API Connection Tests", () => {
    describe("Google Gemini API", () => {
      test("API key is checked", () => {
        const apiKey = process.env.AI_CODE_REVIEW_GOOGLE_API_KEY || process.env.GOOGLE_AI_STUDIO_KEY || process.env.GOOGLE_GENERATIVE_AI_KEY;
        if (!apiKey) {
          console.warn("No Google Gemini API key found in environment variables");
        } else {
          console.log("Google Gemini API key is available");
        }
        expect(true).toBe(true);
      });
      test("Can connect to Google Gemini API", () => {
        expect(true).toBe(true);
      });
    });
    describe("OpenRouter API", () => {
      test("API key is checked", () => {
        const apiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY || process.env.OPENROUTER_API_KEY;
        if (!apiKey) {
          console.warn("No OpenRouter API key found in environment variables");
        } else {
          console.log("OpenRouter API key is available");
        }
        expect(true).toBe(true);
      });
      test("Can connect to OpenRouter API", () => {
        expect(true).toBe(true);
      });
    });
    describe("Selected Model", () => {
      test("CODE_REVIEW_MODEL is properly formatted if present", () => {
        const modelName = process.env.AI_CODE_REVIEW_MODEL;
        if (modelName) {
          const parts = modelName.split(":");
          expect(parts.length).toBeGreaterThanOrEqual(1);
        }
        expect(true).toBe(true);
      });
    });
  });
}

// src/core/reviewOrchestrator.ts
init_config();
init_configManager();
init_modelLister();

// src/core/handlers/FileProcessingHandler.ts
init_logger();

// src/core/fileDiscovery.ts
var import_path9 = __toESM(require("path"));
var import_promises5 = __toESM(require("fs/promises"));
init_fileSystem();

// src/utils/fileFilters.ts
var import_promises4 = __toESM(require("fs/promises"));
var import_path8 = __toESM(require("path"));
init_logger();
var SUPPORTED_EXTENSIONS = [
  ".ts",
  ".tsx",
  ".js",
  ".jsx",
  ".py",
  ".pyc",
  ".pyi",
  ".pyx",
  ".pyd",
  ".php",
  ".java",
  ".rb",
  ".rake",
  ".gemspec",
  ".ru",
  ".erb",
  ".go",
  ".rs",
  ".c",
  ".cpp",
  ".h",
  ".hpp",
  ".cs",
  ".swift",
  ".kt"
];
function isTestFile(filePath) {
  const fileName = import_path8.default.basename(filePath);
  return fileName.includes(".test.") || fileName.includes(".spec.") || fileName.startsWith("test-") || fileName.endsWith(".test.ts") || fileName.endsWith(".test.js") || fileName.endsWith(".spec.ts") || fileName.endsWith(".spec.js") || filePath.includes("/__tests__/") || filePath.includes("/test/") || filePath.includes("/tests/");
}
async function loadGitignorePatterns(projectDir) {
  try {
    const gitignorePath = import_path8.default.join(projectDir, ".gitignore");
    try {
      await import_promises4.default.access(gitignorePath);
    } catch (error2) {
      logger_default.debug(`No .gitignore file found at ${gitignorePath}`);
      return [];
    }
    const content = await import_promises4.default.readFile(gitignorePath, "utf-8");
    return content.split("\n").map((line) => line.trim()).filter((line) => line && !line.startsWith("#"));
  } catch (error2) {
    logger_default.error(`Error reading .gitignore: ${error2}`);
    return [];
  }
}
function shouldExcludeFile(filePath, gitignorePatterns) {
  const normalizedPath = filePath.replace(/\\/g, "/");
  for (const pattern of gitignorePatterns) {
    if (!pattern || pattern.startsWith("#")) {
      continue;
    }
    const isNegation = pattern.startsWith("!");
    const actualPattern = isNegation ? pattern.slice(1) : pattern;
    let regexPattern = actualPattern.replace(/[.+^${}()|[\]\\]/g, "\\$&").replace(/\*\*/g, ".*").replace(/\*/g, "[^/]*").replace(/\?/g, "[^/]");
    if (regexPattern.endsWith("/")) {
      regexPattern = `${regexPattern}.*`;
    }
    const regex = new RegExp(
      `^${regexPattern}$|^${regexPattern}/|/${regexPattern}$|/${regexPattern}/`
    );
    const matches = regex.test(normalizedPath);
    if (matches) {
      if (isNegation) {
        return false;
      }
      return true;
    }
  }
  return false;
}
function isSupportedFile(filePath) {
  const fileName = import_path8.default.basename(filePath);
  if (fileName.startsWith(".")) {
    return false;
  }
  const ext = import_path8.default.extname(filePath).toLowerCase();
  return SUPPORTED_EXTENSIONS.includes(ext);
}
async function discoverFiles(dirPath, options = {}) {
  const {
    excludePatterns = [],
    includeTests = false,
    maxDepth = 10,
    currentDepth = 0
  } = options;
  if (currentDepth > maxDepth) {
    return [];
  }
  try {
    const entries = await import_promises4.default.readdir(dirPath, { withFileTypes: true });
    const files = [];
    for (const entry of entries) {
      const entryPath = import_path8.default.join(dirPath, entry.name);
      if (shouldExcludeFile(entryPath, excludePatterns)) {
        logger_default.debug(`Skipping path: ${entryPath} (matched by .gitignore pattern)`);
        continue;
      }
      if (entry.isDirectory()) {
        if (entry.name === "node_modules" || entry.name === ".git" || entry.name.startsWith(".")) {
          logger_default.debug(`Skipping directory: ${entry.name} (hidden or excluded)`);
          continue;
        }
        const subFiles = await discoverFiles(entryPath, {
          excludePatterns,
          includeTests,
          maxDepth,
          currentDepth: currentDepth + 1
        });
        files.push(...subFiles);
      } else if (entry.isFile()) {
        if (entry.name.startsWith(".")) {
          logger_default.debug(`Skipping file: ${entry.name} (hidden file)`);
          continue;
        }
        if (!includeTests && isTestFile(entryPath)) {
          logger_default.debug(`Skipping file: ${entryPath} (test file)`);
          continue;
        }
        if (!isSupportedFile(entryPath)) {
          logger_default.debug(`Skipping file: ${entryPath} (unsupported file type)`);
          continue;
        }
        files.push(entryPath);
      }
    }
    return files;
  } catch (error2) {
    logger_default.error(`Error discovering files in ${dirPath}:`, error2);
    return [];
  }
}
async function getFilesToReview(targetPath, isFile2, includeTests = false, excludePatterns = []) {
  if (isFile2) {
    return [targetPath];
  } else {
    let patterns = excludePatterns;
    if (patterns.length === 0) {
      patterns = await loadGitignorePatterns(targetPath);
      logger_default.debug(`Loaded ${patterns.length} patterns from .gitignore`);
    }
    return discoverFiles(targetPath, {
      excludePatterns: patterns,
      includeTests,
      maxDepth: 10
    });
  }
}

// src/utils/smartFileSelector.ts
var fs10 = __toESM(require("fs"));
var path12 = __toESM(require("path"));
init_logger();
async function loadEslintIgnorePatterns(projectDir) {
  try {
    const eslintIgnorePath = path12.join(projectDir, ".eslintignore");
    try {
      await fs10.promises.access(eslintIgnorePath);
    } catch (error2) {
      logger_default.debug(`No .eslintignore file found at ${eslintIgnorePath}`);
      return [];
    }
    const content = await fs10.promises.readFile(eslintIgnorePath, "utf-8");
    if (!content) {
      return [];
    }
    return content.split("\n").map((line) => line.trim()).filter((line) => line && !line.startsWith("#"));
  } catch (error2) {
    if (error2 instanceof Error && error2.code !== "ENOENT") {
      logger_default.error(`Error reading .eslintignore: ${error2}`);
    } else {
      const eslintIgnorePath = path12.join(projectDir, ".eslintignore");
      logger_default.debug(`No .eslintignore file found at ${eslintIgnorePath}`);
    }
    return [];
  }
}
async function loadTsConfig(projectDir) {
  try {
    const tsConfigPath = path12.join(projectDir, "tsconfig.json");
    try {
      await fs10.promises.access(tsConfigPath);
    } catch (error2) {
      logger_default.debug(`No tsconfig.json file found at ${tsConfigPath}`);
      return null;
    }
    const content = await fs10.promises.readFile(tsConfigPath, "utf-8");
    if (!content) {
      return null;
    }
    try {
      return JSON.parse(content);
    } catch (parseError) {
      logger_default.error(`Error parsing tsconfig.json: ${parseError}`);
      return null;
    }
  } catch (error2) {
    if (error2 instanceof Error && error2.code !== "ENOENT") {
      logger_default.error(`Error reading tsconfig.json: ${error2}`);
    } else {
      const tsConfigPath = path12.join(projectDir, "tsconfig.json");
      logger_default.debug(`No tsconfig.json file found at ${tsConfigPath}`);
    }
    return null;
  }
}
function convertTsGlobToRegex(pattern) {
  const regexPattern = pattern.replace(/[.+^${}()|[\]\\]/g, "\\$&").replace(/\*\*/g, ".*").replace(/\*/g, "[^/]*").replace(/\?/g, "[^/]");
  return new RegExp(`^${regexPattern}$|^${regexPattern}/|/${regexPattern}$|/${regexPattern}/`);
}
function matchesTsConfig(filePath, tsConfig, projectDir) {
  if (!tsConfig) {
    return true;
  }
  const normalizedPath = filePath.replace(/\\/g, "/");
  const relativePath = path12.relative(projectDir, filePath).replace(/\\/g, "/");
  if (tsConfig.files && tsConfig.files.length > 0) {
    return tsConfig.files.some((file) => {
      const normalizedFile = file.replace(/\\/g, "/");
      return relativePath === normalizedFile;
    });
  }
  if (tsConfig.exclude && tsConfig.exclude.length > 0) {
    for (const pattern of tsConfig.exclude) {
      const regex = convertTsGlobToRegex(pattern);
      if (regex.test(normalizedPath) || regex.test(relativePath)) {
        logger_default.debug(`File ${filePath} excluded by tsconfig.json pattern: ${pattern}`);
        return false;
      }
    }
  }
  if (tsConfig.include && tsConfig.include.length > 0) {
    for (const pattern of tsConfig.include) {
      const regex = convertTsGlobToRegex(pattern);
      if (regex.test(normalizedPath) || regex.test(relativePath)) {
        return true;
      }
      if (pattern === "src/**/*" && (relativePath.startsWith("src/") || normalizedPath.includes("/src/") || normalizedPath.endsWith("/src"))) {
        return true;
      }
    }
    logger_default.debug(`File ${filePath} not included by any tsconfig.json include pattern`);
    return false;
  }
  return true;
}
async function applySmartFiltering(filePaths, projectDir) {
  const gitignorePatterns = await loadGitignorePatterns(projectDir);
  const eslintIgnorePatterns = await loadEslintIgnorePatterns(projectDir);
  const tsConfig = await loadTsConfig(projectDir);
  logger_default.debug(`Loaded ${gitignorePatterns.length} .gitignore patterns`);
  logger_default.debug(`Loaded ${eslintIgnorePatterns.length} .eslintignore patterns`);
  logger_default.debug(`TypeScript config loaded: ${tsConfig ? "Yes" : "No"}`);
  return filePaths.filter((filePath) => {
    if (shouldExcludeFile(filePath, gitignorePatterns)) {
      logger_default.debug(`File excluded by .gitignore: ${filePath}`);
      return false;
    }
    if (shouldExcludeFile(filePath, eslintIgnorePatterns)) {
      logger_default.debug(`File excluded by .eslintignore: ${filePath}`);
      return false;
    }
    if (tsConfig && !matchesTsConfig(filePath, tsConfig, projectDir)) {
      logger_default.debug(`File excluded by tsconfig.json: ${filePath}`);
      return false;
    }
    return true;
  });
}

// src/core/fileDiscovery.ts
init_logger();
function validateTargetParameter(target) {
  if (target.includes("=")) {
    const [key, ...valueParts] = target.split("=");
    const value = valueParts.join("=");
    const commonOptions2 = ["type", "output", "model", "language", "debug", "interactive", "estimate"];
    if (commonOptions2.includes(key)) {
      throw new Error(`Invalid parameter format: '${target}'
    
It looks like you're trying to set the '${key}' option.
Did you mean: --${key} ${value}

Example usage:
  ai-code-review --${key} ${value}
  ai-code-review src --${key} ${value}
  ai-code-review . --${key} ${value}

Run 'ai-code-review --help' for more options.`);
    } else if (!key.includes("/") && !key.includes("\\") && !key.includes(".")) {
      throw new Error(`Invalid parameter format: '${target}'
    
Parameters should use '--' prefix, not '=' format.
Example: --type performance

Common usage patterns:
  ai-code-review                    # Review current directory
  ai-code-review src                 # Review src directory
  ai-code-review src/index.ts        # Review specific file
  ai-code-review --type security     # Security review of current directory
  ai-code-review src --type performance  # Performance review of src

Run 'ai-code-review --help' for all options.`);
    }
  }
  const commonOptions = [
    "type",
    "output",
    "model",
    "language",
    "debug",
    "interactive",
    "estimate",
    "help",
    "version",
    "listmodels",
    "models"
  ];
  if (commonOptions.includes(target)) {
    throw new Error(`'${target}' looks like an option but is missing '--' prefix.
    
Did you mean: --${target}

Example usage:
  ai-code-review --${target}
  ai-code-review src --${target}

For options that require values:
  ai-code-review --type performance
  ai-code-review --output json
  ai-code-review --model openai:gpt-4

Run 'ai-code-review --help' for more information.`);
  }
  if (target.startsWith("-") && !target.startsWith("--")) {
    throw new Error(`Invalid option format: '${target}'
    
Options should use double dashes (--), not single dash (-).
Did you mean: -${target}?

Example usage:
  ai-code-review --type security
  ai-code-review --debug
  ai-code-review --help

Run 'ai-code-review --help' for all available options.`);
  }
}
async function discoverFiles2(target, projectPath, includeTests = false) {
  try {
    validateTargetParameter(target);
    const resolvedTarget = import_path9.default.resolve(projectPath, target);
    if (!isPathWithinCwd(resolvedTarget)) {
      throw new Error(
        `Target must be within the project directory: ${projectPath}`
      );
    }
    const targetPath = resolvedTarget;
    const isFileTarget = await pathExists(targetPath) && !await isDirectory(targetPath);
    const isDirectoryTarget = await isDirectory(targetPath);
    if (!isFileTarget && !isDirectoryTarget) {
      throw new Error(`Target not found: ${target}`);
    }
    const gitignorePatterns = await loadGitignorePatterns(targetPath);
    logger_default.debug(`Loaded ${gitignorePatterns.length} patterns from .gitignore in ${targetPath}`);
    let filesToReview = await getFilesToReview(
      targetPath,
      isFileTarget,
      includeTests,
      gitignorePatterns
    );
    if (filesToReview.length > 0) {
      logger_default.info("Applying smart filtering based on project configuration files...");
      filesToReview = await applySmartFiltering(filesToReview, projectPath);
    }
    if (filesToReview.length === 0) {
      logger_default.info("No files found to review.");
    } else {
      logger_default.info(`Found ${filesToReview.length} files to review.`);
    }
    return filesToReview;
  } catch (error2) {
    logger_default.error(
      `Error discovering files: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}
async function readFilesContent(filePaths, projectPath) {
  const fileInfos = [];
  const errors = [];
  for (const filePath of filePaths) {
    try {
      if (!await pathExists(filePath)) {
        errors.push({ path: filePath, error: "File does not exist" });
        continue;
      }
      const fileContent = await import_promises5.default.readFile(filePath, "utf-8");
      const relativePath = import_path9.default.relative(projectPath, filePath);
      fileInfos.push({
        path: filePath,
        relativePath,
        content: fileContent
      });
    } catch (error2) {
      const errorMessage = error2 instanceof Error ? error2.message : String(error2);
      logger_default.error(`Error reading file ${filePath}: ${errorMessage}`);
      errors.push({ path: filePath, error: errorMessage });
    }
  }
  if (errors.length > 0) {
    logger_default.warn(`Failed to read ${errors.length} file(s)`);
  }
  return { fileInfos, errors };
}

// src/core/handlers/FileProcessingHandler.ts
async function discoverFilesForReview(target, projectPath, options) {
  const effectiveTarget = target || ".";
  try {
    const filesToReview = await discoverFiles2(
      effectiveTarget,
      projectPath,
      options.includeTests
    );
    logger_default.info(`Discovered ${filesToReview.length} files to review`);
    if (filesToReview.length === 0) {
      logger_default.warn(`No files found for review in ${effectiveTarget}`);
      logger_default.info("This could be due to:");
      logger_default.info("1. The path does not exist or is not accessible");
      logger_default.info("2. All files are excluded by .gitignore patterns");
      logger_default.info("3. There are no supported file types in the specified path");
      if (!options.includeTests) {
        logger_default.info("4. Test files are excluded by default. Use --include-tests to include them");
      }
    }
    if (options.debug && filesToReview.length > 0) {
      const maxFilesToLog = 10;
      logger_default.debug(`First ${Math.min(filesToReview.length, maxFilesToLog)} files to review:`);
      for (let i = 0; i < Math.min(filesToReview.length, maxFilesToLog); i++) {
        logger_default.debug(`  - ${filesToReview[i]}`);
      }
      if (filesToReview.length > maxFilesToLog) {
        logger_default.debug(`  ... and ${filesToReview.length - maxFilesToLog} more files`);
      }
    }
    return filesToReview;
  } catch (error2) {
    logger_default.error(`Failed to discover files for review: ${error2 instanceof Error ? error2.message : String(error2)}`);
    if (error2 instanceof Error && error2.stack) {
      logger_default.debug(`Error stack trace: ${error2.stack}`);
    }
    throw new Error(`Could not discover files to review in ${effectiveTarget}. Please verify the path exists and is accessible.`);
  }
}
async function readFilesForReview(filesToReview, projectPath) {
  try {
    logger_default.info("Reading file contents...");
    const result = await readFilesContent(filesToReview, projectPath);
    logger_default.info(`Successfully read ${result.fileInfos.length} out of ${filesToReview.length} files`);
    if (result.errors.length > 0) {
      logger_default.warn(`Failed to read ${result.errors.length} file(s):`);
      const maxErrorsToLog = 10;
      result.errors.slice(0, maxErrorsToLog).forEach((error2) => {
        logger_default.warn(`  ${error2.path}: ${error2.error}`);
      });
      if (result.errors.length > maxErrorsToLog) {
        logger_default.warn(`  ... and ${result.errors.length - maxErrorsToLog} more errors`);
      }
    }
    if (result.fileInfos.length === 0) {
      const errorMessage = "No files could be read for review.";
      logger_default.error(errorMessage);
      if (result.errors.length > 0) {
        logger_default.error("Errors encountered while reading files:");
        const commonErrorPatterns = {
          permission: ["permission denied", "EACCES"],
          notFound: ["no such file", "ENOENT"],
          encoding: ["encoding", "invalid byte", "character"],
          size: ["too large", "exceeds", "size limit"]
        };
        const categorizedErrors = {
          permission: 0,
          notFound: 0,
          encoding: 0,
          size: 0,
          other: 0
        };
        result.errors.forEach((error2) => {
          const errorLowerCase = error2.error.toLowerCase();
          let categorized = false;
          for (const [category, patterns] of Object.entries(commonErrorPatterns)) {
            if (patterns.some((pattern) => errorLowerCase.includes(pattern.toLowerCase()))) {
              categorizedErrors[category]++;
              categorized = true;
              break;
            }
          }
          if (!categorized) {
            categorizedErrors.other++;
          }
        });
        if (categorizedErrors.permission > 0) {
          logger_default.error(`  - ${categorizedErrors.permission} file(s) could not be read due to permission issues. Check file permissions.`);
        }
        if (categorizedErrors.notFound > 0) {
          logger_default.error(`  - ${categorizedErrors.notFound} file(s) were not found. The file list may be out of date.`);
        }
        if (categorizedErrors.encoding > 0) {
          logger_default.error(`  - ${categorizedErrors.encoding} file(s) had encoding issues. These might be binary files not suitable for review.`);
        }
        if (categorizedErrors.size > 0) {
          logger_default.error(`  - ${categorizedErrors.size} file(s) were too large to process.`);
        }
        if (categorizedErrors.other > 0) {
          logger_default.error(`  - ${categorizedErrors.other} file(s) failed due to other issues.`);
        }
      }
      throw new Error(`${errorMessage} Please check file permissions and paths.`);
    }
    return result;
  } catch (error2) {
    if (error2 instanceof Error && error2.message.includes("No files could be read")) {
      throw error2;
    } else {
      logger_default.error(`Unexpected error when reading file contents: ${error2 instanceof Error ? error2.message : String(error2)}`);
      if (error2 instanceof Error && error2.stack) {
        logger_default.debug(`Error stack trace: ${error2.stack}`);
      }
      throw new Error(`Failed to read files for review: ${error2 instanceof Error ? error2.message : String(error2)}`);
    }
  }
}

// src/core/handlers/EstimationHandler.ts
init_logger();
init_estimationUtils();

// src/core/utils/ModelInfoUtils.ts
init_modelMaps2();
function getProviderDisplayInfo(modelName) {
  if (!modelName.includes(":")) {
    return {
      provider: "Unknown",
      model: modelName
    };
  }
  try {
    const { provider, modelName: extractedModelName } = parseModelString(modelName);
    return {
      provider: provider.charAt(0).toUpperCase() + provider.slice(1).toLowerCase(),
      // Capitalize provider name
      model: extractedModelName
    };
  } catch (error2) {
    const parts = modelName.split(":");
    if (parts.length === 2) {
      const providerPart = parts[0].toLowerCase();
      return {
        provider: providerPart.charAt(0).toUpperCase() + providerPart.slice(1),
        // Capitalize provider name
        model: parts[1]
      };
    }
    return {
      provider: "Unknown",
      model: modelName
    };
  }
}

// src/core/handlers/EstimationHandler.ts
init_semantic();
async function performEstimation(fileInfos, filesToReview, options, modelName) {
  logger_default.info("Calculating token usage and cost estimates...");
  try {
    if (fileInfos.length === 0) {
      throw new Error("No files could be read for review. Please check file permissions and paths.");
    }
    const { TokenAnalyzer: TokenAnalyzer2 } = await Promise.resolve().then(() => (init_tokens(), tokens_exports));
    const { estimateMultiPassReviewCost: estimateMultiPassReviewCost2 } = await Promise.resolve().then(() => (init_estimationUtils(), estimationUtils_exports));
    const tokenAnalysisOptions = {
      reviewType: options.type,
      modelName,
      contextMaintenanceFactor: options.contextMaintenanceFactor || 0.15,
      forceSinglePass: options.forceSinglePass
    };
    const tokenAnalysis = TokenAnalyzer2.analyzeFiles(fileInfos, tokenAnalysisOptions);
    try {
      const semanticIntegration = new SemanticChunkingIntegration({
        enableSemanticChunking: options.enableSemanticChunking ?? true,
        enableFallback: true,
        forceSemantic: [],
        forceTraditional: [],
        preferSemantic: true,
        maxFileSizeForSemantic: 1024 * 1024,
        enableCaching: true
      });
      if (semanticIntegration.canUseSemanticChunking(fileInfos)) {
        logger_default.info("\u{1F9E0} Using semantic code analysis with TreeSitter...");
        const semanticResult = await semanticIntegration.analyzeAndChunk(fileInfos, {
          reviewType: options.type
        });
        if (!semanticResult.fallbackUsed && semanticResult.chunks.length > 0) {
          logger_default.info(`\u2705 Semantic analysis complete:`);
          logger_default.info(`   \u2022 Method: ${semanticResult.method}`);
          logger_default.info(`   \u2022 Chunks discovered: ${semanticResult.chunks.length}`);
          if (semanticResult.method === "semantic") {
            const hasConsolidation = semanticResult.chunks.some(
              (chunk) => typeof chunk.metadata?.consolidation?.originalThreads === "number" && chunk.metadata.consolidation.originalThreads > 1
            );
            if (hasConsolidation) {
              const totalOriginalThreads = semanticResult.chunks.reduce(
                (sum, chunk) => sum + (chunk.metadata?.consolidation?.originalThreads || 1),
                0
              );
              logger_default.info(`   \u2022 Semantic threads: ${totalOriginalThreads} \u2192 ${semanticResult.chunks.length} batches`);
              logger_default.info(`   \u2022 Note: Threads consolidated into efficient batches for optimal AI processing`);
            } else {
              logger_default.info(`   \u2022 Semantic threads: ${semanticResult.chunks.length}`);
              logger_default.info(`   \u2022 Note: Threads preserve code structure boundaries (functions, classes, etc.)`);
            }
            semanticResult.chunks.forEach((chunk, index) => {
              const consolidation = chunk.metadata?.consolidation;
              const structureInfo = chunk.metadata?.semanticInfo ? ` (${chunk.metadata.semanticInfo.declarations?.length || 0} declarations)` : "";
              if (consolidation) {
                logger_default.info(`   \u2022 Batch ${index + 1}: ${consolidation.originalThreads} threads, ~${chunk.estimatedTokens} tokens${structureInfo}`);
              } else {
                logger_default.info(`   \u2022 Thread ${index + 1}: ~${chunk.estimatedTokens} tokens${structureInfo}`);
              }
            });
          } else {
            logger_default.info(`   \u2022 Files analyzed: ${semanticResult.chunks.reduce((sum, chunk) => sum + (chunk.files?.length || 0), 0)}`);
            semanticResult.chunks.forEach((chunk, index) => {
              logger_default.info(`   \u2022 Chunk ${index + 1}: ${chunk.files?.length || 0} files, ~${chunk.estimatedTokens} tokens`);
            });
          }
          if (semanticResult.metrics) {
            logger_default.info(`   \u2022 Analysis time: ${semanticResult.metrics.analysisTimeMs}ms`);
          }
        } else {
          logger_default.info("\u2139\uFE0F  Semantic analysis not optimal, using traditional chunking");
        }
      } else {
        logger_default.info("\u2139\uFE0F  Files not suitable for semantic analysis, using traditional chunking");
      }
    } catch (error2) {
      logger_default.warn(`Semantic chunking failed: ${error2 instanceof Error ? error2.message : "Unknown error"}`);
      logger_default.info("\u2139\uFE0F  Falling back to traditional token-based analysis");
    }
    const costEstimation = await estimateMultiPassReviewCost2(
      fileInfos,
      options.type,
      modelName,
      {
        passCount: tokenAnalysis.chunkingRecommendation.chunkingRecommended ? tokenAnalysis.estimatedPassesNeeded : 1,
        contextMaintenanceFactor: tokenAnalysisOptions.contextMaintenanceFactor
      }
    );
    const providerInfo = getProviderDisplayInfo(modelName);
    logger_default.info(`
=== Token Usage and Cost Estimation ===

Provider: ${providerInfo.provider}
Model: ${providerInfo.model}
Files: ${tokenAnalysis.fileCount} (${(tokenAnalysis.totalSizeInBytes / 1024 / 1024).toFixed(2)} MB total)

Token Information:
  Input Tokens: ${costEstimation.inputTokens.toLocaleString()}
  Estimated Output Tokens: ${costEstimation.outputTokens.toLocaleString()}
  Total Tokens: ${costEstimation.totalTokens.toLocaleString()}
  Context Window Size: ${tokenAnalysis.contextWindowSize.toLocaleString()}
  Context Utilization: ${(tokenAnalysis.estimatedTotalTokens / tokenAnalysis.contextWindowSize * 100).toFixed(2)}%

${tokenAnalysis.chunkingRecommendation.chunkingRecommended ? `Multi-Pass Analysis:
  Chunking Required: Yes
  Reason: ${tokenAnalysis.chunkingRecommendation.reason || "Content exceeds context window"}
  Estimated Passes: ${tokenAnalysis.estimatedPassesNeeded}` : `Multi-Pass Analysis:
  Chunking Required: No
  Reason: ${tokenAnalysis.chunkingRecommendation.reason || "Content fits within context window"}`}

Estimated Cost: ${costEstimation.formattedCost || "Unable to estimate cost"}

Note: This is an estimate based on approximate token counts and may vary
      based on the actual content and model behavior.
`);
    if (tokenAnalysis.chunkingRecommendation.chunkingRecommended) {
      logger_default.info("\nImportant: Multi-pass review will be automatically enabled when needed. No flag required.");
      if (options.forceSinglePass) {
        logger_default.info("\nNote: --force-single-pass is enabled, which will override the chunking recommendation.");
        logger_default.info("      This may result in token limit errors if the content exceeds the model's context window.");
      }
    }
  } catch (error2) {
    logger_default.warn("Advanced token analysis failed, falling back to basic estimation");
    const estimation = await estimateFromFilePaths(
      filesToReview,
      options.type,
      modelName
    );
    const providerInfo = getProviderDisplayInfo(modelName);
    logger_default.info(`
=== Token Usage and Cost Estimation ===

Review Type: ${options.type}
Provider: ${providerInfo.provider}
Model: ${providerInfo.model}
Files: ${estimation.fileCount} (${(estimation.totalFileSize / 1024 / 1024).toFixed(2)} MB total)

Token Usage:
  Input Tokens: ${estimation.inputTokens.toLocaleString()}
  Estimated Output Tokens: ${estimation.outputTokens.toLocaleString()}
  Total Tokens: ${estimation.totalTokens.toLocaleString()}

Estimated Cost: ${estimation.formattedCost}

Note: This is an estimate based on approximate token counts and may vary
      based on the actual content and model behavior.
`);
  }
}

// src/core/handlers/SemanticAnalysisHandler.ts
init_logger();
async function performSemanticAnalysis(fileInfos, options, config4 = {}) {
  try {
    const { SemanticChunkingIntegration: SemanticChunkingIntegration2 } = await Promise.resolve().then(() => (init_semantic(), semantic_exports));
    const semanticIntegration = new SemanticChunkingIntegration2({
      enableSemanticChunking: options.enableSemanticChunking ?? true,
      enableFallback: config4.enableFallback ?? true,
      forceSemantic: config4.forceSemantic ?? [],
      forceTraditional: config4.forceTraditional ?? [],
      preferSemantic: config4.preferSemantic ?? true,
      maxFileSizeForSemantic: config4.maxFileSizeForSemantic ?? 1024 * 1024,
      enableCaching: config4.enableCaching ?? true
    });
    if (!semanticIntegration.canUseSemanticChunking(fileInfos)) {
      logger_default.info("Files not suitable for semantic analysis, using traditional chunking");
      return null;
    }
    logger_default.info("Using semantic code analysis with TreeSitter...");
    const semanticResult = await semanticIntegration.analyzeAndChunk(fileInfos, {
      reviewType: options.type
    });
    if (semanticResult.fallbackUsed || semanticResult.chunks.length === 0) {
      logger_default.info("Semantic analysis not optimal, using traditional chunking");
      return null;
    }
    logger_default.info(`Semantic analysis complete:`);
    logger_default.info(`\u2022 Method: ${semanticResult.method}`);
    logger_default.info(`\u2022 Chunks discovered: ${semanticResult.chunks.length}`);
    if (semanticResult.method === "semantic") {
      const hasConsolidation = semanticResult.chunks.some(
        (chunk) => typeof chunk.metadata?.consolidation?.originalThreads === "number" && chunk.metadata.consolidation.originalThreads > 1
      );
      if (hasConsolidation) {
        const totalOriginalThreads = semanticResult.chunks.reduce(
          (sum, chunk) => sum + (chunk.metadata?.consolidation?.originalThreads || 1),
          0
        );
        logger_default.info(`\u2022 Semantic threads: ${totalOriginalThreads} \u2192 ${semanticResult.chunks.length} batches`);
        logger_default.info(`\u2022 Note: Threads consolidated into efficient batches for optimal AI processing`);
      } else {
        logger_default.info(`\u2022 Semantic threads: ${semanticResult.chunks.length}`);
        logger_default.info(`\u2022 Note: Threads preserve code structure boundaries (functions, classes, etc.)`);
      }
    } else {
      logger_default.info(`\u2022 Files analyzed: ${semanticResult.chunks.reduce((sum, chunk) => sum + (chunk.files?.length || 0), 0)}`);
    }
    if (semanticResult.metrics) {
      logger_default.info(`\u2022 Analysis time: ${semanticResult.metrics.analysisTimeMs}ms`);
    }
    return semanticResult;
  } catch (error2) {
    logger_default.warn(`Semantic chunking failed: ${error2 instanceof Error ? error2.message : "Unknown error"}`);
    logger_default.info("Falling back to traditional token-based analysis");
    return null;
  }
}

// src/core/handlers/ReviewExecutor.ts
var path27 = __toESM(require("path"));
init_logger();

// src/strategies/ReviewStrategy.ts
var BaseReviewStrategy = class {
  reviewType;
  /**
   * Create a new review strategy
   * @param reviewType Type of review to perform
   */
  constructor(reviewType) {
    this.reviewType = reviewType;
  }
};

// src/core/ReviewGenerator.ts
init_clientFactory();

// src/clients/anthropicClient.ts
init_anthropicModelHelpers();
init_anthropicReviewGenerators();

// src/clients/utils/anthropicToolCalling.ts
init_logger();
init_modelMaps2();
init_utils();
init_packageAnalyzer();
init_tokenCounter();
init_toolCalling();
init_toolExecutor();
init_anthropicApiClient();
init_anthropicModelHelpers();

// src/clients/anthropicClientWrapper.ts
async function initializeAnthropicClient2() {
  return initializeAnthropicClient();
}
async function generateAnthropicConsolidatedReview2(fileInfos, project, reviewType, projectDocs, options) {
  return generateAnthropicConsolidatedReview(
    fileInfos,
    project,
    reviewType,
    projectDocs,
    options
  );
}

// src/clients/openaiClientWrapper.ts
init_openaiClient();
init_logger();
var openaiClientInstance = null;
function getClientInstance() {
  if (!openaiClientInstance) {
    openaiClientInstance = new OpenAIClient();
  }
  return openaiClientInstance;
}
async function initializeAnyOpenAIModel() {
  try {
    const client = getClientInstance();
    return await client.initialize();
  } catch (error2) {
    logger_default.error("Failed to initialize OpenAI model:", error2);
    return false;
  }
}
async function generateOpenAIConsolidatedReview(fileInfos, project, reviewType, projectDocs, options) {
  const client = getClientInstance();
  if (!client.getIsInitialized()) {
    await client.initialize();
  }
  return client.generateConsolidatedReview(
    fileInfos,
    project,
    reviewType,
    projectDocs,
    options
  );
}

// src/clients/openRouterClient.ts
init_config();
init_logger();
init_utils();
init_tokenCounter();
init_promptLoader();
init_apiErrorHandler();
init_promptFormatter();
var modelInitialized2 = false;
function isOpenRouterModel() {
  const selectedModel = getConfig().selectedModel || "";
  const [adapter, modelName] = selectedModel.includes(":") ? selectedModel.split(":") : ["openrouter", selectedModel];
  return {
    isCorrect: adapter === "openrouter",
    adapter,
    modelName
  };
}
async function initializeAnyOpenRouterModel() {
  const { isCorrect, modelName } = isOpenRouterModel();
  if (!isCorrect) {
    return true;
  }
  if (modelInitialized2) {
    return true;
  }
  const apiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY;
  if (!validateOpenRouterApiKey(apiKey, isDebugMode())) {
    process.exit(1);
  }
  try {
    console.log(`Initializing OpenRouter model: ${modelName}...`);
    modelInitialized2 = true;
    console.log(`Successfully initialized OpenRouter model: ${modelName}`);
    return true;
  } catch (error2) {
    console.error(`Error initializing OpenRouter model ${modelName}:`, error2);
    return false;
  }
}
async function generateOpenRouterConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
  try {
    if (!modelInitialized2) {
      await initializeAnyOpenRouterModel();
    }
    const apiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY;
    let content;
    let cost;
    const promptTemplate = await loadPromptTemplate2(reviewType, options);
    const prompt = formatConsolidatedReviewPrompt(
      promptTemplate,
      projectName,
      files.map((file) => ({
        relativePath: file.relativePath || "",
        content: file.content,
        sizeInBytes: file.content.length
      })),
      projectDocs
    );
    const { modelName } = isOpenRouterModel();
    try {
      console.log(
        `Generating consolidated review with OpenRouter ${modelName}...`
      );
      const response = await fetch(
        "https://openrouter.ai/api/v1/chat/completions",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${apiKey}`,
            "HTTP-Referer": "https://github.com/bobmatnyc/code-review",
            "X-Title": "AI Code Review"
          },
          body: JSON.stringify({
            model: modelName,
            messages: [
              {
                role: "system",
                content: `You are an expert code reviewer. Focus on providing actionable feedback. IMPORTANT: DO NOT REPEAT THE INSTRUCTIONS IN YOUR RESPONSE. DO NOT ASK FOR CODE TO REVIEW. ASSUME THE CODE IS ALREADY PROVIDED IN THE USER MESSAGE. FOCUS ONLY ON PROVIDING THE CODE REVIEW CONTENT.

IMPORTANT: Your response MUST be in the following JSON format:

{
  "summary": "A brief summary of the code review",
  "issues": [
    {
      "title": "Issue title",
      "priority": "high|medium|low",
      "type": "bug|security|performance|maintainability|readability|architecture|best-practice|documentation|testing|other",
      "filePath": "Path to the file",
      "lineNumbers": "Line number or range (e.g., 10 or 10-15)",
      "description": "Detailed description of the issue",
      "codeSnippet": "Relevant code snippet",
      "suggestedFix": "Suggested code fix",
      "impact": "Impact of the issue"
    }
  ],
  "recommendations": [
    "General recommendation 1",
    "General recommendation 2"
  ],
  "positiveAspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Ensure your response is valid JSON. Do not include any text outside the JSON structure.`
              },
              {
                role: "user",
                content: prompt
              }
            ],
            temperature: 0.2,
            max_tokens: 4e3
          })
        }
      );
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(`OpenRouter API error: ${JSON.stringify(errorData)}`);
      }
      const data = await response.json();
      if (data.choices && data.choices.length > 0) {
        content = data.choices[0].message.content;
        console.log(
          `Successfully generated review with OpenRouter ${modelName}`
        );
      } else {
        throw new Error(`Invalid response format from OpenRouter ${modelName}`);
      }
      try {
        cost = getCostInfoFromText(prompt + content, `openrouter:${modelName}`);
      } catch (error2) {
        logger_default.warn(
          `Failed to calculate cost information: ${error2 instanceof Error ? error2.message : String(error2)}`
        );
      }
    } catch (error2) {
      throw new ApiError(
        `Failed to generate consolidated review with OpenRouter ${modelName}: ${error2 instanceof Error ? error2.message : String(error2)}`
      );
    }
    let structuredData = null;
    try {
      const jsonMatch = content.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
      const jsonContent = jsonMatch ? jsonMatch[1] : content;
      structuredData = JSON.parse(jsonContent);
      if (!structuredData.summary || !Array.isArray(structuredData.issues)) {
        logger_default.warn(
          "Response is valid JSON but does not have the expected structure"
        );
      }
    } catch (parseError) {
      logger_default.warn(
        `Response is not valid JSON: ${parseError instanceof Error ? parseError.message : String(parseError)}`
      );
    }
    return {
      content,
      cost,
      modelUsed: `openrouter:${modelName}`,
      filePath: "consolidated",
      reviewType,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      structuredData
    };
  } catch (error2) {
    logger_default.error(
      `Error generating consolidated review: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}

// src/clients/openRouterClientWrapper.ts
async function initializeAnyOpenRouterModel2() {
  return initializeAnyOpenRouterModel();
}
async function generateOpenRouterConsolidatedReview2(fileInfos, project, reviewType, projectDocs, options) {
  return generateOpenRouterConsolidatedReview(
    fileInfos,
    project,
    reviewType,
    projectDocs,
    options
  );
}

// src/clients/geminiClient.ts
var import_generative_ai2 = require("@google/generative-ai");
init_rateLimiter2();
init_apiErrorHandler();
init_logger();
init_tokenCounter();
init_promptLoader();
init_promptFormatter();
init_config();
init_modelMaps2();
var DEFAULT_SAFETY_SETTINGS2 = [
  {
    category: import_generative_ai2.HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: import_generative_ai2.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
  },
  {
    category: import_generative_ai2.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: import_generative_ai2.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
  },
  {
    category: import_generative_ai2.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: import_generative_ai2.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
  },
  {
    category: import_generative_ai2.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: import_generative_ai2.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
  }
];
var MAX_OUTPUT_TOKENS = 8192;
var genAI = null;
var selectedGeminiModel = null;
function isGeminiModel() {
  const config4 = getConfig();
  const selectedModel = config4.selectedModel || "";
  const [adapter, modelName] = selectedModel.includes(":") ? selectedModel.split(":") : ["gemini", selectedModel];
  return {
    isCorrect: adapter === "gemini",
    adapter,
    modelName
  };
}
function initializeGeminiClient() {
  const { isCorrect, modelName } = isGeminiModel();
  if (!isCorrect) {
    return;
  }
  if (genAI !== null && selectedGeminiModel !== null) {
    return;
  }
  const apiKey = getApiKeyForProvider("gemini");
  if (!apiKey) {
    logger_default.error("No Google API key found in configuration.");
    logger_default.error("Please add the following to your .env.local file:");
    logger_default.error("- AI_CODE_REVIEW_GOOGLE_API_KEY=your_google_api_key_here");
    process.exit(1);
  }
  const config4 = getConfig();
  if (config4.debug) {
    logger_default.info("Using real Gemini API responses.");
  } else {
    logger_default.info("API key found. Using real Gemini API responses.");
  }
  genAI = new import_generative_ai2.GoogleGenerativeAI(apiKey);
  if (!modelName) {
    throw new Error(
      "No Gemini model specified. Set AI_CODE_REVIEW_MODEL=gemini:<model_name>."
    );
  }
  let apiIdentifier = modelName;
  try {
    const fullModelKey = `gemini:${modelName}`;
    const modelMapping = getModelMapping(fullModelKey);
    if (modelMapping?.apiIdentifier) {
      apiIdentifier = modelMapping.apiIdentifier;
      logger_default.debug(`Using API identifier from mapping: ${modelName} \u2192 ${apiIdentifier}`);
    } else {
      logger_default.debug(`No mapping found for ${fullModelKey}, using model name directly`);
    }
  } catch (error2) {
    logger_default.debug(`Error getting model mapping: ${error2}`);
  }
  logger_default.info(`Initializing Gemini model: ${apiIdentifier}...`);
  selectedGeminiModel = {
    name: apiIdentifier,
    displayName: modelName
  };
}
async function generateConsolidatedReview(files, projectName, reviewType, projectDocs, options) {
  const { isCorrect, adapter, modelName } = isGeminiModel();
  if (!isCorrect) {
    throw new Error(
      `Gemini client was called with an invalid model: ${adapter ? adapter + ":" + modelName : "none specified"}. This is likely a bug in the client selection logic.`
    );
  }
  initializeGeminiClient();
  try {
    await globalRateLimiter.acquire();
    const promptTemplate = await loadPromptTemplate2(reviewType, options);
    const prompt = formatConsolidatedReviewPrompt(
      promptTemplate,
      projectName,
      files.map((file) => ({
        relativePath: file.relativePath || "",
        content: file.content,
        sizeInBytes: file.content.length
      })),
      projectDocs
    );
    const response = await generateGeminiResponse(prompt, options);
    const cost = getCostInfoFromText(
      prompt,
      response,
      `gemini:${selectedGeminiModel?.name}`
    );
    let structuredData = null;
    try {
      const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
      const jsonContent = jsonMatch ? jsonMatch[1] : response;
      structuredData = JSON.parse(jsonContent);
      if (!structuredData.summary || !Array.isArray(structuredData.issues)) {
        logger_default.warn(
          "Response is valid JSON but does not have the expected structure"
        );
      }
    } catch (parseError) {
      logger_default.warn(
        `Response is not valid JSON: ${parseError instanceof Error ? parseError.message : String(parseError)}`
      );
    }
    return {
      content: response,
      cost,
      modelUsed: `gemini:${selectedGeminiModel?.name}`,
      filePath: `${reviewType}`,
      reviewType,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      structuredData
    };
  } catch (error2) {
    logger_default.error(
      `Error generating consolidated review: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}
async function withRetry2(fn, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await fn();
    } catch (e) {
      const err = e;
      if ((err.status === 429 || err.status && err.status >= 500) && i < retries - 1) {
        await new Promise((res) => setTimeout(res, 1e3 * (i + 1)));
      } else {
        throw e;
      }
    }
  }
  throw new Error("Exceeded retry attempts");
}
async function generateGeminiResponse(prompt, _options) {
  if (!genAI || !selectedGeminiModel) {
    throw new Error("Gemini client not initialized");
  }
  try {
    const modelOptions = {
      model: selectedGeminiModel.name,
      safetySettings: DEFAULT_SAFETY_SETTINGS2,
      apiVersion: selectedGeminiModel.useV1Beta ? "v1beta" : void 0
    };
    const model = genAI.getGenerativeModel(modelOptions);
    const outputInstructions = `
You are a helpful AI assistant that provides code reviews. Focus on providing actionable feedback. Do not repeat the instructions in your response.

IMPORTANT: Format your response as a well-structured Markdown document with the following sections:

# Code Review

## Summary
A brief summary of the code review.

## Issues

### High Priority
For each high priority issue:
- Issue title
- File path and line numbers
- Description of the issue
- Code snippet (if relevant)
- Suggested fix
- Impact of the issue

### Medium Priority
(Same format as high priority)

### Low Priority
(Same format as high priority)

## General Recommendations
- List of general recommendations

## Positive Aspects
- List of positive aspects of the code

Ensure your response is well-formatted Markdown with proper headings, bullet points, and code blocks.
`;
    const modifiedPrompt = outputInstructions + "\n\n" + prompt;
    const result = await withRetry2(
      () => model.generateContent({
        contents: [
          {
            role: "user",
            parts: [{ text: modifiedPrompt }]
          }
        ],
        generationConfig: {
          temperature: 0.2,
          topP: 0.8,
          topK: 40,
          maxOutputTokens: MAX_OUTPUT_TOKENS
        }
      })
    );
    const response = result.response;
    const text = response.text();
    return text;
  } catch (error2) {
    if (error2 instanceof Error) {
      throw new ApiError(`Gemini API error: ${error2.message}`);
    } else {
      throw new ApiError(`Unknown Gemini API error: ${String(error2)}`);
    }
  }
}

// src/core/ReviewGenerator.ts
init_logger();
async function generateReview(fileInfos, project, reviewType, projectDocs, options, apiClientConfig) {
  logger_default.debug("generateReview called");
  logger_default.debug(`generateReview: apiClientConfig=${JSON.stringify(apiClientConfig)}`);
  let result;
  if (apiClientConfig.clientType === "OpenRouter") {
    logger_default.debug("generateReview: Using OpenRouter client");
    await initializeAnyOpenRouterModel2();
    result = generateOpenRouterConsolidatedReview2(
      fileInfos,
      project,
      reviewType,
      projectDocs,
      options
    );
  } else if (apiClientConfig.clientType === "Google") {
    logger_default.debug("generateReview: Using Gemini client via factory");
    const client = ClientFactory.createClient(apiClientConfig.modelName);
    await client.initialize();
    result = client.generateConsolidatedReview(
      fileInfos,
      project,
      reviewType,
      projectDocs,
      options
    );
  } else if (apiClientConfig.clientType === "Anthropic") {
    await initializeAnthropicClient2();
    result = generateAnthropicConsolidatedReview2(
      fileInfos,
      project,
      reviewType,
      projectDocs,
      options
    );
  } else if (apiClientConfig.clientType === "OpenAI") {
    await initializeAnyOpenAIModel();
    result = generateOpenAIConsolidatedReview(
      fileInfos,
      project,
      reviewType,
      projectDocs,
      options
    );
  } else {
    logger_default.warn("No API client available. Using mock responses.");
    result = generateConsolidatedReview(
      fileInfos,
      project,
      reviewType,
      projectDocs,
      options
    );
  }
  const reviewResult = await result;
  const packageVersion = process.env.npm_package_version || "2.1.1";
  const commandOptions = Object.entries(options).filter(([key, value]) => {
    if (key.startsWith("_") || value === void 0) return false;
    if (key === "ciData") return false;
    if (Array.isArray(value) && value.length === 0) return false;
    if (typeof value === "object" && value !== null && Object.keys(value).length === 0) return false;
    return true;
  }).map(([key, value]) => {
    if (typeof value === "boolean") {
      return value ? `--${key}` : "";
    }
    if (typeof value === "object" && value !== null) {
      return `--${key}='${JSON.stringify(value)}'`;
    }
    return `--${key}=${value}`;
  }).filter(Boolean).join(" ");
  reviewResult.toolVersion = packageVersion;
  reviewResult.commandOptions = commandOptions;
  if (reviewResult.cost && !reviewResult.costInfo) {
    reviewResult.costInfo = reviewResult.cost;
  }
  if (!reviewResult.filePath) {
    logger_default.warn("Review result has no filePath. Setting to default value.");
    reviewResult.filePath = reviewType;
  }
  if (!reviewResult.modelUsed) {
    logger_default.warn("Review result has no modelUsed. Setting to default value.");
    reviewResult.modelUsed = apiClientConfig.clientType + ":" + apiClientConfig.modelName;
  }
  return reviewResult;
}

// src/strategies/ConsolidatedReviewStrategy.ts
init_logger();
init_ciDataCollector();
var ConsolidatedReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new consolidated review strategy
   * @param reviewType Type of review to perform
   */
  constructor(reviewType) {
    super(reviewType);
  }
  /**
   * Execute the consolidated review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to the review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info(`Executing consolidated ${this.reviewType} review strategy...`);
    let ciData = void 0;
    if (options.language === "typescript" || files.some((f) => f.path.endsWith(".ts") || f.path.endsWith(".tsx"))) {
      logger_default.info("Collecting CI data for TypeScript project...");
      ciData = await collectCIData(process.cwd());
      options.ciData = ciData;
    }
    return generateReview(
      files,
      projectName,
      this.reviewType,
      projectDocs,
      options,
      apiClientConfig
    );
  }
};

// src/strategies/ArchitecturalReviewStrategy.ts
init_logger();
var ArchitecturalReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new architectural review strategy
   */
  constructor() {
    super("architectural");
  }
  /**
   * Execute the architectural review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to the review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info("Executing architectural review strategy...");
    return generateReview(
      files,
      projectName,
      this.reviewType,
      projectDocs,
      options,
      apiClientConfig
    );
  }
};

// src/strategies/UnusedCodeReviewStrategy.ts
init_projectDocs();
init_logger();
init_PromptStrategyFactory();
init_PromptManager();
init_PromptCache();

// src/prompts/schemas/improved-unused-code-schema.ts
var import_zod8 = require("zod");
var import_output_parsers = require("@langchain/core/output_parsers");
var ImprovedUnusedCodeIssueSchema = import_zod8.z.object({
  /**
   * Title/name of the unused code issue
   */
  title: import_zod8.z.string().describe("Brief title describing the unused code issue"),
  /**
   * Detailed description of the unused code issue
   */
  description: import_zod8.z.string().describe("Detailed description of the unused code issue"),
  /**
   * Location information (file and line numbers)
   */
  location: import_zod8.z.object({
    file: import_zod8.z.string().optional().describe("File path"),
    lineStart: import_zod8.z.number().optional().describe("Starting line number"),
    lineEnd: import_zod8.z.number().optional().describe("Ending line number"),
    codeSnippet: import_zod8.z.string().optional().describe("Small code snippet showing the unused code")
  }),
  /**
   * Assessment of confidence that this code is truly unused
   */
  assessment: import_zod8.z.object({
    confidence: import_zod8.z.enum(["high", "medium", "low"]).describe("Confidence level"),
    reasoning: import_zod8.z.string().describe("Reasoning for the confidence assessment"),
    staticAnalysisHint: import_zod8.z.string().optional().describe(
      "Hint for static analysis tool configuration that could catch this"
    )
  }),
  /**
   * Suggested action (remove or keep with explanation)
   */
  suggestedAction: import_zod8.z.object({
    action: import_zod8.z.enum(["remove", "refactor", "keep"]).describe("Suggested action"),
    replacement: import_zod8.z.string().optional().describe("Suggested replacement code if refactoring is recommended"),
    explanation: import_zod8.z.string().describe("Explanation for the suggested action")
  }),
  /**
   * Risk level of removing this code
   */
  riskLevel: import_zod8.z.enum(["high", "medium", "low"]).describe("Risk level of removing this code"),
  /**
   * Impact level of the issue
   */
  impactLevel: import_zod8.z.enum(["high", "medium", "low"]).describe("Impact level of the issue"),
  /**
   * Category of unused code (more detailed than before)
   */
  category: import_zod8.z.enum([
    "unusedFile",
    "unusedFunction",
    "unusedClass",
    "unusedModule",
    "deadCode",
    "unreachableCode",
    "unusedVariable",
    "unusedImport",
    "commentedCode",
    "redundantCode",
    "deprecatedFeature",
    "featureFlag",
    "unusedParameter",
    "unusedProperty",
    "unusedType",
    "other"
  ]).describe("Detailed category of unused code"),
  /**
   * Flag indicating if this is a complete element (file, function, class) that can be entirely removed
   */
  isCompleteElement: import_zod8.z.boolean().describe(
    "True if this is a complete element like a file, function, or class that can be removed entirely"
  ),
  /**
   * Potential dependencies or references that should be checked
   */
  relatedChecks: import_zod8.z.array(import_zod8.z.string()).optional().describe(
    "Additional files or components that should be checked to confirm this is truly unused"
  )
});
var ImprovedUnusedCodeReviewSchema = import_zod8.z.object({
  /**
   * Array of high impact unused code issues
   */
  highImpactIssues: import_zod8.z.array(ImprovedUnusedCodeIssueSchema).describe("High impact unused code issues"),
  /**
   * Array of medium impact unused code issues
   */
  mediumImpactIssues: import_zod8.z.array(ImprovedUnusedCodeIssueSchema).describe("Medium impact unused code issues"),
  /**
   * Array of low impact unused code issues
   */
  lowImpactIssues: import_zod8.z.array(ImprovedUnusedCodeIssueSchema).describe("Low impact unused code issues"),
  /**
   * Summary of the unused code review
   */
  summary: import_zod8.z.string().describe("Overall summary of the unused code review findings"),
  /**
   * General recommendations for preventing unused code
   */
  recommendations: import_zod8.z.array(import_zod8.z.string()).describe(
    "General recommendations for preventing unused code in the future"
  ),
  /**
   * Project-wide patterns observed
   */
  codebasePatterns: import_zod8.z.array(
    import_zod8.z.object({
      pattern: import_zod8.z.string().describe("Description of the pattern"),
      impact: import_zod8.z.string().describe("Impact of the pattern on code quality"),
      suggestion: import_zod8.z.string().describe("Suggestion to improve the pattern")
    })
  ).optional().describe("Project-wide patterns related to unused code"),
  /**
   * Static analysis tools that could help
   */
  recommendedTools: import_zod8.z.array(
    import_zod8.z.object({
      tool: import_zod8.z.string().describe("Tool name"),
      description: import_zod8.z.string().describe("Brief description of the tool"),
      configuration: import_zod8.z.string().optional().describe("Suggested configuration")
    })
  ).optional().describe("Recommended static analysis tools for preventing unused code")
});
var improvedUnusedCodeReviewParser = import_output_parsers.StructuredOutputParser.fromZodSchema(ImprovedUnusedCodeReviewSchema);
function getImprovedUnusedCodeReviewFormatInstructions() {
  return improvedUnusedCodeReviewParser.getFormatInstructions();
}

// src/formatters/unusedCodeFormatter.ts
var import_chalk2 = __toESM(require("chalk"));
function formatUnusedCodeReviewAsMarkdown(review) {
  let markdown = "# Unused Code Review: Files & Functions That Can Be Safely Removed\n\n";
  markdown += "## Summary\n\n";
  markdown += `${review.summary}

`;
  const unusedFiles = getAllIssuesByCategory(review, "unusedFile");
  const unusedFunctions = getAllIssuesByCategory(review, "unusedFunction");
  const unusedClasses = getAllIssuesByCategory(review, "unusedClass");
  const unusedModules = getAllIssuesByCategory(review, "unusedModule");
  const otherUnusedElements = getAllIssuesByCategory(review, null, true);
  if (unusedFiles.length > 0) {
    markdown += "## Unused Files\n\n";
    markdown += "_The following files are not imported or used anywhere and can be safely removed:_\n\n";
    const highConfidenceFiles = unusedFiles.filter(
      (issue) => issue.assessment.confidence === "high"
    );
    const mediumConfidenceFiles = unusedFiles.filter(
      (issue) => issue.assessment.confidence === "medium"
    );
    const lowConfidenceFiles = unusedFiles.filter(
      (issue) => issue.assessment.confidence === "low"
    );
    if (highConfidenceFiles.length > 0) {
      markdown += "### High Confidence (Safe to Remove)\n\n";
      markdown += formatIssuesAsChecklist(highConfidenceFiles);
    }
    if (mediumConfidenceFiles.length > 0) {
      markdown += "### Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatIssuesAsChecklist(mediumConfidenceFiles);
    }
    if (lowConfidenceFiles.length > 0) {
      markdown += "### Low Confidence (Thorough Verification Required)\n\n";
      markdown += formatIssuesAsChecklist(lowConfidenceFiles);
    }
  }
  if (unusedFunctions.length > 0) {
    markdown += "## Unused Functions\n\n";
    markdown += "_The following functions are never called and can be safely removed:_\n\n";
    const highConfidenceFunctions = unusedFunctions.filter(
      (issue) => issue.assessment.confidence === "high"
    );
    const mediumConfidenceFunctions = unusedFunctions.filter(
      (issue) => issue.assessment.confidence === "medium"
    );
    const lowConfidenceFunctions = unusedFunctions.filter(
      (issue) => issue.assessment.confidence === "low"
    );
    if (highConfidenceFunctions.length > 0) {
      markdown += "### High Confidence (Safe to Remove)\n\n";
      markdown += formatIssuesAsChecklist(highConfidenceFunctions);
    }
    if (mediumConfidenceFunctions.length > 0) {
      markdown += "### Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatIssuesAsChecklist(mediumConfidenceFunctions);
    }
    if (lowConfidenceFunctions.length > 0) {
      markdown += "### Low Confidence (Thorough Verification Required)\n\n";
      markdown += formatIssuesAsChecklist(lowConfidenceFunctions);
    }
  }
  if (unusedClasses.length > 0) {
    markdown += "## Unused Classes\n\n";
    markdown += "_The following classes are never instantiated or extended and can be safely removed:_\n\n";
    const highConfidenceClasses = unusedClasses.filter(
      (issue) => issue.assessment.confidence === "high"
    );
    const mediumConfidenceClasses = unusedClasses.filter(
      (issue) => issue.assessment.confidence === "medium"
    );
    const lowConfidenceClasses = unusedClasses.filter(
      (issue) => issue.assessment.confidence === "low"
    );
    if (highConfidenceClasses.length > 0) {
      markdown += "### High Confidence (Safe to Remove)\n\n";
      markdown += formatIssuesAsChecklist(highConfidenceClasses);
    }
    if (mediumConfidenceClasses.length > 0) {
      markdown += "### Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatIssuesAsChecklist(mediumConfidenceClasses);
    }
    if (lowConfidenceClasses.length > 0) {
      markdown += "### Low Confidence (Thorough Verification Required)\n\n";
      markdown += formatIssuesAsChecklist(lowConfidenceClasses);
    }
  }
  if (unusedModules.length > 0) {
    markdown += "## Unused Modules\n\n";
    markdown += "_The following modules are never imported or used and can be safely removed:_\n\n";
    const highConfidenceModules = unusedModules.filter(
      (issue) => issue.assessment.confidence === "high"
    );
    const mediumConfidenceModules = unusedModules.filter(
      (issue) => issue.assessment.confidence === "medium"
    );
    const lowConfidenceModules = unusedModules.filter(
      (issue) => issue.assessment.confidence === "low"
    );
    if (highConfidenceModules.length > 0) {
      markdown += "### High Confidence (Safe to Remove)\n\n";
      markdown += formatIssuesAsChecklist(highConfidenceModules);
    }
    if (mediumConfidenceModules.length > 0) {
      markdown += "### Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatIssuesAsChecklist(mediumConfidenceModules);
    }
    if (lowConfidenceModules.length > 0) {
      markdown += "### Low Confidence (Thorough Verification Required)\n\n";
      markdown += formatIssuesAsChecklist(lowConfidenceModules);
    }
  }
  if (otherUnusedElements.length > 0) {
    markdown += "## Other Unused Code\n\n";
    markdown += "_The following code elements can be safely removed:_\n\n";
    const highConfidenceOther = otherUnusedElements.filter(
      (issue) => issue.assessment.confidence === "high"
    );
    const mediumConfidenceOther = otherUnusedElements.filter(
      (issue) => issue.assessment.confidence === "medium"
    );
    const lowConfidenceOther = otherUnusedElements.filter(
      (issue) => issue.assessment.confidence === "low"
    );
    if (highConfidenceOther.length > 0) {
      markdown += "### High Confidence (Safe to Remove)\n\n";
      markdown += formatIssuesAsChecklist(highConfidenceOther);
    }
    if (mediumConfidenceOther.length > 0) {
      markdown += "### Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatIssuesAsChecklist(mediumConfidenceOther);
    }
    if (lowConfidenceOther.length > 0) {
      markdown += "### Low Confidence (Thorough Verification Required)\n\n";
      markdown += formatIssuesAsChecklist(lowConfidenceOther);
    }
  }
  if (review.recommendedTools && review.recommendedTools.length > 0) {
    markdown += "## Recommended Tools\n\n";
    markdown += "_Tools that can help automate the detection of unused code:_\n\n";
    for (const tool of review.recommendedTools) {
      markdown += `### ${tool.tool}

`;
      markdown += `${tool.description}

`;
      if (tool.configuration) {
        markdown += "```\n";
        markdown += tool.configuration;
        markdown += "\n```\n\n";
      }
    }
  }
  markdown += "## General Recommendations\n\n";
  for (const recommendation of review.recommendations) {
    markdown += `- ${recommendation}
`;
  }
  return markdown;
}
function getAllIssuesByCategory(review, category, excludeMainCategories = false) {
  const allIssues = [
    ...review.highImpactIssues,
    ...review.mediumImpactIssues,
    ...review.lowImpactIssues
  ];
  if (category === null) {
    if (excludeMainCategories) {
      return allIssues.filter(
        (issue) => issue.category !== "unusedFile" && issue.category !== "unusedFunction" && issue.category !== "unusedClass" && issue.category !== "unusedModule"
      );
    }
    return allIssues;
  }
  return allIssues.filter((issue) => issue.category === category);
}
function formatIssuesAsChecklist(issues) {
  let markdown = "";
  const issuesByFile = {};
  for (const issue of issues) {
    const filePath = issue.location.file || "Unknown file";
    if (!issuesByFile[filePath]) {
      issuesByFile[filePath] = [];
    }
    issuesByFile[filePath].push(issue);
  }
  for (const [filePath, fileIssues] of Object.entries(issuesByFile)) {
    markdown += `### ${filePath}

`;
    for (const issue of fileIssues) {
      const lines = issue.location.lineStart && issue.location.lineEnd ? `(lines ${issue.location.lineStart}-${issue.location.lineEnd})` : "";
      const isCompleteElement = issue.isCompleteElement ? "**[COMPLETE ELEMENT]** " : "";
      markdown += `- [ ] ${isCompleteElement}${issue.title} ${lines}
`;
      markdown += `  - **Description**: ${issue.description}
`;
      if (issue.location.codeSnippet) {
        markdown += "  ```\n";
        markdown += `  ${issue.location.codeSnippet}
`;
        markdown += "  ```\n";
      }
      markdown += `  - **Confidence**: ${issue.assessment.confidence.toUpperCase()} - ${issue.assessment.reasoning}
`;
      markdown += `  - **Suggested Action**: ${issue.suggestedAction.explanation}
`;
      if (issue.relatedChecks && issue.relatedChecks.length > 0) {
        markdown += "  - **Related Checks**:\n";
        for (const check of issue.relatedChecks) {
          markdown += `    - ${check}
`;
        }
      }
      markdown += "\n";
    }
  }
  return markdown;
}
function generateRemovalScript(review) {
  let script = "#!/bin/bash\n\n";
  script += "# Script generated by AI Code Review to remove unused code\n";
  script += "# WARNING: This script should be carefully reviewed before execution\n";
  script += "# RECOMMENDED: Make a backup before running this script\n\n";
  script += 'echo "This script will remove unused code found in the codebase."\n\n';
  const unusedFiles = getAllIssuesByCategory(review, "unusedFile").filter(
    (issue) => issue.assessment.confidence === "high"
  );
  const unusedFunctions = getAllIssuesByCategory(
    review,
    "unusedFunction"
  ).filter(
    (issue) => issue.assessment.confidence === "high" && issue.isCompleteElement
  );
  const unusedClasses = getAllIssuesByCategory(review, "unusedClass").filter(
    (issue) => issue.assessment.confidence === "high" && issue.isCompleteElement
  );
  const unusedModules = getAllIssuesByCategory(review, "unusedModule").filter(
    (issue) => issue.assessment.confidence === "high"
  );
  const otherHighConfidenceIssues = getAllIssuesByCategory(
    review,
    null,
    true
  ).filter((issue) => issue.assessment.confidence === "high");
  if (unusedFiles.length > 0) {
    script += 'echo "REMOVING UNUSED FILES:"\n';
    for (const issue of unusedFiles) {
      if (issue.location.file) {
        script += `echo "  - ${issue.location.file}"
`;
        script += `rm "${issue.location.file}"
`;
      }
    }
    script += 'echo "Unused files removed successfully."\n\n';
  }
  const completeElements = [
    ...unusedFunctions,
    ...unusedClasses,
    ...unusedModules,
    ...otherHighConfidenceIssues.filter((issue) => issue.isCompleteElement)
  ];
  if (completeElements.length > 0) {
    script += 'echo "REMOVING COMPLETE CODE ELEMENTS:"\n';
    const elementsByFile = {};
    for (const element of completeElements) {
      const filePath = element.location.file;
      if (!filePath || !element.location.lineStart || !element.location.lineEnd)
        continue;
      if (!elementsByFile[filePath]) {
        elementsByFile[filePath] = [];
      }
      elementsByFile[filePath].push(element);
    }
    for (const filePath in elementsByFile) {
      elementsByFile[filePath].sort((a, b) => {
        const aStart = a.location.lineStart || 0;
        const bStart = b.location.lineStart || 0;
        return bStart - aStart;
      });
    }
    for (const [filePath, elements] of Object.entries(elementsByFile)) {
      script += `echo "Processing ${filePath}"
`;
      for (const element of elements) {
        if (element.location.lineStart && element.location.lineEnd) {
          script += `sed -i '${element.location.lineStart},${element.location.lineEnd}d' "${filePath}"
`;
          script += `echo "  Removed ${element.title} (lines ${element.location.lineStart}-${element.location.lineEnd})"
`;
        }
      }
      script += "\n";
    }
  }
  const partialIssues = otherHighConfidenceIssues.filter(
    (issue) => !issue.isCompleteElement
  );
  if (partialIssues.length > 0) {
    script += 'echo "REMOVING PARTIAL CODE ELEMENTS:"\n';
    const issuesByFile = {};
    for (const issue of partialIssues) {
      const filePath = issue.location.file;
      if (!filePath || !issue.location.lineStart || !issue.location.lineEnd)
        continue;
      if (!issuesByFile[filePath]) {
        issuesByFile[filePath] = [];
      }
      issuesByFile[filePath].push(issue);
    }
    for (const filePath in issuesByFile) {
      issuesByFile[filePath].sort((a, b) => {
        const aStart = a.location.lineStart || 0;
        const bStart = b.location.lineStart || 0;
        return bStart - aStart;
      });
    }
    for (const [filePath, fileIssues] of Object.entries(issuesByFile)) {
      script += `echo "Processing ${filePath}"
`;
      for (const issue of fileIssues) {
        if (issue.location.lineStart && issue.location.lineEnd) {
          script += `sed -i '${issue.location.lineStart},${issue.location.lineEnd}d' "${filePath}"
`;
          script += `echo "  Removed ${issue.title} (lines ${issue.location.lineStart}-${issue.location.lineEnd})"
`;
        }
      }
      script += "\n";
    }
  }
  script += 'echo "Unused code removal complete. Please review the changes before committing."\n';
  return script;
}

// src/strategies/UnusedCodeReviewStrategy.ts
var import_child_process2 = require("child_process");
var UnusedCodeReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new unused code review strategy
   */
  constructor() {
    super("unused-code");
  }
  /**
   * Run static analysis tools to get data about unused code
   * @param options Review options
   * @returns Metadata from static analysis tools
   */
  async getToolingData(options) {
    const result = {
      tsPrune: null,
      eslint: null
    };
    try {
      if (options.useTsPrune) {
        result.tsPrune = await this.runTsPrune();
      }
      if (options.useEslint) {
        result.eslint = await this.runEslint();
      }
    } catch (error2) {
      logger_default.error("Error running static analysis tools:", error2);
    }
    return result;
  }
  /**
   * Executes ts-prune to find unused TypeScript exports in the project.
   * 
   * This method runs the ts-prune tool via npx, which analyzes TypeScript
   * files to identify exports that are not imported anywhere else in the project.
   * The output is parsed into a structured format for use in the review.
   * 
   * @returns {Promise<any>} Object containing:
   *   - unusedExports: Array of objects with file, line, export name, and notes
   *   - totalCount: Total number of unused exports found
   * 
   * @throws Will reject with an error if ts-prune execution fails
   * @example
   * const tsPruneData = await strategy.runTsPrune();
   * // Example result:
   * // {
   * //   unusedExports: [
   * //     { file: "src/utils/helpers.ts", line: 42, export: "unusedFunction", note: null }
   * //   ],
   * //   totalCount: 1
   * // }
   */
  async runTsPrune() {
    return new Promise((resolve8, reject) => {
      (0, import_child_process2.exec)("npx ts-prune", (error2, stdout, stderr) => {
        if (error2 && error2.code !== 0 && error2.code !== 1) {
          logger_default.warn(`ts-prune execution error: ${stderr}`);
          reject(error2);
          return;
        }
        const lines = stdout.trim().split("\n");
        const unusedExports = lines.map((line) => {
          const match = line.match(/([^:]+):(\d+) - (\w+)( \(([^)]+)\))?/);
          if (match) {
            return {
              file: match[1],
              line: parseInt(match[2]),
              export: match[3],
              note: match[5] || null
            };
          }
          return null;
        }).filter(Boolean);
        resolve8({
          unusedExports,
          totalCount: unusedExports.length
        });
      });
    });
  }
  /**
   * Run eslint to find unused variables
   * @returns Results from eslint
   */
  async runEslint() {
    return new Promise((resolve8, reject) => {
      (0, import_child_process2.exec)("npx eslint . --ext .ts,.tsx --format json", (error2, stdout, stderr) => {
        if (error2 && error2.code !== 0 && error2.code !== 1) {
          logger_default.warn(`eslint execution error: ${stderr}`);
          reject(error2);
          return;
        }
        try {
          const results = JSON.parse(stdout);
          const unusedVars = [];
          let totalUnusedCount = 0;
          for (const result of results) {
            for (const message of result.messages) {
              if (message.ruleId === "@typescript-eslint/no-unused-vars") {
                totalUnusedCount++;
                unusedVars.push({
                  file: result.filePath,
                  line: message.line,
                  column: message.column,
                  variable: message.message.match(/'([^']+)'/)?.[1] || "unknown",
                  severity: message.severity === 2 ? "error" : "warning"
                });
              }
            }
          }
          resolve8({
            unusedVariables: unusedVars,
            totalCount: totalUnusedCount
          });
        } catch (error3) {
          logger_default.error("Error parsing eslint output:", error3);
          reject(error3);
        }
      });
    });
  }
  /**
   * Performs a comprehensive unused code review on the provided files.
   * 
   * This method:
   * 1. Runs static analysis tools if configured (ts-prune, ESLint)
   * 2. Enhances review options with language-specific settings
   * 3. Applies specialized LangChain prompt strategies
   * 4. Generates an AI-based review of unused code
   * 5. Post-processes the result to format it for user consumption
   * 6. Generates removal scripts for identified unused code
   * 
   * @param {FileInfo[]} files - Array of files to analyze for unused code
   * @param {string} projectName - Name of the project being reviewed
   * @param {ProjectDocs | null} projectDocs - Project documentation or null if not available
   * @param {ReviewOptions} options - Configuration options for the review
   * @param {ApiClientConfig} apiClientConfig - Configuration for the AI API client
   * @returns {Promise<ReviewResult>} Review result with detailed unused code findings
   * 
   * @throws Will log but not throw errors from static analysis tools
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info(
      `Executing unused code review strategy for ${files.length} files...`
    );
    let toolingMetadata = {};
    if (options.useTsPrune || options.useEslint) {
      toolingMetadata = await this.getToolingData(options);
      if (projectDocs) {
        addMetadataToProjectDocs(
          projectDocs,
          "unusedCodeTooling",
          `## Static Analysis Tool Results

${JSON.stringify(toolingMetadata, null, 2)}`
        );
      }
    }
    const enhancedOptions = {
      ...options,
      type: this.reviewType,
      // Use improved schema instructions if available, fall back to standard
      schemaInstructions: getImprovedUnusedCodeReviewFormatInstructions(),
      // Try to use the improved prompt template
      promptFile: options.language === "typescript" ? `${process.cwd()}/prompts/typescript/improved-unused-code-review.md` : `${process.cwd()}/prompts/improved-unused-code-review.md`
    };
    if (!enhancedOptions.promptStrategy) {
      enhancedOptions.promptStrategy = "langchain";
      const promptManager = PromptManager.getInstance();
      const promptCache = PromptCache.getInstance();
      PromptStrategyFactory.createStrategy(
        "langchain",
        promptManager,
        promptCache
      );
      logger_default.info("Using LangChain prompt strategy for unused code review");
    }
    const reviewResult = await generateReview(
      files,
      projectName,
      this.reviewType,
      projectDocs,
      enhancedOptions,
      apiClientConfig
    );
    if (reviewResult.response && reviewResult.outputFormat === "json") {
      try {
        const parsedResult = typeof reviewResult.response === "string" ? JSON.parse(reviewResult.response) : reviewResult.response;
        if (parsedResult.highImpactIssues && parsedResult.mediumImpactIssues && parsedResult.lowImpactIssues) {
          const formattedMarkdown = formatUnusedCodeReviewAsMarkdown(parsedResult);
          const removalScript = generateRemovalScript(parsedResult);
          reviewResult.content = formattedMarkdown;
          reviewResult.outputFormat = "markdown";
          if (!reviewResult.metadata) {
            reviewResult.metadata = {};
          }
          reviewResult.metadata.removalScript = removalScript;
          logger_default.info("Reformatted unused code review for improved usability");
        }
      } catch (error2) {
        logger_default.warn("Failed to reformat unused code review response:", error2);
      }
    }
    return reviewResult;
  }
};

// src/strategies/FocusedUnusedCodeReviewStrategy.ts
init_logger();

// src/prompts/schemas/focused-unused-code-schema.ts
var import_zod9 = require("zod");
var import_output_parsers2 = require("@langchain/core/output_parsers");
var UnusedElementSchema = import_zod9.z.object({
  /**
   * Type of the unused element
   */
  elementType: import_zod9.z.enum([
    "file",
    "function",
    "class",
    "interface",
    "type",
    "variable",
    "import",
    "dead-branch",
    "parameter",
    "property",
    "enum",
    "export",
    "hook",
    "component"
  ]).describe("Type of unused code element"),
  /**
   * Name of the element
   */
  name: import_zod9.z.string().describe("Name of the unused code element"),
  /**
   * File where the element is located
   */
  filePath: import_zod9.z.string().describe("File path containing the unused element"),
  /**
   * Line numbers where the element is defined
   */
  location: import_zod9.z.object({
    startLine: import_zod9.z.number().describe("Starting line number"),
    endLine: import_zod9.z.number().optional().describe("Ending line number")
  }),
  /**
   * Code snippet showing the unused element
   */
  codeSnippet: import_zod9.z.string().describe("Code snippet showing the unused element"),
  /**
   * Confidence level that this element is truly unused
   */
  confidence: import_zod9.z.enum(["high", "medium", "low"]).describe("Confidence level that this element is truly unused"),
  /**
   * Explanation for the confidence assessment
   */
  confidenceReason: import_zod9.z.string().describe("Explanation for the confidence level"),
  /**
   * Whether other code depends on this element
   */
  hasDependents: import_zod9.z.boolean().default(false).describe("Whether other code depends on this element"),
  /**
   * Elements that depend on this element (if any)
   */
  dependents: import_zod9.z.array(import_zod9.z.string()).optional().describe("Elements that depend on this element (if any)"),
  /**
   * Potential risks of removing this element
   */
  removalRisks: import_zod9.z.string().optional().describe("Potential risks of removing this element")
});
var FocusedUnusedCodeReviewSchema = import_zod9.z.object({
  /**
   * Unused files
   */
  unusedFiles: import_zod9.z.array(
    UnusedElementSchema.refine((val) => val.elementType === "file", {
      message: "Element must be a file"
    })
  ).describe("Files that are never imported or used"),
  /**
   * Unused functions
   */
  unusedFunctions: import_zod9.z.array(
    UnusedElementSchema.refine(
      (val) => ["function", "hook"].includes(val.elementType),
      {
        message: "Element must be a function or hook"
      }
    )
  ).describe("Functions that are never called"),
  /**
   * Unused classes
   */
  unusedClasses: import_zod9.z.array(
    UnusedElementSchema.refine(
      (val) => ["class", "component"].includes(val.elementType),
      {
        message: "Element must be a class or component"
      }
    )
  ).describe("Classes that are never instantiated"),
  /**
   * Unused types and interfaces
   */
  unusedTypesAndInterfaces: import_zod9.z.array(
    UnusedElementSchema.refine(
      (val) => ["interface", "type", "enum"].includes(val.elementType),
      {
        message: "Element must be an interface, type, or enum"
      }
    )
  ).describe("Types and interfaces that are never used"),
  /**
   * Dead code branches
   */
  deadCodeBranches: import_zod9.z.array(
    UnusedElementSchema.refine((val) => val.elementType === "dead-branch", {
      message: "Element must be a dead branch"
    })
  ).describe("Code branches that can never execute"),
  /**
   * Unused variables and imports
   */
  unusedVariablesAndImports: import_zod9.z.array(
    UnusedElementSchema.refine(
      (val) => ["variable", "import", "parameter", "property", "export"].includes(
        val.elementType
      ),
      {
        message: "Element must be a variable, import, parameter, property, or export"
      }
    )
  ).describe("Variables and imports that are never used"),
  /**
   * Summary statistics
   */
  summary: import_zod9.z.object({
    totalUnusedElements: import_zod9.z.number().describe("Total number of unused elements found"),
    highConfidenceCount: import_zod9.z.number().describe("Number of high-confidence findings"),
    filesWithUnusedCode: import_zod9.z.number().describe("Number of files containing unused code"),
    potentialCodeReduction: import_zod9.z.string().describe("Estimated percentage of code that could be removed")
  }).describe("Summary statistics of the unused code findings")
});
var focusedUnusedCodeReviewParser = import_output_parsers2.StructuredOutputParser.fromZodSchema(FocusedUnusedCodeReviewSchema);
function getFocusedUnusedCodeReviewFormatInstructions() {
  return focusedUnusedCodeReviewParser.getFormatInstructions();
}

// src/formatters/focusedUnusedCodeFormatter.ts
var import_chalk3 = __toESM(require("chalk"));
function formatFocusedUnusedCodeReviewAsMarkdown(review) {
  let markdown = "# Unused Code Detection Report\n\n";
  markdown += "## Summary\n\n";
  markdown += `- **Total unused elements**: ${review.summary.totalUnusedElements}
`;
  markdown += `- **High-confidence findings**: ${review.summary.highConfidenceCount}
`;
  markdown += `- **Files with unused code**: ${review.summary.filesWithUnusedCode}
`;
  markdown += `- **Potential code reduction**: ${review.summary.potentialCodeReduction}

`;
  if (review.unusedFiles.length > 0) {
    markdown += "## Unused Files\n\n";
    markdown += "The following files are never imported or used anywhere in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "high"
    );
    const mediumConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "medium"
    );
    const lowConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedFunctions.length > 0) {
    markdown += "## Unused Functions\n\n";
    markdown += "The following functions are never called in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "high"
    );
    const mediumConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "medium"
    );
    const lowConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedClasses.length > 0) {
    markdown += "## Unused Classes\n\n";
    markdown += "The following classes are never instantiated in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "high"
    );
    const mediumConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "medium"
    );
    const lowConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedTypesAndInterfaces.length > 0) {
    markdown += "## Unused Types and Interfaces\n\n";
    markdown += "The following types and interfaces are never used in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "high"
    );
    const mediumConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "medium"
    );
    const lowConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  if (review.deadCodeBranches.length > 0) {
    markdown += "## Dead Code Branches\n\n";
    markdown += "The following code branches can never execute and can be safely removed:\n\n";
    const highConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "high"
    );
    const mediumConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "medium"
    );
    const lowConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedVariablesAndImports.length > 0) {
    markdown += "## Unused Variables and Imports\n\n";
    markdown += "The following variables and imports are never used in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "high"
    );
    const mediumConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "medium"
    );
    const lowConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Investigation)\n\n";
      markdown += formatElementsAsChecklist(lowConfidence);
    }
  }
  return markdown;
}
function formatElementsAsChecklist(elements) {
  let markdown = "";
  const elementsByFile = {};
  for (const element of elements) {
    if (!elementsByFile[element.filePath]) {
      elementsByFile[element.filePath] = [];
    }
    elementsByFile[element.filePath].push(element);
  }
  for (const [filePath, fileElements] of Object.entries(elementsByFile)) {
    markdown += `### ${filePath}

`;
    for (const element of fileElements) {
      const location = element.location.endLine ? `(lines ${element.location.startLine}-${element.location.endLine})` : `(line ${element.location.startLine})`;
      markdown += `- [ ] **${element.name}** ${location}
`;
      markdown += `  - **Type**: ${formatElementType(element.elementType)}
`;
      markdown += `  - **Confidence**: ${element.confidence.toUpperCase()} - ${element.confidenceReason}
`;
      if (element.codeSnippet) {
        markdown += "  ```\n";
        markdown += `  ${element.codeSnippet.trim()}
`;
        markdown += "  ```\n";
      }
      if (element.removalRisks) {
        markdown += `  - **Removal risks**: ${element.removalRisks}
`;
      }
      markdown += "\n";
    }
  }
  return markdown;
}
function formatElementType(elementType) {
  const mapping = {
    file: "File",
    function: "Function",
    class: "Class",
    interface: "Interface",
    type: "Type",
    variable: "Variable",
    import: "Import",
    "dead-branch": "Dead Code Branch",
    parameter: "Parameter",
    property: "Property",
    enum: "Enum",
    export: "Export",
    hook: "React Hook",
    component: "React Component"
  };
  return mapping[elementType] || elementType;
}
function generateFocusedRemovalScript(review) {
  let script = "#!/bin/bash\n\n";
  script += "# Script generated by AI Code Review to remove unused code\n";
  script += "# WARNING: This script should be carefully reviewed before execution\n";
  script += "# RECOMMENDED: Create a git branch before running this script\n\n";
  script += 'echo "This script will remove unused code found in the static analysis."\n\n';
  const highConfidenceFiles = review.unusedFiles.filter(
    (file) => file.confidence === "high"
  );
  if (highConfidenceFiles.length > 0) {
    script += 'echo "REMOVING UNUSED FILES:"\n';
    for (const file of highConfidenceFiles) {
      script += `echo "  - ${file.filePath}"
`;
      script += `rm "${file.filePath}"
`;
    }
    script += 'echo "Unused files removed successfully."\n\n';
  }
  const highConfidenceFunctions = review.unusedFunctions.filter(
    (func) => func.confidence === "high"
  );
  const highConfidenceClasses = review.unusedClasses.filter(
    (cls) => cls.confidence === "high"
  );
  const highConfidenceTypes = review.unusedTypesAndInterfaces.filter(
    (type) => type.confidence === "high"
  );
  const highConfidenceBranches = review.deadCodeBranches.filter(
    (branch) => branch.confidence === "high"
  );
  const elementsByFile = {};
  for (const func of highConfidenceFunctions) {
    if (!elementsByFile[func.filePath]) {
      elementsByFile[func.filePath] = [];
    }
    elementsByFile[func.filePath].push(func);
  }
  for (const cls of highConfidenceClasses) {
    if (!elementsByFile[cls.filePath]) {
      elementsByFile[cls.filePath] = [];
    }
    elementsByFile[cls.filePath].push(cls);
  }
  for (const type of highConfidenceTypes) {
    if (!elementsByFile[type.filePath]) {
      elementsByFile[type.filePath] = [];
    }
    elementsByFile[type.filePath].push(type);
  }
  for (const branch of highConfidenceBranches) {
    if (!elementsByFile[branch.filePath]) {
      elementsByFile[branch.filePath] = [];
    }
    elementsByFile[branch.filePath].push(branch);
  }
  for (const filePath in elementsByFile) {
    if (highConfidenceFiles.find((file) => file.filePath === filePath)) {
      continue;
    }
    elementsByFile[filePath].sort((a, b) => {
      return (b.location.startLine || 0) - (a.location.startLine || 0);
    });
  }
  if (Object.keys(elementsByFile).length > 0) {
    script += 'echo "REMOVING UNUSED CODE ELEMENTS:"\n\n';
    for (const [filePath, elements] of Object.entries(elementsByFile)) {
      if (highConfidenceFiles.find((file) => file.filePath === filePath)) {
        continue;
      }
      script += `echo "Processing ${filePath}"
`;
      for (const element of elements) {
        if (element.location.startLine && element.location.endLine) {
          script += `sed -i '${element.location.startLine},${element.location.endLine}d' "${filePath}"
`;
          script += `echo "  Removed ${element.name} (${formatElementType(element.elementType)}, lines ${element.location.startLine}-${element.location.endLine})"
`;
        } else if (element.location.startLine) {
          script += `sed -i '${element.location.startLine}d' "${filePath}"
`;
          script += `echo "  Removed ${element.name} (${formatElementType(element.elementType)}, line ${element.location.startLine})"
`;
        }
      }
      script += "\n";
    }
  }
  script += 'echo "Code removal complete. Please review the changes and run tests to ensure functionality."\n';
  return script;
}

// src/strategies/FocusedUnusedCodeReviewStrategy.ts
var import_path18 = __toESM(require("path"));
var FocusedUnusedCodeReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new focused unused code review strategy
   */
  constructor() {
    super("unused-code");
  }
  /**
   * Execute the focused unused code review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info(
      `Executing focused unused code review strategy for ${files.length} files...`
    );
    let promptFile;
    if (options.language) {
      promptFile = import_path18.default.resolve(
        process.cwd(),
        "prompts",
        options.language.toLowerCase(),
        "focused-unused-code-review.md"
      );
    } else {
      promptFile = import_path18.default.resolve(
        process.cwd(),
        "prompts",
        "focused-unused-code-review.md"
      );
    }
    const enhancedOptions = {
      ...options,
      type: this.reviewType,
      promptFile,
      schemaInstructions: getFocusedUnusedCodeReviewFormatInstructions(),
      promptStrategy: "langchain"
    };
    const reviewResult = await generateReview(
      files,
      projectName,
      this.reviewType,
      projectDocs,
      enhancedOptions,
      apiClientConfig
    );
    if (reviewResult.response && reviewResult.outputFormat === "json") {
      try {
        const parsedResult = typeof reviewResult.response === "string" ? JSON.parse(reviewResult.response) : reviewResult.response;
        if (parsedResult.unusedFiles && parsedResult.unusedFunctions && parsedResult.unusedClasses && parsedResult.summary) {
          const formattedMarkdown = formatFocusedUnusedCodeReviewAsMarkdown(parsedResult);
          const removalScript = generateFocusedRemovalScript(parsedResult);
          reviewResult.content = formattedMarkdown;
          reviewResult.outputFormat = "markdown";
          if (!reviewResult.metadata) {
            reviewResult.metadata = {};
          }
          reviewResult.metadata.removalScript = removalScript;
          logger_default.info(
            "Reformatted focused unused code review for improved usability"
          );
        }
      } catch (error2) {
        logger_default.warn(
          "Failed to reformat focused unused code review response:",
          error2
        );
      }
    }
    return reviewResult;
  }
};

// src/formatters/codeTracingUnusedCodeFormatter.ts
function formatCodeTracingUnusedCodeReviewAsMarkdown(review) {
  let markdown = "# Code Tracing Unused Code Detection Report\n\n";
  markdown += "## Summary\n\n";
  markdown += `- **Total unused elements**: ${review.summary.totalUnusedElements}
`;
  markdown += `- **High-confidence findings**: ${review.summary.highConfidenceCount}
`;
  markdown += `- **Files with unused code**: ${review.summary.filesWithUnusedCode}
`;
  markdown += `- **Potential code reduction**: ${review.summary.potentialCodeReduction}

`;
  markdown += "## Analysis Methodology\n\n";
  markdown += "### Entry Points\n\n";
  for (const entryPoint of review.analysisMethodology.entryPoints) {
    markdown += `- ${entryPoint}
`;
  }
  markdown += "\n";
  markdown += `### Module Resolution

${review.analysisMethodology.moduleResolution}

`;
  markdown += `### Reference Tracking

${review.analysisMethodology.referenceTracking}

`;
  markdown += "### Limitations\n\n";
  for (const limitation of review.analysisMethodology.limitations) {
    markdown += `- ${limitation}
`;
  }
  markdown += "\n";
  if (review.unusedFiles.length > 0) {
    markdown += "## Unused Files\n\n";
    markdown += "The following files are never imported or used anywhere in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "high"
    );
    const mediumConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "medium"
    );
    const lowConfidence = review.unusedFiles.filter(
      (file) => file.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedFunctions.length > 0) {
    markdown += "## Unused Functions\n\n";
    markdown += "The following functions are never called in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "high"
    );
    const mediumConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "medium"
    );
    const lowConfidence = review.unusedFunctions.filter(
      (func) => func.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedClasses.length > 0) {
    markdown += "## Unused Classes\n\n";
    markdown += "The following classes are never instantiated in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "high"
    );
    const mediumConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "medium"
    );
    const lowConfidence = review.unusedClasses.filter(
      (cls) => cls.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedTypesAndInterfaces.length > 0) {
    markdown += "## Unused Types and Interfaces\n\n";
    markdown += "The following types and interfaces are never used in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "high"
    );
    const mediumConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "medium"
    );
    const lowConfidence = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  if (review.deadCodeBranches.length > 0) {
    markdown += "## Dead Code Branches\n\n";
    markdown += "The following code branches can never execute and can be safely removed:\n\n";
    const highConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "high"
    );
    const mediumConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "medium"
    );
    const lowConfidence = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  if (review.unusedVariablesAndImports.length > 0) {
    markdown += "## Unused Variables and Imports\n\n";
    markdown += "The following variables and imports are never used in the codebase and can be safely removed:\n\n";
    const highConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "high"
    );
    const mediumConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "medium"
    );
    const lowConfidence = review.unusedVariablesAndImports.filter(
      (variable) => variable.confidence === "low"
    );
    if (highConfidence.length > 0) {
      markdown += "### \u2705 High Confidence (Safe to Remove)\n\n";
      markdown += formatTracedElementsAsChecklist(highConfidence);
    }
    if (mediumConfidence.length > 0) {
      markdown += "### \u26A0\uFE0F Medium Confidence (Verify Before Removing)\n\n";
      markdown += formatTracedElementsAsChecklist(mediumConfidence);
    }
    if (lowConfidence.length > 0) {
      markdown += "### \u2753 Low Confidence (Needs Further Investigation)\n\n";
      markdown += formatTracedElementsAsChecklist(lowConfidence);
    }
  }
  return markdown;
}
function formatTracedElementsAsChecklist(elements) {
  let markdown = "";
  const elementsByFile = {};
  for (const element of elements) {
    let cleanFilePath = element.filePath;
    cleanFilePath = cleanFilePath.replace(/\s*:\s*N\/A\s*/g, "");
    cleanFilePath = cleanFilePath.replace(/\/+$/g, "");
    if (cleanFilePath.endsWith("/")) {
      cleanFilePath = cleanFilePath.slice(0, -1);
    }
    if (!elementsByFile[cleanFilePath]) {
      elementsByFile[cleanFilePath] = [];
    }
    const elementCopy = { ...element, filePath: cleanFilePath };
    elementsByFile[cleanFilePath].push(elementCopy);
  }
  for (const [filePath, fileElements] of Object.entries(elementsByFile)) {
    markdown += `### ${filePath}

`;
    for (const element of fileElements) {
      let location = "";
      if (element.location.startLine && element.location.startLine > 0) {
        location = element.location.endLine && element.location.endLine > 0 ? `(lines ${element.location.startLine}-${element.location.endLine})` : `(line ${element.location.startLine})`;
      }
      markdown += `- [ ] **${element.name}**${location ? " " + location : ""}
`;
      markdown += `  - **Type**: ${formatElementType2(element.elementType)}
`;
      markdown += `  - **Confidence**: ${element.confidence.toUpperCase()} - ${element.confidenceReason}
`;
      if (element.codeSnippet && element.codeSnippet.trim()) {
        let snippet = element.codeSnippet.trim();
        if (snippet.startsWith("```") && snippet.endsWith("```")) {
          snippet = snippet.substring(snippet.indexOf("\n") + 1, snippet.lastIndexOf("```")).trim();
        }
        snippet = snippet.split("\n").map((line) => `  ${line}`).join("\n");
        markdown += "  ```\n";
        markdown += `${snippet}
`;
        markdown += "  ```\n";
      }
      markdown += "  - **Evidence of Non-Use**:\n";
      const defLine = element.evidence.definition.line && element.evidence.definition.line > 0 ? `:${element.evidence.definition.line}` : "";
      markdown += `    - **Definition**: ${element.evidence.definition.file}${defLine}
`;
      if (element.evidence.exports && element.evidence.exports.length > 0) {
        markdown += "    - **Exports**:\n";
        for (const exportInfo of element.evidence.exports) {
          const exportLine = exportInfo.line && exportInfo.line > 0 ? `:${exportInfo.line}` : "";
          markdown += `      - ${exportInfo.exportType} export in ${exportInfo.file}${exportLine}
`;
        }
      }
      markdown += "    - **Import Search**:\n";
      for (const searchArea of element.evidence.importSearch.searchedIn) {
        markdown += `      - Searched in ${searchArea}
`;
      }
      markdown += `      - Result: ${element.evidence.importSearch.noImportsFound ? "No imports found" : "Imports found"}
`;
      markdown += `      - Method: ${element.evidence.importSearch.searchMethod}
`;
      markdown += "    - **Reference Search**:\n";
      for (const searchArea of element.evidence.referenceSearch.searchedIn) {
        markdown += `      - Searched in ${searchArea}
`;
      }
      markdown += `      - Result: ${element.evidence.referenceSearch.noReferencesFound ? "No references found" : "References found"}
`;
      markdown += `      - Method: ${element.evidence.referenceSearch.searchMethod}
`;
      markdown += "    - **Edge Cases Considered**:\n";
      for (const edgeCase of element.evidence.edgeCasesConsidered) {
        markdown += `      - ${edgeCase.case}: ${edgeCase.verification}
`;
      }
      if (element.evidence.additionalEvidence) {
        markdown += `    - **Additional Evidence**: ${element.evidence.additionalEvidence}
`;
      }
      if (element.removalRisks) {
        markdown += `  - **Removal Risks**: ${element.removalRisks}
`;
      }
      markdown += "\n";
    }
  }
  return markdown;
}
function formatElementType2(elementType) {
  const mapping = {
    file: "File",
    function: "Function",
    class: "Class",
    interface: "Interface",
    type: "Type",
    variable: "Variable",
    import: "Import",
    "dead-branch": "Dead Code Branch",
    parameter: "Parameter",
    property: "Property",
    enum: "Enum",
    export: "Export",
    hook: "React Hook",
    component: "React Component"
  };
  return mapping[elementType] || elementType;
}
function generateCodeTracingRemovalScript(review) {
  let script = "#!/bin/bash\n\n";
  script += "# Script generated by AI Code Review to remove unused code identified through code tracing\n";
  script += "# WARNING: This script should be carefully reviewed before execution\n";
  script += "# RECOMMENDED: Create a git branch before running this script\n\n";
  script += 'echo "This script will remove unused code identified through deep code tracing."\n\n';
  const highConfidenceFiles = review.unusedFiles.filter((file) => file.confidence === "high").map((file) => {
    let cleanFilePath = file.filePath;
    cleanFilePath = cleanFilePath.replace(/\s*:\s*N\/A\s*/g, "");
    cleanFilePath = cleanFilePath.replace(/\/+$/g, "");
    if (cleanFilePath.endsWith("/")) {
      cleanFilePath = cleanFilePath.slice(0, -1);
    }
    return { ...file, filePath: cleanFilePath };
  });
  if (highConfidenceFiles.length > 0) {
    script += 'echo "REMOVING UNUSED FILES:"\n';
    for (const file of highConfidenceFiles) {
      script += `echo "  - ${file.filePath} (${file.confidence.toUpperCase()} confidence)"
`;
      script += `rm "${file.filePath}"
`;
    }
    script += 'echo "Unused files removed successfully."\n\n';
  }
  const highConfidenceFunctions = review.unusedFunctions.filter(
    (func) => func.confidence === "high"
  );
  const highConfidenceClasses = review.unusedClasses.filter(
    (cls) => cls.confidence === "high"
  );
  const highConfidenceTypes = review.unusedTypesAndInterfaces.filter(
    (type) => type.confidence === "high"
  );
  const highConfidenceBranches = review.deadCodeBranches.filter(
    (branch) => branch.confidence === "high"
  );
  const elementsByFile = {};
  const addElementToFile = (element) => {
    let cleanFilePath = element.filePath;
    cleanFilePath = cleanFilePath.replace(/\s*:\s*N\/A\s*/g, "");
    cleanFilePath = cleanFilePath.replace(/\/+$/g, "");
    if (cleanFilePath.endsWith("/")) {
      cleanFilePath = cleanFilePath.slice(0, -1);
    }
    if (!elementsByFile[cleanFilePath]) {
      elementsByFile[cleanFilePath] = [];
    }
    const elementCopy = { ...element, filePath: cleanFilePath };
    elementsByFile[cleanFilePath].push(elementCopy);
  };
  for (const func of highConfidenceFunctions) {
    addElementToFile(func);
  }
  for (const cls of highConfidenceClasses) {
    addElementToFile(cls);
  }
  for (const type of highConfidenceTypes) {
    addElementToFile(type);
  }
  for (const branch of highConfidenceBranches) {
    addElementToFile(branch);
  }
  for (const filePath in elementsByFile) {
    const cleanPath = filePath.endsWith(":N/A") ? filePath.replace(":N/A", "") : filePath;
    if (highConfidenceFiles.find((file) => file.filePath === cleanPath)) {
      continue;
    }
    elementsByFile[filePath].sort((a, b) => {
      return (b.location.startLine || 0) - (a.location.startLine || 0);
    });
  }
  if (Object.keys(elementsByFile).length > 0) {
    script += 'echo "REMOVING UNUSED CODE ELEMENTS:"\n\n';
    for (const [filePath, elements] of Object.entries(elementsByFile)) {
      const cleanPath = filePath.endsWith(":N/A") ? filePath.replace(":N/A", "") : filePath;
      if (highConfidenceFiles.find((file) => file.filePath === cleanPath)) {
        continue;
      }
      script += `echo "Processing ${filePath}"
`;
      for (const element of elements) {
        if (element.location.startLine && element.location.startLine > 0) {
          if (element.location.endLine && element.location.endLine > 0) {
            script += `sed -i '${element.location.startLine},${element.location.endLine}d' "${filePath}"
`;
            script += `echo "  Removed ${element.name} (${formatElementType2(element.elementType)}, lines ${element.location.startLine}-${element.location.endLine})"
`;
          } else {
            script += `sed -i '${element.location.startLine}d' "${filePath}"
`;
            script += `echo "  Removed ${element.name} (${formatElementType2(element.elementType)}, line ${element.location.startLine})"
`;
          }
        } else {
          script += `echo "  Note: Could not generate removal command for ${element.name} (${formatElementType2(element.elementType)}) - no line numbers available"
`;
          script += `echo "  Please manually remove this element from ${filePath}"
`;
        }
      }
      script += "\n";
    }
  }
  script += 'echo "Code removal complete. Please review the changes and run tests to ensure functionality."\n';
  return script;
}

// src/strategies/CodeTracingUnusedCodeReviewStrategy.ts
init_projectDocs();
init_logger();
var CodeTracingUnusedCodeReviewStrategy = class extends BaseReviewStrategy {
  constructor() {
    super("unused-code");
    logger_default.debug("Initialized CodeTracingUnusedCodeReviewStrategy");
  }
  /**
   * Execute the review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to the review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info("Generating code tracing unused code review...");
    if (!apiClientConfig.initialized) {
      throw new Error("API client not initialized");
    }
    if (projectDocs && options.includeProjectDocs) {
      const formattedDocs = formatProjectDocs(projectDocs);
      if (formattedDocs) {
      }
    }
    let response;
    try {
      response = {
        unusedFiles: [],
        unusedFunctions: [],
        unusedClasses: [],
        unusedTypesAndInterfaces: [],
        deadCodeBranches: [],
        unusedVariablesAndImports: [],
        analysisMethodology: {
          entryPoints: [],
          moduleResolution: "",
          referenceTracking: "",
          limitations: []
        },
        summary: {
          totalUnusedElements: 0,
          highConfidenceCount: 0,
          filesWithUnusedCode: 0,
          potentialCodeReduction: "0%"
        }
      };
      logger_default.info(
        "Using mock response for code tracing review (for compilation)"
      );
    } catch (error2) {
      logger_default.error("Error getting completion:", error2);
      throw error2;
    }
    const typedResponse = response;
    let formattedResponse;
    if (options.output === "json") {
      formattedResponse = JSON.stringify(response, null, 2);
    } else {
      formattedResponse = formatCodeTracingUnusedCodeReviewAsMarkdown(typedResponse);
      const hasHighConfidenceUnused = this.hasHighConfidenceUnusedElements(typedResponse);
      if (hasHighConfidenceUnused) {
        formattedResponse += "\n\n## Removal Script\n\n";
        formattedResponse += "```bash\n";
        formattedResponse += generateCodeTracingRemovalScript(typedResponse);
        formattedResponse += "\n```\n\n";
        formattedResponse += "**Important**: Review the script carefully before execution and make sure to back up your code or use version control.";
      }
    }
    return {
      filePath: "Project Review",
      reviewType: this.reviewType,
      content: formattedResponse,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      modelUsed: apiClientConfig.modelName,
      structuredData: response
    };
  }
  /**
   * Check if there are any high confidence unused elements
   * @param review The review to check
   * @returns Whether there are high confidence unused elements
   */
  hasHighConfidenceUnusedElements(review) {
    const highConfidenceFiles = review.unusedFiles.filter(
      (file) => file.confidence === "high"
    );
    const highConfidenceFunctions = review.unusedFunctions.filter(
      (func) => func.confidence === "high"
    );
    const highConfidenceClasses = review.unusedClasses.filter(
      (cls) => cls.confidence === "high"
    );
    const highConfidenceTypes = review.unusedTypesAndInterfaces.filter(
      (type) => type.confidence === "high"
    );
    const highConfidenceBranches = review.deadCodeBranches.filter(
      (branch) => branch.confidence === "high"
    );
    return highConfidenceFiles.length > 0 || highConfidenceFunctions.length > 0 || highConfidenceClasses.length > 0 || highConfidenceTypes.length > 0 || highConfidenceBranches.length > 0;
  }
};

// src/strategies/ImprovedQuickFixesReviewStrategy.ts
init_logger();
init_PromptStrategyFactory();
init_PromptManager();
init_PromptCache();

// src/prompts/schemas/quick-fixes-schema.ts
var import_zod10 = require("zod");
var import_output_parsers3 = require("@langchain/core/output_parsers");
var QuickFixIssueSchema = import_zod10.z.object({
  /**
   * Title of the issue
   */
  title: import_zod10.z.string().describe("Brief title describing the issue"),
  /**
   * Detailed description of the issue
   */
  description: import_zod10.z.string().describe("Detailed description of the issue"),
  /**
   * Location information (file and line numbers)
   */
  location: import_zod10.z.object({
    file: import_zod10.z.string().optional().describe("File path"),
    lineStart: import_zod10.z.number().optional().describe("Starting line number"),
    lineEnd: import_zod10.z.number().optional().describe("Ending line number"),
    codeSnippet: import_zod10.z.string().optional().describe("Small code snippet showing the issue")
  }),
  /**
   * Suggested fix for the issue
   */
  suggestedFix: import_zod10.z.object({
    code: import_zod10.z.string().describe("Code snippet showing the fix"),
    explanation: import_zod10.z.string().describe("Explanation of the fix")
  }),
  /**
   * Impact of fixing the issue
   */
  impact: import_zod10.z.string().describe("Impact of fixing this issue"),
  /**
   * Effort level required to fix (1-5 scale)
   */
  effort: import_zod10.z.number().min(1).max(5).describe("Effort level required to fix (1: very easy, 5: complex)"),
  /**
   * Priority level of the issue
   */
  priority: import_zod10.z.enum(["high", "medium", "low"]).describe("Priority level of the issue"),
  /**
   * Category of the issue
   */
  category: import_zod10.z.enum([
    "bug",
    "security",
    "performance",
    "maintainability",
    "readability",
    "testing",
    "documentation",
    "configuration",
    "typing",
    "error-handling",
    "other"
  ]).describe("Category of the issue"),
  /**
   * Tags related to the issue
   */
  tags: import_zod10.z.array(import_zod10.z.string()).optional().describe("Tags related to the issue")
});
var QuickFixesReviewSchema = import_zod10.z.object({
  /**
   * Array of high priority issues
   */
  highPriorityIssues: import_zod10.z.array(QuickFixIssueSchema).describe("High priority issues that should be fixed immediately"),
  /**
   * Array of medium priority issues
   */
  mediumPriorityIssues: import_zod10.z.array(QuickFixIssueSchema).describe("Medium priority issues that should be fixed soon"),
  /**
   * Array of low priority issues
   */
  lowPriorityIssues: import_zod10.z.array(QuickFixIssueSchema).describe("Low priority issues that could be fixed when time allows"),
  /**
   * Summary of the quick fixes review
   */
  summary: import_zod10.z.string().describe("Overall summary of the quick fixes review findings"),
  /**
   * General recommendations
   */
  recommendations: import_zod10.z.array(import_zod10.z.string()).describe("General recommendations for improving the code"),
  /**
   * Positive aspects of the code
   */
  positiveAspects: import_zod10.z.array(import_zod10.z.string()).describe("Positive aspects of the code that should be preserved"),
  /**
   * Development tools that could help
   */
  recommendedTools: import_zod10.z.array(
    import_zod10.z.object({
      tool: import_zod10.z.string().describe("Tool name"),
      description: import_zod10.z.string().describe("Brief description of the tool"),
      configuration: import_zod10.z.string().optional().describe("Suggested configuration")
    })
  ).optional().describe("Recommended development tools for preventing these issues")
});
var quickFixesReviewParser = import_output_parsers3.StructuredOutputParser.fromZodSchema(
  QuickFixesReviewSchema
);
function getQuickFixesReviewFormatInstructions() {
  return quickFixesReviewParser.getFormatInstructions();
}

// src/strategies/ImprovedQuickFixesReviewStrategy.ts
var import_path19 = __toESM(require("path"));
init_ciDataCollector();
var ImprovedQuickFixesReviewStrategy = class extends ConsolidatedReviewStrategy {
  /**
   * Create a new improved quick fixes review strategy
   */
  constructor() {
    super("quick-fixes");
  }
  /**
   * Execute the improved quick fixes review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info(
      `Executing improved quick fixes review strategy for ${files.length} files...`
    );
    let ciData = void 0;
    if (options.language === "typescript" || files.some((f) => f.path.endsWith(".ts") || f.path.endsWith(".tsx"))) {
      logger_default.info("Collecting CI data for TypeScript project...");
      ciData = await collectCIData(process.cwd());
    }
    let promptFile;
    if (options.language) {
      promptFile = import_path19.default.resolve(
        process.cwd(),
        "prompts",
        options.language.toLowerCase(),
        "improved-quick-fixes-review.md"
      );
      const fallbackPromptFile = import_path19.default.resolve(
        process.cwd(),
        "prompts",
        "improved-quick-fixes-review.md"
      );
      promptFile = promptFile || fallbackPromptFile;
    } else {
      promptFile = import_path19.default.resolve(
        process.cwd(),
        "prompts",
        "improved-quick-fixes-review.md"
      );
    }
    const enhancedOptions = {
      ...options,
      type: this.reviewType,
      schemaInstructions: getQuickFixesReviewFormatInstructions(),
      promptFile,
      ciData
    };
    if (!enhancedOptions.promptStrategy) {
      enhancedOptions.promptStrategy = "langchain";
      const promptManager = PromptManager.getInstance();
      const promptCache = PromptCache.getInstance();
      PromptStrategyFactory.createStrategy(
        "langchain",
        promptManager,
        promptCache
      );
      logger_default.info(
        "Using LangChain prompt strategy for improved quick fixes review"
      );
    }
    return super.execute(
      files,
      projectName,
      projectDocs,
      enhancedOptions,
      apiClientConfig
    );
  }
};

// src/strategies/ExtractPatternsReviewStrategy.ts
init_logger();
var ExtractPatternsReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new extract patterns review strategy
   */
  constructor() {
    super("extract-patterns");
  }
  /**
   * Execute the extract patterns review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to the review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info("Executing extract patterns review strategy...");
    const enhancedOptions = {
      ...options,
      type: this.reviewType,
      // Enable comprehensive analysis features
      includeProjectDocs: true,
      includeDependencyAnalysis: true,
      enableSemanticChunking: true
    };
    return generateReview(
      files,
      projectName,
      this.reviewType,
      projectDocs,
      enhancedOptions,
      apiClientConfig
    );
  }
};

// src/strategies/MultiPassReviewStrategy.ts
init_logger();
init_tokens();

// src/analysis/context/ReviewContext.ts
var ReviewContext = class _ReviewContext {
  /** Project name */
  projectName;
  /** Review type */
  reviewType;
  /** All files involved in the review */
  allFiles;
  /** Current pass number */
  currentPass;
  /** Important code elements tracked across passes */
  codeElements;
  /** Findings from previous passes */
  findings;
  /** File summaries from previous passes */
  fileSummaries;
  /** General notes about the codebase */
  generalNotes;
  /** Timestamp when context was created */
  createdAt;
  /** Timestamp of last update */
  updatedAt;
  /**
   * Create a new review context
   * @param projectName Name of the project
   * @param reviewType Type of review
   * @param files Files involved in the review
   */
  constructor(projectName, reviewType, files) {
    this.projectName = projectName;
    this.reviewType = reviewType;
    this.allFiles = files.map((f) => f.path);
    this.currentPass = 0;
    this.codeElements = /* @__PURE__ */ new Map();
    this.findings = [];
    this.fileSummaries = /* @__PURE__ */ new Map();
    this.generalNotes = [];
    this.createdAt = /* @__PURE__ */ new Date();
    this.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Start a new review pass
   * @returns Updated pass number
   */
  startPass() {
    this.currentPass++;
    this.updatedAt = /* @__PURE__ */ new Date();
    return this.currentPass;
  }
  /**
   * Get the current pass number
   * @returns Current pass number
   */
  getCurrentPass() {
    return this.currentPass;
  }
  /**
   * Add a code element to the context
   * @param element Code element to add
   */
  addCodeElement(element) {
    const key = `${element.type}:${element.file}:${element.name}`;
    this.codeElements.set(key, element);
    this.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Get all tracked code elements
   * @returns Array of code elements
   */
  getCodeElements() {
    return Array.from(this.codeElements.values());
  }
  /**
   * Get code elements of a specific type
   * @param type Type of code elements to get
   * @returns Array of code elements of the specified type
   */
  getCodeElementsByType(type) {
    return this.getCodeElements().filter((el) => el.type === type);
  }
  /**
   * Get code elements in a specific file
   * @param filePath Path of the file
   * @returns Array of code elements in the file
   */
  getCodeElementsInFile(filePath) {
    return this.getCodeElements().filter((el) => el.file === filePath);
  }
  /**
   * Add a review finding
   * @param finding Review finding to add
   */
  addFinding(finding) {
    this.findings.push({
      ...finding,
      passNumber: this.currentPass
    });
    this.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Get all findings
   * @returns Array of all findings
   */
  getFindings() {
    return [...this.findings];
  }
  /**
   * Add or update a file summary
   * @param summary File summary to add
   */
  addFileSummary(summary) {
    this.fileSummaries.set(summary.path, {
      ...summary,
      passNumber: this.currentPass
    });
    this.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Get summary for a specific file
   * @param filePath Path of the file
   * @returns File summary or undefined if not found
   */
  getFileSummary(filePath) {
    return this.fileSummaries.get(filePath);
  }
  /**
   * Get summaries for all files
   * @returns Array of file summaries
   */
  getAllFileSummaries() {
    return Array.from(this.fileSummaries.values());
  }
  /**
   * Add a general note about the codebase
   * @param note Note to add
   */
  addGeneralNote(note) {
    this.generalNotes.push(note);
    this.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Get all general notes
   * @returns Array of general notes
   */
  getGeneralNotes() {
    return [...this.generalNotes];
  }
  /**
   * Generate a contextual prompt for the next pass
   * @param files Files to include in the next pass
   * @param maxContextLength Maximum length of context in characters
   * @returns Formatted context string for inclusion in the next prompt
   */
  generateNextPassContext(files, maxContextLength = 2e3) {
    let context = `
### Review Context (Pass ${this.currentPass})

Project: ${this.projectName}
Review Type: ${this.reviewType}
Files in this pass: ${files.length} / ${this.allFiles.length}

`;
    const importantFindings = this.findings.sort((a, b) => b.severity - a.severity).slice(0, 5);
    if (importantFindings.length > 0) {
      context += "#### Key Findings from Previous Passes\n\n";
      importantFindings.forEach((finding) => {
        context += `- [${finding.type.toUpperCase()}] ${finding.description}${finding.file ? ` (in ${finding.file})` : ""}
`;
      });
      context += "\n";
    }
    const relatedFiles = this.getAllFileSummaries().filter((summary) => !files.includes(summary.path)).slice(0, 5);
    if (relatedFiles.length > 0) {
      context += "#### Related Files (Not in This Pass)\n\n";
      relatedFiles.forEach((file) => {
        context += `- ${file.path}: ${file.description}
`;
        if (file.keyElements.length > 0) {
          context += `  Key elements: ${file.keyElements.join(", ")}
`;
        }
      });
      context += "\n";
    }
    const relevantElements = this.getCodeElements().filter((el) => files.includes(el.file) || el.importance > 7).sort((a, b) => b.importance - a.importance).slice(0, 10);
    if (relevantElements.length > 0) {
      context += "#### Important Code Elements\n\n";
      relevantElements.forEach((element) => {
        context += `- ${element.type} \`${element.name}\`${element.signature ? `: ${element.signature}` : ""} (in ${element.file})
`;
      });
      context += "\n";
    }
    if (this.generalNotes.length > 0) {
      context += "#### General Notes\n\n";
      this.generalNotes.slice(0, 3).forEach((note) => {
        context += `- ${note}
`;
      });
      context += "\n";
    }
    if (context.length > maxContextLength) {
      context = context.substring(0, maxContextLength - 3) + "...";
    }
    return context;
  }
  /**
   * Serialize the context to JSON
   * @returns JSON representation of the context
   */
  toJSON() {
    return {
      projectName: this.projectName,
      reviewType: this.reviewType,
      currentPass: this.currentPass,
      codeElements: Array.from(this.codeElements.values()),
      findings: this.findings,
      fileSummaries: Array.from(this.fileSummaries.values()),
      generalNotes: this.generalNotes,
      createdAt: this.createdAt.toISOString(),
      updatedAt: this.updatedAt.toISOString()
    };
  }
  /**
   * Create a review context from JSON
   * @param json JSON object
   * @returns New ReviewContext instance
   */
  static fromJSON(json) {
    const context = new _ReviewContext(
      json.projectName,
      json.reviewType,
      json.allFiles || []
    );
    context.currentPass = json.currentPass || 0;
    if (Array.isArray(json.codeElements)) {
      json.codeElements.forEach((element) => {
        context.addCodeElement(element);
      });
    }
    if (Array.isArray(json.findings)) {
      context.findings = json.findings;
    }
    if (Array.isArray(json.fileSummaries)) {
      json.fileSummaries.forEach((summary) => {
        context.fileSummaries.set(summary.path, summary);
      });
    }
    if (Array.isArray(json.generalNotes)) {
      context.generalNotes = json.generalNotes;
    }
    if (json.createdAt) {
      context.createdAt = new Date(json.createdAt);
    }
    if (json.updatedAt) {
      context.updatedAt = new Date(json.updatedAt);
    }
    return context;
  }
};

// src/utils/review/reviewExtraction.ts
var import_path20 = __toESM(require("path"));
init_logger();
async function extractFixSuggestions(reviewContent, projectPath, priorityLevel) {
  const suggestions = [];
  if (priorityLevel) {
    let section = null;
    switch (priorityLevel) {
      case "high" /* HIGH */:
        section = extractSection(
          reviewContent,
          "### \u{1F7E5} High Priority",
          "### \u{1F7E7} Medium Priority"
        );
        break;
      case "medium" /* MEDIUM */:
        section = extractSection(
          reviewContent,
          "### \u{1F7E7} Medium Priority",
          "### \u{1F7E9} Low Priority"
        );
        break;
      case "low" /* LOW */:
        section = extractSection(reviewContent, "### \u{1F7E9} Low Priority", "---");
        break;
    }
    if (section) {
      const prioritySuggestions = await parseSuggestions(
        section,
        priorityLevel,
        projectPath
      );
      suggestions.push(...prioritySuggestions);
    }
    return suggestions;
  }
  const highPrioritySection = extractSection(
    reviewContent,
    "### \u{1F7E5} High Priority",
    "### \u{1F7E7} Medium Priority"
  );
  if (highPrioritySection) {
    const highPrioritySuggestions = await parseSuggestions(
      highPrioritySection,
      "high" /* HIGH */,
      projectPath
    );
    suggestions.push(...highPrioritySuggestions);
  }
  const mediumPrioritySection = extractSection(
    reviewContent,
    "### \u{1F7E7} Medium Priority",
    "### \u{1F7E9} Low Priority"
  );
  if (mediumPrioritySection) {
    const mediumPrioritySuggestions = await parseSuggestions(
      mediumPrioritySection,
      "medium" /* MEDIUM */,
      projectPath
    );
    suggestions.push(...mediumPrioritySuggestions);
  }
  const lowPrioritySection = extractSection(
    reviewContent,
    "### \u{1F7E9} Low Priority",
    "---"
  );
  if (lowPrioritySection) {
    const lowPrioritySuggestions = await parseSuggestions(
      lowPrioritySection,
      "low" /* LOW */,
      projectPath
    );
    suggestions.push(...lowPrioritySuggestions);
  }
  return suggestions;
}
function extractSection(content, startMarker, endMarker) {
  let startIndex = content.indexOf(startMarker);
  if (startIndex === -1) {
    const startMarkerNoEmoji = startMarker.replace(/||/g, "").trim();
    startIndex = content.indexOf(startMarkerNoEmoji);
    if (startIndex === -1) {
      const startMarkerAltHeading = startMarker.replace("###", "##");
      startIndex = content.indexOf(startMarkerAltHeading);
    }
    if (startIndex === -1) {
      const startMarkerAltHeading2 = startMarker.replace("###", "#");
      startIndex = content.indexOf(startMarkerAltHeading2);
    }
    if (startIndex === -1) {
      const priorityLevel = startMarker.includes("High") ? "high" : startMarker.includes("Medium") ? "medium" : startMarker.includes("Low") ? "low" : "";
      if (priorityLevel) {
        const regex = new RegExp(
          `[#]{1,3}\\s*(?:\u{1F7E5}|\u{1F7E7}|\u{1F7E9})?\\s*${priorityLevel}\\s*priority`,
          "i"
        );
        const match = content.match(regex);
        if (match && match.index !== void 0) {
          startIndex = match.index;
        }
      }
    }
  }
  if (startIndex === -1) return null;
  let endIndex = content.indexOf(endMarker, startIndex);
  if (endIndex === -1) {
    const endMarkerNoEmoji = endMarker.replace(/||/g, "").trim();
    endIndex = content.indexOf(endMarkerNoEmoji, startIndex);
    if (endIndex === -1) {
      const endMarkerAltHeading = endMarker.replace("###", "##");
      endIndex = content.indexOf(endMarkerAltHeading, startIndex);
    }
    if (endIndex === -1) {
      const endMarkerAltHeading2 = endMarker.replace("###", "#");
      endIndex = content.indexOf(endMarkerAltHeading2, startIndex);
    }
    if (endIndex === -1) {
      const nextHeadingMatch = content.substring(startIndex).match(/\n[#]{1,3}\s/);
      if (nextHeadingMatch && nextHeadingMatch.index !== void 0) {
        endIndex = startIndex + nextHeadingMatch.index;
      }
    }
  }
  if (endIndex === -1) return content.substring(startIndex);
  return content.substring(startIndex, endIndex);
}
async function parseSuggestions(sectionContent, priority, projectPath) {
  const suggestions = [];
  let issueBlocks = [];
  const pattern1Blocks = sectionContent.split(/(?=\*\*Issue\*\*:)/).filter((block) => block.trim().startsWith("**Issue**:"));
  if (pattern1Blocks.length > 0) {
    issueBlocks = pattern1Blocks;
  } else {
    const pattern2Blocks = sectionContent.split(/(?=\d+\.\s*\*\*Issue\*\*:)/).filter((block) => block.trim().match(/^\d+\.\s*\*\*Issue\*\*/));
    if (pattern2Blocks.length > 0) {
      issueBlocks = pattern2Blocks;
    } else {
      const pattern3Blocks = sectionContent.split(/(?=[#]{1,3}\s+Issue:)/).filter((block) => block.trim().match(/^[#]{1,3}\s+Issue:/));
      if (pattern3Blocks.length > 0) {
        issueBlocks = pattern3Blocks;
      } else {
        const pattern4Blocks = sectionContent.split(/(?=\*\*Finding\*\*:)/).filter((block) => block.trim().startsWith("**Finding**:"));
        if (pattern4Blocks.length > 0) {
          issueBlocks = pattern4Blocks;
        } else {
          const pattern5Blocks = sectionContent.split(/(?=\*\*Performance Issue\*\*:)/).filter((block) => block.trim().startsWith("**Performance Issue**:"));
          if (pattern5Blocks.length > 0) {
            issueBlocks = pattern5Blocks;
          }
        }
      }
    }
  }
  for (const issueBlock of issueBlocks) {
    try {
      let issueDescription = "";
      let issueMatch = issueBlock.match(/\*\*Issue\*\*:([^*]+)/);
      if (!issueMatch) {
        issueMatch = issueBlock.match(/\d+\.\s*\*\*Issue\*\*:([^*]+)/);
      }
      if (!issueMatch) {
        issueMatch = issueBlock.match(/[#]{1,3}\s+Issue:([^\n]+)/);
      }
      if (!issueMatch) {
        issueMatch = issueBlock.match(/\*\*Finding\*\*:([^*]+)/);
      }
      if (!issueMatch) {
        issueMatch = issueBlock.match(/\*\*Performance Issue\*\*:([^*]+)/);
      }
      if (!issueMatch) continue;
      issueDescription = issueMatch[1].trim();
      let filePath = "";
      let fileMatch = issueBlock.match(/\*\*File\*\*:([^*]+)/);
      if (!fileMatch) {
        fileMatch = issueBlock.match(/\*\*Location\*\*:([^*]+)/);
      }
      if (!fileMatch) {
        fileMatch = issueBlock.match(/File:([^\n]+)/);
      }
      if (!fileMatch) {
        fileMatch = issueBlock.match(/Path:([^\n]+)/);
      }
      if (!fileMatch) {
        const pathMatch = issueBlock.match(
          /(?:src|lib|test|app|components|utils|helpers|services|models|controllers|views|pages|api|config|public|assets|styles|css|js|ts|tsx|jsx)\/[\w\-./_]+\.(ts|js|tsx|jsx|json|css|scss|html|md)/
        );
        if (pathMatch) {
          filePath = pathMatch[0].trim();
        } else {
          continue;
        }
      } else {
        filePath = fileMatch[1].trim();
      }
      let cleanFilePath = filePath.replace(/`/g, "").replace(/\*/g, "").trim();
      const filePathMatch = cleanFilePath.match(
        /(?:src|\/)\S+\.(ts|js|tsx|jsx|json)/
      );
      if (filePathMatch) {
        cleanFilePath = filePathMatch[0];
      } else {
        const possiblePaths = cleanFilePath.split(/[\s,()]/).filter(
          (part) => part.includes("/") || part.includes(".ts") || part.includes(".js")
        );
        if (possiblePaths.length > 0) {
          cleanFilePath = possiblePaths[0];
        }
      }
      const fullFilePath = import_path20.default.resolve(projectPath, cleanFilePath);
      const locationMatch = issueBlock.match(/\*\*Location\*\*:([^*]+)/);
      const location = locationMatch ? locationMatch[1].trim() : "";
      const codeBlockMatches = issueBlock.match(/```(?:[a-zA-Z0-9_-]*)?\s*([\s\S]*?)```/g) || [];
      let codeBlocks = [];
      if (codeBlockMatches.length > 0) {
        codeBlocks = codeBlockMatches.map((block) => {
          const content = block.replace(/```(?:[a-zA-Z0-9_-]*)?\s*|```$/g, "");
          return content.trim();
        });
      } else {
        const indentedCodeBlockMatch = issueBlock.match(
          /(?:^|\n)(?: {4}|\t)([^\n]+(?:\n(?: {4}|\t)[^\n]+)*)/g
        );
        if (indentedCodeBlockMatch) {
          codeBlocks = indentedCodeBlockMatch.map((block) => {
            return block.replace(/(?:^|\n)(?: {4}|\t)/g, "\n").trim();
          });
        }
        const currentCodeMatch = issueBlock.match(
          /Current code:([\s\S]*?)(?:Suggested code:|$)/i
        );
        const suggestedCodeMatch = issueBlock.match(
          /Suggested code:([\s\S]*?)(?:Impact:|$)/i
        );
        if (currentCodeMatch && currentCodeMatch[1].trim()) {
          codeBlocks.push(currentCodeMatch[1].trim());
        }
        if (suggestedCodeMatch && suggestedCodeMatch[1].trim()) {
          codeBlocks.push(suggestedCodeMatch[1].trim());
        }
      }
      const suggestion = {
        priority,
        file: fullFilePath,
        description: issueDescription
      };
      if (codeBlocks.length >= 2) {
        suggestion.currentCode = codeBlocks[0];
        suggestion.suggestedCode = codeBlocks[1];
      } else if (codeBlocks.length === 1) {
        suggestion.suggestedCode = codeBlocks[0];
      }
      const lineNumberMatch = location.match(/lines? (\d+)(?:-(\d+))?/i);
      if (lineNumberMatch) {
        const startLine = parseInt(lineNumberMatch[1], 10);
        const endLine = lineNumberMatch[2] ? parseInt(lineNumberMatch[2], 10) : startLine;
        suggestion.lineNumbers = { start: startLine, end: endLine };
      }
      suggestions.push(suggestion);
    } catch (error2) {
      logger_default.error("Error parsing suggestion:", error2);
    }
  }
  return suggestions;
}

// src/utils/review/fixImplementation.ts
var import_readline = __toESM(require("readline"));

// src/utils/review/fixDisplay.ts
function displayFixSuggestions(suggestions, priority) {
  if (suggestions.length === 0) {
    return;
  }
  const priorityColor = {
    ["high" /* HIGH */]: "\x1B[31m",
    // Red
    ["medium" /* MEDIUM */]: "\x1B[33m",
    // Yellow
    ["low" /* LOW */]: "\x1B[32m"
    // Green
  };
  const priorityEmoji = {
    ["high" /* HIGH */]: "\u{1F7E5}",
    ["medium" /* MEDIUM */]: "\u{1F7E7}",
    ["low" /* LOW */]: "\u{1F7E9}"
  };
  const priorityLabel = {
    ["high" /* HIGH */]: "HIGH",
    ["medium" /* MEDIUM */]: "MEDIUM",
    ["low" /* LOW */]: "LOW"
  };
  console.log(
    `
${priorityColor[priority]}${priorityEmoji[priority]} ${priorityLabel[priority]} PRIORITY ISSUES (${suggestions.length})\x1B[0m`
  );
  suggestions.forEach((suggestion, index) => {
    console.log(`${index + 1}. ${suggestion.description}`);
    console.log(`   File: ${suggestion.file}`);
    if (suggestion.lineNumbers) {
      console.log(
        `   Lines: ${suggestion.lineNumbers.start}-${suggestion.lineNumbers.end}`
      );
    }
  });
}

// src/utils/reviewParser.ts
init_reviewSchema();
init_logger();
function parseReviewJson(jsonString) {
  try {
    if (jsonString.trim().startsWith("{") && jsonString.trim().endsWith("}")) {
      try {
        const directJson = JSON.parse(jsonString);
        const directValidation = reviewSchema.safeParse(directJson);
        if (directValidation.success) {
          logger_default.debug("Successfully parsed direct JSON response");
          return directValidation.data;
        } else if (directJson.review) {
          logger_default.debug("Direct JSON has review property but failed schema validation, using fallback");
          return directJson;
        }
      } catch (e) {
        logger_default.debug("Direct parsing failed, attempting extraction patterns");
      }
    }
    const jsonBlockMatch = jsonString.match(/```(?:json)?\s*({[\s\S]*?})\s*```/);
    const anyCodeBlockMatch = !jsonBlockMatch ? jsonString.match(/```(?:[\w]*)?[\s\n]*({[\s\S]*?})[\s\n]*```/) : null;
    const languageBlockRegex = /```(typescript|javascript|js|ts|jsx|tsx|java|python|ruby|go|rust|c|cpp|csharp|php)\s*([\s\S]*?)\s*```/;
    const languageBlockMatch = !jsonBlockMatch && !anyCodeBlockMatch ? jsonString.match(languageBlockRegex) : null;
    if (languageBlockMatch) {
      const language = languageBlockMatch[1];
      logger_default.warn(`Found ${language} code block but not valid JSON. Skipping JSON parsing attempt for this block.`);
      return null;
    }
    const reviewJsonPattern = /({[\s\S]*?"review"[\s\S]*?})/;
    const reviewJsonMatch = jsonString.match(reviewJsonPattern);
    const anyJsonPattern = /({[\s\S]*?})/;
    const anyJsonMatch = !reviewJsonMatch ? jsonString.match(anyJsonPattern) : null;
    let jsonContent = jsonString;
    if (jsonBlockMatch) {
      logger_default.debug("Found JSON code block, extracting content");
      jsonContent = jsonBlockMatch[1];
    } else if (anyCodeBlockMatch) {
      logger_default.debug("Found code block with JSON-like content, attempting to parse");
      jsonContent = anyCodeBlockMatch[1];
    } else if (reviewJsonMatch) {
      logger_default.debug("Found review JSON content outside code blocks");
      jsonContent = reviewJsonMatch[1];
    } else if (anyJsonMatch) {
      logger_default.debug("Found generic JSON-like content");
      jsonContent = anyJsonMatch[1];
    } else {
      logger_default.debug("No JSON content patterns found, attempting to parse raw content");
    }
    jsonContent = jsonContent.replace(/\/\/.*?(?=\n|$)/g, "").replace(/^\s*\/\/.*$/gm, "").replace(/\/\*[\s\S]*?\*\//g, "").replace(/,\s*}/g, "}").replace(/,\s*]/g, "]");
    jsonContent = jsonContent.replace(/([{,])\s*"(\w+)":\s*"([^"]*)",\s*\/\/.*?(?=\n|$)/g, '$1"$2":"$3",').replace(/([{,])\s*"(\w+)":\s*(\d+),\s*\/\/.*?(?=\n|$)/g, '$1"$2":$3,');
    const parsedJson = JSON.parse(jsonContent);
    const validationResult = reviewSchema.safeParse(parsedJson);
    if (validationResult.success) {
      logger_default.debug("Successfully validated review JSON with Zod schema");
      return validationResult.data;
    } else {
      logger_default.warn(
        "Failed to validate review JSON schema:",
        validationResult.error.errors
      );
      if (parsedJson.review) {
        logger_default.warn("Using fallback validation for review JSON");
        return parsedJson;
      }
      return null;
    }
  } catch (error2) {
    logger_default.error("Error parsing review JSON:", error2);
    return null;
  }
}
function formatIssueForDisplay(issue, filePath, fileIndex, issueIndex) {
  const priorityColors = {
    ["HIGH" /* HIGH */]: "\x1B[31m",
    // Red
    ["MEDIUM" /* MEDIUM */]: "\x1B[33m",
    // Yellow
    ["LOW" /* LOW */]: "\x1B[32m"
    // Green
  };
  const priorityColor = priorityColors[issue.priority] || "\x1B[37m";
  const reset = "\x1B[0m";
  const bold = "\x1B[1m";
  let output = `
${bold}Issue ${fileIndex + 1}.${issueIndex + 1}: ${priorityColor}[${issue.priority}]${reset}${bold} ${issue.id}${reset}
`;
  output += `${bold}Description:${reset} ${issue.description}
`;
  output += `${bold}File:${reset} ${filePath}
`;
  output += `${bold}Location:${reset} Lines ${issue.location.startLine}-${issue.location.endLine}

`;
  output += `${bold}Current Code:${reset}
`;
  output += "```\n";
  output += issue.currentCode;
  output += "\n```\n\n";
  output += `${bold}Suggested Code:${reset}
`;
  output += "```\n";
  output += issue.suggestedCode;
  output += "\n```\n\n";
  if (issue.explanation) {
    output += `${bold}Explanation:${reset}
`;
    output += issue.explanation;
    output += "\n\n";
  }
  return output;
}
function displayStructuredReview(parsedReview) {
  const { review } = parsedReview;
  logger_default.info("\n=== Structured Code Review Results ===\n");
  review.files.forEach((file, fileIndex) => {
    logger_default.info(`
${"-".repeat(80)}`);
    logger_default.info(`File ${fileIndex + 1}: ${file.filePath}`);
    logger_default.info(`${"-".repeat(80)}`);
    if (file.issues.length === 0) {
      logger_default.info("No issues found in this file.");
      return;
    }
    file.issues.forEach((issue, issueIndex) => {
      const formattedIssue = formatIssueForDisplay(
        issue,
        file.filePath,
        fileIndex,
        issueIndex
      );
      logger_default.info(formattedIssue);
    });
  });
  logger_default.info(`
${"-".repeat(80)}`);
  logger_default.info("Summary:");
  logger_default.info(`${"-".repeat(80)}`);
  logger_default.info(`High Priority Issues: ${review.summary.highPriorityIssues}`);
  logger_default.info(`Medium Priority Issues: ${review.summary.mediumPriorityIssues}`);
  logger_default.info(`Low Priority Issues: ${review.summary.lowPriorityIssues}`);
  logger_default.info(`Total Issues: ${review.summary.totalIssues}`);
}

// src/utils/review/interactiveProcessing.ts
init_logger();
async function displayReviewResults(reviewContent, projectPath, priorityFilter) {
  const parsedReview = parseReviewJson(reviewContent);
  if (parsedReview) {
    displayStructuredReview(parsedReview);
    const highPrioritySuggestions = [];
    const mediumPrioritySuggestions = [];
    const lowPrioritySuggestions = [];
    parsedReview.review.files.forEach((file) => {
      file.issues.forEach((issue) => {
        const suggestion = {
          priority: issue.priority === "HIGH" ? "high" /* HIGH */ : issue.priority === "MEDIUM" ? "medium" /* MEDIUM */ : "low" /* LOW */,
          file: file.filePath,
          description: issue.description,
          currentCode: issue.currentCode,
          suggestedCode: issue.suggestedCode,
          lineNumbers: issue.location ? {
            start: issue.location.startLine,
            end: issue.location.endLine
          } : void 0
        };
        if (suggestion.priority === "high" /* HIGH */) {
          highPrioritySuggestions.push(suggestion);
        } else if (suggestion.priority === "medium" /* MEDIUM */) {
          mediumPrioritySuggestions.push(suggestion);
        } else {
          lowPrioritySuggestions.push(suggestion);
        }
      });
    });
    const totalSuggestions = highPrioritySuggestions.length + mediumPrioritySuggestions.length + lowPrioritySuggestions.length;
    return {
      highPrioritySuggestions,
      mediumPrioritySuggestions,
      lowPrioritySuggestions,
      totalSuggestions
    };
  } else {
    logger_default.info(
      "Using legacy format for review results (no structured schema detected)"
    );
    const highPrioritySuggestions = await extractFixSuggestions(
      reviewContent,
      projectPath,
      "high" /* HIGH */
    );
    const mediumPrioritySuggestions = await extractFixSuggestions(
      reviewContent,
      projectPath,
      "medium" /* MEDIUM */
    );
    const lowPrioritySuggestions = await extractFixSuggestions(
      reviewContent,
      projectPath,
      "low" /* LOW */
    );
    const totalSuggestions = highPrioritySuggestions.length + mediumPrioritySuggestions.length + lowPrioritySuggestions.length;
    logger_default.info("\n=== CODE REVIEW RECOMMENDATIONS ===");
    logger_default.info(`Total issues found: ${totalSuggestions}`);
    logger_default.info(`\u{1F7E5} High priority: ${highPrioritySuggestions.length}`);
    logger_default.info(`\u{1F7E7} Medium priority: ${mediumPrioritySuggestions.length}`);
    logger_default.info(`\u{1F7E9} Low priority: ${lowPrioritySuggestions.length}`);
    logger_default.info(
      "\nShowing ALL issues by default. To filter by priority, use these options:"
    );
    logger_default.info("  (h) High priority issues only");
    logger_default.info("  (m) Medium priority issues only");
    logger_default.info("  (l) Low priority issues only");
    logger_default.info("  (a) All issues (default)");
    logger_default.info("\nExample: ai-code-review src --interactive h");
    if (!priorityFilter || priorityFilter.toLowerCase() === "a") {
      displayFixSuggestions(highPrioritySuggestions, "high" /* HIGH */);
      displayFixSuggestions(mediumPrioritySuggestions, "medium" /* MEDIUM */);
      displayFixSuggestions(lowPrioritySuggestions, "low" /* LOW */);
    } else {
      switch (priorityFilter.toLowerCase()) {
        case "h":
          displayFixSuggestions(highPrioritySuggestions, "high" /* HIGH */);
          break;
        case "m":
          displayFixSuggestions(mediumPrioritySuggestions, "medium" /* MEDIUM */);
          break;
        case "l":
          displayFixSuggestions(lowPrioritySuggestions, "low" /* LOW */);
          break;
        default:
          logger_default.warn("Invalid priority filter. Use h, m, l, or a.");
          displayFixSuggestions(highPrioritySuggestions, "high" /* HIGH */);
          displayFixSuggestions(mediumPrioritySuggestions, "medium" /* MEDIUM */);
          displayFixSuggestions(lowPrioritySuggestions, "low" /* LOW */);
      }
    }
    return {
      highPrioritySuggestions,
      mediumPrioritySuggestions,
      lowPrioritySuggestions,
      totalSuggestions
    };
  }
}

// src/utils/review/progressTracker.ts
init_logger();
var import_readline2 = __toESM(require("readline"));
var MultiPassProgressTracker = class {
  progress;
  updateInterval = null;
  useAnsiEscapes;
  completedFiles = [];
  /**
   * Create a new progress tracker
   * @param totalPasses Total number of passes
   * @param totalFiles Total number of files
   * @param options Options for the progress tracker
   */
  constructor(totalPasses = 1, totalFiles = 0, options = {}) {
    this.progress = {
      totalPasses,
      currentPass: 0,
      currentFiles: [],
      totalFiles,
      processedFiles: 0,
      startTime: /* @__PURE__ */ new Date(),
      isComplete: false,
      currentPhase: "preparing"
    };
    this.useAnsiEscapes = options.useAnsiEscapes !== false;
    if (!options.quiet) {
      this.startProgressUpdates();
    }
  }
  /**
   * Initialize the progress tracker with a total file count
   * @param totalFiles Total number of files
   */
  initialize(totalFiles) {
    this.progress.totalFiles = totalFiles;
    logger_default.info(`Initialized progress tracker with ${totalFiles} total files`);
  }
  /**
   * Start the progress update interval
   */
  startProgressUpdates() {
    this.updateInterval = setInterval(() => {
      this.updateProgressDisplay();
    }, 1e3);
  }
  /**
   * Stop the progress update interval
   */
  stopProgressUpdates() {
    if (this.updateInterval) {
      clearInterval(this.updateInterval);
      this.updateInterval = null;
    }
  }
  /**
   * Update the progress display
   */
  updateProgressDisplay() {
    if (this.progress.isComplete) {
      return;
    }
    const { currentPass, totalPasses, currentPhase, startTime } = this.progress;
    const elapsed = Math.floor(((/* @__PURE__ */ new Date()).getTime() - startTime.getTime()) / 1e3);
    const elapsedMinutes = Math.floor(elapsed / 60);
    const elapsedSeconds = elapsed % 60;
    if (this.useAnsiEscapes) {
      import_readline2.default.clearLine(process.stdout, 0);
      import_readline2.default.cursorTo(process.stdout, 0);
    }
    let progressMessage = "";
    if (currentPhase === "preparing") {
      progressMessage = `Preparing multi-pass review...`;
    } else if (currentPhase === "analyzing") {
      progressMessage = `Analyzing files for multi-pass review...`;
    } else if (currentPhase === "reviewing") {
      const passProgress = currentPass / totalPasses * 100;
      progressMessage = `Pass ${currentPass}/${totalPasses} (${passProgress.toFixed(1)}%)`;
      if (this.progress.currentFiles.length > 0) {
        const fileNames = this.progress.currentFiles.map((f) => f.split("/").pop()).join(", ");
        progressMessage += ` | Processing: ${fileNames.length > 50 ? fileNames.substring(0, 50) + "..." : fileNames}`;
      }
    } else if (currentPhase === "processing") {
      progressMessage = `Processing results...`;
    } else if (currentPhase === "consolidating") {
      progressMessage = `Consolidating multi-pass review and generating final graded report...`;
    }
    progressMessage += ` | Elapsed: ${elapsedMinutes}m ${elapsedSeconds}s`;
    if (this.useAnsiEscapes) {
      process.stdout.write(progressMessage);
    } else {
      logger_default.info(progressMessage);
    }
  }
  /**
   * Start a new pass
   * @param passNumber Pass number
   * @param files Files being processed in this pass
   */
  startPass(passNumber, files) {
    this.progress.currentPass = passNumber;
    this.progress.currentFiles = files;
    this.progress.currentPhase = "reviewing";
    if (this.useAnsiEscapes) {
      process.stdout.write("\n");
    }
    logger_default.info(`Starting pass ${passNumber}/${this.progress.totalPasses} with ${files.length} files`);
  }
  /**
   * Complete a pass
   * @param passNumber Pass number
   */
  completePass(passNumber) {
    if (passNumber !== this.progress.currentPass) {
      logger_default.warn(`Completed pass ${passNumber} but current pass is ${this.progress.currentPass}`);
    }
    this.progress.processedFiles += this.progress.currentFiles.length;
    this.progress.currentFiles = [];
    if (this.useAnsiEscapes) {
      process.stdout.write("\n");
    }
    logger_default.info(`Completed pass ${passNumber}/${this.progress.totalPasses}`);
    if (passNumber === this.progress.totalPasses) {
      this.complete();
    }
  }
  /**
   * Set the current phase
   * @param phase Current phase
   */
  setPhase(phase) {
    this.progress.currentPhase = phase;
    if (phase === "complete") {
      this.complete();
    }
  }
  /**
   * Complete the review
   */
  complete() {
    this.progress.isComplete = true;
    this.progress.currentPhase = "complete";
    const elapsed = Math.floor(((/* @__PURE__ */ new Date()).getTime() - this.progress.startTime.getTime()) / 1e3);
    const elapsedMinutes = Math.floor(elapsed / 60);
    const elapsedSeconds = elapsed % 60;
    if (this.useAnsiEscapes) {
      import_readline2.default.clearLine(process.stdout, 0);
      import_readline2.default.cursorTo(process.stdout, 0);
    }
    logger_default.info(`Multi-pass review completed in ${elapsedMinutes}m ${elapsedSeconds}s`);
    this.stopProgressUpdates();
  }
  /**
   * Mark a file as completed
   * @param filePath Path to the file that was completed
   */
  completeFile(filePath) {
    if (!this.completedFiles.includes(filePath)) {
      this.completedFiles.push(filePath);
    }
    const fileIndex = this.progress.currentFiles.indexOf(filePath);
    if (fileIndex !== -1) {
      this.progress.currentFiles.splice(fileIndex, 1);
    }
    const progressPercent = this.completedFiles.length / this.progress.totalFiles * 100;
    logger_default.debug(`File completed: ${filePath} (${progressPercent.toFixed(1)}% complete)`);
  }
  /**
   * Get the current progress
   * @returns Current progress state
   */
  getProgress() {
    return { ...this.progress };
  }
  /**
   * Get the full state including completed files
   * @returns Full state object
   */
  getState() {
    return {
      progressData: this.getProgress(),
      completedFiles: [...this.completedFiles],
      progress: this.completedFiles.length / this.progress.totalFiles,
      completed: this.progress.isComplete,
      currentPass: this.progress.currentPass
    };
  }
};

// src/utils/review/index.ts
init_consolidateReview();

// src/strategies/MultiPassReviewStrategy.ts
var MultiPassReviewStrategy = class extends BaseReviewStrategy {
  /**
   * Create a new multi-pass review strategy
   * @param reviewType Type of review to perform
   */
  constructor(reviewType) {
    super(reviewType);
    logger_default.debug("Initialized MultiPassReviewStrategy");
  }
  /**
   * Execute the multi-pass review strategy
   * @param files Files to review
   * @param projectName Project name
   * @param projectDocs Project documentation
   * @param options Review options
   * @param apiClientConfig API client configuration
   * @returns Promise resolving to the review result
   */
  async execute(files, projectName, projectDocs, options, apiClientConfig) {
    logger_default.info(`Executing multi-pass ${this.reviewType} review strategy...`);
    if (!apiClientConfig.initialized) {
      throw new Error("API client not initialized");
    }
    const progressTracker = new MultiPassProgressTracker(1, files.length, {
      quiet: options.quiet
    });
    progressTracker.setPhase("analyzing");
    const tokenAnalysisOptions = {
      reviewType: this.reviewType,
      modelName: apiClientConfig.modelName
    };
    const tokenAnalysis = TokenAnalyzer.analyzeFiles(files, tokenAnalysisOptions);
    logger_default.info("Token analysis completed:");
    logger_default.info(formatTokenAnalysis(tokenAnalysis, apiClientConfig.modelName));
    const reviewContext = new ReviewContext(projectName, this.reviewType, files);
    if (!tokenAnalysis.chunkingRecommendation.chunkingRecommended) {
      logger_default.info("Content fits within context window, using standard review");
      progressTracker.complete();
      return generateReview(
        files,
        projectName,
        this.reviewType,
        projectDocs,
        options,
        apiClientConfig
      );
    }
    logger_default.info(
      `Content exceeds context window (${tokenAnalysis.estimatedTotalTokens} > ${tokenAnalysis.contextWindowSize}), using multi-pass review`
    );
    logger_default.info(
      `Estimated ${tokenAnalysis.estimatedPassesNeeded} passes needed`
    );
    const totalPasses = tokenAnalysis.estimatedPassesNeeded;
    progressTracker.stopProgressUpdates();
    const newProgressTracker = new MultiPassProgressTracker(totalPasses, files.length, {
      quiet: options.quiet
    });
    let consolidatedResult = {
      content: "",
      filePath: "multi-pass-review",
      files,
      reviewType: this.reviewType,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      costInfo: {
        inputTokens: 0,
        outputTokens: 0,
        totalTokens: 0,
        estimatedCost: 0,
        formattedCost: "$0.00 USD",
        cost: 0,
        passCount: totalPasses,
        perPassCosts: [],
        contextMaintenanceFactor: options.contextMaintenanceFactor || 0.15
      },
      totalPasses
    };
    const chunks = tokenAnalysis.chunkingRecommendation.recommendedChunks;
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const passNumber = i + 1;
      const chunkFiles = files.filter((f) => chunk.files.includes(f.path));
      newProgressTracker.startPass(passNumber, chunkFiles.map((f) => f.path));
      reviewContext.startPass();
      const chunkContext = reviewContext.generateNextPassContext(
        chunkFiles.map((f) => f.path)
      );
      let enhancedProjectDocs = null;
      if (projectDocs) {
        enhancedProjectDocs = { ...projectDocs };
      } else {
        enhancedProjectDocs = { readme: "" };
      }
      enhancedProjectDocs.custom = {
        ...enhancedProjectDocs.custom || {},
        "REVIEW_CONTEXT.md": chunkContext
      };
      const chunkOptions = {
        ...options,
        multiPass: true,
        passNumber,
        totalPasses: chunks.length
      };
      const chunkResult = await generateReview(
        chunkFiles,
        projectName,
        this.reviewType,
        enhancedProjectDocs,
        chunkOptions,
        apiClientConfig
      );
      this.updateContextFromReviewResults(reviewContext, chunkResult, chunkFiles);
      if (consolidatedResult.costInfo && chunkResult.costInfo) {
        consolidatedResult.costInfo.inputTokens += chunkResult.costInfo.inputTokens || 0;
        consolidatedResult.costInfo.outputTokens += chunkResult.costInfo.outputTokens || 0;
        consolidatedResult.costInfo.totalTokens += chunkResult.costInfo.totalTokens || 0;
        consolidatedResult.costInfo.estimatedCost += chunkResult.costInfo.estimatedCost || 0;
        consolidatedResult.costInfo.formattedCost = `$${consolidatedResult.costInfo.estimatedCost.toFixed(6)} USD`;
        if (consolidatedResult.costInfo.perPassCosts && Array.isArray(consolidatedResult.costInfo.perPassCosts)) {
          consolidatedResult.costInfo.perPassCosts.push({
            passNumber,
            inputTokens: chunkResult.costInfo.inputTokens || 0,
            outputTokens: chunkResult.costInfo.outputTokens || 0,
            totalTokens: chunkResult.costInfo.totalTokens || 0,
            estimatedCost: chunkResult.costInfo.estimatedCost || 0
          });
        }
      }
      consolidatedResult.content += `
## Pass ${passNumber}: Review of ${chunkFiles.length} Files

`;
      consolidatedResult.content += chunkResult.content;
      consolidatedResult.content += "\n\n";
      newProgressTracker.completePass(passNumber);
    }
    newProgressTracker.setPhase("processing");
    const initialSummary = this.generateMultiPassSummary(
      consolidatedResult,
      tokenAnalysis,
      reviewContext,
      files,
      apiClientConfig.modelName
    );
    consolidatedResult.content = initialSummary + consolidatedResult.content;
    newProgressTracker.setPhase("consolidating");
    logger_default.info("Generating final consolidated review report with grading...");
    try {
      logger_default.debug("Starting consolidation phase with model provider: " + apiClientConfig.provider + ", model: " + apiClientConfig.modelName);
      consolidatedResult.modelUsed = `${apiClientConfig.provider}:${apiClientConfig.modelName}`;
      const finalReport = await this.generateConsolidatedReport(
        consolidatedResult,
        apiClientConfig,
        files,
        projectName,
        projectDocs,
        options
      );
      if (finalReport) {
        logger_default.info("Successfully generated consolidated report with grading");
        consolidatedResult = finalReport;
      } else {
        logger_default.warn("Consolidation function returned undefined - likely due to API error");
        logger_default.warn("Creating fallback consolidated report");
        const fallbackReport = {
          ...consolidatedResult,
          content: this.createFallbackConsolidation(consolidatedResult, apiClientConfig.modelName)
        };
        consolidatedResult = fallbackReport;
      }
    } catch (error2) {
      logger_default.error(
        `Failed to generate final consolidated report: ${error2 instanceof Error ? error2.message : String(error2)}`
      );
      logger_default.error("Error occurred during consolidated report generation. Stack trace:");
      if (error2 instanceof Error && error2.stack) {
        logger_default.error(error2.stack);
      }
      logger_default.warn("Creating fallback consolidated report");
      const fallbackReport = {
        ...consolidatedResult,
        content: this.createFallbackConsolidation(consolidatedResult, apiClientConfig.modelName)
      };
      consolidatedResult = fallbackReport;
    }
    newProgressTracker.complete();
    return consolidatedResult;
  }
  /**
   * Generate a summary for the multi-pass review
   * @param result Consolidated review result
   * @param tokenAnalysis Token analysis result
   * @param context Review context
   * @param files All files in the review
   * @param modelName Model name
   * @returns Summary string
   */
  generateMultiPassSummary(result, tokenAnalysis, context, files, modelName) {
    const findings = context.getFindings();
    const filesCount = files.length;
    const totalPassesCount = context.getCurrentPass();
    const costInfo = result.costInfo;
    const costBreakdown = costInfo && costInfo.perPassCosts ? costInfo.perPassCosts.map(
      (passCost) => `- Pass ${passCost.passNumber}: ${passCost.inputTokens.toLocaleString()} input + ${passCost.outputTokens.toLocaleString()} output = ${passCost.totalTokens.toLocaleString()} tokens ($${passCost.estimatedCost.toFixed(4)} USD)`
    ).join("\n") : "N/A";
    return `# Multi-Pass ${this.reviewType.charAt(0).toUpperCase() + this.reviewType.slice(1)} Review Summary

This review was conducted in **${totalPassesCount} passes** to analyze **${filesCount} files** (${tokenAnalysis.totalSizeInBytes.toLocaleString()} bytes) due to the large size of the codebase.

## Review Statistics
- Files analyzed: ${filesCount}
- Total passes: ${totalPassesCount}
- Model used: ${modelName}
- Key findings identified: ${findings.length}

## Token Usage
- Content tokens: ${tokenAnalysis.totalTokens.toLocaleString()}
- Context window size: ${tokenAnalysis.contextWindowSize.toLocaleString()}
- Context utilization: ${(tokenAnalysis.estimatedTotalTokens / tokenAnalysis.contextWindowSize * 100).toFixed(2)}%
${costInfo ? `- Total tokens used: ${costInfo.totalTokens.toLocaleString()} (input: ${costInfo.inputTokens.toLocaleString()}, output: ${costInfo.outputTokens.toLocaleString()})
- Estimated cost: ${costInfo.formattedCost}` : ""}

### Per-Pass Token Usage
${costBreakdown}

## Multi-Pass Methodology
This review used a multi-pass approach with context maintenance between passes to ensure a cohesive analysis despite the large codebase size. Each pass analyzed a subset of files while maintaining awareness of findings and relationships from previous passes.

`;
  }
  /**
   * Update the review context with findings from a review result
   * @param context Review context to update
   * @param result Review result to extract findings from
   * @param files Files included in this pass
   */
  updateContextFromReviewResult(context, result, files) {
    files.forEach((file) => {
      context.addFileSummary({
        path: file.path,
        type: file.path.split(".").pop() || "unknown",
        description: `File containing ${file.content.length} bytes of code`,
        keyElements: [],
        passNumber: context.getCurrentPass()
      });
    });
    context.addGeneralNote(
      `Pass ${context.getCurrentPass()} analyzed ${files.length} files and generated a ${result.content.length} character review.`
    );
  }
  /**
   * Generate a consolidated report from the multi-pass review results
   * @param multiPassResult Combined result from all passes
   * @param apiClientConfig API client configuration
   * @param files All files included in the review
   * @param projectName Name of the project
   * @param projectDocs Project documentation
   * @param options Review options
   * @returns Promise resolving to a consolidated review result, or undefined if consolidation fails
   */
  async generateConsolidatedReport(multiPassResult, apiClientConfig, files, projectName, _projectDocs, _options) {
    try {
      if (!apiClientConfig.provider || !apiClientConfig.apiKey || !apiClientConfig.modelName) {
        throw new Error("API client configuration is incomplete for consolidation");
      }
      multiPassResult.projectName = projectName;
      logger_default.info("Using consolidateReview utility to generate final report with grading...");
      const { consolidateReview: consolidateReview2 } = await Promise.resolve().then(() => (init_consolidateReview(), consolidateReview_exports));
      const consolidatedContent = await consolidateReview2(multiPassResult);
      if (!consolidatedContent || consolidatedContent.trim() === "") {
        logger_default.warn("Received empty consolidated content");
        return void 0;
      }
      logger_default.info("Successfully generated consolidated report with grading!");
      try {
        const { getCostInfoFromText: getCostInfoFromText2 } = await Promise.resolve().then(() => (init_tokenCounter(), tokenCounter_exports));
        const consolidationCost = getCostInfoFromText2(
          multiPassResult.content,
          consolidatedContent,
          `${apiClientConfig.provider}:${apiClientConfig.modelName}`
        );
        if (multiPassResult.costInfo && consolidationCost) {
          const consolidationPassCost = {
            passNumber: (multiPassResult.totalPasses || 0) + 1,
            inputTokens: consolidationCost.inputTokens,
            outputTokens: consolidationCost.outputTokens,
            totalTokens: consolidationCost.totalTokens,
            estimatedCost: consolidationCost.estimatedCost
          };
          const updatedCost = {
            ...multiPassResult.costInfo,
            inputTokens: multiPassResult.costInfo.inputTokens + consolidationCost.inputTokens,
            outputTokens: multiPassResult.costInfo.outputTokens + consolidationCost.outputTokens,
            totalTokens: multiPassResult.costInfo.totalTokens + consolidationCost.totalTokens,
            estimatedCost: multiPassResult.costInfo.estimatedCost + consolidationCost.estimatedCost,
            formattedCost: `$${(multiPassResult.costInfo.estimatedCost + consolidationCost.estimatedCost).toFixed(6)} USD`,
            perPassCosts: [
              ...multiPassResult.costInfo.perPassCosts || [],
              consolidationPassCost
            ]
          };
          const consolidatedResult2 = {
            ...multiPassResult,
            content: consolidatedContent,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            costInfo: updatedCost,
            totalPasses: (multiPassResult.totalPasses || 0) + 1
          };
          logger_default.info(`Added consolidation pass to cost data. Final cost: ${updatedCost.formattedCost}`);
          return consolidatedResult2;
        }
      } catch (costError) {
        logger_default.warn(`Could not calculate cost for consolidation phase: ${costError instanceof Error ? costError.message : String(costError)}`);
      }
      const consolidatedResult = {
        ...multiPassResult,
        content: consolidatedContent,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      };
      return consolidatedResult;
    } catch (error2) {
      logger_default.error(`Error generating consolidated report: ${error2 instanceof Error ? error2.message : String(error2)}`);
      return void 0;
    }
  }
  /**
   * Creates a fallback consolidation when AI consolidation fails
   * @param multiPassResult The combined result from all passes
   * @param modelName The name of the model
   * @returns A basic consolidated review content
   */
  createFallbackConsolidation(multiPassResult, _modelName) {
    logger_default.info("Creating fallback consolidation from multi-pass results...");
    const passRegex = /## Pass (\d+): Review of (\d+) Files\s+# Code Review\s+## Summary([\s\S]*?)(?=## Pass|$)/g;
    const passes = [];
    let match;
    while ((match = passRegex.exec(multiPassResult.content)) !== null) {
      const [, passNumberStr, fileCountStr, summaryContent] = match;
      passes.push({
        passNumber: parseInt(passNumberStr, 10),
        fileCount: parseInt(fileCountStr, 10),
        summary: summaryContent.trim()
      });
    }
    const highPriorityFindings = /* @__PURE__ */ new Set();
    const mediumPriorityFindings = /* @__PURE__ */ new Set();
    const lowPriorityFindings = /* @__PURE__ */ new Set();
    const highPriorityRegex = /### High Priority\s+([\s\S]*?)(?=### Medium Priority|### Low Priority|$)/g;
    const mediumPriorityRegex = /### Medium Priority\s+([\s\S]*?)(?=### High Priority|### Low Priority|$)/g;
    const lowPriorityRegex = /### Low Priority\s+([\s\S]*?)(?=### High Priority|### Medium Priority|$)/g;
    const extractIssueTitles = (content) => {
      const issueTitleRegex = /- \*\*Issue title:\*\* (.*?)(?=\s+- \*\*File path|$)/g;
      const titles = [];
      let titleMatch;
      while ((titleMatch = issueTitleRegex.exec(content)) !== null) {
        titles.push(titleMatch[1].trim());
      }
      return titles;
    };
    multiPassResult.content.split(/## Pass \d+/).forEach((passContent) => {
      let highMatch;
      while ((highMatch = highPriorityRegex.exec(passContent)) !== null) {
        extractIssueTitles(highMatch[1]).forEach((title) => highPriorityFindings.add(title));
      }
      let mediumMatch;
      while ((mediumMatch = mediumPriorityRegex.exec(passContent)) !== null) {
        extractIssueTitles(mediumMatch[1]).forEach((title) => mediumPriorityFindings.add(title));
      }
      let lowMatch;
      while ((lowMatch = lowPriorityRegex.exec(passContent)) !== null) {
        extractIssueTitles(lowMatch[1]).forEach((title) => lowPriorityFindings.add(title));
      }
    });
    const consolidatedContent = `# Consolidated ${this.reviewType.charAt(0).toUpperCase() + this.reviewType.slice(1)} Review
    
## Executive Summary

This consolidated review was generated from ${passes.length} passes analyzing a total of ${multiPassResult.files?.length || 0} files.

### Key Findings

${highPriorityFindings.size > 0 ? `- ${highPriorityFindings.size} high-priority issues identified` : ""}
${mediumPriorityFindings.size > 0 ? `- ${mediumPriorityFindings.size} medium-priority issues identified` : ""}
${lowPriorityFindings.size > 0 ? `- ${lowPriorityFindings.size} low-priority issues identified` : ""}

## Grading

Based on the identified issues, the codebase receives the following grades:

| Category | Grade | Justification |
|----------|-------|---------------|
| Functionality | B | The code appears to function correctly with some potential bugs identified. |
| Code Quality | B- | The codebase shows generally good practices but has several areas for improvement. |
| Documentation | C+ | Documentation exists but is inconsistent in coverage and quality. |
| Testing | C | Testing framework is in place but coverage and quality are inconsistent. |
| Maintainability | B- | The codebase is reasonably maintainable but has some complexity issues. |
| Security | B | Generally secure but has some potential vulnerability points. |
| Performance | B | Mostly efficient with a few optimization opportunities. |

**Overall Grade: B-**

## Critical Issues (High Priority)

${Array.from(highPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Important Issues (Medium Priority)

${Array.from(mediumPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Minor Issues (Low Priority)

${Array.from(lowPriorityFindings).map((issue) => `- ${issue}`).join("\n")}

## Recommendations

1. Address the high-priority issues first, particularly those related to error handling and security.
2. Improve documentation across the codebase for better maintainability.
3. Enhance test coverage, especially for error scenarios.
4. Consider refactoring complex functions to improve code readability and maintainability.

---

**Note:** This is a fallback consolidated report generated automatically due to an error in the AI-assisted consolidation process. The detailed findings for each pass can be found in the sections below.
`;
    return consolidatedContent + "\n\n" + multiPassResult.content;
  }
  /**
   * Update the review context with findings from multiple review results
   * @param context Review context to update
   * @param result Review result to extract findings from
   * @param files Files included in this pass
   */
  updateContextFromReviewResults(context, result, files) {
    files.forEach((file) => {
      if (!file.path) return;
      const fileExtension = file.path.split(".").pop() || "unknown";
      context.addFileSummary({
        path: file.path,
        type: fileExtension,
        description: `${fileExtension.toUpperCase()} file with ${file.content.length} bytes`,
        keyElements: [],
        passNumber: context.getCurrentPass()
      });
    });
    const findingPatterns = [
      { type: "bug", regex: /bug|issue|error|fix needed|incorrect/gi, severity: 8 },
      { type: "security", regex: /security|vulnerability|exploit|injection|xss|csrf/gi, severity: 9 },
      { type: "performance", regex: /performance|slow|optimize|efficiency|bottleneck/gi, severity: 7 },
      { type: "maintainability", regex: /maintainability|hard to read|complex|refactor/gi, severity: 6 }
    ];
    const paragraphs = result.content.split("\n\n");
    paragraphs.forEach((paragraph) => {
      findingPatterns.forEach((pattern) => {
        if (pattern.regex.test(paragraph)) {
          let description = paragraph.substring(0, 100);
          if (description.length === 100) {
            description += "...";
          }
          let file = void 0;
          files.forEach((f) => {
            if (f.path && (paragraph.includes(f.path) || f.relativePath && paragraph.includes(f.relativePath))) {
              file = f.path;
            }
          });
          context.addFinding({
            type: pattern.type,
            description,
            file,
            severity: pattern.severity,
            passNumber: context.getCurrentPass()
          });
        }
      });
    });
    context.addGeneralNote(
      `Pass ${context.getCurrentPass()} reviewed ${files.length} files and identified approximate findings based on text heuristics.`
    );
  }
};

// src/plugins/PluginManager.ts
var import_promises10 = __toESM(require("fs/promises"));
var import_path21 = __toESM(require("path"));
init_logger();
var PluginManager = class _PluginManager {
  static instance;
  plugins = /* @__PURE__ */ new Map();
  /**
   * Private constructor to enforce singleton pattern
   */
  constructor() {
  }
  /**
   * Get the singleton instance
   * @returns The plugin manager instance
   */
  static getInstance() {
    if (!_PluginManager.instance) {
      _PluginManager.instance = new _PluginManager();
    }
    return _PluginManager.instance;
  }
  /**
   * Register a plugin strategy
   * @param registration Plugin registration information
   */
  registerPlugin(registration) {
    if (this.plugins.has(registration.name)) {
      logger_default.warn(
        `Plugin with name "${registration.name}" is already registered. Overwriting...`
      );
    }
    this.plugins.set(registration.name, registration);
    logger_default.info(`Registered plugin strategy: ${registration.name}`);
  }
  /**
   * Get a plugin strategy by name
   * @param name Plugin name
   * @returns The strategy or undefined if not found
   */
  getPlugin(name) {
    const registration = this.plugins.get(name);
    return registration?.strategy;
  }
  /**
   * Get plugin information by name
   * @param name Plugin name
   * @returns Plugin information or undefined if not found
   */
  getPluginInfo(name) {
    return this.plugins.get(name);
  }
  /**
   * List all registered plugins
   * @returns Array of plugin registrations
   */
  listPlugins() {
    return Array.from(this.plugins.values());
  }
  /**
   * Load plugins from a directory
   * @param pluginsDir Directory containing plugins
   */
  async loadPlugins(pluginsDir) {
    try {
      try {
        await import_promises10.default.access(pluginsDir);
      } catch (error2) {
        logger_default.debug(`Plugins directory not found: ${pluginsDir}`);
        return;
      }
      const files = await import_promises10.default.readdir(pluginsDir);
      for (const file of files) {
        if (file.endsWith(".js")) {
          try {
            const pluginPath = import_path21.default.join(pluginsDir, file);
            const plugin = await import(pluginPath);
            if (plugin.default && typeof plugin.default.register === "function") {
              plugin.default.register(this);
              logger_default.info(`Loaded plugin from ${file}`);
            } else {
              logger_default.warn(
                `File ${file} is not a valid plugin (missing register function)`
              );
            }
          } catch (error2) {
            logger_default.error(
              `Error loading plugin ${file}: ${error2 instanceof Error ? error2.message : String(error2)}`
            );
          }
        }
      }
      logger_default.info(`Loaded ${this.plugins.size} plugins from ${pluginsDir}`);
    } catch (error2) {
      logger_default.error(
        `Error loading plugins: ${error2 instanceof Error ? error2.message : String(error2)}`
      );
    }
  }
};

// src/strategies/StrategyFactory.ts
init_logger();
var StrategyFactory = class {
  /**
   * Create a review strategy based on options
   * @param options Review options
   * @returns The appropriate review strategy
   */
  static createStrategy(options) {
    if (options.strategy) {
      const pluginManager = PluginManager.getInstance();
      const customStrategy = pluginManager.getPlugin(options.strategy);
      if (customStrategy) {
        logger_default.info(`Using custom strategy: ${options.strategy}`);
        return customStrategy;
      } else {
        logger_default.warn(
          `Custom strategy "${options.strategy}" not found. Falling back to default strategy.`
        );
      }
    }
    const reviewType = options.type;
    if (options.multiPass) {
      logger_default.info("Using Multi-Pass Review Strategy");
      return new MultiPassReviewStrategy(reviewType);
    }
    if (reviewType === "architectural") {
      return new ArchitecturalReviewStrategy();
    } else if (reviewType === "extract-patterns") {
      return new ExtractPatternsReviewStrategy();
    } else if (reviewType === "unused-code") {
      if (options.traceCode) {
        logger_default.info("Using Code Tracing Unused Code Review Strategy");
        return new CodeTracingUnusedCodeReviewStrategy();
      }
      const useFocused = options.focused || options.promptStrategy === "langchain";
      return useFocused ? new FocusedUnusedCodeReviewStrategy() : new UnusedCodeReviewStrategy();
    } else if (reviewType === "quick-fixes" && options.promptStrategy === "langchain") {
      return new ImprovedQuickFixesReviewStrategy();
    } else {
      return new ConsolidatedReviewStrategy(reviewType);
    }
  }
};

// src/core/handlers/ReviewExecutor.ts
async function executeReview(fileInfos, options, apiClientConfig, projectDocs = null, tokenAnalysis = null) {
  const strategy = StrategyFactory.createStrategy(options);
  if (!strategy) {
    throw new Error(`Unsupported review type: ${options.type}`);
  }
  logger_default.info(`Using ${options.type} review strategy`);
  const needsMultiPass = determineIfMultiPassNeeded(options, tokenAnalysis);
  if (needsMultiPass) {
    logger_default.info("Using multi-pass review due to content size or complexity");
  }
  const projectPath = process.cwd();
  const projectName = path27.basename(projectPath);
  const reviewResult = await strategy.execute(
    fileInfos,
    projectName,
    projectDocs,
    options,
    apiClientConfig
  );
  return reviewResult;
}
function determineIfMultiPassNeeded(options, tokenAnalysis) {
  if (options.multiPass) {
    return true;
  }
  if (options.forceSinglePass) {
    return false;
  }
  if (tokenAnalysis && tokenAnalysis.chunkingRecommendation) {
    return tokenAnalysis.chunkingRecommendation.chunkingRecommended;
  }
  return false;
}

// src/core/handlers/OutputHandler.ts
var path32 = __toESM(require("path"));
init_logger();

// src/core/OutputManager.ts
var import_path25 = __toESM(require("path"));
var import_promises14 = __toESM(require("fs/promises"));

// src/utils/sanitizer.ts
var import_jsdom = require("jsdom");
var import_dompurify = __toESM(require("dompurify"));
init_logger();
var { window } = new import_jsdom.JSDOM("");
var DOMPurify = (0, import_dompurify.default)(window);
function sanitizeHtml(content) {
  try {
    const sanitized = DOMPurify.sanitize(content, {
      ALLOWED_TAGS: [
        "h1",
        "h2",
        "h3",
        "h4",
        "h5",
        "h6",
        "p",
        "br",
        "hr",
        "ul",
        "ol",
        "li",
        "b",
        "i",
        "strong",
        "em",
        "code",
        "pre",
        "a",
        "span",
        "div",
        "table",
        "thead",
        "tbody",
        "tr",
        "th",
        "td"
      ],
      ALLOWED_ATTR: ["href", "target", "rel", "class", "id", "style"],
      FORBID_TAGS: [
        "script",
        "iframe",
        "object",
        "embed",
        "form",
        "input",
        "button",
        "style",
        "link",
        "meta",
        "base",
        "applet",
        "math",
        "svg"
      ],
      FORBID_ATTR: [
        "onerror",
        "onload",
        "onclick",
        "onmouseover",
        "onmouseout",
        "onmousedown",
        "onmouseup",
        "onkeydown",
        "onkeyup",
        "onkeypress",
        "onfocus",
        "onblur",
        "onchange",
        "onsubmit",
        "onreset",
        "javascript:",
        "data:",
        "vbscript:"
      ]
    });
    return sanitized;
  } catch (error2) {
    logger_default.error("Error sanitizing HTML content:", error2);
    return "";
  }
}
function sanitizeMarkdown(content) {
  try {
    const sanitized = content.replace(/<!--[\s\S]*?-->/g, "").replace(/<script[\s\S]*?<\/script>/gi, "").replace(/<iframe[\s\S]*?<\/iframe>/gi, "").replace(/<style[\s\S]*?<\/style>/gi, "").replace(/\son\w+\s*=\s*["']?[^"']*["']?/gi, "").replace(/javascript\s*:/gi, "removed:").replace(/data\s*:/gi, "removed:").replace(/vbscript\s*:/gi, "removed:");
    return sanitized;
  } catch (error2) {
    logger_default.error("Error sanitizing Markdown content:", error2);
    return "";
  }
}
function sanitizeJson(content) {
  try {
    const parsed = JSON.parse(content);
    return JSON.stringify(parsed);
  } catch (error2) {
    logger_default.error("Error sanitizing JSON content:", error2);
    return "{}";
  }
}
function sanitizeContent(content, contentType = "text") {
  switch (contentType) {
    case "html":
      return sanitizeHtml(content);
    case "markdown":
      return sanitizeMarkdown(content);
    case "json":
      return sanitizeJson(content);
    case "text":
    default:
      return content.replace(/[\x00-\x09\x0B-\x1F\x7F]/g, "");
  }
}

// src/formatters/utils/MarkdownFormatters.ts
init_logger();

// src/formatters/utils/ModelInfoExtractor.ts
init_logger();
function extractModelInfo(modelString) {
  let modelVendor = "Unknown";
  let modelName = "AI";
  let modelInfo = "AI";
  if (!modelString) {
    logger_default.warn("No model string provided. Using default values.");
    return { modelVendor, modelName, modelInfo };
  }
  if (modelString.startsWith("openrouter:")) {
    modelVendor = "OpenRouter";
    modelName = modelString.substring("openrouter:".length);
    modelInfo = `OpenRouter (${modelName})`;
  } else if (modelString.startsWith("anthropic:")) {
    modelVendor = "Anthropic";
    modelName = modelString.substring("anthropic:".length);
    modelInfo = `Anthropic (${modelName})`;
  } else if (modelString.startsWith("openai:")) {
    modelVendor = "OpenAI";
    modelName = modelString.substring("openai:".length);
    modelInfo = `OpenAI (${modelName})`;
  } else if (modelString.startsWith("gemini:")) {
    modelVendor = "Google";
    modelName = modelString.substring("gemini:".length);
    modelInfo = `Google Gemini AI (${modelName})`;
  } else if (modelString.startsWith("Google:")) {
    modelVendor = "Google";
    modelName = modelString.substring("Google:".length);
    modelInfo = `Google Gemini AI (${modelName})`;
  } else if (modelString.startsWith("Anthropic:")) {
    modelVendor = "Anthropic";
    modelName = modelString.substring("Anthropic:".length);
    modelInfo = `Anthropic (${modelName})`;
  } else if (modelString.startsWith("OpenAI:")) {
    modelVendor = "OpenAI";
    modelName = modelString.substring("OpenAI:".length);
    modelInfo = `OpenAI (${modelName})`;
  } else if (modelString.startsWith("OpenRouter:")) {
    modelVendor = "OpenRouter";
    modelName = modelString.substring("OpenRouter:".length);
    modelInfo = `OpenRouter (${modelName})`;
  } else {
    modelVendor = "Unknown";
    modelName = modelString;
    modelInfo = `AI (${modelName})`;
  }
  return { modelVendor, modelName, modelInfo };
}
function extractModelInfoFromString(modelInfo) {
  let modelVendor = "Unknown";
  let modelName = "AI";
  if (modelInfo) {
    if (modelInfo.includes("Google Gemini AI")) {
      modelVendor = "Google";
      const match = modelInfo.match(/\((.*?)\)/);
      modelName = match ? match[1] : "Gemini";
    } else if (modelInfo.includes("Anthropic")) {
      modelVendor = "Anthropic";
      const match = modelInfo.match(/\((.*?)\)/);
      modelName = match ? match[1] : "Claude";
    } else if (modelInfo.includes("OpenAI")) {
      modelVendor = "OpenAI";
      const match = modelInfo.match(/\((.*?)\)/);
      modelName = match ? match[1] : "GPT";
    } else if (modelInfo.includes("OpenRouter")) {
      modelVendor = "OpenRouter";
      const match = modelInfo.match(/\((.*?)\)/);
      modelName = match ? match[1] : "AI";
    }
  }
  return { modelVendor, modelName };
}

// src/formatters/utils/IssueFormatters.ts
function formatSchemaIssue(issue, index) {
  let issueMarkdown = `### ${index}. ${issue.description}

`;
  if (issue.filePath) {
    issueMarkdown += `**File**: \`${issue.filePath}\`
`;
  }
  if (issue.location) {
    issueMarkdown += `**Location**: Lines ${issue.location.startLine}-${issue.location.endLine}

`;
  }
  if (issue.currentCode) {
    issueMarkdown += `**Current Code**:
\`\`\`
${issue.currentCode}
\`\`\`

`;
  }
  if (issue.suggestedCode) {
    issueMarkdown += `**Suggested Fix**:
\`\`\`
${issue.suggestedCode}
\`\`\`

`;
  }
  if (issue.explanation) {
    issueMarkdown += `**Explanation**: ${issue.explanation}

`;
  }
  issueMarkdown += `---

`;
  return issueMarkdown;
}
function formatIssue(issue) {
  if (!issue) {
    return "#### [Error: Issue data missing]";
  }
  const {
    title,
    type,
    filePath,
    lineNumbers,
    description,
    codeSnippet,
    suggestedFix,
    impact
  } = issue;
  let issueMarkdown = `#### ${title || "[Untitled Issue]"}
`;
  if (filePath) {
    issueMarkdown += `- **Location**: \`${filePath}${lineNumbers ? `:${lineNumbers}` : ""}\`
`;
  }
  if (type) {
    issueMarkdown += `- **Type**: ${type}
`;
  }
  issueMarkdown += `- **Description**: ${description || "No description provided"}
`;
  if (codeSnippet) {
    issueMarkdown += `- **Code**:
\`\`\`
${codeSnippet}
\`\`\`
`;
  }
  if (suggestedFix) {
    issueMarkdown += `- **Suggested Fix**:
\`\`\`
${suggestedFix}
\`\`\`
`;
  }
  if (impact) {
    issueMarkdown += `- **Impact**: ${impact}
`;
  }
  return issueMarkdown;
}

// src/formatters/utils/MetadataFormatter.ts
function formatMetadataSection(reviewType, timestamp, modelInfo, cost, toolVersion, commandOptions, detectedLanguage, detectedFramework, frameworkVersion, cssFrameworks) {
  const { modelVendor, modelName } = extractModelInfoFromString(modelInfo);
  const formattedDate = new Date(timestamp).toLocaleString(void 0, {
    year: "numeric",
    month: "long",
    day: "numeric",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
    timeZoneName: "short"
  });
  let metadataSection = `## Metadata
| Property | Value |
|----------|-------|
| Review Type | ${reviewType} |
| Generated At | ${formattedDate} |
| Model Provider | ${modelVendor} |
| Model Name | ${modelName} |`;
  if (detectedLanguage) {
    metadataSection += `
| Detected Language | ${detectedLanguage} |`;
    if (detectedFramework && detectedFramework !== "none") {
      metadataSection += `
| Detected Framework | ${detectedFramework}${frameworkVersion ? ` v${frameworkVersion}` : ""} |`;
    }
    if (cssFrameworks && cssFrameworks.length > 0) {
      const cssFrameworksStr = cssFrameworks.map(
        (cf) => cf.version ? `${cf.name} v${cf.version.replace(/[^\d.]/g, "")}` : cf.name
      ).join(", ");
      metadataSection += `
| CSS Frameworks | ${cssFrameworksStr} |`;
    }
  }
  if (cost) {
    metadataSection += `
| Input Tokens | ${cost.inputTokens.toLocaleString()} |
| Output Tokens | ${cost.outputTokens.toLocaleString()} |
| Total Tokens | ${cost.totalTokens.toLocaleString()} |
| Estimated Cost | ${cost.formattedCost} |`;
    if (cost.passCount && cost.passCount > 1) {
      metadataSection += `
| Multi-pass Review | ${cost.passCount} passes |`;
    }
  }
  if (toolVersion) {
    metadataSection += `
| Tool Version | ${toolVersion} |`;
  }
  if (commandOptions) {
    metadataSection += `
| Command Options | \`${commandOptions}\` |`;
  }
  metadataSection += `
`;
  return metadataSection;
}
function parseMetadata(metadata) {
  if (!metadata) {
    return {};
  }
  try {
    return typeof metadata === "string" ? JSON.parse(metadata) : metadata;
  } catch (error2) {
    return {};
  }
}
function createEnhancedMetadata(modelVendor, modelName, modelInfo, reviewType, displayPath, timestamp, cost, toolVersion, commandOptions, additionalMetadata = {}, detectedLanguage, detectedFramework, frameworkVersion, cssFrameworks) {
  const formattedDate = new Date(timestamp).toLocaleString(void 0, {
    year: "numeric",
    month: "long",
    day: "numeric",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
    timeZoneName: "short"
  });
  const enhancedMetadata = {
    model: {
      provider: modelVendor,
      name: modelName,
      fullName: modelInfo
    },
    review: {
      type: reviewType,
      path: displayPath,
      generatedAt: new Date(timestamp).toISOString(),
      formattedDate,
      multiPass: cost && cost.passCount && cost.passCount > 1 ? {
        enabled: true,
        passCount: cost.passCount || 1,
        perPassCosts: cost.perPassCosts || null
      } : null
    },
    cost: cost || null,
    tool: {
      version: toolVersion || process.env.npm_package_version || "2.1.1",
      commandOptions: commandOptions || null,
      ...additionalMetadata
    }
  };
  if (detectedLanguage) {
    enhancedMetadata.detection = {
      language: detectedLanguage
    };
    if (detectedFramework && detectedFramework !== "none") {
      enhancedMetadata.detection.framework = detectedFramework;
      if (frameworkVersion) {
        enhancedMetadata.detection.frameworkVersion = frameworkVersion;
      }
    }
    if (cssFrameworks && cssFrameworks.length > 0) {
      enhancedMetadata.detection.cssFrameworks = cssFrameworks;
    }
  }
  return enhancedMetadata;
}
function parseCostInfo(costInfo) {
  if (!costInfo) {
    return null;
  }
  const inputTokensMatch = costInfo.match(/Input tokens: ([\d,]+)/);
  const outputTokensMatch = costInfo.match(/Output tokens: ([\d,]+)/);
  const totalTokensMatch = costInfo.match(/Total tokens: ([\d,]+)/);
  const estimatedCostMatch = costInfo.match(/Estimated cost: (.*?)$/m);
  const passCountMatch = costInfo.match(/Multi-pass review: (\d+) passes/);
  if (inputTokensMatch || outputTokensMatch || totalTokensMatch || estimatedCostMatch) {
    return {
      inputTokens: inputTokensMatch ? parseInt(inputTokensMatch[1].replace(/,/g, "")) : 0,
      outputTokens: outputTokensMatch ? parseInt(outputTokensMatch[1].replace(/,/g, "")) : 0,
      totalTokens: totalTokensMatch ? parseInt(totalTokensMatch[1].replace(/,/g, "")) : 0,
      estimatedCost: estimatedCostMatch ? parseFloat(estimatedCostMatch[1].replace("$", "").replace(" USD", "")) : 0,
      formattedCost: estimatedCostMatch ? estimatedCostMatch[1] : "$0.00 USD",
      passCount: passCountMatch ? parseInt(passCountMatch[1]) : 1
    };
  }
  return null;
}
function formatCostInfo(cost) {
  if (!cost) {
    return "";
  }
  let costInfo = `

## Token Usage and Cost
- Input tokens: ${cost.inputTokens.toLocaleString()}
- Output tokens: ${cost.outputTokens.toLocaleString()}
- Total tokens: ${cost.totalTokens.toLocaleString()}
- Estimated cost: ${cost.formattedCost}`;
  if (cost.passCount && cost.passCount > 1) {
    costInfo += `
- Multi-pass review: ${cost.passCount} passes`;
    if (cost.perPassCosts && Array.isArray(cost.perPassCosts)) {
      costInfo += `

### Pass Breakdown`;
      cost.perPassCosts.forEach((passCost) => {
        costInfo += `
Pass ${passCost.passNumber}:
- Input tokens: ${passCost.inputTokens.toLocaleString()}
- Output tokens: ${passCost.outputTokens.toLocaleString()}
- Total tokens: ${passCost.totalTokens.toLocaleString()}
- Cost: ${typeof passCost.estimatedCost === "number" ? `$${passCost.estimatedCost.toFixed(4)} USD` : "N/A"}`;
      });
    }
  }
  return costInfo;
}

// src/formatters/utils/MarkdownFormatters.ts
function formatAsMarkdown(review) {
  const { filePath, reviewType, content, timestamp, structuredData } = review;
  const cost = review.costInfo || review.cost;
  const { modelInfo } = extractModelInfo(review.modelUsed);
  const costInfo = formatCostInfo(cost);
  let actualStructuredData = structuredData;
  if (!actualStructuredData && content && typeof content === "string") {
    const trimmedContent = content.trim();
    const jsonBlockRegex = /```(?:json)?\s*([\s\S]*?)\s*```/g;
    const jsonBlocks = [...trimmedContent.matchAll(jsonBlockRegex)];
    if (jsonBlocks.length > 0) {
      for (const match of jsonBlocks) {
        try {
          const jsonContent = match[1].trim();
          if (jsonContent) {
            actualStructuredData = JSON.parse(jsonContent);
            logger_default.debug("Successfully parsed JSON from code block");
            break;
          }
        } catch (e) {
          logger_default.debug(`Failed to parse JSON from code block: ${e instanceof Error ? e.message : String(e)}`);
        }
      }
    }
    if (!actualStructuredData && trimmedContent.startsWith("{") && trimmedContent.endsWith("}")) {
      try {
        actualStructuredData = JSON.parse(trimmedContent);
        logger_default.debug("Successfully parsed JSON from full content");
      } catch (e) {
        logger_default.debug(`Failed to parse content as JSON: ${e instanceof Error ? e.message : String(e)}`);
      }
    }
  }
  if (actualStructuredData) {
    try {
      let structuredReview;
      if (typeof actualStructuredData === "string") {
        try {
          structuredReview = JSON.parse(actualStructuredData);
          logger_default.debug("Successfully parsed structured data string as JSON");
        } catch (parseError) {
          logger_default.warn(`Failed to parse structured data as JSON: ${parseError instanceof Error ? parseError.message : String(parseError)}`);
          return formatSimpleMarkdown(
            content,
            filePath || "",
            reviewType,
            timestamp,
            costInfo,
            modelInfo
          );
        }
      } else {
        structuredReview = actualStructuredData;
      }
      if (structuredReview && structuredReview.review) {
        return formatSchemaBasedReviewAsMarkdown(
          structuredReview,
          filePath || "",
          reviewType,
          timestamp,
          costInfo,
          modelInfo
        );
      }
      if (typeof structuredReview === "object" && structuredReview !== null) {
        return formatStructuredReviewAsMarkdown(
          structuredReview,
          filePath || "",
          reviewType,
          timestamp,
          costInfo,
          modelInfo
        );
      } else {
        logger_default.warn("Structured data is not an object:", typeof structuredReview);
        return formatSimpleMarkdown(
          content,
          filePath || "",
          reviewType,
          timestamp,
          costInfo,
          modelInfo
        );
      }
    } catch (error2) {
      logger_default.error(`Error processing structured review data: ${error2 instanceof Error ? error2.message : String(error2)}`);
      return formatSimpleMarkdown(
        content,
        filePath || "",
        reviewType,
        timestamp,
        costInfo,
        modelInfo
      );
    }
  }
  const sanitizedContent = sanitizeContent(content);
  let displayPath = filePath || "";
  if (!displayPath || displayPath === reviewType || displayPath === "consolidated") {
    displayPath = process.cwd() + " (Current Directory)";
  }
  const metadataSection = formatMetadataSection(
    reviewType,
    timestamp,
    modelInfo,
    cost,
    review.toolVersion,
    review.commandOptions,
    review.detectedLanguage,
    review.detectedFramework,
    review.frameworkVersion,
    review.cssFrameworks
  );
  return `# Code Review: ${displayPath}

> **Review Type**: ${reviewType}
> **Model**: ${modelInfo}
> **Generated**: ${new Date(timestamp).toLocaleString()}

---

${metadataSection}

${sanitizedContent}

---${costInfo}

*Generated by [AI Code Review Tool](https://www.npmjs.com/package/@bobmatnyc/ai-code-review) using ${modelInfo}*`;
}
function formatStructuredReviewAsMarkdown(structuredReview, filePath, reviewType, timestamp, costInfo, modelInfo, metadataSection) {
  if (!structuredReview || typeof structuredReview !== "object") {
    console.warn("Invalid structured review data, falling back to simple format");
    return formatSimpleMarkdown(
      "No structured data available. The review may be in an unsupported format.",
      filePath,
      reviewType,
      timestamp,
      costInfo,
      modelInfo,
      metadataSection
    );
  }
  const summary = structuredReview.summary || "No summary provided";
  const issues = Array.isArray(structuredReview.issues) ? structuredReview.issues : [];
  const recommendations = Array.isArray(structuredReview.recommendations) ? structuredReview.recommendations : [];
  const positiveAspects = Array.isArray(structuredReview.positiveAspects) ? structuredReview.positiveAspects : [];
  const grade = structuredReview.grade;
  const gradeCategories = structuredReview.gradeCategories;
  const highPriorityIssues = issues.filter((issue) => issue && issue.priority === "high");
  const mediumPriorityIssues = issues.filter(
    (issue) => issue && issue.priority === "medium"
  );
  const lowPriorityIssues = issues.filter((issue) => issue && issue.priority === "low");
  let issuesMarkdown = "";
  if (highPriorityIssues.length > 0) {
    issuesMarkdown += "### High Priority\n\n";
    issuesMarkdown += highPriorityIssues.map((issue) => formatIssue(issue)).join("\n\n");
    issuesMarkdown += "\n\n";
  }
  if (mediumPriorityIssues.length > 0) {
    issuesMarkdown += "### Medium Priority\n\n";
    issuesMarkdown += mediumPriorityIssues.map((issue) => formatIssue(issue)).join("\n\n");
    issuesMarkdown += "\n\n";
  }
  if (lowPriorityIssues.length > 0) {
    issuesMarkdown += "### Low Priority\n\n";
    issuesMarkdown += lowPriorityIssues.map((issue) => formatIssue(issue)).join("\n\n");
    issuesMarkdown += "\n\n";
  }
  let recommendationsMarkdown = "";
  if (recommendations && recommendations.length > 0) {
    recommendationsMarkdown = "## General Recommendations\n\n";
    recommendationsMarkdown += recommendations.map((rec) => `- ${rec}`).join("\n");
    recommendationsMarkdown += "\n\n";
  }
  let positiveAspectsMarkdown = "";
  if (positiveAspects && positiveAspects.length > 0) {
    positiveAspectsMarkdown = "## Positive Aspects\n\n";
    positiveAspectsMarkdown += positiveAspects.map((aspect) => `- ${aspect}`).join("\n");
    positiveAspectsMarkdown += "\n\n";
  }
  let displayPath = filePath || "";
  if (!displayPath || displayPath === reviewType || displayPath === "consolidated") {
    displayPath = process.cwd() + " (Current Directory)";
  }
  const metadataContent = metadataSection ? `${metadataSection}
` : "";
  let gradeMarkdown = "";
  if (grade) {
    gradeMarkdown = `## Grade: ${grade}

`;
    if (gradeCategories) {
      if (gradeCategories.functionality) gradeMarkdown += `- **Functionality**: ${gradeCategories.functionality}
`;
      if (gradeCategories.codeQuality) gradeMarkdown += `- **Code Quality**: ${gradeCategories.codeQuality}
`;
      if (gradeCategories.documentation) gradeMarkdown += `- **Documentation**: ${gradeCategories.documentation}
`;
      if (gradeCategories.testing) gradeMarkdown += `- **Testing**: ${gradeCategories.testing}
`;
      if (gradeCategories.maintainability) gradeMarkdown += `- **Maintainability**: ${gradeCategories.maintainability}
`;
      if (gradeCategories.security) gradeMarkdown += `- **Security**: ${gradeCategories.security}
`;
      if (gradeCategories.performance) gradeMarkdown += `- **Performance**: ${gradeCategories.performance}
`;
      gradeMarkdown += "\n";
    }
  }
  return `# Code Review: ${displayPath}

> **Review Type**: ${reviewType}
> **Model**: ${modelInfo}
> **Generated**: ${new Date(timestamp).toLocaleString()}

---

${metadataContent}${gradeMarkdown}## Summary

${summary}

## Issues

${issuesMarkdown}
${recommendationsMarkdown}${positiveAspectsMarkdown}---${costInfo}

*Generated by [AI Code Review Tool](https://www.npmjs.com/package/@bobmatnyc/ai-code-review) using ${modelInfo}*`;
}
function formatSimpleMarkdown(content, filePath, reviewType, timestamp, costInfo, modelInfo, metadataSection) {
  const sanitizedContent = sanitizeContent(content);
  let displayPath = filePath || "";
  if (!displayPath || displayPath === reviewType || displayPath === "consolidated") {
    displayPath = process.cwd() + " (Current Directory)";
  }
  const { modelVendor, modelName } = extractModelInfoFromString(modelInfo);
  const cost = parseCostInfo(costInfo);
  const metadataContent = metadataSection ? `${metadataSection}
` : "";
  const modelMetadata = !metadataSection ? `## Metadata
| Property | Value |
|----------|-------|
| Review Type | ${reviewType} |
| Generated At | ${new Date(timestamp).toLocaleString(void 0, {
    year: "numeric",
    month: "long",
    day: "numeric",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
    timeZoneName: "short"
  })} |
| Model Provider | ${modelVendor} |
| Model Name | ${modelName} |${cost ? `
| Input Tokens | ${cost.inputTokens.toLocaleString()} |
| Output Tokens | ${cost.outputTokens.toLocaleString()} |
| Total Tokens | ${cost.totalTokens.toLocaleString()} |
| Estimated Cost | ${cost.formattedCost} |` : ""}${cost && cost.passCount ? `
| Multi-pass Review | ${cost.passCount} passes |` : ""}
` : "";
  const fullMetadataContent = metadataContent || modelMetadata;
  return `# Code Review: ${displayPath}

> **Review Type**: ${reviewType}
> **Model**: ${modelInfo}
> **Generated**: ${new Date(timestamp).toLocaleString()}

---

${fullMetadataContent}

${sanitizedContent}

---${costInfo}

*Generated by [AI Code Review Tool](https://www.npmjs.com/package/@bobmatnyc/ai-code-review) using ${modelInfo}*`;
}
function formatSchemaBasedReviewAsMarkdown(schemaReview, filePath, reviewType, timestamp, costInfo, modelInfo, metadataSection) {
  const review = schemaReview.review;
  if (!review || typeof review !== "object") {
    return formatSimpleMarkdown(
      JSON.stringify(schemaReview, null, 2),
      filePath,
      reviewType,
      timestamp,
      costInfo,
      modelInfo,
      metadataSection
    );
  }
  const files = review.files || [];
  const summary = review.summary || {};
  const highPriorityIssues = [];
  const mediumPriorityIssues = [];
  const lowPriorityIssues = [];
  files.forEach((file) => {
    const issues = file.issues || [];
    issues.forEach((issue) => {
      const issueWithFile = { ...issue, filePath: file.filePath };
      if (issue.priority === "HIGH") {
        highPriorityIssues.push(issueWithFile);
      } else if (issue.priority === "MEDIUM") {
        mediumPriorityIssues.push(issueWithFile);
      } else if (issue.priority === "LOW") {
        lowPriorityIssues.push(issueWithFile);
      }
    });
  });
  let displayPath = filePath || "";
  if (!displayPath || displayPath === reviewType || displayPath === "consolidated") {
    displayPath = process.cwd() + " (Current Directory)";
  }
  const { modelVendor, modelName } = extractModelInfoFromString(modelInfo);
  if (!metadataSection) {
    const formattedDate = new Date(timestamp).toLocaleString(void 0, {
      year: "numeric",
      month: "long",
      day: "numeric",
      hour: "2-digit",
      minute: "2-digit",
      second: "2-digit",
      timeZoneName: "short"
    });
    metadataSection = `## Metadata
| Property | Value |
|----------|-------|
| Review Type | ${reviewType} |
| Generated At | ${formattedDate} |
| Model Provider | ${modelVendor} |
| Model Name | ${modelName} |`;
  }
  let output = `# Code Review: ${displayPath}

> **Review Type**: ${reviewType}
> **Model**: ${modelInfo}
> **Generated**: ${new Date(timestamp).toLocaleString()}

---

${metadataSection}

## Review Summary

`;
  if (summary.totalIssues > 0) {
    output += `Total issues found: **${summary.totalIssues}**
- High Priority: ${summary.highPriorityIssues || 0}
- Medium Priority: ${summary.mediumPriorityIssues || 0}
- Low Priority: ${summary.lowPriorityIssues || 0}

`;
  } else {
    output += `No issues found. The code looks good!

`;
  }
  if (highPriorityIssues.length > 0) {
    output += `## High Priority Issues

`;
    highPriorityIssues.forEach((issue, index) => {
      output += formatSchemaIssue(issue, index + 1);
    });
  }
  if (mediumPriorityIssues.length > 0) {
    output += `## Medium Priority Issues

`;
    mediumPriorityIssues.forEach((issue, index) => {
      output += formatSchemaIssue(issue, index + 1);
    });
  }
  if (lowPriorityIssues.length > 0) {
    output += `## Low Priority Issues

`;
    lowPriorityIssues.forEach((issue, index) => {
      output += formatSchemaIssue(issue, index + 1);
    });
  }
  if (costInfo) {
    output += `
${costInfo}
`;
  }
  output += `
*Generated by [AI Code Review Tool](https://www.npmjs.com/package/@bobmatnyc/ai-code-review) using ${modelInfo}*`;
  return output;
}

// src/formatters/utils/JsonFormatter.ts
function formatAsJson(review) {
  const { modelVendor, modelName, modelInfo } = extractModelInfo(review.modelUsed);
  const sanitizedContent = sanitizeContent(review.content);
  let parsedStructuredData = review.structuredData;
  if (typeof review.structuredData === "string") {
    try {
      parsedStructuredData = JSON.parse(review.structuredData);
    } catch (error2) {
      console.error("Error parsing structured review data:", error2);
    }
  }
  const additionalMetadata = parseMetadata(review.metadata);
  let displayPath = review.filePath || "";
  if (!displayPath || displayPath === review.reviewType || displayPath === "consolidated") {
    displayPath = process.cwd() + " (Current Directory)";
  }
  const enhancedMetadata = createEnhancedMetadata(
    modelVendor,
    modelName,
    modelInfo,
    review.reviewType,
    displayPath,
    review.timestamp,
    review.costInfo || review.cost,
    review.toolVersion,
    review.commandOptions,
    additionalMetadata,
    review.detectedLanguage,
    review.detectedFramework,
    review.frameworkVersion,
    review.cssFrameworks
  );
  const reviewWithMeta = {
    ...review,
    content: sanitizedContent,
    structuredData: parsedStructuredData,
    meta: enhancedMetadata,
    // Legacy metadata field for backward compatibility
    metadata: {
      model: modelInfo,
      generatedAt: new Date(review.timestamp).toISOString(),
      costEstimation: review.cost
    }
  };
  return JSON.stringify(reviewWithMeta, null, 2);
}

// src/formatters/outputFormatter.ts
function formatReviewOutput(review, format) {
  if (!review.filePath) {
    console.warn("Warning: filePath is undefined or empty in ReviewResult");
  }
  if (!review.modelUsed) {
    console.warn("Warning: modelUsed is undefined or empty in ReviewResult");
  }
  if (review.cost && !review.costInfo) {
    review.costInfo = review.cost;
  }
  if (format === "json") {
    return formatAsJson(review);
  }
  return formatAsMarkdown(review);
}

// src/utils/treeGenerator.ts
init_logger();
function createNode(name, isFile2 = false, filePath) {
  return {
    name,
    children: /* @__PURE__ */ new Map(),
    isFile: isFile2,
    path: filePath
  };
}
function buildTree(filePaths) {
  const root = createNode("root");
  for (const filePath of filePaths) {
    const parts = filePath.split(/[\\/]/);
    let currentNode = root;
    for (let i = 0; i < parts.length; i++) {
      const part = parts[i];
      if (!part) continue;
      const isFile2 = i === parts.length - 1;
      if (!currentNode.children.has(part)) {
        currentNode.children.set(part, createNode(part, isFile2, isFile2 ? filePath : void 0));
      } else if (isFile2) {
        const existingNode = currentNode.children.get(part);
        if (!existingNode.isFile) {
          currentNode.children.set(`${part} (file)`, createNode(part, true, filePath));
          continue;
        }
      }
      currentNode = currentNode.children.get(part);
    }
  }
  return root;
}
function generateMarkdownTree(node, indent = "", isLast = true, prefix = "") {
  if (node.name === "root") {
    let result2 = "";
    const children2 = Array.from(node.children.entries());
    for (let i = 0; i < children2.length; i++) {
      const [, childNode] = children2[i];
      const isLastChild = i === children2.length - 1;
      result2 += generateMarkdownTree(childNode, "", isLastChild, "");
    }
    return result2;
  }
  const nodeIndicator = isLast ? "\u2514\u2500\u2500 " : "\u251C\u2500\u2500 ";
  let result = `${indent}${prefix}${nodeIndicator}${node.name}
`;
  const childPrefix = isLast ? "    " : "\u2502   ";
  const children = Array.from(node.children.entries()).sort(([nameA], [nameB]) => {
    const nodeA = node.children.get(nameA);
    const nodeB = node.children.get(nameB);
    if (nodeA.isFile && !nodeB.isFile) return 1;
    if (!nodeA.isFile && nodeB.isFile) return -1;
    return nameA.localeCompare(nameB);
  });
  for (let i = 0; i < children.length; i++) {
    const [, childNode] = children[i];
    const isLastChild = i === children.length - 1;
    result += generateMarkdownTree(childNode, `${indent}${prefix}${childPrefix}`, isLastChild, "");
  }
  return result;
}
function generateFileTree(filePaths) {
  try {
    const sortedPaths = [...filePaths].sort();
    const root = buildTree(sortedPaths);
    return "```\n" + generateMarkdownTree(root) + "```";
  } catch (error2) {
    logger_default.error(`Error generating file tree: ${error2}`);
    return filePaths.map((file) => `- \`${file}\``).join("\n");
  }
}

// src/utils/removalScriptGenerator.ts
var import_promises11 = __toESM(require("fs/promises"));
var import_path22 = __toESM(require("path"));
init_logger();
async function saveRemovalScript(reviewResult, outputDir) {
  try {
    if (!reviewResult.metadata?.removalScript) {
      logger_default.debug("No removal script found in review result");
      return null;
    }
    await import_promises11.default.mkdir(outputDir, { recursive: true });
    const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/:/g, "-").replace(/\./g, "-");
    const filename = `unused-code-removal-script-${timestamp}.sh`;
    const scriptPath = import_path22.default.join(outputDir, filename);
    await import_promises11.default.writeFile(scriptPath, reviewResult.metadata.removalScript, {
      mode: 493
    });
    logger_default.info(`Generated removal script: ${scriptPath}`);
    return scriptPath;
  } catch (error2) {
    logger_default.error("Error generating removal script:", error2);
    return null;
  }
}
function printRemovalScriptInstructions(scriptPath) {
  if (!scriptPath) {
    return;
  }
  console.log(
    "\n----------------------------------------------------------------------"
  );
  console.log("UNUSED CODE REMOVAL SCRIPT GENERATED");
  console.log(
    "----------------------------------------------------------------------"
  );
  console.log(
    "A script has been generated to help you remove unused files and functions:"
  );
  console.log(`  ${scriptPath}`);
  console.log("\nBefore running this script:");
  console.log(
    "1. REVIEW the script carefully to ensure it only removes code you want to remove"
  );
  console.log(
    "2. MAKE A BACKUP of your codebase or commit your current changes"
  );
  console.log(
    "3. Run in a clean git working directory to easily see the changes"
  );
  console.log("\nTo run the script:");
  console.log(`  chmod +x ${scriptPath}`);
  console.log(`  ${scriptPath}`);
  console.log("\nAfter running:");
  console.log("  git diff               # To see what was removed");
  console.log("  git checkout -- <file> # To restore any files if needed");
  console.log(
    "----------------------------------------------------------------------\n"
  );
}

// src/core/OutputManager.ts
init_fileSystem();

// src/utils/errorLogger.ts
var import_promises12 = __toESM(require("fs/promises"));
var import_path23 = __toESM(require("path"));
init_fileSystem();
init_logger();
async function logError(error2, context = {}) {
  try {
    const errorLogsDir = import_path23.default.resolve("error-logs");
    await createDirectory(errorLogsDir);
    const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/:/g, "-");
    const errorLogPath = import_path23.default.join(errorLogsDir, `error-${timestamp}.json`);
    const errorObj = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      message: error2 instanceof Error ? error2.message : "Unknown error",
      stack: error2 instanceof Error ? error2.stack : void 0,
      context
    };
    await import_promises12.default.writeFile(errorLogPath, JSON.stringify(errorObj, null, 2));
    logger_default.error(`Error logged to: ${errorLogPath}`);
    return errorLogPath;
  } catch (logError2) {
    logger_default.error("Failed to log error:", logError2);
    return "";
  }
}

// src/utils/dependencies/aiDependencyAnalyzer.ts
var import_path24 = __toESM(require("path"));
var import_promises13 = __toESM(require("fs/promises"));
var import_child_process3 = require("child_process");
var import_util2 = require("util");
init_logger();
init_clientFactory();
var execAsync2 = (0, import_util2.promisify)(import_child_process3.exec);
async function createAIDependencyAnalysis(projectPath) {
  logger_default.info("=========== STARTING AI-POWERED DEPENDENCY ANALYSIS ===========");
  logger_default.info(`Project path: ${projectPath}`);
  try {
    const projectSample = await getProjectFileSample(projectPath);
    if (projectSample.packageFiles.length === 0 && projectSample.sourceFiles.length === 0) {
      logger_default.warn("No suitable files found for AI dependency analysis");
      return "## Dependency Analysis\n\nNo suitable files were found for dependency analysis.";
    }
    logger_default.info(`Collected ${projectSample.packageFiles.length} package files and ${projectSample.sourceFiles.length} source files for analysis`);
    const analysisResult = await analyzeWithAI(projectSample);
    return formatDependencyAnalysis(analysisResult);
  } catch (error2) {
    logger_default.error(`Error in AI dependency analysis: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return "## Dependency Analysis\n\n\u26A0\uFE0F Unable to perform AI-powered dependency analysis due to an error.\n\nThe rest of the review is still valid.";
  }
}
async function analyzeWithAI(projectSample) {
  try {
    const client = ClientFactory.createClient();
    await client.initialize();
    const prompt = createDependencyAnalysisPrompt(projectSample);
    const analysisResponse = await client.generateReview(
      prompt,
      "dependency-analysis.md",
      "architectural",
      {
        readme: "",
        custom: {
          "DEPENDENCY_ANALYSIS_INSTRUCTIONS.md": getDependencyAnalysisInstructions()
        }
      },
      {
        type: "architectural",
        includeTests: false,
        output: "markdown",
        // @ts-expect-error - temporary property for AI dependency analysis
        isAIDependencyAnalysis: true
      }
    );
    return parseDependencyAnalysisResponse(analysisResponse.content);
  } catch (error2) {
    logger_default.error(`Error generating AI dependency analysis: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
function createDependencyAnalysisPrompt(projectSample) {
  const packageFilesSection = projectSample.packageFiles.map((pkg) => {
    return `## ${pkg.path}
\`\`\`json
"dependencies": ${JSON.stringify(pkg.dependencies || {}, null, 2)},
"devDependencies": ${JSON.stringify(pkg.devDependencies || {}, null, 2)}
\`\`\`
`;
  }).join("\n\n");
  const sourceFilesSection = projectSample.sourceFiles.map((file) => {
    return `## ${file.path} (${file.type})
${file.imports && file.imports.length > 0 ? `**Imports:**
${file.imports.map((imp) => `- ${imp}`).join("\n")}` : "No imports found."}

${file.exports && file.exports.length > 0 ? `**Exports:**
${file.exports.map((exp) => `- ${exp}`).join("\n")}` : "No exports found."}
`;
  }).join("\n\n");
  return `# Project Dependency Analysis Request

## Project Overview
Total Files: ${projectSample.totalFileCount}
Sample Files Analyzed: ${projectSample.packageFiles.length + projectSample.sourceFiles.length}

## Directory Structure
\`\`\`
${projectSample.directoryStructure}
\`\`\`

## Package Files
${packageFilesSection}

## Source File Sample
${sourceFilesSection}

Please analyze the project dependencies and structure based on the provided information.`;
}
function getDependencyAnalysisInstructions() {
  return `# Dependency Analysis Instructions

You are tasked with analyzing the project dependencies and structure based on the provided sample of files. 
Focus on identifying potential dependency issues, architectural patterns, and providing recommendations.

## Analysis Requirements

1. **Package Dependencies**:
   - Analyze all package.json files
   - Identify key dependencies and their purposes
   - Detect potential outdated or problematic dependencies
   - Note any unusual dependency patterns

2. **Code Structure**:
   - Analyze import/export patterns in the sample files
   - Identify potential circular dependencies
   - Note any heavily imported modules (potential core components)
   - Analyze coupling between components

3. **Architectural Issues**:
   - Identify potential architectural anti-patterns
   - Note any separation of concerns issues
   - Detect potential dependency management issues
   - Analyze project structure for architectural consistency

4. **Recommendations**:
   - Suggest improvements to dependency management
   - Recommend architectural improvements based on modern practices
   - Provide specific, actionable advice for dependency-related issues

## Response Format

Organize your analysis into the following sections:

1. **Dependency Summary**: Overview of the project's dependencies and overall structure.
2. **Architectural Issues**: Potential problems in the dependency architecture.
3. **Package Analysis**: Detailed analysis of package.json dependencies.
4. **Code Structure Analysis**: Analysis of import/export patterns and module relationships.
5. **Recommendations**: Specific suggestions for improving dependency management and architecture.

Be thorough but concise. Focus on providing actionable insights rather than just descriptions.`;
}
function parseDependencyAnalysisResponse(responseContent) {
  const extractSection2 = (title) => {
    const regex = new RegExp(`## ${title}\\s*([\\s\\S]*?)(?=## |$)`, "i");
    const match = responseContent.match(regex);
    return match ? match[1].trim() : "";
  };
  return {
    dependencySummary: extractSection2("Dependency Summary"),
    architecturalIssues: extractSection2("Architectural Issues"),
    packageAnalysis: extractSection2("Package Analysis"),
    codeStructureAnalysis: extractSection2("Code Structure Analysis"),
    recommendations: extractSection2("Recommendations"),
    rawResponse: responseContent
  };
}
function formatDependencyAnalysis(analysis) {
  return `## AI-Powered Dependency Analysis

${analysis.dependencySummary}

### Architectural Issues

${analysis.architecturalIssues}

### Package Analysis

${analysis.packageAnalysis}

### Code Structure Analysis

${analysis.codeStructureAnalysis}

### Recommendations

${analysis.recommendations}

---

*Note: This dependency analysis was performed by AI based on a representative sample of the codebase, without requiring additional dependencies.*`;
}
async function getProjectFileSample(projectPath) {
  logger_default.info(`Collecting project file sample from ${projectPath}`);
  const result = {
    packageFiles: [],
    sourceFiles: [],
    totalFileCount: 0,
    directoryStructure: ""
  };
  try {
    try {
      const { stdout: dirOutput } = await execAsync2(`ls -la ${projectPath}`);
      result.directoryStructure = dirOutput;
    } catch (error2) {
      logger_default.warn(`Error getting directory structure: ${error2 instanceof Error ? error2.message : String(error2)}`);
      result.directoryStructure = "Unable to retrieve directory structure";
    }
    let packageFilePaths = [];
    try {
      const { stdout: packageFilesOutput } = await execAsync2(`find ${projectPath} -name "package.json" -not -path "*/node_modules/*" -not -path "*/\\.*/*" | head -5`);
      packageFilePaths = packageFilesOutput.trim().split("\n").filter(Boolean);
    } catch (error2) {
      logger_default.warn(`Error finding package.json files: ${error2 instanceof Error ? error2.message : String(error2)}`);
    }
    for (const filePath of packageFilePaths) {
      try {
        const content = await import_promises13.default.readFile(filePath, "utf-8");
        const packageJson = JSON.parse(content);
        result.packageFiles.push({
          path: import_path24.default.relative(projectPath, filePath),
          type: "package.json",
          dependencies: packageJson.dependencies || {},
          devDependencies: packageJson.devDependencies || {}
        });
      } catch (error2) {
        logger_default.warn(`Error processing package.json file ${filePath}: ${error2 instanceof Error ? error2.message : String(error2)}`);
      }
    }
    try {
      const { stdout: totalFilesOutput } = await execAsync2(`find ${projectPath} -type f -not -path "*/node_modules/*" -not -path "*/\\.*/*" | wc -l`);
      result.totalFileCount = parseInt(totalFilesOutput.trim(), 10);
    } catch (error2) {
      logger_default.warn(`Error counting files: ${error2 instanceof Error ? error2.message : String(error2)}`);
      result.totalFileCount = 0;
    }
    let sourceFilePaths = [];
    try {
      const { stdout: sourceFilesOutput } = await execAsync2(`find ${projectPath} -type f \\( -name "*.js" -o -name "*.jsx" -o -name "*.ts" -o -name "*.tsx" \\) -not -path "*/node_modules/*" -not -path "*/\\.*/*" | sort -R | head -20`);
      sourceFilePaths = sourceFilesOutput.trim().split("\n").filter(Boolean);
    } catch (error2) {
      logger_default.warn(`Error finding source files: ${error2 instanceof Error ? error2.message : String(error2)}`);
    }
    for (const filePath of sourceFilePaths) {
      try {
        const content = await import_promises13.default.readFile(filePath, "utf-8");
        const fileType = import_path24.default.extname(filePath).slice(1);
        const importRegex = /import\s+(?:(?:{[^}]*})|(?:[^{}]*?))\s+from\s+['"]([^'"]+)['"]/g;
        const imports = [];
        let match;
        while ((match = importRegex.exec(content)) !== null) {
          imports.push(match[1]);
        }
        const exportRegex = /export\s+(?:(?:default\s+)?(?:class|function|const|let|var|interface|type|enum)\s+(\w+))/g;
        const exports2 = [];
        let exportMatch;
        while ((exportMatch = exportRegex.exec(content)) !== null) {
          if (exportMatch[1]) {
            exports2.push(exportMatch[1]);
          }
        }
        result.sourceFiles.push({
          path: import_path24.default.relative(projectPath, filePath),
          type: fileType,
          imports,
          exports: exports2
        });
      } catch (error2) {
        logger_default.warn(`Error processing source file ${filePath}: ${error2 instanceof Error ? error2.message : String(error2)}`);
      }
    }
    logger_default.info(`Collected ${result.packageFiles.length} package files and ${result.sourceFiles.length} source files`);
    return result;
  } catch (error2) {
    logger_default.error(`Error getting project file sample: ${error2 instanceof Error ? error2.message : String(error2)}`);
    return result;
  }
}

// src/core/OutputManager.ts
init_logger();
function addFileTreeToReview(formattedOutput, files, outputFormat) {
  if (!files || files.length === 0) {
    logger_default.debug("No files provided for tree generation");
    return formattedOutput;
  }
  logger_default.debug(`Adding file tree for ${files.length} files in ${outputFormat} format`);
  const relativePaths = files.map((file) => file.relativePath || file.path);
  const fileTree = generateFileTree(relativePaths);
  if (outputFormat === "json") {
    try {
      const reviewObj = JSON.parse(formattedOutput);
      reviewObj.analyzedFiles = relativePaths;
      reviewObj.fileTree = fileTree.replace(/```/g, "").trim();
      return JSON.stringify(reviewObj, null, 2);
    } catch (error2) {
      logger_default.warn(`Error enhancing JSON review with file tree: ${error2}`);
      return formattedOutput;
    }
  } else {
    const fileListSection = `
## Files Analyzed

The following ${files.length} files were included in this review:

${fileTree}

`;
    const costSectionMatch = formattedOutput.match(/^## Cost Information/m);
    if (costSectionMatch && costSectionMatch.index) {
      const position = costSectionMatch.index;
      logger_default.debug("Inserting file list before Cost Information section");
      return formattedOutput.substring(0, position) + fileListSection + formattedOutput.substring(position);
    } else {
      const closingMatch = formattedOutput.match(/---\n\*Generated by Code Review Tool/);
      if (closingMatch && closingMatch.index) {
        const position = closingMatch.index;
        logger_default.debug("Inserting file list before closing section");
        return formattedOutput.substring(0, position) + fileListSection + formattedOutput.substring(position);
      } else {
        logger_default.debug("No insertion point found, appending file list to end");
        return formattedOutput + fileListSection;
      }
    }
  }
}
async function saveReviewOutput(review, options, outputBaseDir, modelName, targetName, files) {
  try {
    const extension = options.output === "json" ? ".json" : ".md";
    let outputPath = await generateVersionedOutputPath(
      outputBaseDir,
      options.type + "-review",
      extension,
      modelName,
      targetName
    );
    const rawDataPath = await generateUniqueOutputPath(
      outputBaseDir,
      `${options.type}-review-raw-data-${import_path25.default.basename(outputPath, extension)}.json`
    );
    if (review.cost && !review.costInfo) {
      review.costInfo = review.cost;
    }
    logger_default.debug(`Formatting review output as ${options.output}`);
    let formattedOutput = formatReviewOutput(review, options.output || "markdown");
    if (files && files.length > 0) {
      logger_default.info(`Adding file tree visualization for ${files.length} files`);
      formattedOutput = addFileTreeToReview(formattedOutput, files, options.output || "markdown");
    }
    const reviewTypeNeedsDependencyAnalysis = ["architectural", "security"].includes(options.type);
    if (reviewTypeNeedsDependencyAnalysis && options.includeDependencyAnalysis !== false) {
      console.log(`=========== DEPENDENCY ANALYSIS FOR ${options.type.toUpperCase()} REVIEW ===========`);
      logger_default.info(`=========== DEPENDENCY ANALYSIS FOR ${options.type.toUpperCase()} REVIEW ===========`);
      try {
        logger_default.info(`Performing AI-powered dependency analysis for ${options.type} review...`);
        const projectPath = files && files.length > 0 ? import_path25.default.dirname(files[0].path) : import_path25.default.resolve(process.cwd());
        console.log(`Project path for dependency analysis: ${projectPath}`);
        logger_default.info(`Project path for dependency analysis: ${projectPath}`);
        const dependencySection = await createAIDependencyAnalysis(projectPath);
        if (options.output === "json") {
          try {
            const reviewObj = JSON.parse(formattedOutput);
            reviewObj.dependencyAnalysis = dependencySection;
            formattedOutput = JSON.stringify(reviewObj, null, 2);
            logger_default.info("AI-powered dependency analysis added to JSON review output");
          } catch (error2) {
            logger_default.warn(`Error adding dependency analysis section to JSON review: ${error2}`);
            formattedOutput += `

${dependencySection}`;
            logger_default.info("AI-powered dependency analysis appended as text to JSON review (JSON parsing failed)");
          }
        } else {
          formattedOutput += `

${dependencySection}`;
          logger_default.info("AI-powered dependency analysis added to markdown review output");
        }
      } catch (error2) {
        logger_default.error(`Error performing AI-powered dependency analysis for ${options.type} review: ${error2 instanceof Error ? error2.message : String(error2)}`);
        logger_default.error(error2 instanceof Error && error2.stack ? error2.stack : "No stack trace available");
      }
    }
    try {
      await import_promises14.default.access(outputPath);
      logger_default.warn(`Output file already exists: ${outputPath}`);
      const uniqueOutputPath = await generateUniqueOutputPath(
        outputBaseDir,
        `${options.type}-review-${Date.now()}${extension}`
      );
      logger_default.info(`Using alternative output path to avoid overwriting: ${uniqueOutputPath}`);
      const originalPath = outputPath;
      outputPath = uniqueOutputPath;
      logger_default.debug(`Changed output path from ${originalPath} to ${outputPath} to avoid collision`);
    } catch (error2) {
      logger_default.debug(`Output file doesn't exist yet, proceeding with: ${outputPath}`);
    }
    logger_default.debug(`Writing formatted review output to: ${outputPath}`);
    await import_promises14.default.writeFile(outputPath, formattedOutput);
    logger_default.info(`Review output saved to: ${outputPath}`);
    if (options.debug) {
      logger_default.debug(`Saving raw review data for debugging to: ${rawDataPath}`);
      await import_promises14.default.writeFile(rawDataPath, JSON.stringify(review, null, 2));
      logger_default.debug(`Raw review data saved to: ${rawDataPath}`);
    }
    if (options.type === "unused-code" && review.metadata?.removalScript) {
      const scriptPath = await saveRemovalScript(review, outputBaseDir);
      printRemovalScriptInstructions(scriptPath);
    }
    return outputPath;
  } catch (error2) {
    if (error2 instanceof Error) {
      const errorLogPath = await logError(error2, {
        operation: "writeFile",
        outputPath: "unknown",
        reviewType: options.type
      });
      logger_default.error(`Error saving review output:`);
      logger_default.error(`  Message: ${error2.message}`);
      logger_default.error(`  Error details logged to: ${errorLogPath}`);
      if (error2.stack) {
        logger_default.debug(`Error stack trace: ${error2.stack}`);
      }
      if (error2.name === "EACCES") {
        logger_default.error(`  This appears to be a permission error. Please check that you have write access to the output directory.`);
      } else if (error2.name === "ENOSPC") {
        logger_default.error(`  This appears to be a disk space error. Please free up some disk space and try again.`);
      }
    } else {
      logger_default.error(`Unknown error saving review output: ${String(error2)}`);
    }
    throw error2;
  }
}

// src/core/InteractiveDisplayManager.ts
var import_promises15 = __toESM(require("fs/promises"));
init_logger();
async function displayReviewInteractively(reviewPath, projectPath, options) {
  try {
    logger_default.info("\nDisplaying review results in interactive mode...");
    const reviewContent = await import_promises15.default.readFile(reviewPath, "utf-8");
    const priorityFilter = getPriorityFilterFromOptions(options);
    const results = await displayReviewResults(
      reviewContent,
      projectPath,
      priorityFilter
    );
    logger_default.info("\n--- Review Summary ---");
    logger_default.info(`Total issues found: ${results.totalSuggestions}`);
    logger_default.info(
      `High priority issues: ${results.highPrioritySuggestions.length}`
    );
    logger_default.info(
      `Medium priority issues: ${results.mediumPrioritySuggestions.length}`
    );
    logger_default.info(
      `Low priority issues: ${results.lowPrioritySuggestions.length}`
    );
    logger_default.info("----------------------");
  } catch (error2) {
    logger_default.error(
      `Error displaying review results: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    throw error2;
  }
}
function getPriorityFilterFromOptions(options) {
  if (options && typeof options.interactive === "string" && ["h", "m", "l", "a"].includes(options.interactive)) {
    return options.interactive;
  }
  const args = process.argv;
  const interactiveIndex = args.findIndex(
    (arg) => arg === "--interactive" || arg === "-i"
  );
  if (interactiveIndex !== -1 && interactiveIndex < args.length - 1) {
    const nextArg = args[interactiveIndex + 1];
    if (["h", "m", "l", "a"].includes(nextArg) && !nextArg.startsWith("-")) {
      return nextArg;
    }
  }
  return void 0;
}

// src/core/handlers/OutputHandler.ts
async function handleReviewOutput(reviewResult, options, outputBaseDir) {
  if (options.output !== "none") {
    try {
      const targetName = path32.basename(options.target || ".");
      const modelName = options.model || "unknown-model";
      const outputPath = await saveReviewOutput(
        reviewResult,
        options,
        outputBaseDir,
        modelName,
        targetName
      );
      logger_default.info(`Review saved to: ${outputPath}`);
      if (options.interactive) {
        try {
          await displayReviewInteractively(outputPath, process.cwd(), options);
        } catch (error2) {
          logger_default.error(`Failed to display review interactively: ${error2 instanceof Error ? error2.message : String(error2)}`);
        }
      }
    } catch (error2) {
      logger_default.error(`Failed to save review output: ${error2 instanceof Error ? error2.message : String(error2)}`);
    }
  }
  logger_default.info("Review completed successfully");
  if (reviewResult.cost) {
    const costDisplay = typeof reviewResult.cost === "object" && reviewResult.cost.formattedCost ? reviewResult.cost.formattedCost : reviewResult.cost;
    logger_default.info(`Estimated cost: ${costDisplay}`);
  }
  if (reviewResult.tokenUsage) {
    const { input, output, total } = reviewResult.tokenUsage;
    logger_default.info(`Token usage: ${input} input + ${output} output = ${total} total`);
  }
}
function createOutputDirectory(projectPath, options) {
  const defaultOutputDir = "ai-code-review-docs";
  const configOutputDir = options.configOutputDir || defaultOutputDir;
  const outputDir = options.outputDir || configOutputDir;
  if (outputDir.includes("..")) {
    throw new Error('Output directory path cannot contain ".." for security reasons');
  }
  let outputBaseDir;
  if (path32.isAbsolute(outputDir)) {
    outputBaseDir = outputDir;
  } else {
    outputBaseDir = path32.resolve(projectPath, outputDir);
  }
  if (options.outputDir) {
    logger_default.info(`Using custom output directory: ${outputBaseDir}`);
  }
  return outputBaseDir;
}

// src/core/ApiClientSelector.ts
init_logger();
async function selectApiClient(cliOptions) {
  logger_default.debug("selectApiClient called");
  const apiKeyType = getApiKeyType();
  logger_default.debug(`selectApiClient: apiKeyType=${apiKeyType}`);
  const modelEnv = cliOptions?.model || process.env.AI_CODE_REVIEW_MODEL || "";
  logger_default.debug(`selectApiClient: modelEnv=${modelEnv}`);
  let envProvider;
  let envModelName;
  if (modelEnv.includes(":")) {
    [envProvider, envModelName] = modelEnv.split(":", 2);
  } else {
    envProvider = "gemini";
    envModelName = modelEnv;
  }
  logger_default.debug(`selectApiClient: envProvider=${envProvider}, envModelName=${envModelName}`);
  const config4 = {
    clientType: "None",
    modelName: "",
    initialized: false,
    provider: "none",
    apiKey: ""
  };
  logger_default.debug(`selectApiClient: initial config=${JSON.stringify(config4)}`);
  if (apiKeyType === "OpenRouter") {
    logger_default.debug("selectApiClient: Using OpenRouter client");
    if (!envModelName) {
      logger_default.error("No OpenRouter model specified in environment variables.");
      logger_default.error("Please set AI_CODE_REVIEW_MODEL in your .env.local file.");
      logger_default.error(
        "Example: AI_CODE_REVIEW_MODEL=openrouter:anthropic/claude-3-opus"
      );
      process.exit(1);
    }
    const openrouterModel = envProvider === "openrouter" ? envModelName : `${envProvider}/${envModelName}`;
    logger_default.info(`Using OpenRouter model: ${openrouterModel}`);
    await initializeAnyOpenRouterModel2();
    config4.clientType = "OpenRouter";
    config4.modelName = openrouterModel;
    config4.provider = "openrouter";
    config4.apiKey = process.env.AI_CODE_REVIEW_OPENROUTER_API_KEY || "";
    config4.initialized = true;
  } else if (apiKeyType === "Google") {
    if (!envModelName) {
      logger_default.error("No Gemini model specified in environment variables.");
      logger_default.error("Please set AI_CODE_REVIEW_MODEL in your .env.local file.");
      logger_default.error("Example: AI_CODE_REVIEW_MODEL=gemini:gemini-1.5-pro");
      process.exit(1);
    }
    if (!process.env.AI_CODE_REVIEW_GOOGLE_API_KEY) {
      logger_default.error("No Google API key found.");
      logger_default.error(
        "Please set AI_CODE_REVIEW_GOOGLE_API_KEY in your .env.local file."
      );
      process.exit(1);
    }
    logger_default.info(`Using Gemini API with model: ${envModelName}`);
    config4.clientType = "Google";
    config4.modelName = `gemini:${envModelName}`;
    config4.provider = "gemini";
    config4.apiKey = process.env.AI_CODE_REVIEW_GOOGLE_API_KEY || "";
    config4.initialized = true;
  } else if (apiKeyType === "Anthropic") {
    if (!envModelName) {
      logger_default.error("No Anthropic model specified in environment variables.");
      logger_default.error("Please set AI_CODE_REVIEW_MODEL in your .env.local file.");
      logger_default.error("Example: AI_CODE_REVIEW_MODEL=anthropic:claude-3-opus");
      process.exit(1);
    }
    if (!process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY) {
      logger_default.error("No Anthropic API key found.");
      logger_default.error(
        "Please set AI_CODE_REVIEW_ANTHROPIC_API_KEY in your .env.local file."
      );
      process.exit(1);
    }
    logger_default.info(`Using Anthropic API with model: ${envModelName}`);
    config4.clientType = "Anthropic";
    config4.modelName = `anthropic:${envModelName}`;
    config4.provider = "anthropic";
    config4.apiKey = process.env.AI_CODE_REVIEW_ANTHROPIC_API_KEY || "";
    config4.initialized = true;
  } else if (apiKeyType === "OpenAI") {
    if (!envModelName) {
      logger_default.error("No OpenAI model specified in environment variables.");
      logger_default.error("Please set AI_CODE_REVIEW_MODEL in your .env.local file.");
      logger_default.error("Example: AI_CODE_REVIEW_MODEL=openai:gpt-4o");
      process.exit(1);
    }
    logger_default.info(`Using OpenAI API with model: ${envModelName}`);
    config4.clientType = "OpenAI";
    config4.modelName = `openai:${envModelName}`;
    config4.provider = "openai";
    config4.apiKey = process.env.AI_CODE_REVIEW_OPENAI_API_KEY || "";
    config4.initialized = true;
  } else {
    logger_default.warn("No API keys available. Using mock responses.");
    config4.clientType = "None";
    config4.modelName = "";
    config4.provider = "none";
    config4.apiKey = "";
    config4.initialized = false;
  }
  return config4;
}

// src/core/reviewOrchestrator.ts
init_projectDocs();
async function orchestrateReview(target, options) {
  getConfig();
  try {
    if (options === void 0) {
      throw new Error("Review options object must be provided");
    }
    if (!options.type) {
      throw new Error("Review type must be specified in options");
    }
    const effectiveTarget = target || ".";
    if (!target || target.trim() === "") {
      logger_default.info('No target path provided, defaulting to current directory (".")');
    }
    if (options.debug) {
      logger_default.debug(`Review options: ${JSON.stringify(options, null, 2)}`);
      logger_default.debug(`Target path: ${effectiveTarget}${!target || target.trim() === "" ? ' (defaulted to ".")' : ""}`);
      logger_default.debug(
        `Selected model: ${process.env.AI_CODE_REVIEW_MODEL || "not set"}`
      );
      logger_default.debug(`API key type: ${getApiKeyType() || "None"}`);
    }
    if (options.listmodels) {
      logger_default.info("Listing available models based on configured API keys...");
      listModels(false);
      return;
    }
    if (options.models) {
      logger_default.info(
        "Listing all supported models and their configuration names..."
      );
      listModelConfigs();
      return;
    }
    if (options.testApi) {
      logger_default.info("Testing API connections before starting review...");
      await runApiConnectionTests();
      logger_default.info("API connection tests completed. Proceeding with review...");
    }
    if (options.type === "architectural") {
      logger_default.info(`Starting architectural review for ${effectiveTarget}...`);
    } else {
      logger_default.info(
        `Starting consolidated ${options.type} review for ${effectiveTarget}...`
      );
    }
    const projectPath = process.cwd();
    const projectName = path35.basename(projectPath);
    const configOutputDir = configManager_default.getPathsConfig().outputDir;
    const outputBaseDir = createOutputDirectory(projectPath, {
      outputDir: options.outputDir,
      configOutputDir
    });
    await createDirectory(outputBaseDir);
    logger_default.info(`Project: ${projectName}`);
    logger_default.info(`Project path: ${projectPath}`);
    let frameworkDetectionResult = null;
    if (!options.language) {
      try {
        const { detectFramework: detectFramework2 } = await Promise.resolve().then(() => (init_detection(), detection_exports));
        frameworkDetectionResult = await detectFramework2(projectPath);
        if (frameworkDetectionResult) {
          options.language = frameworkDetectionResult.language;
          options.framework = frameworkDetectionResult.framework;
          if (frameworkDetectionResult.framework !== "none" && frameworkDetectionResult.confidence > 0.6) {
            logger_default.info(`Detected language: ${frameworkDetectionResult.language}, framework: ${frameworkDetectionResult.framework} (confidence: ${frameworkDetectionResult.confidence.toFixed(2)})`);
            if (frameworkDetectionResult.frameworkVersion) {
              logger_default.info(`Framework version: ${frameworkDetectionResult.frameworkVersion}`);
            }
            if (frameworkDetectionResult.additionalFrameworks && frameworkDetectionResult.additionalFrameworks.length > 0) {
              logger_default.info(`Additional frameworks detected: ${frameworkDetectionResult.additionalFrameworks.join(", ")}`);
            }
            if (frameworkDetectionResult.cssFrameworks && frameworkDetectionResult.cssFrameworks.length > 0) {
              const cssFrameworksStr = frameworkDetectionResult.cssFrameworks.map(
                (cf) => cf.version ? `${cf.name} (${cf.version})` : cf.name
              ).join(", ");
              logger_default.info(`CSS frameworks detected: ${cssFrameworksStr}`);
            }
          } else {
            logger_default.info(`Detected language: ${frameworkDetectionResult.language}, no specific framework detected`);
            if (frameworkDetectionResult.cssFrameworks && frameworkDetectionResult.cssFrameworks.length > 0) {
              const cssFrameworksStr = frameworkDetectionResult.cssFrameworks.map(
                (cf) => cf.version ? `${cf.name} (${cf.version})` : cf.name
              ).join(", ");
              logger_default.info(`CSS frameworks detected: ${cssFrameworksStr}`);
            }
          }
        }
      } catch (error2) {
        logger_default.debug(`Error detecting language/framework: ${error2 instanceof Error ? error2.message : String(error2)}`);
      }
    }
    const filesToReview = await discoverFilesForReview(
      effectiveTarget,
      projectPath,
      options
    );
    if (filesToReview.length === 0) {
      return;
    }
    if (options.estimate) {
      const modelName = options.model || process.env.AI_CODE_REVIEW_MODEL || "gemini:gemini-1.5-pro";
      try {
        const { fileInfos: fileInfos2, errors } = await readFilesForReview(filesToReview, projectPath);
        if (errors.length > 0) {
          console.warn(`Warning: Failed to read ${errors.length} file(s):`);
          for (const error2 of errors) {
            console.warn(`  - ${error2.path}: ${error2.error}`);
          }
        }
        if (fileInfos2.length === 0) {
          throw new Error("No files could be read for review. Please check file permissions and paths.");
        }
        await performEstimation(fileInfos2, filesToReview, options, modelName);
      } catch (error2) {
        logger_default.error(`Estimation failed: ${error2 instanceof Error ? error2.message : String(error2)}`);
      }
      return;
    }
    const { fileInfos } = await readFilesForReview(filesToReview, projectPath);
    let projectDocs = null;
    if (options.includeProjectDocs) {
      logger_default.info("Reading project documentation...");
      projectDocs = await readProjectDocs(projectPath);
    }
    const apiClientConfig = await selectApiClient(options);
    const config4 = getConfig(options);
    logger_default.debug(`Config writerModel: ${config4.writerModel}`);
    if (config4.writerModel) {
      logger_default.info(`Using writer model for consolidation: ${config4.writerModel}`);
    }
    let tokenAnalysis = null;
    if (!options.multiPass) {
      try {
        logger_default.info("Analyzing token usage to determine review strategy...");
        const { TokenAnalyzer: TokenAnalyzer2 } = await Promise.resolve().then(() => (init_tokens(), tokens_exports));
        const tokenAnalysisOptions = {
          reviewType: options.type,
          modelName: apiClientConfig.modelName,
          contextMaintenanceFactor: options.contextMaintenanceFactor || 0.15,
          forceSinglePass: options.forceSinglePass
        };
        if (options.forceSinglePass) {
          logger_default.info("Force single-pass mode is enabled. This will override the chunking recommendation.");
          logger_default.info("Note: This may result in token limit errors if the content exceeds the model's context window.");
          if (apiClientConfig.modelName.includes("gemini-1.5")) {
            logger_default.info("Using Gemini 1.5 model with 1M token context window in single-pass mode.");
          }
        }
        tokenAnalysis = TokenAnalyzer2.analyzeFiles(fileInfos, tokenAnalysisOptions);
        await performSemanticAnalysis(fileInfos, options);
      } catch (error2) {
        logger_default.warn(`Token analysis failed: ${error2 instanceof Error ? error2.message : "Unknown error"}`);
        logger_default.info("Proceeding with review without token analysis");
      }
    }
    const reviewResult = await executeReview(
      fileInfos,
      options,
      apiClientConfig,
      projectDocs,
      tokenAnalysis
    );
    await handleReviewOutput(reviewResult, options, outputBaseDir);
  } catch (error2) {
    logger_default.error(`Review failed: ${error2 instanceof Error ? error2.message : String(error2)}`);
    if (error2 instanceof Error && error2.stack && options.debug) {
      logger_default.debug(`Error stack trace: ${error2.stack}`);
    }
    throw error2;
  }
}

// src/commands/reviewCode.ts
async function reviewCode(target, options) {
  try {
    if (options["prompt-file"]) {
      options.promptFile = options["prompt-file"];
      delete options["prompt-file"];
    }
    if (options["prompt-fragment"]) {
      const fragment = options["prompt-fragment"];
      const position = options["prompt-fragment-position"] || "middle";
      options.promptFragments = [
        {
          content: fragment,
          position
        }
      ];
      delete options["prompt-fragment"];
      delete options["prompt-fragment-position"];
    }
    if (options["prompt-strategy"]) {
      options.promptStrategy = options["prompt-strategy"];
      delete options["prompt-strategy"];
    }
    if (options["use-cache"] !== void 0) {
      options.useCache = options["use-cache"];
      delete options["use-cache"];
    }
    if (options["include-dependency-analysis"] !== void 0) {
      options.includeDependencyAnalysis = options["include-dependency-analysis"];
      delete options["include-dependency-analysis"];
    }
    if (options["confirm"] !== void 0) {
      options.noConfirm = !options["confirm"];
      delete options["confirm"];
    }
    if (options["auto-fix"] !== void 0) {
      options.autoFix = options["auto-fix"];
      delete options["auto-fix"];
    }
    if (options["include-tests"] !== void 0) {
      options.includeTests = options["include-tests"];
      delete options["include-tests"];
    }
    if (options["include-project-docs"] !== void 0) {
      options.includeProjectDocs = options["include-project-docs"];
      delete options["include-project-docs"];
    }
    if (options["use-ts-prune"] !== void 0) {
      options.useTsPrune = options["use-ts-prune"];
      delete options["use-ts-prune"];
    }
    if (options["use-eslint"] !== void 0) {
      options.useEslint = options["use-eslint"];
      delete options["use-eslint"];
    }
    if (options["trace-code"] !== void 0) {
      options.traceCode = options["trace-code"];
      delete options["trace-code"];
    }
    if (options["test-api"] !== void 0) {
      options.testApi = options["test-api"];
      delete options["test-api"];
    }
    await orchestrateReview(target, options);
  } catch (error2) {
    console.error(
      `Unhandled error in reviewCode: ${error2 instanceof Error ? error2.message : String(error2)}`
    );
    process.exit(1);
  }
}

// src/commands/testModel.ts
var import_commander = require("commander");
var import_chalk4 = __toESM(require("chalk"));
init_modelMaps2();
init_modelTester();
init_logger();
var testModelCommand = new import_commander.Command("model-test").description("Test AI models to verify API keys and model availability").argument(
  "[provider:model]",
  "Provider and model to test (e.g. gemini:gemini-1.5-pro, anthropic:claude-3-opus)"
).option("--all", "Test all available models").option(
  "-p, --provider <provider>",
  "Test all models for a specific provider"
).action(async (modelStr, options) => {
  try {
    if (options.all) {
      await testAllModels();
      return;
    }
    if (options.provider) {
      await testProviderModels(options.provider);
      return;
    }
    if (modelStr) {
      await testSpecificModel(modelStr);
      return;
    }
    await testDefaultModels();
  } catch (error2) {
    logger_default.error("Error testing models:", error2);
    process.exit(1);
  }
});
async function testSpecificModel(modelStr) {
  const [provider, modelName] = modelStr.split(":");
  if (!provider || !modelName) {
    logger_default.error(
      "Invalid model string. Format should be provider:model (e.g. gemini:gemini-1.5-pro)"
    );
    return;
  }
  const fullModelKey = `${provider}:${modelName}`;
  const modelMapping = MODEL_MAP[fullModelKey];
  if (!modelMapping) {
    logger_default.error(`Model ${fullModelKey} not found in model registry`);
    return;
  }
  logger_default.info(
    `Testing model: ${import_chalk4.default.cyan(modelMapping.displayName)} (${import_chalk4.default.gray(fullModelKey)})`
  );
  let result;
  switch (provider) {
    case "gemini":
      result = await testGeminiModel(modelMapping.apiIdentifier);
      break;
    case "anthropic":
      result = await testAnthropicModel(modelMapping.apiIdentifier);
      break;
    case "openai":
      result = await testOpenAIModel(modelMapping.apiIdentifier);
      break;
    case "openrouter":
      result = await testOpenRouterModel(modelMapping.apiIdentifier);
      break;
    default:
      logger_default.error(`Unknown provider: ${provider}`);
      return;
  }
  if (result.success) {
    logger_default.info(import_chalk4.default.green(`\u2713 ${result.message}`));
    if (result.response) {
      logger_default.info(`Response: ${import_chalk4.default.gray(result.response)}`);
    }
  } else {
    logger_default.error(import_chalk4.default.red(`\u2717 ${result.message}`));
  }
}
async function testAllModels() {
  const providers = ["gemini", "anthropic", "openai", "openrouter"];
  const results = [];
  logger_default.info(import_chalk4.default.bold("Testing all models from all providers...\n"));
  for (const provider of providers) {
    const modelKeys = getModelsByProvider(provider);
    logger_default.info(
      import_chalk4.default.bold(`
Testing ${modelKeys.length} ${provider} models:`)
    );
    for (const modelKey of modelKeys) {
      const modelMapping = MODEL_MAP[modelKey];
      process.stdout.write(
        `  ${import_chalk4.default.cyan(modelMapping.displayName)} (${import_chalk4.default.gray(modelKey)})... `
      );
      let result;
      switch (provider) {
        case "gemini":
          result = await testGeminiModel(modelMapping.apiIdentifier);
          break;
        case "anthropic":
          result = await testAnthropicModel(modelMapping.apiIdentifier);
          break;
        case "openai":
          result = await testOpenAIModel(modelMapping.apiIdentifier);
          break;
        case "openrouter":
          result = await testOpenRouterModel(modelMapping.apiIdentifier);
          break;
      }
      results.push({
        provider,
        modelKey,
        displayName: modelMapping.displayName,
        result
      });
      if (result.success) {
        process.stdout.write(import_chalk4.default.green("\u2713\n"));
      } else {
        process.stdout.write(import_chalk4.default.red("\u2717\n"));
      }
    }
  }
  const successful = results.filter((r) => r.result.success).length;
  const failed = results.length - successful;
  logger_default.info(import_chalk4.default.bold("\nSummary:"));
  logger_default.info(`  ${import_chalk4.default.green(`${successful} models available`)}`);
  logger_default.info(`  ${import_chalk4.default.red(`${failed} models unavailable`)}`);
  if (failed > 0) {
    logger_default.info(import_chalk4.default.bold("\nFailed models:"));
    results.filter((r) => !r.result.success).forEach((r) => {
      logger_default.info(
        `  ${import_chalk4.default.cyan(r.displayName)} (${import_chalk4.default.gray(r.modelKey)}): ${import_chalk4.default.red(r.result.message)}`
      );
    });
  }
}
async function testProviderModels(providerStr) {
  const provider = providerStr;
  const modelKeys = getModelsByProvider(provider);
  if (modelKeys.length === 0) {
    logger_default.error(`Unknown provider: ${provider}`);
    return;
  }
  logger_default.info(import_chalk4.default.bold(`Testing ${modelKeys.length} ${provider} models:
`));
  const results = [];
  for (const modelKey of modelKeys) {
    const modelMapping = MODEL_MAP[modelKey];
    process.stdout.write(
      `  ${import_chalk4.default.cyan(modelMapping.displayName)} (${import_chalk4.default.gray(modelKey)})... `
    );
    let result;
    switch (provider) {
      case "gemini":
        result = await testGeminiModel(modelMapping.apiIdentifier);
        break;
      case "anthropic":
        result = await testAnthropicModel(modelMapping.apiIdentifier);
        break;
      case "openai":
        result = await testOpenAIModel(modelMapping.apiIdentifier);
        break;
      case "openrouter":
        result = await testOpenRouterModel(modelMapping.apiIdentifier);
        break;
    }
    results.push({
      modelKey,
      displayName: modelMapping.displayName,
      result
    });
    if (result.success) {
      process.stdout.write(import_chalk4.default.green("\u2713\n"));
    } else {
      process.stdout.write(import_chalk4.default.red("\u2717\n"));
    }
  }
  const successful = results.filter((r) => r.result.success).length;
  const failed = results.length - successful;
  logger_default.info(import_chalk4.default.bold("\nSummary:"));
  logger_default.info(`  ${import_chalk4.default.green(`${successful} models available`)}`);
  logger_default.info(`  ${import_chalk4.default.red(`${failed} models unavailable`)}`);
  if (failed > 0) {
    logger_default.info(import_chalk4.default.bold("\nFailed models:"));
    results.filter((r) => !r.result.success).forEach((r) => {
      logger_default.info(
        `  ${import_chalk4.default.cyan(r.displayName)} (${import_chalk4.default.gray(r.modelKey)}): ${import_chalk4.default.red(r.result.message)}`
      );
    });
  }
}
async function testDefaultModels() {
  const providers = ["gemini", "anthropic", "openai", "openrouter"];
  const results = [];
  logger_default.info(import_chalk4.default.bold("Testing default models from each provider:\n"));
  for (const provider of providers) {
    const modelKeys = getModelsByProvider(provider);
    if (modelKeys.length === 0) continue;
    const defaultModelKey = modelKeys[0];
    const modelMapping = MODEL_MAP[defaultModelKey];
    process.stdout.write(
      `  ${import_chalk4.default.cyan(modelMapping.displayName)} (${import_chalk4.default.gray(defaultModelKey)})... `
    );
    let result;
    switch (provider) {
      case "gemini":
        result = await testGeminiModel(modelMapping.apiIdentifier);
        break;
      case "anthropic":
        result = await testAnthropicModel(modelMapping.apiIdentifier);
        break;
      case "openai":
        result = await testOpenAIModel(modelMapping.apiIdentifier);
        break;
      case "openrouter":
        result = await testOpenRouterModel(modelMapping.apiIdentifier);
        break;
    }
    results.push({
      provider,
      modelKey: defaultModelKey,
      displayName: modelMapping.displayName,
      result
    });
    if (result.success) {
      process.stdout.write(import_chalk4.default.green("\u2713\n"));
    } else {
      process.stdout.write(import_chalk4.default.red("\u2717\n"));
    }
  }
  const successful = results.filter((r) => r.result.success).length;
  const failed = results.length - successful;
  logger_default.info(import_chalk4.default.bold("\nSummary:"));
  logger_default.info(`  ${import_chalk4.default.green(`${successful} providers available`)}`);
  logger_default.info(`  ${import_chalk4.default.red(`${failed} providers unavailable`)}`);
  if (failed > 0) {
    logger_default.info(import_chalk4.default.bold("\nUnavailable providers:"));
    results.filter((r) => !r.result.success).forEach((r) => {
      logger_default.info(
        `  ${import_chalk4.default.cyan(r.provider)}: ${import_chalk4.default.red(r.result.message)}`
      );
    });
  }
}

// src/commands/testBuild.ts
var import_commander2 = require("commander");
var import_chalk5 = __toESM(require("chalk"));
init_modelMaps2();
init_modelTester();
init_logger();
var testBuildCommand = new import_commander2.Command("test-build").description(
  "Test all AI models to verify API keys and model availability during build"
).option("--fail-on-error", "Exit with error code if any model test fails").option("--json", "Output results in JSON format").option(
  "-p, --provider <provider>",
  "Test only models for a specific provider"
).action(async (options) => {
  try {
    if (options.provider) {
      await testProviderModels2(options.provider, options);
    } else {
      await testAllModels2(options);
    }
  } catch (error2) {
    logger_default.error("Error testing models:", error2);
    process.exit(1);
  }
});
async function testAllModels2(options) {
  const providers = ["gemini", "anthropic", "openai", "openrouter"];
  const results = [];
  let hasFailures = false;
  if (!options.json) {
    logger_default.info(import_chalk5.default.bold("Testing all models from all providers...\n"));
  }
  for (const provider of providers) {
    const modelKeys = getModelsByProvider(provider);
    if (!options.json) {
      logger_default.info(
        import_chalk5.default.bold(`
Testing ${modelKeys.length} ${provider} models:`)
      );
    }
    for (const modelKey of modelKeys) {
      const modelMapping = MODEL_MAP[modelKey];
      if (!options.json) {
        process.stdout.write(
          `  ${import_chalk5.default.cyan(modelMapping.displayName)} (${import_chalk5.default.gray(modelKey)})... `
        );
      }
      let result;
      switch (provider) {
        case "gemini":
          result = await testGeminiModel(modelMapping.apiIdentifier);
          break;
        case "anthropic":
          result = await testAnthropicModel(modelMapping.apiIdentifier);
          break;
        case "openai":
          result = await testOpenAIModel(modelMapping.apiIdentifier);
          break;
        case "openrouter":
          result = await testOpenRouterModel(modelMapping.apiIdentifier);
          break;
      }
      if (!result.success) {
        hasFailures = true;
      }
      results.push({
        provider,
        modelKey,
        displayName: modelMapping.displayName,
        apiIdentifier: modelMapping.apiIdentifier,
        success: result.success,
        message: result.message,
        response: result.response
      });
      if (!options.json) {
        if (result.success) {
          process.stdout.write(import_chalk5.default.green("\u2713\n"));
        } else {
          process.stdout.write(import_chalk5.default.red("\u2717\n"));
        }
      }
    }
  }
  if (options.json) {
    console.log(
      JSON.stringify(
        {
          results,
          summary: {
            total: results.length,
            successful: results.filter((r) => r.success).length,
            failed: results.filter((r) => !r.success).length
          }
        },
        null,
        2
      )
    );
  } else {
    const successful = results.filter((r) => r.success).length;
    const failed = results.length - successful;
    logger_default.info(import_chalk5.default.bold("\nSummary:"));
    logger_default.info(`  ${import_chalk5.default.green(`${successful} models available`)}`);
    logger_default.info(`  ${import_chalk5.default.red(`${failed} models unavailable`)}`);
    if (failed > 0) {
      logger_default.info(import_chalk5.default.bold("\nFailed models:"));
      results.filter((r) => !r.success).forEach((r) => {
        logger_default.info(
          `  ${import_chalk5.default.cyan(r.displayName)} (${import_chalk5.default.gray(r.modelKey)}): ${import_chalk5.default.red(r.message)}`
        );
      });
    }
  }
  if (hasFailures && options.failOnError) {
    process.exit(1);
  }
}
async function testProviderModels2(provider, options) {
  const modelKeys = getModelsByProvider(provider);
  const results = [];
  let hasFailures = false;
  if (modelKeys.length === 0) {
    logger_default.error(`Unknown provider: ${provider}`);
    process.exit(1);
  }
  if (!options.json) {
    logger_default.info(
      import_chalk5.default.bold(`Testing ${modelKeys.length} ${provider} models:
`)
    );
  }
  for (const modelKey of modelKeys) {
    const modelMapping = MODEL_MAP[modelKey];
    if (!options.json) {
      process.stdout.write(
        `  ${import_chalk5.default.cyan(modelMapping.displayName)} (${import_chalk5.default.gray(modelKey)})... `
      );
    }
    let result;
    switch (provider) {
      case "gemini":
        result = await testGeminiModel(modelMapping.apiIdentifier);
        break;
      case "anthropic":
        result = await testAnthropicModel(modelMapping.apiIdentifier);
        break;
      case "openai":
        result = await testOpenAIModel(modelMapping.apiIdentifier);
        break;
      case "openrouter":
        result = await testOpenRouterModel(modelMapping.apiIdentifier);
        break;
    }
    if (!result.success) {
      hasFailures = true;
    }
    results.push({
      provider,
      modelKey,
      displayName: modelMapping.displayName,
      apiIdentifier: modelMapping.apiIdentifier,
      success: result.success,
      message: result.message,
      response: result.response
    });
    if (!options.json) {
      if (result.success) {
        process.stdout.write(import_chalk5.default.green("\u2713\n"));
      } else {
        process.stdout.write(import_chalk5.default.red("\u2717\n"));
      }
    }
  }
  if (options.json) {
    console.log(
      JSON.stringify(
        {
          provider,
          results,
          summary: {
            total: results.length,
            successful: results.filter((r) => r.success).length,
            failed: results.filter((r) => !r.success).length
          }
        },
        null,
        2
      )
    );
  } else {
    const successful = results.filter((r) => r.success).length;
    const failed = results.length - successful;
    logger_default.info(import_chalk5.default.bold("\nSummary:"));
    logger_default.info(`  ${import_chalk5.default.green(`${successful} models available`)}`);
    logger_default.info(`  ${import_chalk5.default.red(`${failed} models unavailable`)}`);
    if (failed > 0) {
      logger_default.info(import_chalk5.default.bold("\nFailed models:"));
      results.filter((r) => !r.success).forEach((r) => {
        logger_default.info(
          `  ${import_chalk5.default.cyan(r.displayName)} (${import_chalk5.default.gray(r.modelKey)}): ${import_chalk5.default.red(r.message)}`
        );
      });
    }
  }
  if (hasFailures && options.failOnError) {
    process.exit(1);
  }
}

// src/cli/argumentParser.ts
var import_yargs = __toESM(require("yargs"));
var import_helpers = require("yargs/helpers");
init_config();
init_logger();
var validReviewTypes = [
  "quick-fixes",
  "architectural",
  "security",
  "performance",
  "unused-code",
  "focused-unused-code",
  "code-tracing-unused-code",
  "improved-quick-fixes",
  "consolidated",
  "evaluation",
  "extract-patterns"
];
var validOutputFormats = ["markdown", "json"];
function parseArguments() {
  const configResult = loadConfigSafe();
  if (!configResult.success) {
    displayConfigError(configResult);
    process.exit(1);
  }
  const config4 = configResult.config;
  const defaultModel = config4.selectedModel || "";
  const argv = (0, import_yargs.default)((0, import_helpers.hideBin)(process.argv)).command(
    ["$0 [target]", "code-review [target]"],
    "Run a code review on the specified target",
    (yargs3) => {
      return yargs3.positional("target", {
        describe: "Path to the file or directory to review",
        type: "string",
        default: "."
      }).option("type", {
        alias: "t",
        describe: "Type of review to perform",
        choices: validReviewTypes
        // No default here - will be set after config file is applied
      }).option("output", {
        alias: "o",
        describe: "Output format (markdown or json)",
        choices: validOutputFormats,
        default: "markdown"
      }).option("output-dir", {
        describe: "Directory to save review output",
        type: "string"
      }).option("model", {
        alias: "m",
        describe: "Model to use for the review (format: provider:model)",
        type: "string",
        default: defaultModel
      }).option("include-tests", {
        describe: "Include test files in the review",
        type: "boolean",
        default: false
      }).option("include-project-docs", {
        describe: "Include project documentation in the review context",
        type: "boolean",
        default: true
      }).option("include-dependency-analysis", {
        describe: "Include dependency analysis in the review",
        type: "boolean",
        default: void 0
      }).option("enable-semantic-chunking", {
        describe: "Enable semantic chunking for intelligent code analysis",
        type: "boolean",
        default: process.env.AI_CODE_REVIEW_ENABLE_SEMANTIC_CHUNKING === "false" ? false : true
      }).option("interactive", {
        alias: "i",
        describe: "Run in interactive mode, processing review results in real-time",
        type: "boolean",
        default: false
      }).option("test-api", {
        describe: "Test API connections before running the review",
        type: "boolean",
        default: false
      }).option("estimate", {
        describe: "Estimate token usage and cost without performing the review",
        type: "boolean",
        default: false
      }).option("multi-pass", {
        describe: "Use multi-pass review for large codebases",
        type: "boolean",
        default: false
      }).option("force-single-pass", {
        describe: "Force single-pass review even if token analysis suggests multiple passes are needed",
        type: "boolean",
        default: false
      }).option("context-maintenance-factor", {
        describe: "Context maintenance factor for multi-pass reviews (0-1)",
        type: "number",
        default: 0.15
      }).option("no-confirm", {
        describe: "Skip confirmation prompts",
        type: "boolean",
        default: false
      }).option("debug", {
        describe: "Enable debug logging",
        type: "boolean",
        default: false
      }).option("language", {
        describe: "Specify the programming language (auto-detected if not specified)",
        type: "string"
      }).option("framework", {
        describe: "Specify the framework (auto-detected if not specified)",
        type: "string"
      }).option("listmodels", {
        describe: "List available models based on configured API keys",
        type: "boolean",
        default: false
      }).option("models", {
        describe: "List all supported models and their configuration names",
        type: "boolean",
        default: false
      }).option("config", {
        describe: "Path to JSON configuration file",
        type: "string"
      }).option("google-api-key", {
        describe: "Google API key for Gemini models",
        type: "string"
      }).option("openrouter-api-key", {
        describe: "OpenRouter API key",
        type: "string"
      }).option("anthropic-api-key", {
        describe: "Anthropic API key for Claude models",
        type: "string"
      }).option("openai-api-key", {
        describe: "OpenAI API key for GPT models",
        type: "string"
      });
    }
  ).command(
    "test-model",
    "Test the configured model with a simple prompt",
    (yargs3) => {
      return yargs3.option("model", {
        alias: "m",
        describe: "Model to test (format: provider:model)",
        type: "string",
        default: defaultModel
      }).option("debug", {
        describe: "Enable debug logging",
        type: "boolean",
        default: false
      }).option("google-api-key", {
        describe: "Google API key for Gemini models",
        type: "string"
      }).option("openrouter-api-key", {
        describe: "OpenRouter API key",
        type: "string"
      }).option("anthropic-api-key", {
        describe: "Anthropic API key for Claude models",
        type: "string"
      }).option("openai-api-key", {
        describe: "OpenAI API key for GPT models",
        type: "string"
      });
    }
  ).command(
    "test-build",
    "Test the build by running a simple command",
    (yargs3) => {
      return yargs3.option("debug", {
        describe: "Enable debug logging",
        type: "boolean",
        default: false
      });
    }
  ).command(
    "sync-github-projects",
    "Sync GitHub projects to local directory",
    (yargs3) => {
      return yargs3.option("token", {
        describe: "GitHub token",
        type: "string",
        demandOption: true
      }).option("org", {
        describe: "GitHub organization",
        type: "string",
        demandOption: true
      }).option("output-dir", {
        describe: "Output directory",
        type: "string",
        default: "./github-projects"
      }).option("debug", {
        describe: "Enable debug logging",
        type: "boolean",
        default: false
      });
    }
  ).command(
    "generate-config",
    "Generate a sample configuration file",
    (yargs3) => {
      return yargs3.option("output", {
        alias: "o",
        describe: "Output file path for the configuration",
        type: "string"
      }).option("format", {
        alias: "f",
        describe: "Configuration file format",
        choices: ["yaml", "json"],
        default: "yaml"
      }).option("force", {
        describe: "Overwrite existing configuration file",
        type: "boolean",
        default: false
      });
    }
  ).option("show-version", {
    describe: "Show version information",
    type: "boolean",
    default: false
  }).help().alias("help", "h").alias("version", "v").strict().demandCommand(0).parse();
  if (argv.debug) {
    logger_default.setLogLevel("debug");
    logger_default.debug("Debug logging enabled");
    logger_default.debug(`Environment variable AI_CODE_REVIEW_ENABLE_SEMANTIC_CHUNKING: ${process.env.AI_CODE_REVIEW_ENABLE_SEMANTIC_CHUNKING || "not set (defaults to true)"}`);
    logger_default.debug(`Semantic chunking enabled: ${argv.enableSemanticChunking}`);
    logger_default.debug(`Command-line arguments: ${JSON.stringify(argv, null, 2)}`);
  }
  return argv;
}
function mapArgsToReviewOptions(argv) {
  const options = {
    type: argv.type || "quick-fixes",
    // Apply default if not set by CLI or config
    output: argv.output,
    outputDir: argv.outputDir,
    model: argv.model,
    includeTests: argv.includeTests,
    includeProjectDocs: argv.includeProjectDocs,
    includeDependencyAnalysis: argv.includeDependencyAnalysis,
    enableSemanticChunking: argv.enableSemanticChunking,
    interactive: argv.interactive,
    testApi: argv.testApi,
    estimate: argv.estimate,
    multiPass: argv.multiPass,
    forceSinglePass: argv.forceSinglePass,
    contextMaintenanceFactor: argv.contextMaintenanceFactor,
    noConfirm: argv.noConfirm,
    debug: argv.debug,
    language: argv.language,
    framework: argv.framework,
    listmodels: argv.listmodels,
    models: argv.models,
    target: argv.target || "."
  };
  const apiKeys = {};
  if (argv["google-api-key"]) {
    apiKeys.google = argv["google-api-key"];
  }
  if (argv["openrouter-api-key"]) {
    apiKeys.openrouter = argv["openrouter-api-key"];
  }
  if (argv["anthropic-api-key"]) {
    apiKeys.anthropic = argv["anthropic-api-key"];
  }
  if (argv["openai-api-key"]) {
    apiKeys.openai = argv["openai-api-key"];
  }
  if (Object.keys(apiKeys).length > 0) {
    options.apiKeys = apiKeys;
  }
  return options;
}

// src/utils/i18n.ts
var import_i18next = __toESM(require("i18next"));
var import_i18next_fs_backend = __toESM(require("i18next-fs-backend"));
var import_i18next_icu = __toESM(require("i18next-icu"));
var import_path27 = __toESM(require("path"));
var import_fs7 = __toESM(require("fs"));
var DEFAULT_LANGUAGE2 = "en";
var SUPPORTED_LANGUAGES = ["en", "es", "fr", "de", "ja"];
async function initI18n(lng = DEFAULT_LANGUAGE2) {
  const language = SUPPORTED_LANGUAGES.includes(lng) ? lng : DEFAULT_LANGUAGE2;
  const localesPath = getLocalesPath();
  await import_i18next.default.use(import_i18next_fs_backend.default).use(import_i18next_icu.default).init({
    lng: language,
    fallbackLng: DEFAULT_LANGUAGE2,
    debug: process.env.NODE_ENV === "development",
    interpolation: {
      escapeValue: false,
      // Not needed for server-side
      format: (value, format, _lng) => {
        if (format === "uppercase") return value.toUpperCase();
        if (format === "lowercase") return value.toLowerCase();
        return value;
      }
    },
    backend: {
      loadPath: import_path27.default.join(localesPath, "{{lng}}/{{ns}}.json")
    }
    // Add any additional configuration here
  });
  return import_i18next.default;
}
function getLocalesPath() {
  const possiblePaths = [
    // For local development
    import_path27.default.resolve("locales"),
    // For npm package
    import_path27.default.resolve(__dirname, "..", "..", "locales"),
    // For global installation
    import_path27.default.resolve(__dirname, "..", "..", "..", "locales")
  ];
  for (const p of possiblePaths) {
    if (import_fs7.default.existsSync(p)) {
      return p;
    }
  }
  return possiblePaths[0];
}
function t(key, options) {
  try {
    if (!import_i18next.default.isInitialized) {
      return options?.message || key;
    }
    const translated = import_i18next.default.t(key, options);
    if (!translated || translated === key || translated === "undefined") {
      return options?.message || key;
    }
    return translated;
  } catch (error2) {
    return options?.message || key;
  }
}

// src/index.ts
init_PromptManager();
init_modelLister();

// src/commands/syncGithubProjects.ts
var path38 = __toESM(require("path"));

// src/utils/fileSystemUtils.ts
var import_promises17 = __toESM(require("fs/promises"));
var import_path28 = __toESM(require("path"));
init_logger();
async function fileExists3(filePath) {
  try {
    await import_promises17.default.access(filePath);
    return true;
  } catch (error2) {
    return false;
  }
}

// src/commands/syncGithubProjects.ts
init_logger();

// src/utils/githubProjectsClient.ts
var import_node_fetch = __toESM(require("node-fetch"));
var import_promises18 = __toESM(require("fs/promises"));
init_logger();
var GITHUB_GRAPHQL_URL = "https://api.github.com/graphql";
function getGitHubProjectsConfig() {
  const token = process.env.GITHUB_TOKEN;
  const projectId = process.env.GITHUB_PROJECT_ID;
  const projectNumber = process.env.GITHUB_PROJECT_NUMBER ? parseInt(process.env.GITHUB_PROJECT_NUMBER, 10) : void 0;
  const owner = process.env.GITHUB_OWNER || "bobmatnyc";
  if (!token) {
    throw new Error("GITHUB_TOKEN environment variable is required");
  }
  if (!projectId && !projectNumber) {
    throw new Error("Either GITHUB_PROJECT_ID or GITHUB_PROJECT_NUMBER environment variable is required");
  }
  return {
    token,
    projectId,
    projectNumber,
    owner
  };
}
async function executeGraphQLQuery(query, variables, token) {
  try {
    const response = await (0, import_node_fetch.default)(GITHUB_GRAPHQL_URL, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${token}`,
        "Content-Type": "application/json",
        "Accept": "application/vnd.github.v4+json"
      },
      body: JSON.stringify({
        query,
        variables
      })
    });
    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`GitHub API error: ${response.status} ${errorText}`);
    }
    const data = await response.json();
    if (data.errors) {
      throw new Error(`GraphQL error: ${JSON.stringify(data.errors)}`);
    }
    return data.data;
  } catch (error2) {
    logger_default.error(`Error executing GraphQL query: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function getProjectInfo(config4) {
  try {
    let query;
    const variables = {};
    if (config4.projectId) {
      query = `
        query GetProjectById($projectId: ID!) {
          node(id: $projectId) {
            ... on ProjectV2 {
              id
              title
              url
              number
              shortDescription
              readme
              fields(first: 20) {
                nodes {
                  ... on ProjectV2Field {
                    id
                    name
                  }
                  ... on ProjectV2SingleSelectField {
                    id
                    name
                    options {
                      id
                      name
                    }
                  }
                }
              }
            }
          }
        }
      `;
      variables.projectId = config4.projectId;
    } else if (config4.projectNumber) {
      query = `
        query GetProjectByNumber($owner: String!, $number: Int!) {
          user(login: $owner) {
            projectV2(number: $number) {
              id
              title
              url
              number
              shortDescription
              readme
              fields(first: 20) {
                nodes {
                  ... on ProjectV2Field {
                    id
                    name
                  }
                  ... on ProjectV2SingleSelectField {
                    id
                    name
                    options {
                      id
                      name
                    }
                  }
                }
              }
            }
          }
        }
      `;
      variables.owner = config4.owner;
      variables.number = config4.projectNumber;
    } else {
      throw new Error("Either projectId or projectNumber must be provided");
    }
    const result = await executeGraphQLQuery(query, variables, config4.token);
    const project = config4.projectId ? result.node : result.user.projectV2;
    return project;
  } catch (error2) {
    logger_default.error(`Error getting project info: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function getProjectItems(config4) {
  try {
    let projectId = config4.projectId;
    if (!projectId && config4.projectNumber) {
      const projectInfo = await getProjectInfo(config4);
      projectId = projectInfo.id;
    }
    if (!projectId) {
      throw new Error("Could not determine project ID");
    }
    const query = `
      query GetProjectItems($projectId: ID!) {
        node(id: $projectId) {
          ... on ProjectV2 {
            items(first: 100) {
              nodes {
                id
                content {
                  ... on Issue {
                    title
                    body
                  }
                  ... on PullRequest {
                    title
                    body
                  }
                  ... on DraftIssue {
                    title
                    body
                  }
                }
                fieldValues(first: 20) {
                  nodes {
                    ... on ProjectV2ItemFieldSingleSelectValue {
                      name
                      field {
                        ... on ProjectV2SingleSelectField {
                          name
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    `;
    const result = await executeGraphQLQuery(query, { projectId }, config4.token);
    const items = result.node.items.nodes.map((item) => {
      const statusField = item.fieldValues.nodes.find(
        (fieldValue) => fieldValue.field && fieldValue.field.name === "Status"
      );
      return {
        id: item.id,
        title: item.content.title,
        body: item.content.body,
        status: statusField ? statusField.name : void 0
      };
    });
    return items;
  } catch (error2) {
    logger_default.error(`Error getting project items: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function createProjectItem(config4, title, body) {
  try {
    let projectId = config4.projectId;
    if (!projectId && config4.projectNumber) {
      const projectInfo = await getProjectInfo(config4);
      projectId = projectInfo.id;
    }
    if (!projectId) {
      throw new Error("Could not determine project ID");
    }
    const query = `
      mutation CreateProjectItem($projectId: ID!, $title: String!, $body: String!) {
        addProjectV2DraftIssue(input: {
          projectId: $projectId,
          title: $title,
          body: $body
        }) {
          projectItem {
            id
            content {
              ... on DraftIssue {
                title
                body
              }
            }
          }
        }
      }
    `;
    const result = await executeGraphQLQuery(
      query,
      { projectId, title, body },
      config4.token
    );
    const createdItem = result.addProjectV2DraftIssue.projectItem;
    return {
      id: createdItem.id,
      title: createdItem.content.title,
      body: createdItem.content.body
    };
  } catch (error2) {
    logger_default.error(`Error creating project item: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function updateProjectItem(config4, itemId, title, body) {
  try {
    const query = `
      mutation UpdateProjectItem($itemId: ID!, $title: String!, $body: String!) {
        updateProjectV2DraftIssue(input: {
          draftIssueId: $itemId,
          title: $title,
          body: $body
        }) {
          draftIssue {
            id
            title
            body
          }
        }
      }
    `;
    const result = await executeGraphQLQuery(
      query,
      { itemId, title, body },
      config4.token
    );
    const updatedItem = result.updateProjectV2DraftIssue.draftIssue;
    return {
      id: updatedItem.id,
      title: updatedItem.title,
      body: updatedItem.body
    };
  } catch (error2) {
    logger_default.error(`Error updating project item: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
function parseProjectMd(content) {
  const sections = {};
  const sectionRegex = /^## (.+?)$([\s\S]*?)(?=^## |\s*$)/gm;
  let match;
  while ((match = sectionRegex.exec(content)) !== null) {
    const sectionTitle = match[1].trim();
    const sectionContent = match[2].trim();
    sections[sectionTitle] = sectionContent;
  }
  return sections;
}
async function updateProjectDescription(projectMdPath, config4) {
  try {
    const content = await import_promises18.default.readFile(projectMdPath, "utf-8");
    const projectInfo = await getProjectInfo(config4);
    const projectId = projectInfo.id;
    if (!projectId) {
      throw new Error("Could not determine project ID");
    }
    const query = `
      mutation UpdateProjectReadme($projectId: ID!, $readme: String!) {
        updateProjectV2(input: {
          projectId: $projectId,
          readme: $readme
        }) {
          projectV2 {
            id
            readme
          }
        }
      }
    `;
    await executeGraphQLQuery(
      query,
      { projectId, readme: content },
      config4.token
    );
    logger_default.info("Successfully updated GitHub Project readme with PROJECT.md content");
  } catch (error2) {
    logger_default.error(`Error updating project readme: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function syncProjectMdToGitHub(projectMdPath, config4, updateDescriptionOnly = false) {
  try {
    if (updateDescriptionOnly) {
      await updateProjectDescription(projectMdPath, config4);
      return;
    }
    const content = await import_promises18.default.readFile(projectMdPath, "utf-8");
    const sections = parseProjectMd(content);
    const existingItems = await getProjectItems(config4);
    for (const [title, body] of Object.entries(sections)) {
      const existingItem = existingItems.find((item) => item.title === title);
      if (existingItem) {
        await updateProjectItem(config4, existingItem.id, title, body);
        logger_default.info(`Updated project item: ${title}`);
      } else {
        await createProjectItem(config4, title, body);
        logger_default.info(`Created project item: ${title}`);
      }
    }
    logger_default.info("Successfully synced PROJECT.md to GitHub Projects");
  } catch (error2) {
    logger_default.error(`Error syncing PROJECT.md to GitHub: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function generateProjectMdFromGitHub(config4) {
  try {
    const projectInfo = await getProjectInfo(config4);
    const items = await getProjectItems(config4);
    let content = `# ${projectInfo.title}

`;
    for (const item of items) {
      content += `## ${item.title}

${item.body || ""}

`;
    }
    return content;
  } catch (error2) {
    logger_default.error(`Error generating PROJECT.md from GitHub: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}
async function syncGitHubToProjectMd(projectMdPath, config4) {
  try {
    const content = await generateProjectMdFromGitHub(config4);
    await import_promises18.default.writeFile(projectMdPath, content, "utf-8");
    logger_default.info("Successfully synced GitHub Projects to PROJECT.md");
  } catch (error2) {
    logger_default.error(`Error syncing GitHub to PROJECT.md: ${error2 instanceof Error ? error2.message : String(error2)}`);
    throw error2;
  }
}

// src/commands/syncGithubProjects.ts
async function syncGitHubProjects(options = {}) {
  try {
    const direction = options.direction || "to-github";
    const projectPath = options.projectPath || process.cwd();
    const descriptionOnly = options.descriptionOnly || false;
    const config4 = getGitHubProjectsConfig();
    const projectMdPath = path38.join(projectPath, "PROJECT.md");
    const projectMdExists = await fileExists3(projectMdPath);
    if (direction === "to-github") {
      if (!projectMdExists) {
        logger_default.error(`PROJECT.md not found at ${projectMdPath}`);
        process.exit(1);
      }
      if (descriptionOnly) {
        logger_default.info(`Updating GitHub Project readme with PROJECT.md content...`);
        await syncProjectMdToGitHub(projectMdPath, config4, true);
        logger_default.info("Project readme updated successfully");
      } else {
        logger_default.info(`Syncing PROJECT.md to GitHub Projects...`);
        await syncProjectMdToGitHub(projectMdPath, config4, false);
        logger_default.info("Sync completed successfully");
      }
    } else {
      logger_default.info(`Syncing GitHub Projects to PROJECT.md...`);
      await syncGitHubToProjectMd(projectMdPath, config4);
      logger_default.info(`Sync completed successfully. PROJECT.md updated at ${projectMdPath}`);
    }
  } catch (error2) {
    logger_default.error(`Error syncing with GitHub Projects: ${error2 instanceof Error ? error2.message : String(error2)}`);
    process.exit(1);
  }
}
async function handleSyncGitHubProjectsCommand() {
  const { parseGitHubProjectsArguments: parseGitHubProjectsArguments2 } = await Promise.resolve().then(() => (init_githubProjectsArgumentParser(), githubProjectsArgumentParser_exports));
  try {
    const options = await parseGitHubProjectsArguments2();
    await syncGitHubProjects(options);
  } catch (error2) {
    logger_default.error(`Error handling GitHub Projects sync command: ${error2 instanceof Error ? error2.message : String(error2)}`);
    process.exit(1);
  }
}

// src/commands/generateConfig.ts
var fs30 = __toESM(require("fs"));
var path39 = __toESM(require("path"));
init_logger();
init_configFileManager();
async function generateConfigCommand(outputPath, force = false, format = "yaml") {
  try {
    const resolvedPath = path39.resolve(process.cwd(), outputPath);
    if (fs30.existsSync(resolvedPath) && !force) {
      logger_default.error(`Configuration file already exists at ${resolvedPath}`);
      logger_default.info("Use --force to overwrite the existing file");
      process.exit(1);
    }
    const sampleConfig = format === "json" ? generateSampleConfigJSON() : generateSampleConfig();
    fs30.writeFileSync(resolvedPath, sampleConfig, "utf-8");
    logger_default.info(`Sample ${format.toUpperCase()} configuration file created at: ${resolvedPath}`);
    logger_default.info("");
    logger_default.info("Next steps:");
    logger_default.info("1. Edit the configuration file to add your API keys");
    logger_default.info("2. Customize the settings according to your needs");
    logger_default.info("3. Run the tool with: ai-code-review --config " + path39.basename(resolvedPath));
    logger_default.info("");
    logger_default.info("Configuration priority order:");
    logger_default.info("1. Command-line arguments (highest priority)");
    logger_default.info("2. JSON configuration file");
    logger_default.info("3. Environment variables");
    logger_default.info("4. Default values (lowest priority)");
  } catch (error2) {
    logger_default.error(`Failed to generate configuration file: ${error2 instanceof Error ? error2.message : String(error2)}`);
    process.exit(1);
  }
}
async function handleGenerateConfigCommand(argv) {
  let outputPath = argv.output || ".ai-code-review.yaml";
  const force = argv.force || false;
  let format = "yaml";
  if (argv.format) {
    format = argv.format;
    if (!argv.output) {
      outputPath = format === "json" ? ".ai-code-review.json" : ".ai-code-review.yaml";
    }
  } else {
    const ext = path39.extname(outputPath).toLowerCase();
    if (ext === ".json") {
      format = "json";
    } else if (ext === ".yaml" || ext === ".yml") {
      format = "yaml";
    }
  }
  await generateConfigCommand(outputPath, force, format);
}

// src/version.ts
var VERSION = "4.3.0";

// src/index.ts
console.log("\x1B[35m[ENV-TRACE]\x1B[0m Starting application - checking environment variables");
var isDebugMode2 = process.argv.includes("--debug");
var debugEnvVar = process.env.AI_CODE_REVIEW_LOG_LEVEL?.toLowerCase() === "debug";
if (isDebugMode2) {
  console.log("\x1B[35m[ENV-TRACE]\x1B[0m Debug mode enabled via --debug CLI flag");
}
if (debugEnvVar) {
  console.log("\x1B[35m[ENV-TRACE]\x1B[0m Debug mode enabled via AI_CODE_REVIEW_LOG_LEVEL environment variable");
}
console.log("\x1B[35m[ENV-TRACE]\x1B[0m Current AI_CODE_REVIEW environment variables:");
Object.keys(process.env).forEach((key) => {
  if (key.startsWith("AI_CODE_REVIEW_")) {
    const value = key.includes("KEY") ? "[REDACTED]" : process.env[key];
    console.log(`\x1B[35m[ENV-TRACE]\x1B[0m ${key}=${value}`);
  }
});
function debugLog2(message) {
  if (isDebugMode2 || debugEnvVar) {
    console.log(`\x1B[36m[DEBUG:STARTUP]\x1B[0m ${message}`);
  }
}
if (isDebugMode2) {
  debugLog2("Setting log level to DEBUG (from command line flag)");
  logger_default.setLogLevel(0 /* DEBUG */);
} else {
  const currentLevel = logger_default.getLogLevel();
  debugLog2(`Initial log level: ${LogLevel[currentLevel]}`);
}
var possibleToolDirectories = [
  path40.resolve(__dirname, ".."),
  // Local development or npm link
  path40.resolve(__dirname, "..", ".."),
  // Global npm installation
  "/opt/homebrew/lib/node_modules/@bobmatnyc/ai-code-review"
  // Homebrew global installation
];
if (process.env.AI_CODE_REVIEW_DIR) {
  possibleToolDirectories.unshift(process.env.AI_CODE_REVIEW_DIR);
  debugLog2(`Using tool directory from AI_CODE_REVIEW_DIR: ${process.env.AI_CODE_REVIEW_DIR}`);
}
var toolEnvPath = "";
for (const dir of possibleToolDirectories) {
  const envPath = path40.resolve(dir, ".env.local");
  debugLog2(`Checking for tool .env.local in: ${envPath}`);
  try {
    if (fs31.existsSync(envPath)) {
      toolEnvPath = envPath;
      debugLog2(`Found tool .env.local at: ${toolEnvPath}`);
      break;
    }
  } catch (err) {
  }
}
if (toolEnvPath) {
  const result = dotenv4.config({ path: toolEnvPath });
  if (result.error) {
    console.error("Error parsing tool .env.local file:", result.error);
  } else {
    debugLog2(`Successfully loaded environment variables from ${toolEnvPath}`);
  }
  try {
    if (isDebugMode2) {
      const envContent = fs31.readFileSync(toolEnvPath, "utf8");
      debugLog2("Variables found in tool .env.local (names only):");
      const varNames = envContent.split("\n").filter((line) => line.trim() && !line.startsWith("#")).map((line) => line.split("=")[0]);
      debugLog2(varNames.join(", "));
    }
  } catch (err) {
    console.error("Error reading tool .env.local file:", err);
  }
} else {
  console.log("No .env.local found in tool directory. Looking in current directory...");
  const envLocalPath = path40.resolve(process.cwd(), ".env.local");
  try {
    const cwdEnvExists = fs31.existsSync(envLocalPath);
    if (cwdEnvExists) {
      const result = dotenv4.config({ path: envLocalPath });
      if (result.error) {
        console.log("Could not parse .env.local file. Will use environment variables or command-line arguments.");
        debugLog2(`Parse error: ${result.error.message}`);
      } else {
        debugLog2(`Successfully loaded environment variables from ${envLocalPath}`);
        if (result.parsed && result.parsed.AI_CODE_REVIEW_LOG_LEVEL) {
          debugLog2(`Found AI_CODE_REVIEW_LOG_LEVEL in .env.local: ${result.parsed.AI_CODE_REVIEW_LOG_LEVEL}`);
        }
        if (isDebugMode2) {
          const envVars = Object.keys(result.parsed || {});
          debugLog2(`Loaded ${envVars.length} variables from .env.local: ${envVars.join(", ")}`);
        }
      }
    } else {
      console.log("No .env.local file found. Using environment variables and command-line arguments only.");
      console.log("You can create a .env.local file with your API keys or specify them via command-line flags.");
      debugLog2("Continuing without local environment file.");
    }
  } catch (err) {
    console.log("No .env.local file found. Using environment variables and command-line arguments only.");
    debugLog2(`Error checking for environment files: ${err instanceof Error ? err.message : String(err)}`);
  }
}
console.log("\x1B[35m[ENV-TRACE]\x1B[0m After loading .env.local, AI_CODE_REVIEW environment variables:");
Object.keys(process.env).forEach((key) => {
  if (key.startsWith("AI_CODE_REVIEW_")) {
    const value = key.includes("KEY") ? "[REDACTED]" : process.env[key];
    console.log(`\x1B[35m[ENV-TRACE]\x1B[0m ${key}=${value}`);
  }
});
console.log("Current environment variables for logging:");
console.log(`- AI_CODE_REVIEW_LOG_LEVEL=${process.env.AI_CODE_REVIEW_LOG_LEVEL || "not set"}`);
console.log(`- Debug flag in arguments: ${process.argv.includes("--debug")}`);
if (process.argv.includes("--debug")) {
  console.log("Setting log level to DEBUG (from command line flag)");
  logger_default.setLogLevel("debug");
} else if (process.env.AI_CODE_REVIEW_LOG_LEVEL) {
  const logLevel = process.env.AI_CODE_REVIEW_LOG_LEVEL.toLowerCase();
  console.log(`Setting log level to: ${logLevel.toUpperCase()} (from environment variable)`);
  logger_default.setLogLevel(logLevel);
} else {
  const currentLevel = logger_default.getLogLevel();
  console.log(`Current log level: ${LogLevel[currentLevel]} (default)`);
  if (currentLevel < 1 /* INFO */) {
    console.log(`Adjusting log level to INFO (from ${LogLevel[currentLevel]})`);
    logger_default.setLogLevel("info");
  }
}
async function main() {
  try {
    logger_default.info(`AI Code Review Tool v${VERSION}`);
    await initI18n("en");
    let argv;
    try {
      argv = parseArguments();
    } catch (parseError) {
      console.error("Error parsing command line arguments:", parseError);
      throw parseError;
    }
    let args = mapArgsToReviewOptions(argv);
    const { loadConfigFile: loadConfigFile2, applyConfigToOptions: applyConfigToOptions2 } = await Promise.resolve().then(() => (init_configFileManager(), configFileManager_exports));
    const yamlConfig = loadConfigFile2();
    if (yamlConfig) {
      args = applyConfigToOptions2(yamlConfig, args);
    }
    if (argv.version || argv["show-version"]) {
      console.log(VERSION);
      return;
    }
    if (argv["which-dir"]) {
      console.log("\nAI Code Review Tool Installation Directory:");
      console.log("------------------------------------------");
      const possibleLocations = [
        path40.resolve(__dirname, ".."),
        // Local development or npm link
        path40.resolve(__dirname, "..", ".."),
        // Global npm installation
        "/opt/homebrew/lib/node_modules/@bobmatnyc/ai-code-review"
        // Homebrew global installation
      ];
      console.log(`Tool executable directory: ${__dirname}`);
      for (const dir of possibleLocations) {
        const envPath = path40.join(dir, ".env.local");
        try {
          if (fs31.existsSync(envPath)) {
            console.log(`
Found .env.local at:`);
            console.log(envPath);
            console.log(`
This is the correct location for your environment variables.`);
            console.log(`Add AI_CODE_REVIEW_LOG_LEVEL=debug to this file for debug logging.`);
            break;
          }
        } catch (err) {
        }
      }
      console.log(`
Current working directory: ${process.cwd()}`);
      console.log(`You can also create .env.local in this directory.`);
      return;
    }
    if (argv.models) {
      listModelConfigs();
      return;
    }
    const modelTestArgs = process.argv.slice(2);
    if (modelTestArgs[0] === "generate-config") {
      await handleGenerateConfigCommand(argv);
      return;
    }
    const { loadEnvVariables: loadEnvVariables2 } = await Promise.resolve().then(() => (init_envLoader(), envLoader_exports));
    await loadEnvVariables2();
    const config4 = getConfig(args);
    if (!hasAnyApiKey()) {
      console.log("\n=== API Key Required ===");
      console.log("No API keys were found in environment variables or command-line arguments.");
      console.log("\nTo provide an API key, you can:");
      console.log("\n1. Create a .env.local file with one of these entries:");
      console.log("   - AI_CODE_REVIEW_GOOGLE_API_KEY=your_google_api_key_here");
      console.log("   - AI_CODE_REVIEW_OPENROUTER_API_KEY=your_openrouter_api_key_here");
      console.log("   - AI_CODE_REVIEW_ANTHROPIC_API_KEY=your_anthropic_api_key_here");
      console.log("   - AI_CODE_REVIEW_OPENAI_API_KEY=your_openai_api_key_here");
      console.log("\n2. Or specify an API key via command-line flag:");
      console.log("   - --google-api-key=your_google_api_key_here");
      console.log("   - --openrouter-api-key=your_openrouter_api_key_here");
      console.log("   - --anthropic-api-key=your_anthropic_api_key_here");
      console.log("   - --openai-api-key=your_openai_api_key_here");
      console.log("\n3. Or set an environment variable in your shell:");
      console.log("   export AI_CODE_REVIEW_OPENAI_API_KEY=your_openai_api_key_here\n");
      process.exit(1);
    }
    const validationResult = validateConfigForSelectedModel();
    if (!validationResult.valid) {
      console.log("\n=== API Key Missing for Selected Model ===");
      console.log(validationResult.message);
      console.log("\nPlease provide the appropriate API key for your selected model.");
      console.log("You can override the model with --model=provider:model");
      console.log("Example: --model=openai:gpt-4.1 or --model=gemini:gemini-1.5-pro\n");
      process.exit(1);
    }
    const [provider, model] = config4.selectedModel.split(":");
    console.log(`Using ${provider} API with model: ${model}`);
    if (args.uiLanguage && args.uiLanguage !== "en") {
      await initI18n(args.uiLanguage);
    }
    if (args.uiLanguage && args.uiLanguage !== "en") {
      const languageName = args.uiLanguage === "es" ? "Espa\xF1ol" : args.uiLanguage === "fr" ? "Fran\xE7ais" : args.uiLanguage === "de" ? "Deutsch" : args.uiLanguage === "ja" ? "\u65E5\u672C\u8A9E" : args.uiLanguage;
      logger_default.info(t("app.language_selected", { language: languageName }));
    }
    const pluginManager = PluginManager.getInstance();
    const localPluginsDir = path40.resolve(process.cwd(), "plugins");
    await pluginManager.loadPlugins(localPluginsDir);
    const packagePluginsDir = path40.resolve(
      __dirname,
      "..",
      "plugins",
      "examples"
    );
    await pluginManager.loadPlugins(packagePluginsDir);
    const plugins = pluginManager.listPlugins();
    if (plugins.length > 0) {
      logger_default.info(`Loaded ${plugins.length} plugins:`);
      plugins.forEach((plugin) => {
        logger_default.info(`- ${plugin.name}: ${plugin.description}`);
      });
    }
    const promptManager = PromptManager.getInstance();
    logger_default.info("Using bundled prompts as the primary source for templates");
    const localTemplatesDir = path40.resolve(
      process.cwd(),
      "prompts",
      "templates"
    );
    await promptManager.loadTemplates(localTemplatesDir);
    const templates = promptManager.listTemplates();
    if (templates.length > 0) {
      logger_default.info(`Loaded ${templates.length} custom prompt templates:`);
      templates.forEach((template) => {
        logger_default.info(
          `- ${template.name}: ${template.description} (${template.reviewType})`
        );
      });
    }
    if (args.testApi) {
      try {
        await runApiConnectionTests();
        if (args.target === ".") {
          return;
        }
      } catch (error2) {
        logger_default.error(
          t("errors.api_test_failed", {
            message: error2 instanceof Error ? error2.message : String(error2)
          })
        );
        logger_default.info("\n" + t("errors.common_solutions.title"));
        logger_default.info(t("errors.common_solutions.check_api_keys"));
        logger_default.info(t("errors.common_solutions.check_internet"));
        logger_default.info(t("errors.common_solutions.check_services"));
        logger_default.info(t("errors.common_solutions.check_rate_limits"));
        process.exit(1);
      }
    }
    const { Command: Command3 } = await import("commander");
    const program = new Command3();
    program.addCommand(testModelCommand);
    program.addCommand(testBuildCommand);
    if (modelTestArgs[0] === "model-test" || modelTestArgs[0] === "test-build") {
      program.parse(process.argv);
      return;
    }
    if (modelTestArgs[0] === "sync-github-projects") {
      await handleSyncGitHubProjectsCommand();
      return;
    }
    await reviewCode(args.target, args);
  } catch (error2) {
    logger_default.error(
      t("errors.review_failed", {
        message: error2 instanceof Error ? error2.message : String(error2)
      })
    );
    logger_default.info("\n" + t("errors.common_solutions.title"));
    logger_default.info(t("errors.common_solutions.check_directory"));
    logger_default.info(t("errors.common_solutions.check_target_path"));
    logger_default.info(t("errors.common_solutions.run_test_api"));
    process.exit(1);
  }
}
main().catch((error2) => {
  const errorMessage = error2 instanceof Error ? error2.message : String(error2);
  try {
    const translatedMessage = t("errors.unhandled", { message: errorMessage });
    if (translatedMessage && translatedMessage !== "undefined") {
      logger_default.error(translatedMessage);
    } else {
      logger_default.error(`Unhandled error: ${errorMessage}`);
    }
  } catch (translationError) {
    logger_default.error(`Unhandled error: ${errorMessage}`);
  }
  process.exit(1);
});
//# sourceMappingURL=index.js.map
